<!DOCTYPE html>
            <html>
            <head>
            <meta charset="utf-8">
                <meta name="viewport"
            content="width=device-width, height=device-height, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no">
                <meta http-equiv="x-ua-compatible" content="ie=edge">
                <title>Yahoo Tuning Groups Ultimate Backup tuning-math Cangwu Badness</title>
                <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
            </head>
            <body>
            </body>
            </html>
        <a href="/tuning-math">back to list</a><h1>Cangwu Badness</h1><h3><a id=17964 href="#17964">ðŸ”—</a>Graham Breed &#x3C;gbreed@gmail.com&#x3E;</h3><span>7/4/2010 11:36:16 PM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>This is about the badness function I came up with as a generalization<br/>of scalar badness.  I decided to call it &quot;Cangwu badness&quot; although<br/>I&apos;ve never needed to use the name.  If you want a cute name to compare<br/>it with other badnesses you can call it that.  It&apos;s also parametric<br/>scalar badness, and I see I&apos;ve called it scalar parametric badness,<br/>which looks like a bad word order, but never mind.</p><p>It&apos;s documented at <a href="http://x31eq.com/badness.pdf">http://x31eq.com/badness.pdf</a> and that&apos;s what I&apos;m<br/>using to check the details.  I&apos;ve just spotted an error in the<br/>formulas, which runs all the way through the file, so I&apos;ll attend to<br/>that sometime.  W^T should always be W^2 because W is its own<br/>transpose so it doesn&apos;t make sense otherwise.</p><p>I&apos;ll need to talk about transposes of matrices for this, so I&apos;ll use<br/>bra-ket notation.  A column vector is [X&gt; and a row vector is &lt;X].  A<br/>scalar product is &lt;X|Y&gt;.  A product involving a rectangular matrix is<br/>&lt;X|A|Y&gt;.  Sometimes rectangular matrices are also written as bras or<br/>kets and, whatever the standard, &lt;A] is always the transpose of [A&gt;.</p><p>Scalar complexity is ||&lt;M|W&gt;&lt;W|M&gt;/&lt;H|W&gt;&lt;W|H&gt;|| where [M&gt; is the<br/>mapping matrix with vals as columns, [H&gt; is the sizes of prime<br/>intervals as a column vector, and &lt;W] is a matrix containing the<br/>weights of primes, which means it will be diagonal, so &lt;W] = [W&gt;.<br/>||...|| is the square root of the determinant.</p><p>To save typing, I&apos;ll set a metric G to be the square of W, that is G =<br/>[W&gt;&lt;W].  If you&apos;re using weighted mappings, G, [W&gt; and &lt;W] are all the<br/>identity matrix anyway.  So the scalar complexity is now<br/>||&lt;M|G|M&gt;/&lt;H|G|H&gt;||.</p><p>The formula for scalar badness is:</p><p>||&lt;M|G|M&gt;/&lt;H|G|H&gt; - &lt;M|G|H&gt;&lt;H|G|M&gt;/&lt;H|G|H&gt;&lt;H|G|H&gt;||</p><p>The parametric badness is a mixture of scalar badness and scalar<br/>complexity with a parameter E_k squared that I&apos;ll call x.</p><p>B(x) = ||&lt;M|G|M&gt;/&lt;H|G|H&gt;(1 + x) - &lt;M|G|H&gt;&lt;H|G|M&gt;/&lt;H|G|H&gt;&lt;H|G|H&gt;||</p><p>When x=0, this is identical to scalar badness.  As x tends to<br/>infinity, the badness tends to (1+x) times scalar complexity.</p><p>It&apos;s also possible to write it as a function of operators.  If<br/>||&lt;M|K|M&gt;|| is scalar complexity and ||&lt;M|B|M&gt;|| is scalar badness,<br/>then ||&lt;M|K|M&gt;x + &lt;M|B|M&gt;|| is the parametric badness.  Note that K is<br/>not as simple as G/&lt;H|G|H&gt; but it is still a matrix.  When 0 &lt; x &lt; 1,<br/>the parametric badness is defined by a positive definite matrix,<br/>making it an inner product.</p><p>For equal temperaments, the determinant is redundant.  So the square<br/>of the parametric badness is the sum of the squares of the scalar<br/>badness and the scalar complexity multiplied by E_k (the square root<br/>of x).  This looks like a sum of squares of two error times complexity<br/>badnesses.  That&apos;s why E_k is written with an E.  It has dimensions of<br/>error.  It&apos;s roughly the worst error of temperaments you&apos;re interested<br/>in.</p><p>Because the scalar complexity of an equal temperament is almost<br/>exactly the number of notes to the octave, you can predict the most<br/>notes you need to look at for equal temperaments within a given<br/>badness cutoff.  That makes it possible to produce a guaranteed top 10<br/>list of equal temperaments, which is very useful.</p><p>As Cangwu badness is an inner product, it obeys the Cauchy-Schwartz<br/>inequality.  That means the badness of a rank 2 temperament is always<br/>less than the product of the badnesses of the equal temperaments that<br/>generate it.  This is extremely useful when you&apos;re generating<br/>temperament classes by pairing equal temperaments.  Any rank 2<br/>temperament will have, for any given parameter, an optimal pair of<br/>generating equal temperaments.  Geometrically, they&apos;re roughly<br/>orthogonal.  Their badnesses can&apos;t vary by much, because if they did<br/>there&apos;d be a better one between them.  So there&apos;s a high chance that<br/>the best rank 2 temperament is generated by the two best equal<br/>temperaments.</p><p>The hardest rank 2 temperaments to find happen to be the ones like<br/>Mystery or Compton that are an equal temperament with a different<br/>mapping for one or more primes.  For these, it&apos;s difficult to get a<br/>pair of orthogonal equal temperaments, so the poorer one can be quite<br/>high.  There are a lot of such temperaments in the higher prime<br/>searches.  If you&apos;re not interested in such things, the searches<br/>become a lot easier.</p><p>You can see how efficient the searches are with my web application<br/>(<a href="http://x31eq.com/temper/">http://x31eq.com/temper/</a>).  The higher rank results come from pairing<br/>rank 2 temperaments with equal temperaments, and each of those with<br/>the equal temperaments again, and so on.</p><p>                       Graham</p></div><h3><a id=17965 href="#17965">ðŸ”—</a>genewardsmith &#x3C;genewardsmith@sbcglobal.net&#x3E;</h3><span>7/5/2010 5:07:05 AM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Graham Breed &lt;gbreed@...&gt; wrote:<br/>&gt;<br/>&gt; This is about the badness function I came up with as a generalization<br/>&gt; of scalar badness.  I decided to call it &quot;Cangwu badness&quot; although<br/>&gt; I&apos;ve never needed to use the name.  If you want a cute name to compare<br/>&gt; it with other badnesses you can call it that.</p><p>I&apos;m all for cute names, and this looks interesting. But would you PLEASE stop using the appalling phrases &quot;scalar badness&quot; and &quot;scalar complexity&quot; when these are always given as real numbers, and hence there are no vector-valued, matrix-valued, multivector-valued, tensor-valued, division ring valued or anything else of that sort valued badnesses to distinguish it from. ANY badness measure is &quot;scalar badness&quot; and hence the characterization means nothing and is inherently confusing. And a number should be called a number, not a &quot;scalar&quot;, unless in a context where you need to distinguish it from vectors, etc. Would you call something &quot;number badness&quot; or &quot;real number badness&quot;? Didn&apos;t think so.</p><p>I&apos;ll need to wait to make substantive comments, and I hope this does not annoy you too greatly, but it really would help if you would pay more attention to things which serve to confuse people.</p><p>And FYI, I have no idea what you even mean by &quot;scalar badness&quot;. Do you mean one of the badness measures defined from wedge products?</p></div><h3><a id=17966 href="#17966">ðŸ”—</a>genewardsmith &#x3C;genewardsmith@sbcglobal.net&#x3E;</h3><span>7/5/2010 5:29:39 AM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Graham Breed &lt;gbreed@...&gt; wrote:</p><p>&gt; Scalar complexity is ||&lt;M|W&gt;&lt;W|M&gt;/&lt;H|W&gt;&lt;W|H&gt;|| where [M&gt; is the<br/>&gt; mapping matrix with vals as columns, [H&gt; is the sizes of prime<br/>&gt; intervals as a column vector, and &lt;W] is a matrix containing the<br/>&gt; weights of primes, which means it will be diagonal, so &lt;W] = [W&gt;.<br/>&gt; ||...|| is the square root of the determinant.</p><p>What determinant? You&apos;ve got a ratio of two numbers inside ||...||, don&apos;t you? Weighted dot products.</p><p>&gt; The formula for scalar badness is:<br/>&gt;<br/>&gt; ||&lt;M|G|M&gt;/&lt;H|G|H&gt; - &lt;M|G|H&gt;&lt;H|G|M&gt;/&lt;H|G|H&gt;&lt;H|G|H&gt;||</p><p>Assuming G is the identity, this becomes</p><p>||M.M/H.H - (M.H/H.H)^2||</p><p>Where does this formula come from, and what does &quot;[H&gt; is the sizes of prime intervals as a column vector&quot; mean?</p></div><h3><a id=17970 href="#17970">ðŸ”—</a>Graham Breed &#x3C;gbreed@gmail.com&#x3E;</h3><span>7/5/2010 10:35:55 AM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On 5 July 2010 15:29, genewardsmith &lt;<a href="mailto:genewardsmith@sbcglobal.net">genewardsmith@sbcglobal.net</a>&gt; wrote:<br/>&gt;<br/>&gt;<br/>&gt; --- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Graham Breed &lt;gbreed@...&gt; wrote:<br/>&gt;<br/>&gt;&gt; Scalar complexity is ||&lt;M|W&gt;&lt;W|M&gt;/&lt;H|W&gt;&lt;W|H&gt;|| where [M&gt; is the<br/>&gt;&gt; mapping matrix with vals as columns, [H&gt; is the sizes of prime<br/>&gt;&gt; intervals as a column vector, and &lt;W] is a matrix containing the<br/>&gt;&gt; weights of primes, which means it will be diagonal, so &lt;W] = [W&gt;.<br/>&gt;&gt; ||...|| is the square root of the determinant.<br/>&gt;<br/>&gt; What determinant? You&apos;ve got a ratio of two numbers inside ||...||, don&apos;t you? Weighted dot products.</p><p>You know what a determinant is, don&apos;t you?  No, it isn&apos;t a ratio of two numbers.</p><p>&gt;&gt; The formula for scalar badness is:<br/>&gt;&gt;<br/>&gt;&gt; ||&lt;M|G|M&gt;/&lt;H|G|H&gt; - &lt;M|G|H&gt;&lt;H|G|M&gt;/&lt;H|G|H&gt;&lt;H|G|H&gt;||<br/>&gt;<br/>&gt; Assuming G is the identity, this becomes<br/>&gt;<br/>&gt; ||M.M/H.H - (M.H/H.H)^2||</p><p>Maybe, but when you write it like that it looks like a vector formula.</p><p>&gt; Where does this formula come from, and what does &quot;[H&gt; is the sizes of prime intervals as a column vector&quot; mean?</p><p>It comes from primerr.pdf.  Or it&apos;s the same scalar badness we had<br/>last time around.  It&apos;s an orthogonal projection.</p><p>                      Graham</p></div><h3><a id=17971 href="#17971">ðŸ”—</a>genewardsmith &#x3C;genewardsmith@sbcglobal.net&#x3E;</h3><span>7/5/2010 12:53:42 PM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>I won&apos;t be able to follow this very well if I keep being distracted by the word &quot;scalar&quot;, so below I replace it with &quot;breed&quot;.</p><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Graham Breed &lt;gbreed@...&gt; wrote:</p><p>&gt; breed complexity is ||&lt;M|W&gt;&lt;W|M&gt;/&lt;H|W&gt;&lt;W|H&gt;|| where [M&gt; is the<br/>&gt; mapping matrix with vals as columns, [H&gt; is the sizes of prime<br/>&gt; intervals as a column vector, and &lt;W] is a matrix containing the<br/>&gt; weights of primes, which means it will be diagonal, so &lt;W] = [W&gt;.<br/>&gt; ||...|| is the square root of the determinant.</p><p>OK, I see that M is a matrix, not a vector, so getting rid of the W by assuming it is the identity, we get</p><p>sqrt(det(Matrix(vi.vj))) / ||H||</p><p>as the breed complexity. Here Matrix(<a href="http://vi.vi">vi.vi</a>) is the matrix whose i,j-th component is the dot product of the (weighted) ith val dot jth val, and [H&gt; is &quot;the sizes of prime intervals as a column vector&quot;. Graham refuses to say what that means, and I can&apos;t do a very good job of translating this unless I know. Is anyone else following this? Is there an obvious point I am missing? If we assume that H is the JIP, then ||H|| becomes sqrt(n), where n is the number of primes, and the complexity becomes</p><p>sqrt(det(Matrix(vi.vj))/n)</p><p>This would make sense in terms of the wedgie-defined complexity sqrt(wedgie.wedgie/n).</p><p>&gt; The formula for breed badness is:<br/>&gt;<br/>&gt; ||&lt;M|G|M&gt;/&lt;H|G|H&gt; - &lt;M|G|H&gt;&lt;H|G|M&gt;/&lt;H|G|H&gt;&lt;H|G|H&gt;||</p><p>Or in other words</p><p>sqrt(det(Matrix(vi.vj) - (JIP.M)^2)/n)</p><p>This formula doesn&apos;t appear to make sense, as I am subtracting a scalar (note how the word is correctly used) from a matrix. So if anyone else is following this, please chime in.</p></div><h3><a id=17972 href="#17972">ðŸ”—</a>Graham Breed &#x3C;gbreed@gmail.com&#x3E;</h3><span>7/5/2010 9:52:12 PM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On 5 July 2010 16:07, genewardsmith &lt;<a href="mailto:genewardsmith@sbcglobal.net">genewardsmith@sbcglobal.net</a>&gt; wrote:</p><p>&gt; I&apos;m all for cute names, and this looks interesting. But would you<br/>&gt; PLEASE stop using the appalling phrases &quot;scalar badness&quot; and<br/>&gt; &quot;scalar complexity&quot; when these are always given as real numbers,</p><p>No, please stop arguing about terminology every time I say something.<br/>I&apos;ve been calling it scalar complexity for the past three years.  You<br/>were on the list when I announced it.  That was the proper time to<br/>object to the term.</p><p>&gt; And FYI, I have no idea what you even mean by &quot;scalar badness&quot;. Do you mean one of the badness measures defined from wedge products?</p><p>I did define it in that message.  It&apos;s the badness defined from scalar<br/>products of wedge products.</p><p>                               Graham</p></div><h3><a id=17973 href="#17973">ðŸ”—</a>Graham Breed &#x3C;gbreed@gmail.com&#x3E;</h3><span>7/5/2010 10:06:37 PM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On 5 July 2010 23:53, genewardsmith &lt;<a href="mailto:genewardsmith@sbcglobal.net">genewardsmith@sbcglobal.net</a>&gt; wrote:</p><p>&gt;&gt; breed complexity is ||&lt;M|W&gt;&lt;W|M&gt;/&lt;H|W&gt;&lt;W|H&gt;|| where [M&gt; is the<br/>&gt;&gt; mapping matrix with vals as columns, [H&gt; is the sizes of prime<br/>&gt;&gt; intervals as a column vector, and &lt;W] is a matrix containing the<br/>&gt;&gt; weights of primes, which means it will be diagonal, so &lt;W] = [W&gt;.<br/>&gt;&gt; ||...|| is the square root of the determinant.<br/>&gt;<br/>&gt; OK, I see that M is a matrix, not a vector, so getting rid of the W by assuming it is the identity, we get<br/>&gt;<br/>&gt; sqrt(det(Matrix(vi.vj))) / ||H||</p><p>I don&apos;t think it&apos;s safe to take the ||H|| outside the determinant.</p><p>&gt; as the breed complexity. Here Matrix(<a href="http://vi.vi">vi.vi</a>) is the matrix whose i,j-th<br/>&gt; component is the dot product of the (weighted) ith val dot jth val, and [H&gt; is<br/>&gt; &quot;the sizes of prime intervals as a column vector&quot;. Graham refuses to<br/>&gt; say what that means, and I can&apos;t do a very good job of translating this<br/>&gt; unless I know. Is anyone else following this? Is there an obvious point I am<br/>&gt; missing? If we assume that H is the JIP, then ||H|| becomes sqrt(n), where n<br/>&gt; is the number of primes, and the complexity becomes</p><p>I didn&apos;t refuse to define it.  I missed that question when I went<br/>online last night.  Yes, H is like the JIP, but not weighted (unless<br/>you make it so by setting W=I) and not a point.</p><p>&gt; sqrt(det(Matrix(vi.vj))/n)<br/>&gt;<br/>&gt; This would make sense in terms of the wedgie-defined complexity<br/>&gt; sqrt(wedgie.wedgie/n).</p><p>It&apos;s one wedgie-defined complexity.  The scalar product of the wedgie<br/>with itself.</p><p>&gt;&gt; The formula for breed badness is:<br/>&gt;&gt;<br/>&gt;&gt; ||&lt;M|G|M&gt;/&lt;H|G|H&gt; - &lt;M|G|H&gt;&lt;H|G|M&gt;/&lt;H|G|H&gt;&lt;H|G|H&gt;||<br/>&gt;<br/>&gt; Or in other words<br/>&gt;<br/>&gt; sqrt(det(Matrix(vi.vj) - (JIP.M)^2)/n)<br/>&gt;<br/>&gt; This formula doesn&apos;t appear to make sense, as I am subtracting a scalar<br/>&gt; (note how the word is correctly used) from a matrix. So if anyone else is<br/>&gt; following this, please chime in.</p><p>No, you&apos;re using the word &quot;scalar&quot; incorrectly.  Or, at least, you may<br/>genuinely think &lt;M|H&gt;&lt;H|M&gt; gives a scalar but you&apos;re wrong.  Try<br/>thinking about which way round [H&gt; and &lt;H] are instead of jumping to a<br/>dot product that appears to be commutative but isn&apos;t.</p><p>[H&gt; is a column vector and &lt;H] is a row vector.  The product &lt;H|H&gt;<br/>gives a scalar, even if you stick a square weighting matrix in the<br/>middle.  The product [H&gt;&lt;H] is a column multiplied by a row, so it&apos;s a<br/>square matrix, the same size as the weighting.  Hence &lt;M|H&gt;&lt;H|M&gt; is<br/>the same size as &lt;M|M&gt; and the two matrices can be subtracted.</p><p>&lt;M|H&gt;&lt;H|M&gt;/&lt;H|H&gt; is something to do with orthogonal projections.  I<br/>forget exactly what right now.  It isn&apos;t surprising that a formula<br/>with orthogonal projections gives the same result as one with wedge<br/>products.</p><p>                          Graham</p></div><h3><a id=17974 href="#17974">ðŸ”—</a>genewardsmith &#x3C;genewardsmith@sbcglobal.net&#x3E;</h3><span>7/6/2010 12:17:35 AM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Graham Breed &lt;gbreed@...&gt; wrote:<br/>&gt;<br/>&gt; On 5 July 2010 16:07, genewardsmith &lt;genewardsmith@...&gt; wrote:<br/>&gt;<br/>&gt; &gt; I&apos;m all for cute names, and this looks interesting. But would you<br/>&gt; &gt; PLEASE stop using the appalling phrases &quot;scalar badness&quot; and<br/>&gt; &gt; &quot;scalar complexity&quot; when these are always given as real numbers,<br/>&gt;<br/>&gt; No, please stop arguing about terminology every time I say something.<br/>&gt; I&apos;ve been calling it scalar complexity for the past three years.  You<br/>&gt; were on the list when I announced it.  That was the proper time to<br/>&gt; object to the term.</p><p>I didn&apos;t know what it was. For all I knew, there was some reason for you use of the term. I have since learned that the only reason is your limpet-like insistence on clinging to a solecism. If you are too pig-headed to admit you&apos;ve made a mistake in your mathematical diction and change it, I reserve the right to point out your error when and if it suits me, because wrong is wrong. Or you could come up with a reason why &quot;scalar complexity&quot; makes sense when &quot;number complexity clearly would not. Do that, and amaze us all.</p><p>&gt; I did define it in that message.  It&apos;s the badness defined from scalar<br/>&gt; products of wedge products.</p><p>I can&apos;t see how scalar products could be so used in any very meaningful sense. You can rescale a wedge product by means of a scalar product, but that hardly amounts to using it to define a numerical quantity; you can always avoid doing that and achieve the same end, since in the end you are going to produce a number, and multiplication is commutative.</p><p>What is this scalar product which you claim justifies the use of the term?</p><p>Graham, I am trying to understand you. So far as I can tell, no one else is. Does that matter to you at all?</p></div><h3><a id=17975 href="#17975">ðŸ”—</a>genewardsmith &#x3C;genewardsmith@sbcglobal.net&#x3E;</h3><span>7/6/2010 12:56:55 AM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Graham Breed &lt;gbreed@...&gt; wrote:</p><p>&gt; It&apos;s one wedgie-defined complexity.  The scalar product of the wedgie<br/>&gt; with itself.</p><p>The light dawns! This is a usage of &quot;scalar product&quot; common among physicists which mathematicans generally avoid. The reason they avoid it is that it&apos;s bad terminology, since scalar multiplication is also sometimes called the &quot;scalar product&quot;, and I thought that&apos;s what you meant. Mathematicians do not usually think of vectors as arrows, regard them as constructed over arbitrary fields, think inner products can live in any ordered field and Hermitian inner products over any complexification of one, and in general don&apos;t inhabit the same world as physicists and engineers, and I&apos;m sorry if this caused confusion. Mathematicians call what you and many others call a &quot;scalar product&quot; an inner product, or a dot product if it&apos;s the standard orthonormal basis version, or in some contexts a positive-definite symmetric bilinear form.</p></div><h3><a id=17976 href="#17976">ðŸ”—</a>genewardsmith &#x3C;genewardsmith@sbcglobal.net&#x3E;</h3><span>7/6/2010 1:08:25 AM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Graham Breed &lt;gbreed@...&gt; wrote:</p><p>&gt; &gt; sqrt(det(Matrix(vi.vj))) / ||H||<br/>&gt;<br/>&gt; I don&apos;t think it&apos;s safe to take the ||H|| outside the determinant.</p><p>Good point. I&apos;m not sure what it&apos;s doing there, however.</p><p>&gt; I didn&apos;t refuse to define it.  I missed that question when I went<br/>&gt; online last night.  Yes, H is like the JIP, but not weighted (unless<br/>&gt; you make it so by setting W=I) and not a point.</p><p>Sorry, I don&apos;t know what this means. Do you mean it isn&apos;t living inside any kind of space you are considering, but is somehow a vector anyway? Maybe you could give an example.</p></div><h3><a id=17977 href="#17977">ðŸ”—</a>Graham Breed &#x3C;gbreed@gmail.com&#x3E;</h3><span>7/6/2010 2:33:12 AM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On 6 July 2010 12:08, genewardsmith &lt;<a href="mailto:genewardsmith@sbcglobal.net">genewardsmith@sbcglobal.net</a>&gt; wrote:<br/>&gt;<br/>&gt; --- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Graham Breed &lt;gbreed@...&gt; wrote:<br/>&gt;<br/>&gt;&gt; I didn&apos;t refuse to define it. &nbsp;I missed that question when I went<br/>&gt;&gt; online last night. &nbsp;Yes, H is like the JIP, but not weighted (unless<br/>&gt;&gt; you make it so by setting W=I) and not a point.<br/>&gt;<br/>&gt; Sorry, I don&apos;t know what this means. Do you mean it isn&apos;t living inside<br/>&gt; any kind of space you are considering, but is somehow a vector<br/>&gt; anyway? Maybe you could give an example.</p><p>It lives in the vector space, so it&apos;s a vector.  Maybe it&apos;s my physics<br/>training coming back again, but I remember vectors not being points.<br/>It is pretty much what you call the JIP.  I don&apos;t think any music<br/>theoretic planes will crash if you keep calling it the JIP.</p><p>                          Graham</p></div><h3><a id=17978 href="#17978">ðŸ”—</a>Graham Breed &#x3C;gbreed@gmail.com&#x3E;</h3><span>7/6/2010 3:43:14 AM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On 6 July 2010 11:56, genewardsmith &lt;<a href="mailto:genewardsmith@sbcglobal.net">genewardsmith@sbcglobal.net</a>&gt; wrote:<br/>&gt;<br/>&gt;<br/>&gt; --- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Graham Breed &lt;gbreed@...&gt; wrote:<br/>&gt;<br/>&gt;&gt; It&apos;s one wedgie-defined complexity. &nbsp;The scalar product of the wedgie<br/>&gt;&gt; with itself.<br/>&gt;<br/>&gt; The light dawns! This is a usage of &quot;scalar product&quot; common among<br/>&gt; physicists which mathematicans generally avoid. The reason they avoid<br/>&gt; it is that it&apos;s bad terminology, since scalar multiplication is also sometimes<br/>&gt; called the &quot;scalar product&quot;, and I thought that&apos;s what you meant.<br/>&gt; Mathematicians do not usually think of vectors as arrows, regard them as<br/>&gt; constructed over arbitrary fields, think inner products can live in any<br/>&gt; ordered field and Hermitian inner products over any complexification of one,<br/>&gt; and in general don&apos;t inhabit the same world as physicists and engineers,<br/>&gt; and I&apos;m sorry if this caused confusion. Mathematicians call what you and<br/>&gt; many others call a &quot;scalar product&quot; an inner product, or a dot product if<br/>&gt; it&apos;s the standard orthonormal basis version, or in some contexts a<br/>&gt; positive-definite symmetric bilinear form.</p><p>I got it from Browne, and it looks like I got it wrong.  Checking now<br/>I see he reserves &quot;scalar product&quot; for grade 1.  But the Wikipedia<br/>article on geometric algebra says that inner and scalar products are<br/>the same.</p><p>                          Graham</p></div><h3><a id=17980 href="#17980">ðŸ”—</a>genewardsmith &#x3C;genewardsmith@sbcglobal.net&#x3E;</h3><span>7/6/2010 7:50:04 AM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Graham Breed &lt;gbreed@...&gt; wrote:</p><p>&gt; &gt; Sorry, I don&apos;t know what this means. Do you mean it isn&apos;t living inside<br/>&gt; &gt; any kind of space you are considering, but is somehow a vector<br/>&gt; &gt; anyway? Maybe you could give an example.<br/>&gt;<br/>&gt; It lives in the vector space, so it&apos;s a vector.  Maybe it&apos;s my physics<br/>&gt; training coming back again, but I remember vectors not being points.</p><p>Mathematicians think vectors are elements of an algebraic structure called a &quot;vector space&quot;, and since it&apos;s a sort of space, the elements of it are sort of points. Since adding an inner product gives the standard model for the axioms of Euclidean geometry, and not adding it the standard model for affine space, that seems well justified.</p><p>&gt; It is pretty much what you call the JIP.  I don&apos;t think any music<br/>&gt; theoretic planes will crash if you keep calling it the JIP.</p><p>Could be, but what else should it be called?</p></div><h3><a id=17981 href="#17981">ðŸ”—</a>genewardsmith &#x3C;genewardsmith@sbcglobal.net&#x3E;</h3><span>7/6/2010 7:58:45 AM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Graham Breed &lt;gbreed@...&gt; wrote:</p><p>&gt; I see he reserves &quot;scalar product&quot; for grade 1.  But the Wikipedia<br/>&gt; article on geometric algebra says that inner and scalar products are<br/>&gt; the same.</p><p>Pure math people are not in love with geometric algebra either, by the way. Clifford algebras are much in use in certain areas. Originally and I think still most commonly &quot;scalar product&quot; is confined to being the dot product in three dimensions. I hope Wikipedia isn&apos;t spreading the usage of the term, which really should be depreciated. I&apos;ll check Wikipedia out--I would have thought they would claim the dot product and scalar product were the same, not inner product and scalar product.</p></div><h3><a id=17982 href="#17982">ðŸ”—</a>Mike Battaglia &#x3C;battaglia01@gmail.com&#x3E;</h3><span>7/6/2010 2:05:52 PM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On Tue, Jul 6, 2010 at 3:17 AM, genewardsmith<br/>&lt;<a href="mailto:genewardsmith@sbcglobal.net">genewardsmith@sbcglobal.net</a>&gt; wrote:<br/>&gt;<br/>&gt; Graham, I am trying to understand you. So far as I can tell, no one else is. Does that matter to you at all?</p><p>For the record, I generally try to understand everything that both of<br/>you say on this list. The problem is that the scalar product of my<br/>music theory knowledge and my knowledge of abstract math is too low,<br/>for the moment.</p><p>-Mike</p></div><h3><a id=17983 href="#17983">ðŸ”—</a>Graham Breed &#x3C;gbreed@gmail.com&#x3E;</h3><span>7/6/2010 9:32:25 PM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On 6 July 2010 18:50, genewardsmith &lt;<a href="mailto:genewardsmith@sbcglobal.net">genewardsmith@sbcglobal.net</a>&gt; wrote:<br/>&gt;<br/>&gt; --- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Graham Breed &lt;gbreed@...&gt; wrote:</p><p>&gt;&gt; It is pretty much what you call the JIP. &nbsp;I don&apos;t think any music<br/>&gt;&gt; theoretic planes will crash if you keep calling it the JIP.<br/>&gt;<br/>&gt; Could be, but what else should it be called?</p><p>I don&apos;t care what you call it.  I call it H.</p><p>How are you getting on with the parametric badness formula?</p><p>                     Graham</p></div><h3><a id=17984 href="#17984">ðŸ”—</a>genewardsmith &#x3C;genewardsmith@sbcglobal.net&#x3E;</h3><span>7/7/2010 5:27:12 AM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Graham Breed &lt;gbreed@...&gt; wrote:</p><p>&gt; How are you getting on with the parametric badness formula?</p><p>I can compute things, and maybe will need to move to that stage. I don&apos;t see the reasoning behind these formulas, and I have been looking at what my old stuff about Frobenius norms and projection maps in the hope of enlightenment and to give myself a break from Cangwu. It makes more sense when weighted, defines an inner product, and is clearly highly relevant but I can&apos;t see if it&apos;s relevant to this business.</p><p>Here&apos;s the old article:</p><p><a href="/tuning-math/message/12836">/tuning-math/message/12836</a></p><p>To bring it up to date, so to speak, just weight all vals and monzos, and the Frobenius tuning is now exactly the same as TOP-rms. The Frobenius projection map is easily computed from the definition in the unweighted case, but it&apos;s not a good idea to try in the weighted case. But an alternative definition in terms of the pseudoinverse works. So here is a positive-semidefinite (eigenvalues either 0 or 1) matrix defining an inner product on intervals and mappings belonging to a regular temperament, and giving a projection to it. Does this plug in to what you are doing?</p></div><h3><a id=17986 href="#17986">ðŸ”—</a>genewardsmith &#x3C;genewardsmith@sbcglobal.net&#x3E;</h3><span>7/7/2010 10:45:30 PM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Graham Breed &lt;gbreed@...&gt; wrote:</p><p>The parametric badness is a mixture of scalar badness and scalar<br/>complexity with a parameter E_k squared that I&apos;ll call x.</p><p>B(x) = ||&lt;M|G|M&gt;/&lt;H|G|H&gt;(1 + x) - &lt;M|G|H&gt;&lt;H|G|M&gt;/&lt;H|G|H&gt;&lt;H|G|H&gt;||</p><p>When x=0, this is identical to scalar badness. As x tends to<br/>infinity, the badness tends to (1+x) times scalar complexity.</p><p>What&apos;s the payoff here? You can take simple badness, which I think is<br/>the same as your so-called &quot;scalar badness&quot; and which is a term I<br/>thought you had agreed you could use, and multiply it by some power of<br/>complexity, producing a one-parameter family of badness measures. Why<br/>don&apos;t we keep doing that?</p></div><h3><a id=17987 href="#17987">ðŸ”—</a>Graham Breed &#x3C;gbreed@gmail.com&#x3E;</h3><span>7/8/2010 8:28:39 AM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On 08/07/2010, genewardsmith &lt;<a href="mailto:genewardsmith@sbcglobal.net">genewardsmith@sbcglobal.net</a>&gt; wrote:</p><p>&gt; What&apos;s the payoff here? You can take simple badness, which I think<br/>&gt; is the same as your so-called &quot;scalar badness&quot; and which is a term<br/>&gt; I thought you had agreed you could use, and multiply it by some<br/>&gt; power of complexity, producing a one-parameter family of<br/>&gt; badness measures. Why don&apos;t we keep doing that?</p><p>Because it isn&apos;t a positive definite quadratic form.  If it obeys the<br/>Cauchy-Schwartz inequality, I can&apos;t prove it.  If a badness cutoff<br/>corresponds to a complexity cutoff for equal temperaments, I don&apos;t<br/>know how to find it.</p><p>I used things like this before.  I always needed a complexity cutoff<br/>as well as the parameter you mentioned.  If there&apos;s a way around that<br/>I don&apos;t know it.</p><p>                             Graham</p></div>
                <script>
                    let monospace = false
                    $('button').on('click', function () {
                      if (monospace) {
                        $('p').css("font-family", "")
                      } else {
                        $('p').css("font-family", "monospace")
                      }
                      monospace = !monospace
                    })
                </script>
            