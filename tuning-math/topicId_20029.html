<!DOCTYPE html>
            <html>
            <head>
            <meta charset="utf-8">
                <meta name="viewport"
            content="width=device-width, height=device-height, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no">
                <meta http-equiv="x-ua-compatible" content="ie=edge">
                <title>Yahoo Tuning Groups Ultimate Backup tuning-math A new single-processing transform suited for speech-recognition</title>
                <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
            </head>
            <body>
            </body>
            </html>
        <a href="/tuning-math">back to list</a><h1>A new single-processing transform suited for speech-recognition</h1><h3><a id=20029 href="#20029">ðŸ”—</a>WarrenS &#x3C;warren.wds@gmail.com&#x3E;</h3><span>11/15/2011 1:55:28 PM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>1st draft of a new paper by me:<br/>   <a href="http://dl.dropbox.com/u/3507527/SpeechProc.html">http://dl.dropbox.com/u/3507527/SpeechProc.html</a></p><p>New transform in some sense unifies Fourier &amp; Laplace transforms.<br/>Also has &quot;fast&quot; versions ala FFT.<br/>Also corresponds to simple model of what your Cochlea does.</p><p>Comments will be appreciated.  The paper may still be a little flaky.<br/>It seems important I think.</p></div><h3><a id=20030 href="#20030">ðŸ”—</a>WarrenS &#x3C;warren.wds@gmail.com&#x3E;</h3><span>11/15/2011 1:55:53 PM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>1st draft of a new paper by me:<br/>   <a href="http://dl.dropbox.com/u/3507527/SpeechProc.html">http://dl.dropbox.com/u/3507527/SpeechProc.html</a></p><p>New transform in some sense unifies Fourier &amp; Laplace transforms.<br/>Also has &quot;fast&quot; versions ala FFT.<br/>Also corresponds to simple model of what your Cochlea does.</p><p>Comments will be appreciated.  The paper may still be a little flaky.<br/>It seems important I think.</p></div><h3><a id=20031 href="#20031">ðŸ”—</a>Mike Battaglia &#x3C;battaglia01@gmail.com&#x3E;</h3><span>11/15/2011 2:09:45 PM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>This is brief because I don&apos;t have the time to explore this in full.<br/>I&apos;ve been independently exploring something similar for a while now,<br/>although I haven&apos;t cobbled together anything formal yet, under two<br/>different guises:</p><p>1) Using this to model cochlear interaction, as you said, for the<br/>purposes of working with isoharmonicity buzz and Sethares-inspired<br/>dissonance measures<br/>2) Using this to model complex pitch perception, for the purposes of<br/>working with harmonic entropy and Erlich and Terhardt-inspired<br/>dissonance measures</p><p>The same basic concept applies in both cases, but it gets more<br/>complicated with #2.</p><p>Some thought about what you wrote:<br/>Y(L) = ln | fudge(L) &int;t&lt;0 exp(0.0007 t e^L) exp(i e^L t) x(t) dt |</p><p>What is e^L? Is e^L the same thing as exp(L)?</p><p>Is this basically just the Laplace transform, but taken at a different<br/>vertical line than the imaginary axis to introduce frequency<br/>spreading, hence modeling cochlear effects? If so, and if you&apos;re<br/>attempting to use this like a window for a one-sided Fourier<br/>transform, why not just use something like a gammachirp window<br/>instead, which was actually created to model the behavior of the<br/>cochlea? See here:</p><p><a href="http://people.csail.mit.edu/malex/research_files/park_wave.pdf">http://people.csail.mit.edu/malex/research_files/park_wave.pdf</a></p><p>You don&apos;t have to use wavelets, but you can use that window to replace<br/>your Laplace-inspired e^(at) window.</p><p>Also, I don&apos;t think this statement is true:</p><p>&quot;Also, again, wavelet transforms involve some arbitrary discontinuous<br/>chopping of the time axis. The cochlear transform does not &ndash; it is<br/>invariant under time translation.&quot;</p><p>I think that&apos;s only true for the discrete wavelet transform, not the<br/>continuous one. Also, there are plenty of ways to make the DWT<br/>shift-invariant, including but not limited to this:<br/><a href="http://en.wikipedia.org/wiki/Stationary_wavelet_transform">http://en.wikipedia.org/wiki/Stationary_wavelet_transform</a></p><p>-Mike</p><p>On Tue, Nov 15, 2011 at 4:55 PM, WarrenS &lt;<a href="mailto:warren.wds@gmail.com">warren.wds@gmail.com</a>&gt; wrote:<br/>&gt;<br/>&gt; 1st draft of a new paper by me:<br/>&gt; <a href="http://dl.dropbox.com/u/3507527/SpeechProc.html">http://dl.dropbox.com/u/3507527/SpeechProc.html</a><br/>&gt;<br/>&gt; New transform in some sense unifies Fourier &amp; Laplace transforms.<br/>&gt; Also has &quot;fast&quot; versions ala FFT.<br/>&gt; Also corresponds to simple model of what your Cochlea does.<br/>&gt;<br/>&gt; Comments will be appreciated. The paper may still be a little flaky.<br/>&gt; It seems important I think.</p></div><h3><a id=20032 href="#20032">ðŸ”—</a>Keenan Pepper &#x3C;keenanpepper@gmail.com&#x3E;</h3><span>11/15/2011 3:19:59 PM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Mike Battaglia &lt;battaglia01@...&gt; wrote:<br/>&gt; Some thought about what you wrote:<br/>&gt; Y(L) = ln | fudge(L) &acirc;Âˆ&laquo;t&lt;0 exp(0.0007 t e^L) exp(i e^L t) x(t) dt |<br/>&gt;<br/>&gt; What is e^L? Is e^L the same thing as exp(L)?</p><p>I&apos;m sure it is. It says at the top that exp(x) is the same as e^x. And if L is log frequency then e^L is frequency.</p><p>&gt; Is this basically just the Laplace transform, but taken at a different<br/>&gt; vertical line than the imaginary axis to introduce frequency<br/>&gt; spreading, hence modeling cochlear effects? If so, and if you&apos;re<br/>&gt; attempting to use this like a window for a one-sided Fourier<br/>&gt; transform, why not just use something like a gammachirp window<br/>&gt; instead, which was actually created to model the behavior of the<br/>&gt; cochlea? See here:</p><p>This is exactly my question on first looking at this paper - how is this any different in concept from a gammatone or gammachirp filter bank?</p><p>It might be because this transform is supposed to be intertible, but it doesn&apos;t seem to be.</p><p>Keenan</p></div><h3><a id=20033 href="#20033">ðŸ”—</a>Herman Miller &#x3C;hmiller@prismnet.com&#x3E;</h3><span>11/15/2011 5:22:16 PM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On 11/15/2011 4:55 PM, WarrenS wrote:<br/>&gt; 1st draft of a new paper by me:<br/>&gt;     <a href="http://dl.dropbox.com/u/3507527/SpeechProc.html">http://dl.dropbox.com/u/3507527/SpeechProc.html</a><br/>&gt;<br/>&gt; New transform in some sense unifies Fourier&amp;  Laplace transforms.<br/>&gt; Also has &quot;fast&quot; versions ala FFT.<br/>&gt; Also corresponds to simple model of what your Cochlea does.<br/>&gt;<br/>&gt; Comments will be appreciated.  The paper may still be a little flaky.<br/>&gt; It seems important I think.</p><p>It&apos;s not really my area of expertise, but from what I understand it isn&apos;t the linear nature of LPC that&apos;s an issue for speech recognition. The problem is that LPC has trouble with anti-resonances such as those in nasal consonants or nasalized vowels. (See Peter Ladefoged&apos;s _Elements of Acoustic Phonetics_ for an overview of LPC analysis for speech sounds, although it&apos;s written for readers with more of a background in linguistics than math, so you can probably find a better reference that goes more into the mathematical details.)</p><p>For tuning-math relevance, I&apos;m interested in whether you might be able to use this transform to analyze the musical tuning of a recording, and whether it might be better than other approaches for this purpose. Having a logarithmic frequency response instead of linear like the Fourier transform seems like a useful property. Have you done any experiments along those lines?</p></div><h3><a id=20034 href="#20034">ðŸ”—</a>WarrenS &#x3C;warren.wds@gmail.com&#x3E;</h3><span>11/16/2011 11:00:40 AM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>&gt; What is e^L? Is e^L the same thing as exp(L)?</p><p>--yes.</p><p>&gt; Is this basically just the Laplace transform,</p><p>--yes except that s is complex not real.</p><p>&gt;  If so, and if you&apos;re<br/>&gt; attempting to use this like a window for a one-sided Fourier<br/>&gt; transform, why not just use something like a gammachirp window<br/>&gt; instead, which was actually created to model the behavior of the<br/>&gt; cochlea? See here:<br/>&gt;<br/>&gt; <a href="http://people.csail.mit.edu/malex/research_files/park_wave.pdf">http://people.csail.mit.edu/malex/research_files/park_wave.pdf</a></p><p>--my preliminary impression is I&apos;ve been scooped.<br/>That is, their &quot;gammachirp filterbank&quot; thing is essentially the same thing<br/>as my &quot;cochlear transform.&quot;  (Actually I invented this like 20 years ago, but<br/>basically never told anybody... some in some sense maybe I scooped the scoop...)</p><p>However, I have fast algorithms and this park_wave<br/>paper apparently does not, although maybe some other scooper does.</p><p>&gt; You don&apos;t have to use wavelets, but you can use that window to replace<br/>&gt; your Laplace-inspired e^(at) window.</p><p>--don&apos;t know what you are saying there.</p><p>&gt; Also, I don&apos;t think this statement is true:<br/>&gt;<br/>&gt; &quot;Also, again, wavelet transforms involve some arbitrary discontinuous<br/>&gt; chopping of the time axis. The cochlear transform does not -- it is<br/>&gt; invariant under time translation.&quot;<br/>&gt;<br/>&gt; I think that&apos;s only true for the discrete wavelet transform, not the<br/>&gt; continuous one.</p><p>--oh.  But maybe in practice you have to use DWT?</p><p>&gt; Also, there are plenty of ways to make the DWT<br/>&gt; shift-invariant, including but not limited to this:<br/>&gt; <a href="http://en.wikipedia.org/wiki/Stationary_wavelet_transform">http://en.wikipedia.org/wiki/Stationary_wavelet_transform</a></p><p>--oh.   Well, the wikipedia article does not explain it worth a damn, but that does look interesting.</p></div><h3><a id=20035 href="#20035">ðŸ”—</a>WarrenS &#x3C;warren.wds@gmail.com&#x3E;</h3><span>11/16/2011 11:06:54 AM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>&gt; It might be because this transform is supposed to be invertible, but it doesn&apos;t seem to be.</p><p>-- my cochlear transform is invertible in the same sense the laplace transform is invertible...<br/>can do it using a contour integral using a vertical contour.  However, for practical<br/>purposes the Laplace transform is not invertible in the sense this inversion is numerically<br/>very ill-conditioned.  That is also true for  the cochlear transform due to the exponential<br/>dying-off  &quot;window&quot;  really clobbering certain dependencies which in principle still<br/>are there mathematically, but in practice with finite precision arithmetic won&apos;t be.</p><p>So in practice you only will be able to invert it decently for times not too far in the past.</p></div><h3><a id=20036 href="#20036">ðŸ”—</a>Mike Battaglia &#x3C;battaglia01@gmail.com&#x3E;</h3><span>11/16/2011 11:43:33 AM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On Wed, Nov 16, 2011 at 2:00 PM, WarrenS &lt;<a href="mailto:warren.wds@gmail.com">warren.wds@gmail.com</a>&gt; wrote:<br/>&gt;<br/>&gt; &gt; Is this basically just the Laplace transform,<br/>&gt;<br/>&gt; --yes except that s is complex not real.</p><p>What do you mean? In the Laplace transform, s in e^-st is supposed to<br/>be complex.</p><p>&gt; &gt; If so, and if you&apos;re<br/>&gt; &gt; attempting to use this like a window for a one-sided Fourier<br/>&gt; &gt; transform, why not just use something like a gammachirp window<br/>&gt; &gt; instead, which was actually created to model the behavior of the<br/>&gt; &gt; cochlea? See here:<br/>&gt; &gt;<br/>&gt; &gt; <a href="http://people.csail.mit.edu/malex/research_files/park_wave.pdf">http://people.csail.mit.edu/malex/research_files/park_wave.pdf</a><br/>&gt;<br/>&gt; --my preliminary impression is I&apos;ve been scooped.<br/>&gt; That is, their &quot;gammachirp filterbank&quot; thing is essentially the same thing<br/>&gt; as my &quot;cochlear transform.&quot; (Actually I invented this like 20 years ago, but<br/>&gt; basically never told anybody... some in some sense maybe I scooped the scoop...)<br/>&gt;<br/>&gt; However, I have fast algorithms and this park_wave<br/>&gt; paper apparently does not, although maybe some other scooper does.</p><p>There&apos;s also this:</p><p><a href="http://www.audience.com/technology/fast-cochlea.php">http://www.audience.com/technology/fast-cochlea.php</a></p><p>but it&apos;s apparently proprietary.</p><p>&gt; &gt; You don&apos;t have to use wavelets, but you can use that window to replace<br/>&gt; &gt; your Laplace-inspired e^(at) window.<br/>&gt;<br/>&gt; --don&apos;t know what you are saying there.</p><p>Just use an STFT with a gammachirp window.</p><p>&gt; &gt; Also, I don&apos;t think this statement is true:<br/>&gt; &gt;<br/>&gt; &gt; &quot;Also, again, wavelet transforms involve some arbitrary discontinuous<br/>&gt; &gt; chopping of the time axis. The cochlear transform does not -- it is<br/>&gt; &gt; invariant under time translation.&quot;<br/>&gt; &gt;<br/>&gt; &gt; I think that&apos;s only true for the discrete wavelet transform, not the<br/>&gt; &gt; continuous one.<br/>&gt;<br/>&gt; --oh. But maybe in practice you have to use DWT?</p><p>The DWT isn&apos;t just the discrete version of the CWT - they&apos;re very<br/>different. It&apos;s not like the DFT vs the normal fourier transform.</p><p>&gt; &gt; Also, there are plenty of ways to make the DWT<br/>&gt; &gt; shift-invariant, including but not limited to this:<br/>&gt; &gt; <a href="http://en.wikipedia.org/wiki/Stationary_wavelet_transform">http://en.wikipedia.org/wiki/Stationary_wavelet_transform</a><br/>&gt;<br/>&gt; --oh. Well, the wikipedia article does not explain it worth a damn, but that does look interesting.</p><p>I find Wikipedia articles on math to be terrible, in general, but it&apos;s<br/>a neat concept.</p><p>-Mike</p></div><h3><a id=20037 href="#20037">ðŸ”—</a>WarrenS &#x3C;warren.wds@gmail.com&#x3E;</h3><span>11/16/2011 1:00:52 PM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>&gt; &gt; However, I have fast algorithms and this park_wave<br/>&gt; &gt; paper apparently does not, although maybe some other scooper does.<br/>&gt;<br/>&gt; There&apos;s also this:<br/>&gt;<br/>&gt; <a href="http://www.audience.com/technology/fast-cochlea.php">http://www.audience.com/technology/fast-cochlea.php</a><br/>&gt;<br/>&gt; but it&apos;s apparently proprietary.</p><p>--well, holy crap.  It isn&apos;t explained but the nifty picture they give looks exactly like mine.<br/>Son of a bitch.  Major miscellaneous annoyed words.  I presume this is due to Lloyd Watts,<br/>their &quot;chief scientist&quot; (?).</p><p>&gt; The DWT isn&apos;t just the discrete version of the CWT - they&apos;re very<br/>&gt; different. It&apos;s not like the DFT vs the normal fourier transform.</p><p>--well, maybe you can educate me on wavelets.  I read some wavelet papers a long time ago (about when they invented the idea) but not since.<br/>But anyhow, it seemed to me that it was kind of a hybrid of discrete &amp; continuous.</p><p>There was a magic function WVT(t) on the real interval [0,1], called &quot;the wavelet,&quot;<br/>which had to be designed+chosen very carefully.<br/>This function looked &quot;rough,&quot; e.g it was only C2,<br/>i.e. 2-time differentiable but almost-nowhere 3-time differentiable.<br/>Actually, it would not surprise me if this could be done for Ck for any k, and maybe even Cinfinity, but I would conjecture it is not possible to use an analytic function, that&apos;s<br/>asking for too much smoothness and you probably can&apos;t get it.  Quite possibly all<br/>this has been proven by others.  Anyhow...</p><p>Then you decompose the time-axis<br/>into a &quot;binary tree of intervals&quot; such as the integers at length=1,<br/>the half integers at length=1/2, length =1/4, 1/8, 1/16 etc,<br/>and in the other direction 2,4,8,16 etc.</p><p>Anyhow, then the Cool Theorem was that ANY function from some wide class<br/>was representable uniquely as a sum of coefficients times<br/>wavelets rescaled and shifted to lie on the intervals from that tree.</p><p>So that discrete tree explains what I had in mind by &quot;arbitrary chopping of the time axis.&quot;<br/>The &quot;continuous&quot; part of the hybrid is because we are talking about a continuous-time signal.  For computer purposes you would also discretize time, making it a discrete+discrete hybrid.</p><p>Now I see in wikipedia<br/>   <a href="http://en.wikipedia.org/wiki/Continuous_wavelet_transform">http://en.wikipedia.org/wiki/Continuous_wavelet_transform</a><br/>there also something they call &quot;Continuous wavelet transform&quot;<br/>but it just looks stupid, at least the way they describe it.</p></div><h3><a id=20038 href="#20038">ðŸ”—</a>Carl Lumma &#x3C;carl@lumma.org&#x3E;</h3><span>11/16/2011 2:37:42 PM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Warren wrote:</p><p>&gt; &gt; <a href="http://www.audience.com/technology/fast-cochlea.php">http://www.audience.com/technology/fast-cochlea.php</a><br/>&gt; &gt;<br/>&gt; &gt; but it&apos;s apparently proprietary.<br/>&gt;<br/>&gt; --well, holy crap.  It isn&apos;t explained but the nifty picture<br/>&gt; they give looks exactly like mine.  Son of a bitch.  Major<br/>&gt; miscellaneous annoyed words.  I presume this is due to<br/>&gt; Lloyd Watts, their &quot;chief scientist&quot; (?).</p><p>A good friend of mine was their 2nd employee, and I&apos;ve<br/>met and corresponded with Watts on several occasions.<br/>His cochlea is based on Dick Lyon&apos;s work at Apple in the<br/>late &apos;80s / early &apos;90s.  Watts implemented this cochlea<br/>in an FPGA while at Interval Research.  His thesis, under<br/>Carver Mead, as well as various Interval papers, document<br/>this work.  There is really nothing secret about it.  He<br/>ported it to x86 in 2001, since Intel chips were by then<br/>fast enough to do it in real time.  He got Audience funded<br/>by demoing that.  Work since then has progressed well<br/>beyond cochlear models.  Their chip is in the iPhone 4<br/>(and I imagine, the 4S too).</p><p>-Carl</p></div><h3><a id=20039 href="#20039">ðŸ”—</a>WarrenS &#x3C;warren.wds@gmail.com&#x3E;</h3><span>11/17/2011 1:12:14 PM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>I found apparently the only published paper by Watts on his speech processors (?) and have put an e-copy here:</p><p><a href="https://dl-web.dropbox.com/get/Public/WattsVoiceProc2009.pdf?w=53b4c8a6">https://dl-web.dropbox.com/get/Public/WattsVoiceProc2009.pdf?w=53b4c8a6</a></p><p>it is from IEEE Micro 29,2 (Mar-Apr 2009) 54-61.</p><p>It seems a lot less impressive-sounding than their commercial hype-webpage looked.</p><p>Apparently the &quot;gammachirp filterbank&quot; idea,<br/>aka Mellin transform, aka Laplace transform with complex s<br/>(the inversion is called &quot;Bromwich integral&quot; by the way)<br/>was invented for speech signal processing purposes by<br/>Roy D. Patterson and/or Toshio Irino.<br/>I found these two papers by them:</p><p>J.Acoustical Soc. Amer. 101,1 (1997) 412-419<br/>Speech Commun. 36,3-4 (2002) 181-203.</p><p>I do not have access to the second.<br/>A quick look suggests none of these 3 papers recognize the existence<br/>of fast algorithms, so maybe I&apos;m actually not as scooped as I thought...</p><p>I also re-examined the wavelet literature and I still agree with<br/>what I&apos;d said before, actually.  The wavelet literature seems to<br/>contain a lot of red-herring garbage mixed in with a small amount of top-grade jewels, and for the jewels, what I said was valid;  while for the garbage, who cares -- that stuff is best hermetically sealed for safe disposal and shouldn&apos;t be used for anything.  (But, I realize, this statement would be disagreed with by a ton of authors.)</p></div>
                <script>
                    let monospace = false
                    $('button').on('click', function () {
                      if (monospace) {
                        $('p').css("font-family", "")
                      } else {
                        $('p').css("font-family", "monospace")
                      }
                      monospace = !monospace
                    })
                </script>
            