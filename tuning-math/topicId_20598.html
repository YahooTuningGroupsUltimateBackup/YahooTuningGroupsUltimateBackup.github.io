<a href="/tuning-math">back to list</a><h1>TE complexity</h1><h3><a id=20598 href="#20598">ðŸ”—</a>Mike Battaglia &#x3C;battaglia01@gmail.com&#x3E;</h3><span>4/26/2012 9:57:21 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Is the TE complexity of a temperament the area of the primitive cell<br/>of the lattice formed by the vals that support it? (ignoring<br/>contorsion)</p><p>-Mike</p></div><h3><a id=20599 href="#20599">ðŸ”—</a>Graham Breed &#x3C;gbreed@gmail.com&#x3E;</h3><span>4/27/2012 1:09:13 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On 27/04/2012, Mike Battaglia &lt;<a href="mailto:battaglia01@gmail.com">battaglia01@gmail.com</a>&gt; wrote:<br/>&gt; Is the TE complexity of a temperament the area of the primitive cell<br/>&gt; of the lattice formed by the vals that support it? (ignoring<br/>&gt; contorsion)</p><p>Yes.  Something like that.</p><p>                  Graham</p></div><h3><a id=20600 href="#20600">ðŸ”—</a>Mike Battaglia &#x3C;battaglia01@gmail.com&#x3E;</h3><span>4/27/2012 2:17:50 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On Fri, Apr 27, 2012 at 4:09 AM, Graham Breed &lt;<a href="mailto:gbreed@gmail.com">gbreed@gmail.com</a>&gt; wrote:<br/>&gt;<br/>&gt; On 27/04/2012, Mike Battaglia &lt;<a href="mailto:battaglia01@gmail.com">battaglia01@gmail.com</a>&gt; wrote:<br/>&gt; &gt; Is the TE complexity of a temperament the area of the primitive cell<br/>&gt; &gt; of the lattice formed by the vals that support it? (ignoring<br/>&gt; &gt; contorsion)<br/>&gt;<br/>&gt; Yes. Something like that.</p><p>OK, so therefore the TE complexity is the exact same thing as the<br/>hypervolume of the parallelopiped formed by any n linearly independent<br/>generators which form and saturate that lattice.</p><p>Since this is exactly the same thing as the magnitude of the<br/>multivector formed by those vectors, TE complexity is the exact same<br/>thing as the RMS of the coefficients of the wedgie for that<br/>temperament.</p><p>Is this true? How have I never noticed this before?</p><p>-Mike</p></div><h3><a id=20601 href="#20601">ðŸ”—</a>Mike Battaglia &#x3C;battaglia01@gmail.com&#x3E;</h3><span>4/27/2012 2:20:47 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On Fri, Apr 27, 2012 at 5:17 AM, Mike Battaglia &lt;<a href="mailto:battaglia01@gmail.com">battaglia01@gmail.com</a>&gt; wrote:<br/>&gt; On Fri, Apr 27, 2012 at 4:09 AM, Graham Breed &lt;<a href="mailto:gbreed@gmail.com">gbreed@gmail.com</a>&gt; wrote:<br/>&gt;&gt;<br/>&gt;&gt; On 27/04/2012, Mike Battaglia &lt;<a href="mailto:battaglia01@gmail.com">battaglia01@gmail.com</a>&gt; wrote:<br/>&gt;&gt; &gt; Is the TE complexity of a temperament the area of the primitive cell<br/>&gt;&gt; &gt; of the lattice formed by the vals that support it? (ignoring<br/>&gt;&gt; &gt; contorsion)<br/>&gt;&gt;<br/>&gt;&gt; Yes. Something like that.<br/>&gt;<br/>&gt; OK, so therefore the TE complexity is the exact same thing as the<br/>&gt; hypervolume of the parallelopiped formed by any n linearly independent<br/>&gt; generators which form and saturate that lattice.</p><p>This should say &quot;parallelotope.&quot;</p><p>-Mike</p></div><h3><a id=20602 href="#20602">ðŸ”—</a>Wolf Peuker &#x3C;wolfpeuker@googlemail.com&#x3E;</h3><span>4/27/2012 2:25:08 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Hi Mike,</p><p>Am 27.04.2012 11:17, schrieb Mike Battaglia:<br/>&gt; OK, so therefore the TE complexity is the exact same thing as the<br/>&gt; hypervolume of the parallelopiped formed by any n linearly independent<br/>&gt; generators which form and saturate that lattice.<br/>&gt;<br/>&gt; Since this is exactly the same thing as the magnitude of the<br/>&gt; multivector formed by those vectors, TE complexity is the exact same<br/>&gt; thing as the RMS of the coefficients of the wedgie for that<br/>&gt; temperament.<br/>What means RMS?<br/>Where can I find a description of TE complexity for non-mathematicians?</p><p>Thanks!<br/>Wolf</p></div><h3><a id=20603 href="#20603">ðŸ”—</a>Mike Battaglia &#x3C;battaglia01@gmail.com&#x3E;</h3><span>4/27/2012 2:51:08 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On Fri, Apr 27, 2012 at 5:25 AM, Wolf Peuker &lt;<a href="mailto:wolfpeuker@googlemail.com">wolfpeuker@googlemail.com</a>&gt;<br/>wrote:<br/>&gt;<br/>&gt; Hi Mike,<br/>&gt;<br/>&gt; Am 27.04.2012 11:17, schrieb Mike Battaglia:<br/>&gt;<br/>&gt;<br/>&gt; &gt; OK, so therefore the TE complexity is the exact same thing as the<br/>&gt; &gt; hypervolume of the parallelopiped formed by any n linearly independent<br/>&gt; &gt; generators which form and saturate that lattice.<br/>&gt; &gt;<br/>&gt; &gt; Since this is exactly the same thing as the magnitude of the<br/>&gt; &gt; multivector formed by those vectors, TE complexity is the exact same<br/>&gt; &gt; thing as the RMS of the coefficients of the wedgie for that<br/>&gt; &gt; temperament.<br/>&gt; What means RMS?<br/>&gt; Where can I find a description of TE complexity for non-mathematicians?<br/>&gt;<br/>&gt; Thanks!<br/>&gt; Wolf</p><p>RMS means &quot;root mean square.&quot; It&apos;s a type of average. Given a set of<br/>numbers like {1, 2, 3}, the usual average (the mean) is (1 + 2 + 3)/3<br/>= 2. The RMS of this set is sqrt((1^2 + 2^2 + 3^2)/3), which is about<br/>2.160.</p><p>If Gene or Graham answers my question about TE complexity in the<br/>affirmative, then you&apos;ll have your description of TE complexity for<br/>non-mathematicians. This way of thinking about it is much simpler and<br/>more elegant, and I hope it&apos;s correct.</p><p>-Mike</p></div><h3><a id=20605 href="#20605">ðŸ”—</a>genewardsmith &#x3C;genewardsmith@sbcglobal.net&#x3E;</h3><span>4/27/2012 9:22:53 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Mike Battaglia &lt;battaglia01@...&gt; wrote:</p><p>&gt; Is this true? How have I never noticed this before?</p><p>I don&apos;t know. Did you read this:</p><p><a href="http://xenharmonic.wikispaces.com/Tenney-Euclidean+temperament+measures">http://xenharmonic.wikispaces.com/Tenney-Euclidean+temperament+measures</a></p><p>&quot;Given a multival or multimonzo which is a wedge product of weighted vals or monzos, we may define a norm by means of the usual Euclidean norm. We can rescale this by taking the sum of squares of the entries of the multivector, dividing by the number of entries, and taking the square root. This will give a norm which is the RMS (root mean square) average of the entries of the multivector.&quot;</p><p>&quot;Given a wedgie M, that is a canonically reduced r-val correspondng to a temperament of rank r, the norm ||M|| is a measure of the complexity of M; that is, how many notes in some sort of weighted average it takes to get to intervals.&quot;</p><p>Note, however, that Graham doesn&apos;t normalize via the RMS route.</p></div><h3><a id=20608 href="#20608">ðŸ”—</a>Mike Battaglia &#x3C;battaglia01@gmail.com&#x3E;</h3><span>4/28/2012 12:44:08 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On Fri, Apr 27, 2012 at 12:22 PM, genewardsmith<br/>&lt;<a href="mailto:genewardsmith@sbcglobal.net">genewardsmith@sbcglobal.net</a>&gt; wrote:<br/>&gt;<br/>&gt; &quot;Given a multival or multimonzo which is a wedge product of weighted vals<br/>&gt; or monzos, we may define a norm by means of the usual Euclidean norm. We can<br/>&gt; rescale this by taking the sum of squares of the entries of the multivector,<br/>&gt; dividing by the number of entries, and taking the square root. This will<br/>&gt; give a norm which is the RMS (root mean square) average of the entries of<br/>&gt; the multivector.&quot;</p><p>So what happens if you apply a different Lp norm to the wedgie? If<br/>using L2 gives you a geometric interpretation that&apos;s something like<br/>the area of the parallelogram formed by the factors of the wedgie,<br/>what geometric interpretation would using something like the L1 or<br/>Linf norm have?</p><p>&gt; Note, however, that Graham doesn&apos;t normalize via the RMS route.</p><p>He just does sum-squared or something?</p><p>-Mike</p></div><h3><a id=20609 href="#20609">ðŸ”—</a>genewardsmith &#x3C;genewardsmith@sbcglobal.net&#x3E;</h3><span>4/28/2012 1:32:56 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Mike Battaglia &lt;battaglia01@...&gt; wrote:</p><p>&gt; So what happens if you apply a different Lp norm to the wedgie? If<br/>&gt; using L2 gives you a geometric interpretation that&apos;s something like<br/>&gt; the area of the parallelogram formed by the factors of the wedgie,<br/>&gt; what geometric interpretation would using something like the L1 or<br/>&gt; Linf norm have?</p><p>That&apos;s what we were asking ourselves twen years ago.</p><p>&gt; &gt; Note, however, that Graham doesn&apos;t normalize via the RMS route.<br/>&gt;<br/>&gt; He just does sum-squared or something?</p><p>Or something.</p><p>By the way, I think I can define the tuning map by a purely wedgie approach, but it&apos;s bedtime so I&apos;m not going to try right now.</p></div><h3><a id=20613 href="#20613">ðŸ”—</a>Mike Battaglia &#x3C;battaglia01@gmail.com&#x3E;</h3><span>4/29/2012 4:19:11 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On Sat, Apr 28, 2012 at 4:32 AM, genewardsmith &lt;<a href="mailto:genewardsmith@sbcglobal.net">genewardsmith@sbcglobal.net</a>&gt;<br/>wrote:<br/>&gt;<br/>&gt; --- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Mike Battaglia &lt;battaglia01@...&gt;<br/>&gt; wrote:<br/>&gt;<br/>&gt; &gt; So what happens if you apply a different Lp norm to the wedgie? If<br/>&gt; &gt; using L2 gives you a geometric interpretation that&apos;s something like<br/>&gt; &gt; the area of the parallelogram formed by the factors of the wedgie,<br/>&gt; &gt; what geometric interpretation would using something like the L1 or<br/>&gt; &gt; Linf norm have?<br/>&gt;<br/>&gt; That&apos;s what we were asking ourselves twen years ago.</p><p>I guess these different Lp norms generalize the &quot;area&quot; of a bivector<br/>differently, just like different Lp norms generalize the length of a<br/>vector differently.</p><p>So if multivectors generalize vectors as being signed hypervolumes in<br/>a subspace, then the components of a wedgie in this case are like the<br/>signed areas of the projection of the wedgie onto various component<br/>subspaces. So for a bivector like &lt;&lt;1 4 4||, the 1 represents the area<br/>of the parallelogram you get by projecting onto the e2^e3 plane, the 4<br/>is the area of the parallelogram you get by projecting onto the e2^e5<br/>plane, and the other 4 is the area you get by projecting onto the<br/>e3^e5 plane. And then the norm tells you how to take this info to<br/>reconstruct the area of the original parallelogram.</p><p>So for L2, using De Gua&apos;s theorem, which Keenan found out about, it<br/>all works out to reconstruct the area. L1 is basically just the<br/>manhattan version of all that. If you look at the L1 norm of a vector,<br/>it&apos;s like saying &quot;first you have to go this length along component x,<br/>then you turn and go another length along component y, then do it<br/>again for z, and count the total distance you travel.&quot; So for<br/>bivectors, that&apos;d be something like, &quot;count the surface area you need<br/>to cover along component x^y, then count the surface area you need to<br/>cover along component x^z, then count the surface area you need to<br/>cover along component y^z, and add up the total surface area you&apos;ve<br/>covered.&quot;</p><p>So it would appear to be half the surface area of some sort of<br/>bounding parallelotope for the parallelogram. I&apos;m not sure exactly how<br/>to imagine it though, only that it&apos;s the half the surface area for<br/>some sort of bounding thing.</p><p>-Mike</p></div><h3><a id=20620 href="#20620">ðŸ”—</a>Graham Breed &#x3C;gbreed@gmail.com&#x3E;</h3><span>5/3/2012 10:02:07 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On 28/04/2012, Mike Battaglia &lt;<a href="mailto:battaglia01@gmail.com">battaglia01@gmail.com</a>&gt; wrote:<br/>&gt; On Fri, Apr 27, 2012 at 12:22 PM, genewardsmith<br/>&gt; &lt;<a href="mailto:genewardsmith@sbcglobal.net">genewardsmith@sbcglobal.net</a>&gt; wrote:</p><p>&gt;&gt; Note, however, that Graham doesn&apos;t normalize via the RMS route.<br/>&gt;<br/>&gt; He just does sum-squared or something?</p><p>I do it properly, so that the geometry works out.  The measure of a<br/>rank 2 mapping is the area of the parallelogram defined by the two<br/>mappings that produce it.  Normalizing by the number of elements of<br/>the wedgie is wrong.  It breaks theorems.</p><p>                Graham</p></div><h3><a id=20621 href="#20621">ðŸ”—</a>genewardsmith &#x3C;genewardsmith@sbcglobal.net&#x3E;</h3><span>5/3/2012 6:10:04 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Graham Breed &lt;gbreed@...&gt; wrote:<br/>&gt;<br/>&gt; On 28/04/2012, Mike Battaglia &lt;battaglia01@...&gt; wrote:<br/>&gt; &gt; On Fri, Apr 27, 2012 at 12:22 PM, genewardsmith<br/>&gt; &gt; &lt;genewardsmith@...&gt; wrote:<br/>&gt;<br/>&gt; &gt;&gt; Note, however, that Graham doesn&apos;t normalize via the RMS route.<br/>&gt; &gt;<br/>&gt; &gt; He just does sum-squared or something?<br/>&gt;<br/>&gt; I do it properly, so that the geometry works out.  The measure of a<br/>&gt; rank 2 mapping is the area of the parallelogram defined by the two<br/>&gt; mappings that produce it.  Normalizing by the number of elements of<br/>&gt; the wedgie is wrong.  It breaks theorems.</p><p>Any allegedly &quot;broken&quot; theorem can always be reformulated so as not to be broken. The point is to come up with a definition which works well for our specific purposes. Some questions:</p><p>(1) How well does your definition perform in high ranks? Doesn&apos;t the complexity tend to become small?</p><p>(2) How well does it work when comparing a wedgie with its dual?</p></div><h3><a id=20622 href="#20622">ðŸ”—</a>Mike Battaglia &#x3C;battaglia01@gmail.com&#x3E;</h3><span>5/3/2012 11:51:03 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On Thu, May 3, 2012 at 1:02 PM, Graham Breed &lt;<a href="mailto:gbreed@gmail.com">gbreed@gmail.com</a>&gt; wrote:<br/>&gt;<br/>&gt; On 28/04/2012, Mike Battaglia &lt;<a href="mailto:battaglia01@gmail.com">battaglia01@gmail.com</a>&gt; wrote:<br/>&gt; &gt; On Fri, Apr 27, 2012 at 12:22 PM, genewardsmith<br/>&gt; &gt; &lt;<a href="mailto:genewardsmith@sbcglobal.net">genewardsmith@sbcglobal.net</a>&gt; wrote:<br/>&gt;<br/>&gt; &gt;&gt; Note, however, that Graham doesn&apos;t normalize via the RMS route.<br/>&gt; &gt;<br/>&gt; &gt; He just does sum-squared or something?<br/>&gt;<br/>&gt; I do it properly, so that the geometry works out. The measure of a<br/>&gt; rank 2 mapping is the area of the parallelogram defined by the two<br/>&gt; mappings that produce it. Normalizing by the number of elements of<br/>&gt; the wedgie is wrong. It breaks theorems.<br/>&gt;<br/>&gt; Graham</p><p>OK, so it&apos;d just be root-sum-squared, right?</p><p>-Mike</p></div><h3><a id=20628 href="#20628">ðŸ”—</a>Graham Breed &#x3C;gbreed@gmail.com&#x3E;</h3><span>5/7/2012 3:50:47 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>&quot;genewardsmith&quot; &lt;<a href="mailto:genewardsmith@sbcglobal.net">genewardsmith@sbcglobal.net</a>&gt; wrote:<br/>&gt;<br/>&gt; --- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Graham Breed<br/>&gt; &lt;gbreed@...&gt; wrote:</p><p>&gt; &gt; I do it properly, so that the geometry works out.  The<br/>&gt; &gt; measure of a rank 2 mapping is the area of the<br/>&gt; &gt; parallelogram defined by the two mappings that produce<br/>&gt; &gt; it.  Normalizing by the number of elements of the<br/>&gt; &gt; wedgie is wrong.  It breaks theorems.<br/>&gt;<br/>&gt; Any allegedly &quot;broken&quot; theorem can always be reformulated<br/>&gt; so as not to be broken. The point is to come up with a<br/>&gt; definition which works well for our specific purposes.<br/>&gt; Some questions:</p><p>Yes, you can always add complications to the theorems to<br/>match the complications you added to the definition.</p><p>&gt; (1) How well does your definition perform in high ranks?<br/>&gt; Doesn&apos;t the complexity tend to become small?</p><p>It works fine in any rank.  It doesn&apos;t matter what size the<br/>complexity is.</p><p>&gt; (2) How well does it work when comparing a wedgie with<br/>&gt; its dual?</p><p>That would depend on how the dual metric&apos;s defined.  It<br/>should probably work so the complexity of an interval has<br/>something to do with its Tenney height.</p><p>                      Graham</p></div><h3><a id=20629 href="#20629">ðŸ”—</a>Graham Breed &#x3C;gbreed@gmail.com&#x3E;</h3><span>5/7/2012 4:04:28 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Mike Battaglia &lt;<a href="mailto:battaglia01@gmail.com">battaglia01@gmail.com</a>&gt; wrote:</p><p>&gt; OK, so it&apos;d just be root-sum-squared, right?</p><p>You could do that.  The units I usually use are normalized<br/>to be similar to other weighted complexity measures.  To<br/>normalize, you divide by some power of the number of<br/>primes.  You can make this part of the weighting.  Divide<br/>by whatever power of the number of primes (I think it&apos;s<br/>the square root) and then you can take sums of squares of<br/>wedgies or deteminants.</p><p>The argument for the square root: for an ET, the complexity<br/>should be roughly the number of steps to the octave.  Call<br/>the weighted primes (prime mappings divided by the sizes of<br/>the primes) w, and that gives</p><p>RMS(w) = sqrt(sum(w[i]**2)/n)</p><p>for n primes.  That can be rewritten</p><p>RMS(w) = sqrt(sum((w[i]/sqrt(n))**2))</p><p>So it becomes a root-sum-squared when w[i]-&gt;w[i]/sqrt(n)</p><p>                        Graham</p></div>