<a href="/tuning-math">back to list</a><h1>Geometry of Linear Least Squares Problems</h1><h3><a id=17963 href="#17963">ðŸ”—</a>Graham Breed &#x3C;gbreed@gmail.com&#x3E;</h3><span>7/4/2010 2:45:55 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>This information comes from a book called Elementary Linear Algebra by<br/>Anton and Rorres, 9th Edition, Applications Version, Not For Sale in<br/>North America.  Your favorite academic library should have a book with<br/>similar material.</p><p>A linear least squares problem is defined on p.333 as finding x to minimize</p><p>||A x - b||</p><p>As a regular temperament, x is a column vector containing the<br/>generator sizes, b is the weighted just intonation point (JIP) and A<br/>is the mapping matrix, with vals as columns.</p><p>They then define W as the column space of A, which is to say any val<br/>that belongs to the temperament class, including things like vals that<br/>don&apos;t contain integers, or any tuning of the temperament class.  We<br/>already know about this.  The orthogonal projection of b on W is</p><p>proj_W b = A x</p><p>So you project the temperament onto the JIP, and the result is the<br/>tempered (and weighted) tuning map.</p><p>There&apos;s no direct geometric model for x, which somebody asked about a<br/>while back, but the above might help you to find it.  There&apos;s more<br/>working up to p.335 where they give a formula for proj_W b that looks<br/>alarmingly like the pseudoinverse, so it won&apos;t help to repeat it.</p><p>                         Graham</p></div>