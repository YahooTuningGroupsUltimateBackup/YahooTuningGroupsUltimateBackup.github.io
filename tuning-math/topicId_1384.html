<a href="/tuning-math">back to list</a><h1>Temperament bases and lattice basis reduction</h1><h3>genewardsmith@juno.com</h3><span>11/10/2001 12:39:52 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>I&apos;ve been finding the LLL lattice basis reduction algorithm very<br/>useful for finding a basis for a planar temperament, and it probably<br/>would be even more useful for higher dimensions.</p><p>The notation [h19,h22,h27,h31] is a useful one for looking at some of<br/>these, since [h19,h22,h27,h31]^(-1) =<br/>&lt;1728/1715,126/125,225/224,245/243&gt;. This gives us four planar<br/>temperaments, each of which is interesting.</p><p>The above means, for instance, that the 19,22, and 31 ets each set<br/>225/224 to a unison, whereas h27(225/224)=1, a single step. To get a<br/>basis for the 225/224 planar temperament, we therefore eliminate h27.<br/>We now may perform lattice basis reduction on the columns of the<br/>remaining three vals, getting:</p><p>[19 22 31]     [ 0  1  0]<br/>[30 35 49]     [-1  1 -1]<br/>[44 51 72] ==&gt; [ 1  1  0]<br/>[53 62 87]     [ 0 -1 -2]</p><p>Similar calculations with the other commas gives us the following:</p><p>1728/1715: basis 6,1/2,12/7 equivalent to 2,3/2,7/6</p><p>126/125: basis 6/25,5,5/3 equivalent to 2,5,5/3 or 2,3,5/3</p><p>245/243: basis 1/2,9/7,3 equivalent to 2,3/2,9/7</p><p>The LLL lattice basis reduction algorithm is in Maple, which may mean<br/>it is in Matlab also.</p><p>We keep the top row, since we want octave equivalence, and by<br/>preference the second row, since we like 3. We then choose which of<br/>the last two rows will give us a unimodular 3x3 matrix; in this case<br/>it is the third row, so 2,3 and 5 are the remaining primes. We then<br/>invert:</p><p>[ 0 1  0]^(-1)    [-1  0  1]<br/>[-1 1 -1]      =  [ 1  0  0]<br/>[ 1 1  0]         [ 2 -1 -1]</p><p>The three rows of the inverted matrix represent 5/2, 2, and 4/15; a<br/>minor adjustment gives us the equivalent basis of 2,5/4, and 16/15,<br/>which is the Miracle-Magic basis.</p></div><h3>Paul Erlich &#x3C;paul@stretch-music.com&#x3E;</h3><span>11/12/2001 4:39:03 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., genewardsmith@j... wrote:<br/>&gt; I&apos;ve been finding the LLL lattice basis reduction algorithm very<br/>&gt; useful for finding a basis for a planar temperament, and it<br/>probably<br/>&gt; would be even more useful for higher dimensions.<br/>&gt;<br/>&gt; The notation [h19,h22,h27,h31] is a useful one for looking at some<br/>of<br/>&gt; these, since [h19,h22,h27,h31]^(-1) =<br/>&gt; &lt;1728/1715,126/125,225/224,245/243&gt;. This gives us four planar<br/>&gt; temperaments, each of which is interesting.<br/>&gt;<br/>&gt; The above means, for instance, that the 19,22, and 31 ets each set<br/>&gt; 225/224 to a unison, whereas h27(225/224)=1, a single step. To get<br/>a<br/>&gt; basis for the 225/224 planar temperament, we therefore eliminate<br/>h27.<br/>&gt; We now may perform lattice basis reduction on the columns of the<br/>&gt; remaining three vals, getting:<br/>&gt;<br/>&gt; [19 22 31]     [ 0  1  0]<br/>&gt; [30 35 49]     [-1  1 -1]<br/>&gt; [44 51 72] ==&gt; [ 1  1  0]<br/>&gt; [53 62 87]     [ 0 -1 -2]<br/>&gt;<br/>&gt; Similar calculations with the other commas gives us the following:<br/>&gt;<br/>&gt; 1728/1715: basis 6,1/2,12/7 equivalent to 2,3/2,7/6<br/>&gt;<br/>&gt; 126/125: basis 6/25,5,5/3 equivalent to 2,5,5/3 or 2,3,5/3<br/>&gt;<br/>&gt; 245/243: basis 1/2,9/7,3 equivalent to 2,3/2,9/7</p><p>Not sure what this is telling me.<br/>&gt;<br/>&gt; The LLL lattice basis reduction algorithm is in Maple, which may<br/>mean<br/>&gt; it is in Matlab also.</p><p>I don&apos;t see it:</p><p>MAERESIZE Change the size of a matrix to be [m n].<br/>mldivide.m: %\   Backslash or left matrix divide.<br/>mpower.m: %^   Matrix power.<br/>mrdivide.m: %/   Slash or right matrix divide.<br/>mtimes.m: %*   Matrix multiply.<br/>slash.m: %Matrix division.<br/>COMPAN Companion matrix.<br/>DIAG Diagonal matrices and diagonals of a matrix.<br/>EYE Identity matrix.<br/>FLIPDIM Flip matrix along specified dimension.<br/>FLIPLR Flip matrix in left/right direction.<br/>FLIPUD Flip matrix in up/down direction.<br/>HADAMARD Hadamard matrix.<br/>HANKEL Hankel matrix.<br/>HILB   Hilbert matrix.<br/>INVHILB Inverse Hilbert matrix.<br/>ISEMPTY True for empty matrix.<br/>PASCAL Pascal matrix.<br/>ROT90  Rotate matrix 90 degrees.<br/>SIZE   Size of matrix.<br/>TOEPLITZ Toeplitz matrix.<br/>VANDER Vandermonde matrix.<br/>WILKINSON Wilkinson&apos;s eigenvalue test matrix.<br/>EXPM   Matrix exponential.<br/>EXPM1  Matrix exponential via Pade approximation.<br/>EXPM2  Matrix exponential via Taylor series.<br/>EXPM3  Matrix exponential via eigenvalues and eigenvectors.<br/>FUNM Evaluate general matrix function.<br/>INV    Matrix inverse.<br/>LOGM   Matrix logarithm.<br/>NORM   Matrix or vector norm.<br/>NORMEST Estimate the matrix 2-norm.<br/>RANK   Matrix rank.<br/>SQRTM     Matrix square root.<br/>COV Covariance matrix.<br/>POLYVALM Evaluate polynomial with matrix argument.<br/>FULL   Convert sparse matrix to full matrix.<br/>ISSPARSE True for sparse matrix.<br/>NNZ    Number of nonzero matrix elements.<br/>NONZEROS Nonzero matrix elements.<br/>NZMAX  Amount of storage allocated for nonzero matrix elements.<br/>SPALLOC Allocate space for sparse matrix.<br/>SPARSE Create sparse matrix.<br/>SPCONVERT Import from sparse matrix external format.<br/>SPDIAGS Sparse matrix formed from diagonals.<br/>SPEYE  Sparse identity matrix.<br/>SPFUN Apply function to nonzero matrix elements.<br/>SPONES Replace nonzero sparse matrix elements with ones.<br/>SPPARMS Set parameters for sparse matrix routines.<br/>SPRAND Sparse uniformly distributed random matrix.<br/>SPRANDN Sparse normally distributed random matrix.<br/>SPRANDSYM Sparse random symmetric matrix.<br/>UNMESH Convert a list of bedges to a graph or matrix.<br/>VIEWMTX View transformation matrix.<br/>PLOTMATRIX Scatter plot matrix.<br/>MATQUEUE Creates and manipulates a figure-based matrix queue.<br/>TEXTWRAP Return wrapped string matrix for given UI Control.<br/>MAT2STR Convert matrix to eval&apos;able string.<br/>STR2MAT Form blank padded character matrix from strings.<br/>STR2NUM Convert string matrix to numeric array.<br/>AIRFOIL Display sparse matrix from NASA airfoil.<br/>FEM1ODE Stiff problem with a time-dependent mass matrix, M(t)*y&apos; = f<br/>(t,y).<br/>FEM2ODE Stiff problem with a constant mass matrix, M*y&apos; = f(t,y).<br/>MATDEMS For setting up matrix computation demos from the MATLAB DEMO.<br/>PLTMAT Display a matrix in a figure window.<br/>SPIRAL SPIRAL(n) is an n-by-n matrix with elements ranging<br/>CASEWRITE Writes casenames from a string matrix to a file.<br/> PCACOV  Principal Component Analysis using the covariance matrix.<br/>SQUAREFORM Square matrix formatted distance.<br/>X2FX   Factor settings matrix (x) to design matrix (fx).<br/>ATAMULT Example Jacobian-matrix multiply<br/>FINDMAX2 Interpolates the maxima in a matrix of data.<br/>HMULT&#x9;Hessian-matrix product<br/>normal.m: % NORMAL.M - function to normalize a matrix.<br/>standardize.m: % STANDARDIZE.M - function to standardize a matrix.<br/>DISP3D&#x9;Display 3D matrix<br/>ELEM3D&#x9;Element positions of 3-D matrix packed in a 2-D matrix.<br/>FIND3D&#x9;Return position of non-zero elements in 3-D matrix.<br/>NDX3D&#x9;Index into 3-D matrix packed in a 2-D matrix.<br/>SIZE3D&#x9;Size of 2-D matrix to hold 3-D matrix.<br/>CAUCHY Cauchy matrix.<br/>CHEBSPEC Chebyshev spectral differentiation matrix.<br/>CHEBVAND Vandermonde-like matrix for the Chebyshev polynomials.<br/>CHOW   Chow matrix (singular Toeplitz lower Hessenberg matrix).<br/>CIRCUL Circulant matrix.<br/>CLEMENT Clement matrix.<br/>CONDEX &quot;Counter-examples&quot; to matrix condition number estimators.<br/>CYCOL  Matrix whose columns repeat cyclically.<br/>DORR   Dorr matrix.<br/>DRAMADAH Matrix of zeros and ones whose inverse has large integer<br/>entries.<br/>FIEDLER Fiedler matrix.<br/>FORSYTHE Forsythe matrix (perturbed Jordan block).<br/>FRANK  Frank matrix.<br/>GEARMAT Gear matrix.<br/>GRCAR  Grcar matrix.<br/>HANOWA Matrix whose eigenvalues lie on a vertical line.<br/>HOUSE  Householder matrix.<br/>INVHESS Inverse of an upper Hessenberg matrix.<br/>INVOL  Involutory matrix.<br/>IPJFACT Hankel matrix with factorial elements.<br/>KAHAN  Kahan matrix.<br/>KMS    Kac-Murdock-Szego Toeplitz matrix.<br/>KRYLOV Krylov matrix.<br/>LAUCHLI Lauchli matrix.<br/>LEHMER Lehmer matrix.<br/>LESP   Tridiagonal matrix with real, sensitive eigenvalues.<br/>LOTKIN Lotkin matrix.<br/>MINIJ  Symmetric positive definite matrix MIN(i,j).<br/>MOLER  Moler matrix (symmetric positive definite).<br/>NEUMANN Singular matrix from the discrete Neumann problem.<br/>PARTER Parter matrix (Toeplitz with singular values near pi).<br/>PEI    Pei matrix.<br/>POISSON Block tridiagonal matrix from Poisson&apos;s equation.<br/>PROLATE Prolate matrix (symmetric, ill-conditioned Toeplitz matrix).<br/>RANDHESS Random, orthogonal upper Hessenberg matrix.<br/>RANDO  Random matrix with elements -1, 0 or 1.<br/>RANDSVD Random matrix with pre-assigned singular values.<br/>REDHEFF Redheffer matrix.<br/>RIEMANN Matrix associated with the Riemann hypothesis.<br/>RIS    Symmetric Hankel matrix.<br/>SMOKE  Complex matrix with a &quot;smoke ring&quot; pseudospectrum.<br/>TOEPPD Symmetric positive definite Toeplitz matrix.<br/>TOEPPEN Pentadiagonal Toeplitz matrix.<br/>TRIDIAG Tridiagonal matrix (sparse).<br/>TRIW   Upper triangular matrix discussed by Wilkinson and others.<br/>WATHEN Wathen matrix.<br/>ITERAPP   Apply matrix operator to vector and error gracefully.<br/>FINDP  Nonsingular basis permutation matrix.</p><p>&gt; We keep the top row, since we want octave equivalence, and by<br/>&gt; preference the second row, since we like 3. We then choose which of<br/>&gt; the last two rows will give us a unimodular 3x3 matrix; in this<br/>case<br/>&gt; it is the third row, so 2,3 and 5 are the remaining primes. We then<br/>&gt; invert:<br/>&gt;<br/>&gt; [ 0 1  0]^(-1)    [-1  0  1]<br/>&gt; [-1 1 -1]      =  [ 1  0  0]<br/>&gt; [ 1 1  0]         [ 2 -1 -1]<br/>&gt;<br/>&gt; The three rows of the inverted matrix represent 5/2, 2, and 4/15; a<br/>&gt; minor adjustment gives us the equivalent basis of 2,5/4, and 16/15,<br/>&gt; which is the Miracle-Magic basis.</p><p>Wish I followed this post.</p></div><h3>genewardsmith@juno.com</h3><span>11/12/2001 7:06:19 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;Paul Erlich&quot; &lt;paul@s...&gt; wrote:</p><p>&gt; &gt; The LLL lattice basis reduction algorithm is in Maple, which may<br/>&gt; mean<br/>&gt; &gt; it is in Matlab also.</p><p>&gt; I don&apos;t see it:</p><p>In Maple the function is called &quot;lattice&quot; and requires a<br/>&quot;readlib(lattice)&quot; before it can be used; however it&apos;s clear that<br/>Matlab mostly has different names. Since it had a lot of<br/>functionality before the Maple addition, that&apos;s to be expected. Does<br/>it have a help function? Can you put in &quot;lattice&quot;, &quot;lattice<br/>basis&quot; &quot;lattice basis reduction&quot; or &quot;LLL&quot; and see what happens?</p><p>Thanks for the entropy post, I&apos;ll see if I can finally figure out<br/>what you are doing.</p></div><h3>Paul Erlich &#x3C;paul@stretch-music.com&#x3E;</h3><span>11/12/2001 7:11:24 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., genewardsmith@j... wrote:</p><p>&gt; however it&apos;s clear that<br/>&gt; Matlab mostly has different names. Since it had a lot of<br/>&gt; functionality before the Maple addition, that&apos;s to be expected.<br/>Does<br/>&gt; it have a help function? Can you put in &quot;lattice&quot;, &quot;lattice<br/>&gt; basis&quot; &quot;lattice basis reduction&quot; or &quot;LLL&quot; and see what happens?</p><p>Nothing found.</p></div><h3>genewardsmith@juno.com</h3><span>11/13/2001 2:21:24 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;Paul Erlich&quot; &lt;paul@s...&gt; wrote:</p><p>&gt; Nothing found.</p><p>If you are very adventerous, of if by some chance you are on a Linux<br/>box, you could try the freeware mathematicians have cooked up--Pari<br/>and Lydia both have lattice basis reduction. Alas, they come from a<br/>Unix/academic environment, and getting them up and running on a PC is<br/>a pain.</p></div><h3>Paul Erlich &#x3C;paul@stretch-music.com&#x3E;</h3><span>11/14/2001 12:07:14 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., genewardsmith@j... wrote:<br/>&gt; --- In tuning-math@y..., &quot;Paul Erlich&quot; &lt;paul@s...&gt; wrote:<br/>&gt;<br/>&gt; &gt; Nothing found.<br/>&gt;<br/>&gt; If you are very adventerous, of if by some chance you are on a<br/>Linux<br/>&gt; box, you could try the freeware mathematicians have cooked up--Pari<br/>&gt; and Lydia both have lattice basis reduction. Alas, they come from a<br/>&gt; Unix/academic environment, and getting them up and running on a PC<br/>is<br/>&gt; a pain.</p><p>Unfortunately I don&apos;t understand what the point of this is. Could you<br/>please explain your original post to me?</p></div><h3>genewardsmith@juno.com</h3><span>11/14/2001 7:45:37 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;Paul Erlich&quot; &lt;paul@s...&gt; wrote:</p><p>&gt; Unfortunately I don&apos;t understand what the point of this is. Could<br/>you<br/>&gt; please explain your original post to me?</p><p>Let&apos;s first see if we have the idea of lattice basis reduction. I<br/>randomly picked 225/224, 1029/1024 and 1728/1715 from a list of 7-<br/>limit commas. The lattice they generate is<br/>(225/224)^a (1029/1024)^b (1728/1715)^c, which as it happens is the<br/>kernel of the 31-et in the 7-limit. However, there might be<br/>a &quot;better&quot; basis for the kernel, in the sense that the Euclidean<br/>lengths of these, considered as vectors, and the dot products of the<br/>corresponding unit vectors, are smaller. In other words, we<br/>take &quot;better&quot; to mean smaller vectors, more nearly orthogonal. The<br/>idea of lattice basis reduction is to find a &quot;better&quot; basis.</p><p>If I apply the LLL algorithm to the basis [-5,2,2,-1], [-10,1,0,3],<br/>and [6,3,-1,-3] I get [1,2,-2,1], or 126/125; [-4,4,-1,0], or 81/80,<br/>and [-1,-5,-1,4], or 2401/2430. If we check the Euclidean length and<br/>the dot products for these, we find that they are, indeed, &quot;better&quot;.<br/>Moreover, they still generate the kernel of the 31-et. Considered as<br/>commas for a block, they would give a 31-note block, but one with<br/>more regularly sized steps. Also, they are larger.</p><p>Does this make sense so far?</p></div><h3>Paul Erlich &#x3C;paul@stretch-music.com&#x3E;</h3><span>11/15/2001 11:31:47 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., genewardsmith@j... wrote:<br/>&gt; --- In tuning-math@y..., &quot;Paul Erlich&quot; &lt;paul@s...&gt; wrote:<br/>&gt;<br/>&gt; &gt; Unfortunately I don&apos;t understand what the point of this is. Could<br/>&gt; you<br/>&gt; &gt; please explain your original post to me?<br/>&gt;<br/>&gt; Let&apos;s first see if we have the idea of lattice basis reduction. I<br/>&gt; randomly picked 225/224, 1029/1024 and 1728/1715 from a list of 7-<br/>&gt; limit commas. The lattice they generate is<br/>&gt; (225/224)^a (1029/1024)^b (1728/1715)^c, which as it happens is the<br/>&gt; kernel of the 31-et in the 7-limit. However, there might be<br/>&gt; a &quot;better&quot; basis for the kernel, in the sense that the Euclidean<br/>&gt; lengths of these, considered as vectors, and the dot products of<br/>the<br/>&gt; corresponding unit vectors, are smaller. In other words, we<br/>&gt; take &quot;better&quot; to mean smaller vectors, more nearly orthogonal. The<br/>&gt; idea of lattice basis reduction is to find a &quot;better&quot; basis.</p><p>Aha! So this is related (as I suspected from its name) to the quest<br/>for &quot;canonical unison vectors&quot; for PBs that I asked you about a while<br/>back. However, I wouldn&apos;t compute lengths on a Cartesian or<br/>rectangular grid, which it seems you&apos;re doing here . . .</p><p>&gt; If I apply the LLL algorithm to the basis [-5,2,2,-1], [-10,1,0,3],<br/>&gt; and [6,3,-1,-3] I get [1,2,-2,1], or 126/125; [-4,4,-1,0], or 81/80,<br/>&gt; and [-1,-5,-1,4], or 2401/2430. If we check the Euclidean length<br/>and<br/>&gt; the dot products for these, we find that they are,<br/>indeed, &quot;better&quot;.<br/>&gt; Moreover, they still generate the kernel of the 31-et. Considered<br/>as<br/>&gt; commas for a block, they would give a 31-note block, but one with<br/>&gt; more regularly sized steps. Also, they are larger.<br/>&gt;<br/>&gt; Does this make sense so far?</p><p>Yup! Can we modify the algorithm so that it is uses lengths _not_<br/>based on a Cartesian or rectangular grid? For example, if we used<br/>Kees van Prooijen&apos;s lattice, we might end up with the set of unison<br/>vectors that uses the smallest numbers in their ratios, for example.</p></div><h3>genewardsmith@juno.com</h3><span>11/15/2001 12:19:43 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;Paul Erlich&quot; &lt;paul@s...&gt; wrote:</p><p>&gt; Aha! So this is related (as I suspected from its name) to the quest<br/>&gt; for &quot;canonical unison vectors&quot; for PBs that I asked you about a<br/>while<br/>&gt; back.</p><p>I think I mentioned lattice basis reduction then; I thought I&apos;d try<br/>it.</p><p>However, I wouldn&apos;t compute lengths on a Cartesian or<br/>&gt; rectangular grid, which it seems you&apos;re doing here . . .</p><p>That&apos;s the way the classic LLL, which is what I have on Maple, works.<br/>It&apos;s easy enough to adjust it somewhat, however, by adding<br/>multipliers, so that we could weight 3 and 5 more than 17 and 19,<br/>which might be a good plan.</p><p>&gt; Yup! Can we modify the algorithm so that it is uses lengths _not_<br/>&gt; based on a Cartesian or rectangular grid? For example, if we used<br/>&gt; Kees van Prooijen&apos;s lattice, we might end up with the set of unison<br/>&gt; vectors that uses the smallest numbers in their ratios, for example.</p><p>I don&apos;t know what the van Prooijen lattice is; however, there *are*<br/>versions of LLL which work for noneuclidean metrics. I don&apos;t know if<br/>they&apos;ve been implimented or how to lay hands on one, but I could try<br/>if this is what you mean.</p></div><h3>Paul Erlich &#x3C;paul@stretch-music.com&#x3E;</h3><span>11/15/2001 12:56:01 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., genewardsmith@j... wrote:<br/>&gt; --- In tuning-math@y..., &quot;Paul Erlich&quot; &lt;paul@s...&gt; wrote:<br/>&gt;<br/>&gt; &gt; Aha! So this is related (as I suspected from its name) to the<br/>quest<br/>&gt; &gt; for &quot;canonical unison vectors&quot; for PBs that I asked you about a<br/>&gt; while<br/>&gt; &gt; back.<br/>&gt;<br/>&gt; I think I mentioned lattice basis reduction then; I thought I&apos;d try<br/>&gt; it.</p><p>Awesome.<br/>&gt;<br/>&gt; However, I wouldn&apos;t compute lengths on a Cartesian or<br/>&gt; &gt; rectangular grid, which it seems you&apos;re doing here . . .<br/>&gt;<br/>&gt; That&apos;s the way the classic LLL, which is what I have on Maple,<br/>works.<br/>&gt; It&apos;s easy enough to adjust it somewhat, however, by adding<br/>&gt; multipliers, so that we could weight 3 and 5 more than 17 and 19,<br/>&gt; which might be a good plan.</p><p>Is 2 considered a prime on equal footing with the others?<br/>&gt;<br/>&gt; I don&apos;t know what the van Prooijen lattice is; however, there *are*<br/>&gt; versions of LLL which work for noneuclidean metrics. I don&apos;t know<br/>if<br/>&gt; they&apos;ve been implimented or how to lay hands on one, but I could<br/>try<br/>&gt; if this is what you mean.</p><p>Well, Euclidean is not so bad to start with -- what I&apos;m thinking is<br/>more triangular vs. rectangular, along the lines of the &quot;15:8 should<br/>be a longer distance than 6:5&quot; kind of thing . . .</p></div><h3>Paul Erlich &#x3C;paul@stretch-music.com&#x3E;</h3><span>11/15/2001 9:39:16 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>I wrote,<br/>&gt;<br/>&gt; Well, Euclidean is not so bad to start with -- what I&apos;m thinking is<br/>&gt; more triangular vs. rectangular, along the lines of the &quot;15:8<br/>should<br/>&gt; be a longer distance than 6:5&quot; kind of thing . . .</p><p>Hmm . . . the point of this is to have simpler ratios span a smaller<br/>distance -- of course that&apos;s what the Tenney city-block metric, where<br/>the orientations of the axes don&apos;t matter, does so well. Can we<br/>develop a version of LLL for this metric? BTW, what&apos;s the optimality<br/>criterion used by the original LLL . . . that the sum of the lengths<br/>of the basis vectors be minimized, or what?</p></div><h3>genewardsmith@juno.com</h3><span>11/15/2001 10:48:04 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;Paul Erlich&quot; &lt;paul@s...&gt; wrote:</p><p>&gt; Hmm . . . the point of this is to have simpler ratios span a<br/>smaller<br/>&gt; distance -- of course that&apos;s what the Tenney city-block metric,<br/>where<br/>&gt; the orientations of the axes don&apos;t matter, does so well.</p><p>I&apos;ve not heard of a Tenney metric, but it sounds like you are talking<br/>about the L1 (taxicab) metric, for which there is an LLL variant, at<br/>least in theory--or so I&apos;ve heard.</p><p>Can we<br/>&gt; develop a version of LLL for this metric? BTW, what&apos;s the<br/>optimality<br/>&gt; criterion used by the original LLL . . . that the sum of the<br/>lengths<br/>&gt; of the basis vectors be minimized, or what?</p><p>The criterion somewhat complicated, but I could post it if you really<br/>need it, and want to hear about Gram-Schimdt and put up with the fact<br/>that there is a parameter involved, so there really isn&apos;t just one<br/>version anyway. The problem was that if you insist on a canonical<br/>optimally reduced basis, the problem is NP complete, but the trick is<br/>to relax the condition enough to get a polynomial time algorithm. It<br/>then turns out that most of the time, it gives you more than you&apos;ve<br/>proven it ought to, anyway. It&apos;s been a real breakthrough in<br/>computational math.</p></div><h3>Paul Erlich &#x3C;paul@stretch-music.com&#x3E;</h3><span>11/15/2001 11:57:39 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., genewardsmith@j... wrote:<br/>&gt; --- In tuning-math@y..., &quot;Paul Erlich&quot; &lt;paul@s...&gt; wrote:<br/>&gt;<br/>&gt; &gt; Hmm . . . the point of this is to have simpler ratios span a<br/>&gt; smaller<br/>&gt; &gt; distance -- of course that&apos;s what the Tenney city-block metric,<br/>&gt; where<br/>&gt; &gt; the orientations of the axes don&apos;t matter, does so well.<br/>&gt;<br/>&gt; I&apos;ve not heard of a Tenney metric,</p><p>City-block metric, where the length of one rung along prime axis p is<br/>log(p).</p><p>&gt; but it sounds like you are talking<br/>&gt; about the L1 (taxicab) metric,</p><p>Yes, but with the above rung lengths.</p><p>&gt; for which there is an LLL variant, at<br/>&gt; least in theory--or so I&apos;ve heard.</p><p>Cool.</p><p>&gt; Can we<br/>&gt; &gt; develop a version of LLL for this metric? BTW, what&apos;s the<br/>&gt; optimality<br/>&gt; &gt; criterion used by the original LLL . . . that the sum of the<br/>&gt; lengths<br/>&gt; &gt; of the basis vectors be minimized, or what?<br/>&gt;<br/>&gt; The criterion somewhat complicated, but I could post it if you<br/>really<br/>&gt; need it, and want to hear about Gram-Schimdt and put up with the<br/>fact<br/>&gt; that there is a parameter involved, so there really isn&apos;t just one<br/>&gt; version anyway. The problem was that if you insist on a canonical<br/>&gt; optimally reduced basis, the problem is NP complete, but the trick<br/>is<br/>&gt; to relax the condition enough to get a polynomial time algorithm.<br/>It<br/>&gt; then turns out that most of the time, it gives you more than you&apos;ve<br/>&gt; proven it ought to, anyway. It&apos;s been a real breakthrough in<br/>&gt; computational math.</p><p>Well then I&apos;d like to understand the condition, and if it (for some<br/>or all choices of the parameter) has any relatively simple musical<br/>interpretation. Especially if you can hunt down the taxicab version.</p></div>