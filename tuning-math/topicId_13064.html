<a href="/tuning-math">back to list</a><h1>exploring badness</h1><h3>Carl Lumma &#x3C;ekin@lumma.org&#x3E;</h3><span>10/26/2005 10:52:05 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Cadence Research released the long-awaited Chez Scheme 7<br/>recently (<a href="http://www.scheme.com">www.scheme.com</a>), and I dusted off my single-comma<br/>badness code to celebrate.</p><p>Generally, badness has been error * complexity, and that seems<br/>good to me.  But what kind of error and complexity?  My goal was<br/>to try and define these using as few free parameters as possible,<br/>and in a way that makes sense from a composer&apos;s point of view.</p><p>The first thing I decided to do away with was the notion of<br/>harmonic limit.  While we can reasonably expect our composer to<br/>tell us what intervals she considers consonant, it doesn&apos;t seem<br/>reasonable to expect them to conform to a complete odd- or<br/>prime-limit.  Classifying temperaments based on traditional<br/>harmonic limits therefore seems too prescriptive.</p><p>As far as badness is concerned, harmonic limit has mainly been<br/>used to decide how to measure the &apos;length&apos; of a comma on the<br/>lattice.  Is a compound number like 35 one step (of 35) or<br/>two (one each of 5 and 7)?</p><p>One solution is to use log lengths, since log(n*d) is equal to<br/>the sum of the logs of the factors of n*d.  It so happens that<br/>log(n*d) is called Tenney harmonic distance.  I&apos;ll call it<br/>comma-thd for short.  Here&apos;s my Scheme procedure:</p><p>(define thd<br/>   (lambda (f)<br/>      (log2 (tenneyheight f))))<br/>(thd 225/224) -&gt; 15.621136113274641</p><p>An unweighted version of thd:</p><p>(define comma-dist<br/>   (lambda (f)<br/>      (apply + (all-vals (occurrences (factor (tenneyheight f)))))))<br/>(comma-dist 225/224) -&gt; 10</p><p>An octave-equivalent, triangular version of comma-dist (which<br/>is like Paul Hahn&apos;s &quot;diameter&quot;):</p><p>(define comma-hahn<br/>   (lambda (f)<br/>      (let<br/>         ((over (apply +<br/>                   (all-vals<br/>                      (occurrences<br/>                         (remove 2<br/>                            (factor<br/>                               (numerator f)))))))<br/>          (under (apply +<br/>                    (all-vals<br/>                       (occurrences<br/>                          (remove 2<br/>                             (factor<br/>                                (denominator f))))))))<br/>      (max over under))))<br/>(comma-hahn 225/224) -&gt; 4</p><p>A weighted version of comma-hahn:</p><p>(define comma-isosceles<br/>   (lambda (f)<br/>      (letrec ((loop<br/>                  (lambda (ls total)<br/>                     (if (null? ls)<br/>                        total<br/>                        (loop<br/>                           (cancel (cadar ls) (cdr ls))<br/>                           (+ (* (log2 (caar ls)) (abs (cadar ls)))<br/>                              total)))))<br/>               (cancel<br/>                  (lambda (exp ls)<br/>                     (cond<br/>                        [(null? ls) &apos;()]<br/>                        [(zero? exp) ls]<br/>                        [(eq? (sign exp) (sign (cadar ls)))<br/>                           (cons (car ls) (cancel exp (cdr ls)))]<br/>                        [(&lt; (abs exp) (abs (cadar ls)))<br/>                           (cons (list (caar ls) (+ exp (cadar ls)))<br/>                              (cdr ls))]<br/>                        [else (cancel (+ exp (cadar ls)) (cdr ls))]))))<br/>      (loop (reverse (monzo (remove-2s f))) 0))))<br/>(comma-isosceles 225/224) -&gt; 8.29920801838728</p><p>That brings us to error.  John deLaubenfels proposed that the<br/>amount of &quot;pain&quot; mistuning causes us is the square of the error<br/>in a simultaneity, and I agree with him.  My own listening tests<br/>indicate the exponent should be &gt; 1, and 2 is natural because<br/>it gives a nice distribution over the target.  Also, there would<br/>scarcely be a reason to temper with an exponent of 1... if we<br/>spread a 24-cent comma over 12 fifths, we&apos;d experience the same<br/>amount of pain once we heard all of them, no matter how we<br/>tempered.  But (12 * 2^2) = 48 &lt; 24^2 = 576.</p><p>So, for error I arrived at:</p><p>((cents comma)/(comma-dist comma))^2 * (comma-dist comma)</p><p>or</p><p>(cents comma)^2 / (comma-dist comma)</p><p>I use comma-dist here because I want octave-specific (allowing<br/>tempered octaves), unweighted (the available &apos;pain relief&apos; depends<br/>only on the number of intervals to temper over) distances.</p><p>Now complexity.  For Fokker blocks in JI, complexity can be<br/>defined as the number of notes in the block (I know it&apos;s possible<br/>to refactor the unison vectors of a block... can this change<br/>its volume?).  In the single-comma case, we can&apos;t guarantee a<br/>closed block, but we can estimate the comma&apos;s contribution to the<br/>volume of any block by finding the volume of the &apos;cube&apos;.</p><p>(comma-hahn comma)^(- (comma-rank comma) 1)</p><p>Here, comma-rank is simply the number of different primes needed<br/>to factor comma, which I take to be the implied dimensionality of<br/>the lattice.  I chose comma-hahn here because diagonal lengths<br/>seemed to best estimate the comma&apos;s contribution to Fokker block<br/>volume (and can be thought of as the number of dyad-preserving<br/>modulations in its pump) and because measuring a volume of &quot;notes&quot;<br/>usually implies octave-equivalence.  I subtract 1 from the rank<br/>because 2 has been removed from the lattice basis.  I don&apos;t take<br/>any steps to ensure logflat badness, because massively complex<br/>commas are musically useless.  I want my badness to eventually go<br/>high with complexity regardless of size.  This ruins some nice<br/>number-theoretical aspects of badness but frees me from having to<br/>use arbitrary, sharp bounds on complexity to keep useless commas<br/>out of my top-10 list.</p><p>*Results 1*<br/>Here are the top 10 commas &lt; 600 cents with denominators &lt; 1731.</p><p>(0.1111111111111111 1664/1663)<br/>(0.14285714285714285 1697/1696)<br/>(0.16 1409/1408)<br/>(0.18 1472/1471)<br/>(0.19599999999999998 1280/1279)<br/>(0.2016666666666667 1553/1552)<br/>(0.24 1424/1423)<br/>(0.24200000000000005 1544/1543)<br/>(0.24499999999999997 1217/1216)<br/>(0.25 1724/1723)</p><p>Lo and behold, they&apos;re all superparticulars near our maximum<br/>denominator.  That&apos;s bad (though they&apos;re not just in size order).</p><p>(comma-badness 225/224) -&gt; 379.456<br/>(comma-badness 64/63) -&gt;   745.2900000000001<br/>(comma-badness 81/80) -&gt;   821.7777777777778<br/>(comma-badness 36/35) -&gt;  3175.2533333333326<br/>(comma-badness 16/15) -&gt;  8317.926666666668<br/>(comma-badness 21/20) -&gt; 11424.4</p><p>Obviously, the complexity term needs a shot in the arm.  One<br/>way to do this would be to use weighted measures that will<br/>favor the simpler commas we&apos;re used to seeing in these lists.<br/>How much will it help?</p><p>(comma-dist 81/80) -&gt; 9<br/>(comma-dist 1664/1663) -&gt; 9</p><p>(thd 81/80) -&gt; 12.66177809777199<br/>(thd 1664/1663) -&gt; 21.40001217142836</p><p>(comma-hahn 81/80) -&gt; 4<br/>(comma-hahn 1664/1663) -&gt; 1</p><p>(comma-isosceles 81/80) -&gt; 7.076815597050832<br/>(comma-isosceles 1664/1663) -&gt; 10.699572453287269</p><p>Using a weighted measure in the error term will make things<br/>worse, but</p><p>*2*<br/>replacing comma-hahn with comma-isosceles will help.</p><p>(12.720094520349305 1664/1663)<br/>(16.443789134570917 1697/1696)<br/>(17.507382009382244 1409/1408)<br/>(19.93044997474295 1472/1471)<br/>(20.877709098079915 1280/1279)<br/>(21.460940274368443 1699/1697)<br/>(21.501413972449896 1723/1721)<br/>(22.237030720523645 1025/1024)<br/>(22.60480829291785 1601/1600)<br/>(22.662867129390435 1553/1552)</p><p>Hm, that didn&apos;t help as much as I thought it would.</p><p>(comma-badness 81/80) -&gt;   2572.23218947583<br/>(comma-badness 64/63) -&gt;   2958.6253522577035<br/>(comma-badness 225/224) -&gt; 3389.154763755284<br/>(comma-badness 16/15) -&gt;  31740.780048904246<br/>(comma-badness 36/35) -&gt;  53562.19689380825<br/>(comma-badness 21/20) -&gt; 121010.92138877488</p><p>A different and probably better ranking than the unweighted<br/>version, but the top 10 is still dominated by small commas.<br/>One point is that such commas are benefiting from their high<br/>2 exponent in the error term but not getting damaged by it<br/>in our octave-equivalent complexity term.</p><p>*3*<br/>So let&apos;s put the octaves back in to the complexity term<br/>by using plain f instead of &quot;remove-2s f&quot; in comma-isosceles,<br/>If 2 can be tempered, no reason to assume it&apos;s the interval<br/>of equivalence, eh?</p><p>...</p><p>Well it turns out that doesn&apos;t change the top 10 much, and<br/>the ranking for simpler commas was already pretty good<br/>before the change.</p><p>*4*<br/>It seems we&apos;re stuck as long as we&apos;re considering primes like<br/>1663 consonant.  Time to pull out the big guns.  We&apos;ll use<br/>the highest prime in the comma, instead of comma-rank, as the<br/>exponent in the complexity term.</p><p>(define comma-primelimit<br/>   (lambda (f)<br/>      (apply max (factor (tenneyheight f)))))</p><p>Badness is now:</p><p>(* (cents comma)^2 / (comma-dist comma)<br/>   (comma-isosceles-spec comma)^(comma-primelimit comma)</p><p>(602905.4076750558 9/8)<br/>(816040.4736314346 256/243)<br/>(1427907.8221372738 4/3)<br/>(1765367.9922481766 81/80)<br/>(3332379.266365136 32/27)<br/>(7570872.389905203 10/9)<br/>(9646486.522800893 81/64)<br/>(10784218.878497453 25/24)<br/>(13430861.561113684 6/5)<br/>(14953736.77353493 16/15)</p><p>As I feared, we&apos;ve gone too far.  Let&apos;s divide comma-primelimit<br/>by comma-rank.  This basically finds the smallest, most compound<br/>ratios.</p><p>(30.199638182549783 1716/1715)<br/>(235.22671475300302 1275/1274)<br/>(251.22205507245735 1001/1000)<br/>(270.2512143047205 715/714)<br/>(294.25699881529823 441/440)<br/>(302.9311779376435 540/539)<br/>(327.4415910954278 1156/1155)<br/>(351.06550017138903 225/224)<br/>(364.34255767758054 1540/1539)<br/>(555.3403731857843 1575/1573)</p><p>This is perhaps only interesting because of the usually low<br/>score of the top result.</p><p>I didn&apos;t get very far, but I wrote some code and I had some<br/>fun.</p><p>-Carl</p></div><h3>Gene Ward Smith &#x3C;gwsmith@svpal.org&#x3E;</h3><span>10/27/2005 12:49:53 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Carl Lumma &lt;ekin@l...&gt; wrote:</p><p>&gt; comma-thd for short.  Here&apos;s my Scheme procedure:</p><p>Normally the best way to give a definition is to give a mathematical<br/>definition. If you want to give code, the standard pseudo-code is<br/>Algol-like. Scheme is a version of Lisp, and Lisp is infamous for<br/>being an obfuscated language. I think trying to explain things using<br/>Lisp code is a bad idea.</p><p>&gt; (define thd<br/>&gt;    (lambda (f)<br/>&gt;       (log2 (tenneyheight f))))<br/>&gt; (thd 225/224) -&gt; 15.621136113274641</p><p>I would simply say this is log base 2 of the Tenney height, which is<br/>the traditional Tenney norm.</p><p>&gt; An unweighted version of thd:<br/>&gt;<br/>&gt; (define comma-dist<br/>&gt;    (lambda (f)<br/>&gt;       (apply + (all-vals (occurrences (factor (tenneyheight f)))))))<br/>&gt; (comma-dist 225/224) -&gt; 10</p><p>I&apos;d explain this also, but I don&apos;t know what it means. Log2 of the<br/>Kees height would give log2(225), which is 7.81. Why not just give a<br/>definition?</p><p>&gt; (0.1111111111111111 1664/1663)</p><p>&gt; It seems we&apos;re stuck as long as we&apos;re considering primes like<br/>&gt; 1663 consonant.</p><p>Don&apos;t look at me. From now on, you own that comma.</p><p>&gt; As I feared, we&apos;ve gone too far.  Let&apos;s divide comma-primelimit<br/>&gt; by comma-rank.  This basically finds the smallest, most compound<br/>&gt; ratios.<br/>&gt;<br/>&gt; (30.199638182549783 1716/1715)</p><p>Finally, a useful comma! But hardly a godlike comma...</p></div><h3>Carl Lumma &#x3C;ekin@lumma.org&#x3E;</h3><span>10/27/2005 1:05:48 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>&gt;&gt; comma-thd for short.  Here&apos;s my Scheme procedure:<br/>&gt;<br/>&gt;Normally the best way to give a definition is to give a mathematical<br/>&gt;definition. If you want to give code, the standard pseudo-code is<br/>&gt;Algol-like. Scheme is a version of Lisp, and Lisp is infamous for<br/>&gt;being an obfuscated language. I think trying to explain things using<br/>&gt;Lisp code is a bad idea.</p><p>I know, but hell, it&apos;s my one chance to be obscure as you are.  :)<br/>I know this is tuning-math and not tuning-lisp, but these examples<br/>are fairly simple.</p><p>&gt;&gt; (define thd<br/>&gt;&gt;    (lambda (f)<br/>&gt;&gt;       (log2 (tenneyheight f))))<br/>&gt;&gt; (thd 225/224) -&gt; 15.621136113274641<br/>&gt;<br/>&gt;I would simply say this is log base 2 of the Tenney height, which is<br/>&gt;the traditional Tenney norm.</p><p>See, you&apos;re getting the hang of it already.  :)</p><p>&gt;&gt; An unweighted version of thd:<br/>&gt;&gt;<br/>&gt;&gt; (define comma-dist<br/>&gt;&gt;    (lambda (f)<br/>&gt;&gt;       (apply + (all-vals (occurrences (factor (tenneyheight f)))))))<br/>&gt;&gt; (comma-dist 225/224) -&gt; 10<br/>&gt;<br/>&gt;I&apos;d explain this also, but I don&apos;t know what it means. Log2 of the<br/>&gt;Kees height would give log2(225), which is 7.81. Why not just give a<br/>&gt;definition?</p><p>Ach, you&apos;re probably right.  This is the sum of the abs. values<br/>of the elements in the comma&apos;s monzo.</p><p>&gt;&gt; (0.1111111111111111 1664/1663)<br/>&gt;<br/>&gt;&gt; It seems we&apos;re stuck as long as we&apos;re considering primes like<br/>&gt;&gt; 1663 consonant.<br/>&gt;<br/>&gt;Don&apos;t look at me. From now on, you own that comma.<br/>&gt;<br/>&gt;&gt; As I feared, we&apos;ve gone too far.  Let&apos;s divide comma-primelimit<br/>&gt;&gt; by comma-rank.  This basically finds the smallest, most compound<br/>&gt;&gt; ratios.<br/>&gt;&gt;<br/>&gt;&gt; (30.199638182549783 1716/1715)<br/>&gt;<br/>&gt;Finally, a useful comma! But hardly a godlike comma...</p><p>One day, I&apos;ll figure out how to make the badness roll off and<br/>give a finite list of interesting commas without separate size or<br/>error bounds (these may be needed for the computation, of course),<br/>without assuming a particular harmonic limit.</p><p>-C.</p></div><h3>Gene Ward Smith &#x3C;gwsmith@svpal.org&#x3E;</h3><span>10/27/2005 6:17:29 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Carl Lumma &lt;ekin@l...&gt; wrote:</p><p>&gt; I know, but hell, it&apos;s my one chance to be obscure as you are.  :)<br/>&gt; I know this is tuning-math and not tuning-lisp, but these examples<br/>&gt; are fairly simple.</p><p>I&apos;ve actually programmed in Lisp (though never Scheme) and I still<br/>couldn&apos;t sort it out. But at least it isn&apos;t Forth.</p><p>&gt; Ach, you&apos;re probably right.  This is the sum of the abs. values<br/>&gt; of the elements in the comma&apos;s monzo.</p><p>Do you find that particularly interesting?</p></div><h3>Carl Lumma &#x3C;ekin@lumma.org&#x3E;</h3><span>10/28/2005 2:09:32 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>&gt;&gt; I know, but hell, it&apos;s my one chance to be obscure as you are.  :)<br/>&gt;&gt; I know this is tuning-math and not tuning-lisp, but these examples<br/>&gt;&gt; are fairly simple.<br/>&gt;<br/>&gt;I&apos;ve actually programmed in Lisp (though never Scheme) and I still<br/>&gt;couldn&apos;t sort it out. But at least it isn&apos;t Forth.</p><p>I tried to make it as simple as possible.  But things like<br/>tenneyheight, factor, and others are defined in libraries I didn&apos;t<br/>show, and since you don&apos;t know how they&apos;re returning data I can<br/>see how it might be confusing.</p><p>&gt;&gt; Ach, you&apos;re probably right.  This is the sum of the abs. values<br/>&gt;&gt; of the elements in the comma&apos;s monzo.<br/>&gt;<br/>&gt;Do you find that particularly interesting?</p><p>It&apos;s what I&apos;d call unweighted Tenney Harmonic Distance.  I use<br/>it in the error term of the badness formula.  There, I think,<br/>the important thing is the number of intervals over which the<br/>error must be tempered, not the weighted length over which it<br/>must be tempered.</p><p>But I was basically just playing around with everything I<br/>could think of.</p><p>-Carl</p></div><h3>Paul Erlich &#x3C;perlich@aya.yale.edu&#x3E;</h3><span>10/31/2005 6:24:35 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Carl Lumma &lt;ekin@l...&gt; wrote:</p><p>&gt; &gt;&gt; Ach, you&apos;re probably right.  This is the sum of the abs. values<br/>&gt; &gt;&gt; of the elements in the comma&apos;s monzo.<br/>&gt; &gt;<br/>&gt; &gt;Do you find that particularly interesting?<br/>&gt;<br/>&gt; It&apos;s what I&apos;d call unweighted Tenney Harmonic Distance.  I use<br/>&gt; it in the error term of the badness formula.  There, I think,<br/>&gt; the important thing is the number of intervals over which the<br/>&gt; error must be tempered, not the weighted length over which it<br/>&gt; must be tempered.</p><p>Why can error only be tempered over primes and not over other<br/>consonances?</p></div><h3>Carl Lumma &#x3C;ekin@lumma.org&#x3E;</h3><span>11/1/2005 2:38:47 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>&gt;&gt; &gt;&gt; Ach, you&apos;re probably right.  This is the sum of the abs. values<br/>&gt;&gt; &gt;&gt; of the elements in the comma&apos;s monzo.<br/>&gt;&gt; &gt;<br/>&gt;&gt; &gt;Do you find that particularly interesting?<br/>&gt;&gt;<br/>&gt;&gt; It&apos;s what I&apos;d call unweighted Tenney Harmonic Distance.  I use<br/>&gt;&gt; it in the error term of the badness formula.  There, I think,<br/>&gt;&gt; the important thing is the number of intervals over which the<br/>&gt;&gt; error must be tempered, not the weighted length over which it<br/>&gt;&gt; must be tempered.<br/>&gt;<br/>&gt;Why can error only be tempered over primes and not over other<br/>&gt;consonances?</p><p>It will be tempered over all intervals containing those primes.</p><p>-Carl</p></div><h3>Paul Erlich &#x3C;perlich@aya.yale.edu&#x3E;</h3><span>11/1/2005 1:02:25 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Carl Lumma &lt;ekin@l...&gt; wrote:<br/>&gt;<br/>&gt; &gt;&gt; &gt;&gt; Ach, you&apos;re probably right.  This is the sum of the abs.<br/>values<br/>&gt; &gt;&gt; &gt;&gt; of the elements in the comma&apos;s monzo.<br/>&gt; &gt;&gt; &gt;<br/>&gt; &gt;&gt; &gt;Do you find that particularly interesting?<br/>&gt; &gt;&gt;<br/>&gt; &gt;&gt; It&apos;s what I&apos;d call unweighted Tenney Harmonic Distance.  I use<br/>&gt; &gt;&gt; it in the error term of the badness formula.  There, I think,<br/>&gt; &gt;&gt; the important thing is the number of intervals over which the<br/>&gt; &gt;&gt; error must be tempered, not the weighted length over which it<br/>&gt; &gt;&gt; must be tempered.<br/>&gt; &gt;<br/>&gt; &gt;Why can error only be tempered over primes and not over other<br/>&gt; &gt;consonances?<br/>&gt;<br/>&gt; It will be tempered over all intervals containing those primes.</p><p>Above you used &quot;tempered over&quot; to mean a distributing of a fixed<br/>amount of comma so as to contribute equally to several errors. Now<br/>that you say &quot;tempered over all intervals&quot;, it seems to lose that<br/>meaning. Is there something precise you mean here, or is this just a<br/>cop-out?</p></div><h3>Carl Lumma &#x3C;ekin@lumma.org&#x3E;</h3><span>11/1/2005 5:18:25 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>&gt;&gt; &gt;&gt; &gt;&gt; This is the sum of the abs. values<br/>&gt;&gt; &gt;&gt; &gt;&gt; of the elements in the comma&apos;s monzo.<br/>&gt;&gt; &gt;&gt; &gt;<br/>&gt;&gt; &gt;&gt; &gt;Do you find that particularly interesting?<br/>&gt;&gt; &gt;&gt;<br/>&gt;&gt; &gt;&gt; It&apos;s what I&apos;d call unweighted Tenney Harmonic Distance.  I use<br/>&gt;&gt; &gt;&gt; it in the error term of the badness formula.  There, I think,<br/>&gt;&gt; &gt;&gt; the important thing is the number of intervals over which the<br/>&gt;&gt; &gt;&gt; error must be tempered, not the weighted length over which it<br/>&gt;&gt; &gt;&gt; must be tempered.<br/>&gt;&gt; &gt;<br/>&gt;&gt; &gt;Why can error only be tempered over primes and not over other<br/>&gt;&gt; &gt;consonances?<br/>&gt;&gt;<br/>&gt;&gt; It will be tempered over all intervals containing those primes.<br/>&gt;<br/>&gt;Above you used &quot;tempered over&quot; to mean a distributing of a fixed<br/>&gt;amount of comma so as to contribute equally to several errors.</p><p>Yes.</p><p>&gt;Now that you say &quot;tempered over all intervals&quot;, it seems to lose that<br/>&gt;meaning. Is there something precise you mean here, or is this just a<br/>&gt;cop-out?</p><p>Eh?  If I temper the 2-axis, intervals containing 2 will be affected.</p><p>-Carl</p></div><h3>Paul Erlich &#x3C;perlich@aya.yale.edu&#x3E;</h3><span>11/3/2005 12:55:48 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Carl Lumma &lt;ekin@l...&gt; wrote:<br/>&gt;<br/>&gt; &gt;&gt; &gt;&gt; &gt;&gt; This is the sum of the abs. values<br/>&gt; &gt;&gt; &gt;&gt; &gt;&gt; of the elements in the comma&apos;s monzo.<br/>&gt; &gt;&gt; &gt;&gt; &gt;<br/>&gt; &gt;&gt; &gt;&gt; &gt;Do you find that particularly interesting?<br/>&gt; &gt;&gt; &gt;&gt;<br/>&gt; &gt;&gt; &gt;&gt; It&apos;s what I&apos;d call unweighted Tenney Harmonic Distance.  I use<br/>&gt; &gt;&gt; &gt;&gt; it in the error term of the badness formula.  There, I think,<br/>&gt; &gt;&gt; &gt;&gt; the important thing is the number of intervals over which the<br/>&gt; &gt;&gt; &gt;&gt; error must be tempered, not the weighted length over which it<br/>&gt; &gt;&gt; &gt;&gt; must be tempered.<br/>&gt; &gt;&gt; &gt;<br/>&gt; &gt;&gt; &gt;Why can error only be tempered over primes and not over other<br/>&gt; &gt;&gt; &gt;consonances?<br/>&gt; &gt;&gt;<br/>&gt; &gt;&gt; It will be tempered over all intervals containing those primes.<br/>&gt; &gt;<br/>&gt; &gt;Above you used &quot;tempered over&quot; to mean a distributing of a fixed<br/>&gt; &gt;amount of comma so as to contribute equally to several errors.<br/>&gt;<br/>&gt; Yes.<br/>&gt;<br/>&gt; &gt;Now that you say &quot;tempered over all intervals&quot;, it seems to lose<br/>that<br/>&gt; &gt;meaning. Is there something precise you mean here, or is this just<br/>a<br/>&gt; &gt;cop-out?<br/>&gt;<br/>&gt; Eh?  If I temper the 2-axis, intervals containing 2 will be<br/>affected.</p><p>Clearly. How is that different from &quot;tempering over primes?&quot;</p></div><h3>Carl Lumma &#x3C;ekin@lumma.org&#x3E;</h3><span>11/3/2005 2:47:12 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>&gt;&gt; &gt;&gt; &gt;&gt; &gt;&gt; This is the sum of the abs. values<br/>&gt;&gt; &gt;&gt; &gt;&gt; &gt;&gt; of the elements in the comma&apos;s monzo.<br/>&gt;&gt; &gt;&gt; &gt;&gt; &gt;<br/>&gt;&gt; &gt;&gt; &gt;&gt; &gt;Do you find that particularly interesting?<br/>&gt;&gt; &gt;&gt; &gt;&gt;<br/>&gt;&gt; &gt;&gt; &gt;&gt; It&apos;s what I&apos;d call unweighted Tenney Harmonic Distance.  I use<br/>&gt;&gt; &gt;&gt; &gt;&gt; it in the error term of the badness formula.  There, I think,<br/>&gt;&gt; &gt;&gt; &gt;&gt; the important thing is the number of intervals over which the<br/>&gt;&gt; &gt;&gt; &gt;&gt; error must be tempered, not the weighted length over which it<br/>&gt;&gt; &gt;&gt; &gt;&gt; must be tempered.<br/>&gt;&gt; &gt;&gt; &gt;<br/>&gt;&gt; &gt;&gt; &gt;Why can error only be tempered over primes and not over other<br/>&gt;&gt; &gt;&gt; &gt;consonances?<br/>&gt;&gt; &gt;&gt;<br/>&gt;&gt; &gt;&gt; It will be tempered over all intervals containing those primes.<br/>&gt;&gt; &gt;<br/>&gt;&gt; &gt;Above you used &quot;tempered over&quot; to mean a distributing of a fixed<br/>&gt;&gt; &gt;amount of comma so as to contribute equally to several errors.<br/>&gt;&gt;<br/>&gt;&gt; Yes.<br/>&gt;&gt;<br/>&gt;&gt; &gt;Now that you say &quot;tempered over all intervals&quot;, it seems to lose<br/>&gt;&gt; &gt;that meaning. Is there something precise you mean here, or is this<br/>&gt;&gt; &gt;just a cop-out?<br/>&gt;&gt;<br/>&gt;&gt;Eh?  If I temper the 2-axis, intervals containing 2 will be<br/>&gt;&gt;affected.<br/>&gt;<br/>&gt;Clearly. How is that different from &quot;tempering over primes?&quot;</p><p>The only question I&apos;m trying to answer here is: When is it<br/>appropriate to use one-factor (rectangular) measures vs.<br/>two-factor (triangular) ones?</p><p>-Carl</p></div><h3>Paul Erlich &#x3C;perlich@aya.yale.edu&#x3E;</h3><span>11/3/2005 3:22:15 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Carl Lumma &lt;ekin@l...&gt; wrote:<br/>&gt;<br/>&gt; &gt;&gt; &gt;&gt; &gt;&gt; &gt;&gt; This is the sum of the abs. values<br/>&gt; &gt;&gt; &gt;&gt; &gt;&gt; &gt;&gt; of the elements in the comma&apos;s monzo.<br/>&gt; &gt;&gt; &gt;&gt; &gt;&gt; &gt;<br/>&gt; &gt;&gt; &gt;&gt; &gt;&gt; &gt;Do you find that particularly interesting?<br/>&gt; &gt;&gt; &gt;&gt; &gt;&gt;<br/>&gt; &gt;&gt; &gt;&gt; &gt;&gt; It&apos;s what I&apos;d call unweighted Tenney Harmonic Distance.  I<br/>use<br/>&gt; &gt;&gt; &gt;&gt; &gt;&gt; it in the error term of the badness formula.  There, I<br/>think,<br/>&gt; &gt;&gt; &gt;&gt; &gt;&gt; the important thing is the number of intervals over which<br/>the<br/>&gt; &gt;&gt; &gt;&gt; &gt;&gt; error must be tempered, not the weighted length over which<br/>it<br/>&gt; &gt;&gt; &gt;&gt; &gt;&gt; must be tempered.<br/>&gt; &gt;&gt; &gt;&gt; &gt;<br/>&gt; &gt;&gt; &gt;&gt; &gt;Why can error only be tempered over primes and not over<br/>other<br/>&gt; &gt;&gt; &gt;&gt; &gt;consonances?<br/>&gt; &gt;&gt; &gt;&gt;<br/>&gt; &gt;&gt; &gt;&gt; It will be tempered over all intervals containing those<br/>primes.<br/>&gt; &gt;&gt; &gt;<br/>&gt; &gt;&gt; &gt;Above you used &quot;tempered over&quot; to mean a distributing of a<br/>fixed<br/>&gt; &gt;&gt; &gt;amount of comma so as to contribute equally to several errors.<br/>&gt; &gt;&gt;<br/>&gt; &gt;&gt; Yes.<br/>&gt; &gt;&gt;<br/>&gt; &gt;&gt; &gt;Now that you say &quot;tempered over all intervals&quot;, it seems to lose<br/>&gt; &gt;&gt; &gt;that meaning. Is there something precise you mean here, or is<br/>this<br/>&gt; &gt;&gt; &gt;just a cop-out?<br/>&gt; &gt;&gt;<br/>&gt; &gt;&gt;Eh?  If I temper the 2-axis, intervals containing 2 will be<br/>&gt; &gt;&gt;affected.<br/>&gt; &gt;<br/>&gt; &gt;Clearly. How is that different from &quot;tempering over primes?&quot;<br/>&gt;<br/>&gt; The only question I&apos;m trying to answer here is: When is it<br/>&gt; appropriate to use one-factor (rectangular) measures vs.<br/>&gt; two-factor (triangular) ones?</p><p>As for rectangular vs. triangular, I&apos;ve tried to answer that by<br/>saying the geometry in each case comes from making the distance<br/>measure agree as well as possible with a Euclidean sphere. I have no<br/>idea what one-factor vs. two-factor means, or why you equate these to<br/>rectangular vs. triangular.</p></div><h3>Carl Lumma &#x3C;ekin@lumma.org&#x3E;</h3><span>11/3/2005 4:05:49 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>&gt;&gt; The only question I&apos;m trying to answer here is: When is it<br/>&gt;&gt; appropriate to use one-factor (rectangular) measures vs.<br/>&gt;&gt; two-factor (triangular) ones?<br/>&gt;<br/>&gt;As for rectangular vs. triangular, I&apos;ve tried to answer that by<br/>&gt;saying the geometry in each case comes from making the distance<br/>&gt;measure agree as well as possible with a Euclidean sphere. I have no<br/>&gt;idea what one-factor vs. two-factor means, or why you equate these to<br/>&gt;rectangular vs. triangular.</p><p>Unit motions on a triangular lattice remove a pair of factors.<br/>&quot;                &quot; rect.     &quot;             &quot; a single factor.</p><p>-Carl</p></div><h3>Paul Erlich &#x3C;perlich@aya.yale.edu&#x3E;</h3><span>11/4/2005 3:08:12 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Carl Lumma &lt;ekin@l...&gt; wrote:<br/>&gt;<br/>&gt; &gt;&gt; The only question I&apos;m trying to answer here is: When is it<br/>&gt; &gt;&gt; appropriate to use one-factor (rectangular) measures vs.<br/>&gt; &gt;&gt; two-factor (triangular) ones?<br/>&gt; &gt;<br/>&gt; &gt;As for rectangular vs. triangular, I&apos;ve tried to answer that by<br/>&gt; &gt;saying the geometry in each case comes from making the distance<br/>&gt; &gt;measure agree as well as possible with a Euclidean sphere. I have no<br/>&gt; &gt;idea what one-factor vs. two-factor means, or why you equate these<br/>to<br/>&gt; &gt;rectangular vs. triangular.<br/>&gt;<br/>&gt; Unit motions on a triangular lattice remove a pair of factors.</p><p>How do you get &quot;remove&quot;?</p><p>&gt; &quot;                &quot; rect.     &quot;             &quot; a single factor.</p><p>Ditto.</p><p>And aren&apos;t there some unit motions on a triangular lattice<br/>that &quot;remove&quot; a single factor, if you&apos;re not counting 1 as a factor?</p></div><h3>Carl Lumma &#x3C;ekin@lumma.org&#x3E;</h3><span>11/9/2005 4:28:13 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>&gt;&gt; &gt;&gt; The only question I&apos;m trying to answer here is: When is it<br/>&gt;&gt; &gt;&gt; appropriate to use one-factor (rectangular) measures vs.<br/>&gt;&gt; &gt;&gt; two-factor (triangular) ones?<br/>&gt;&gt; &gt;<br/>&gt;&gt; &gt;As for rectangular vs. triangular, I&apos;ve tried to answer that by<br/>&gt;&gt; &gt;saying the geometry in each case comes from making the distance<br/>&gt;&gt; &gt;measure agree as well as possible with a Euclidean sphere. I have no<br/>&gt;&gt; &gt;idea what one-factor vs. two-factor means, or why you equate these<br/>&gt;to<br/>&gt;&gt; &gt;rectangular vs. triangular.<br/>&gt;&gt;<br/>&gt;&gt; Unit motions on a triangular lattice remove a pair of factors.<br/>&gt;<br/>&gt;How do you get &quot;remove&quot;?</p><p>Another way of saying &quot;factor out&quot;.</p><p>&gt;&gt; &quot;                &quot; rect.     &quot;             &quot; a single factor.<br/>&gt;<br/>&gt;Ditto.<br/>&gt;<br/>&gt;And aren&apos;t there some unit motions on a triangular lattice<br/>&gt;that &quot;remove&quot; a single factor, if you&apos;re not counting 1 as a factor?</p><p>Yes. I should have said &quot;up to a pair&quot; I guess.</p><p>-Carl</p></div><h3>Paul Erlich &#x3C;perlich@aya.yale.edu&#x3E;</h3><span>11/10/2005 2:12:38 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Carl Lumma &lt;ekin@l...&gt; wrote:<br/>&gt;<br/>&gt; &gt;&gt; &gt;&gt; The only question I&apos;m trying to answer here is: When is it<br/>&gt; &gt;&gt; &gt;&gt; appropriate to use one-factor (rectangular) measures vs.<br/>&gt; &gt;&gt; &gt;&gt; two-factor (triangular) ones?<br/>&gt; &gt;&gt; &gt;<br/>&gt; &gt;&gt; &gt;As for rectangular vs. triangular, I&apos;ve tried to answer that by<br/>&gt; &gt;&gt; &gt;saying the geometry in each case comes from making the distance<br/>&gt; &gt;&gt; &gt;measure agree as well as possible with a Euclidean sphere. I<br/>have no<br/>&gt; &gt;&gt; &gt;idea what one-factor vs. two-factor means, or why you equate<br/>these<br/>&gt; &gt;to<br/>&gt; &gt;&gt; &gt;rectangular vs. triangular.<br/>&gt; &gt;&gt;<br/>&gt; &gt;&gt; Unit motions on a triangular lattice remove a pair of factors.<br/>&gt; &gt;<br/>&gt; &gt;How do you get &quot;remove&quot;?<br/>&gt;<br/>&gt; Another way of saying &quot;factor out&quot;.</p><p>Or &quot;factor in&quot;, right?</p><p>&gt; &gt;&gt; &quot;                &quot; rect.     &quot;             &quot; a single factor.<br/>&gt; &gt;<br/>&gt; &gt;Ditto.<br/>&gt; &gt;<br/>&gt; &gt;And aren&apos;t there some unit motions on a triangular lattice<br/>&gt; &gt;that &quot;remove&quot; a single factor, if you&apos;re not counting 1 as a<br/>factor?<br/>&gt;<br/>&gt; Yes. I should have said &quot;up to a pair&quot; I guess.</p><p>So where does this leave us?</p><p>:)</p></div><h3>Carl Lumma &#x3C;ekin@lumma.org&#x3E;</h3><span>11/10/2005 9:48:35 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>&gt;&gt; &gt;&gt; &gt;&gt; The only question I&apos;m trying to answer here is: When is it<br/>&gt;&gt; &gt;&gt; &gt;&gt; appropriate to use one-factor (rectangular) measures vs.<br/>&gt;&gt; &gt;&gt; &gt;&gt; two-factor (triangular) ones?<br/>&gt;&gt; &gt;&gt; &gt;<br/>&gt;&gt; &gt;&gt; &gt;As for rectangular vs. triangular, I&apos;ve tried to answer that by<br/>&gt;&gt; &gt;&gt; &gt;saying the geometry in each case comes from making the distance<br/>&gt;&gt; &gt;&gt; &gt;measure agree as well as possible with a Euclidean sphere.<br/>//<br/>&gt;&gt; &gt;&gt; Unit motions on a triangular lattice remove a pair of factors.<br/>&gt;&gt; &gt;<br/>&gt;&gt; &gt;How do you get &quot;remove&quot;?<br/>&gt;&gt;<br/>&gt;&gt; Another way of saying &quot;factor out&quot;.<br/>&gt;<br/>&gt;Or &quot;factor in&quot;, right?</p><p>I think so.</p><p>&gt;&gt; &gt;&gt; &quot;                &quot; rect.     &quot;             &quot; a single factor.<br/>&gt;&gt; &gt;<br/>&gt;&gt; &gt;Ditto.<br/>&gt;&gt; &gt;<br/>&gt;&gt; &gt;And aren&apos;t there some unit motions on a triangular lattice<br/>&gt;&gt; &gt;that &quot;remove&quot; a single factor, if you&apos;re not counting 1 as a<br/>&gt;factor?<br/>&gt;&gt;<br/>&gt;&gt; Yes. I should have said &quot;up to a pair&quot; I guess.<br/>&gt;<br/>&gt;So where does this leave us?<br/>&gt;<br/>&gt;:)</p><p>I&apos;m not sure.  Wait, there&apos;s a question at the very top of this<br/>message.  Maybe you can lay down a definition precise def. of<br/>how to make &quot;the distance agree as well as possible with a Euclidean<br/>sphere&quot;, since that&apos;s what I tried to do.</p><p>-Carl</p></div><h3>Paul Erlich &#x3C;perlich@aya.yale.edu&#x3E;</h3><span>11/14/2005 12:58:02 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Carl Lumma &lt;ekin@l...&gt; wrote:</p><p>&gt; I&apos;m not sure.  Wait, there&apos;s a question at the very top of this<br/>&gt; message.  Maybe you can lay down a definition precise def. of<br/>&gt; how to make &quot;the distance agree as well as possible with a Euclidean<br/>&gt; sphere&quot;, since that&apos;s what I tried to do.</p><p>I guess it means that the ball is represented in Euclidean space in<br/>such a way that it has as many of the symmetries of the sphere as<br/>possible. A regular hexagon has more of the rotational and mirror<br/>symmetries of the circle than any other hexagon.</p></div><h3>Carl Lumma &#x3C;ekin@lumma.org&#x3E;</h3><span>11/14/2005 1:02:56 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>&gt;&gt; I&apos;m not sure.  Wait, there&apos;s a question at the very top of this<br/>&gt;&gt; message.  Maybe you can lay down a definition precise def. of<br/>&gt;&gt; how to make &quot;the distance agree as well as possible with a Euclidean<br/>&gt;&gt; sphere&quot;, since that&apos;s what I tried to do.<br/>&gt;<br/>&gt;I guess it means that the ball is represented in Euclidean space in<br/>&gt;such a way that it has as many of the symmetries of the sphere as<br/>&gt;possible. A regular hexagon has more of the rotational and mirror<br/>&gt;symmetries of the circle than any other hexagon.</p><p>That&apos;s a good thought.</p><p>-Carl</p></div>