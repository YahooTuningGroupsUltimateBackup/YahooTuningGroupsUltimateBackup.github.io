<a href="/tuning-math">back to list</a><h1>Re: further comparisons of well temperaments</h1><h3><a id=12547 href="#12547">ðŸ”—</a>Carl Lumma &#x3C;ekin@lumma.org&#x3E;</h3><span>8/29/2005 4:23:50 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>[see...</p><p><a href="http://launch.groups.yahoo.com/group/tuning/message/59914">http://launch.groups.yahoo.com/group/tuning/message/59914</a></p><p>...]</p><p>&gt; &gt; &gt; &gt; I wanted to implement Absolute TOP error, but the Excel<br/>&gt; &gt; &gt; &gt; formulas got to be unwieldy, as I&apos;d seemingly have to use<br/>&gt; &gt; &gt; &gt; if statements to avoid catastrophe wherever the error<br/>&gt; &gt; &gt; &gt; from JI was zero.<br/>&gt; &gt; &gt;<br/>&gt; &gt; &gt; Why is that? Just use max(abs(...),abs(...),abs(...),...) and<br/>&gt; &gt; &gt; there should be no catastrophe. Of course, there&apos;s still a<br/>&gt; &gt; &gt; question as to what abs terms should be in this expression,<br/>&gt; &gt; &gt; but I would think you&apos;d probably be evaluating a particular<br/>&gt; &gt; &gt; triad so there should be three terms(?) . . .<br/>&gt; &gt;<br/>&gt; &gt; For ATE you need to do logs of errors.  When the errors are<br/>&gt; &gt; zero, Excel&apos;s log function blows up.<br/>&gt;<br/>&gt; My guess is that you&apos;re doing something wrong. What is the formula<br/>&gt; you&apos;re trying to use exactly? You shouldn&apos;t be taking the log of<br/>&gt; anything with units of cents, and on your current spreadsheet it<br/>&gt; doesn&apos;t seem you are.</p><p>I&apos;m not doing ATE, but I wanted to.  For that, you take the<br/>base n*d log of the error, right?</p><p>&gt; &gt; This reminds me that I never liked the minimax nature of<br/>&gt; &gt; TOP.  It&apos;s because...<br/>&gt; &gt;<br/>&gt; &gt; 3 3 3<br/>&gt; &gt; mean = 3<br/>&gt; &gt; max = 3<br/>&gt; &gt;<br/>&gt; &gt; 0 0 9<br/>&gt; &gt; mean = 3<br/>&gt; &gt; max = 9<br/>&gt; &gt;<br/>&gt; &gt; ...I think mean is closer to the truth here than max.  Though<br/>&gt; &gt; I&apos;m not aware of this ever having been established with a<br/>&gt; &gt; listening test.<br/>&gt;<br/>&gt; If you advocate the mean (or the sum, which amounts to the<br/>&gt; same thing as regards tuning comparisons), then you&apos;re<br/>&gt; advocating P=1.  Meanwhile, Gene&apos;s &quot;poptimal&quot; is based on<br/>&gt; a range 2&lt;=P&lt;=infinity.  Another reason for Gene to reconsider?</p><p>I&apos;ve always agreed with John deLaubenfels that errors seem to<br/>get worse with the square of their size.  So I think I&apos;m a P=2<br/>guy.  But it&apos;d be great to get some tetrads and triads to<br/>try to compare infinity with a low P.  It&apos;s not immediately<br/>obvious to me how to calculate examples like 009 vs. 333 since<br/>the pairwise errors in a chord are not independent.</p><p>&gt; The nice thing about minimax, though, is that once you&apos;ve<br/>&gt; established it over the intervals in a tuning system, you<br/>&gt; know that the minimax for any particular chords in the<br/>&gt; tuning system will be less than or equal to the tuning&apos;s<br/>&gt; minimax.  Not so for mean or for any intermediate value<br/>&gt; of P.</p><p>Ok, that&apos;s a key point.  However, isn&apos;t the &quot;tuning&apos;s minimax&quot;<br/>here just another &quot;particular chord&quot;, ultimately?  It&apos;s nice<br/>to think of JI as a lattice, where none of the weighted errors<br/>exceeds a certain bound.  I agree that&apos;s nice.  But really it<br/>seems that only the primary intervals matter... yes, I suppose<br/>mean says that a subset of your basic chord could be worse<br/>than the entire basic chord.  That&apos;s a pain in the butt, but<br/>what if it corresponds to reality?  I dunno, I hate to dig up<br/>the error thing, but it never sat quite right with me.  I<br/>know Gene and Graham have delivered TOP-like results based on<br/>RMS... I never took the time to see what those were like.</p><p>-Carl</p></div><h3><a id=12549 href="#12549">ðŸ”—</a>Paul Erlich &#x3C;perlich@aya.yale.edu&#x3E;</h3><span>8/29/2005 4:37:21 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Carl Lumma &lt;ekin@l...&gt; wrote:<br/>&gt; [see...<br/>&gt;<br/>&gt; <a href="http://launch.groups.yahoo.com/group/tuning/message/59914">http://launch.groups.yahoo.com/group/tuning/message/59914</a><br/>&gt;<br/>&gt; ...]<br/>&gt;<br/>&gt; &gt; &gt; &gt; &gt; I wanted to implement Absolute TOP error, but the Excel<br/>&gt; &gt; &gt; &gt; &gt; formulas got to be unwieldy, as I&apos;d seemingly have to use<br/>&gt; &gt; &gt; &gt; &gt; if statements to avoid catastrophe wherever the error<br/>&gt; &gt; &gt; &gt; &gt; from JI was zero.<br/>&gt; &gt; &gt; &gt;<br/>&gt; &gt; &gt; &gt; Why is that? Just use max(abs(...),abs(...),abs(...),...) and<br/>&gt; &gt; &gt; &gt; there should be no catastrophe. Of course, there&apos;s still a<br/>&gt; &gt; &gt; &gt; question as to what abs terms should be in this expression,<br/>&gt; &gt; &gt; &gt; but I would think you&apos;d probably be evaluating a particular<br/>&gt; &gt; &gt; &gt; triad so there should be three terms(?) . . .<br/>&gt; &gt; &gt;<br/>&gt; &gt; &gt; For ATE you need to do logs of errors.  When the errors are<br/>&gt; &gt; &gt; zero, Excel&apos;s log function blows up.<br/>&gt; &gt;<br/>&gt; &gt; My guess is that you&apos;re doing something wrong. What is the<br/>formula<br/>&gt; &gt; you&apos;re trying to use exactly? You shouldn&apos;t be taking the log of<br/>&gt; &gt; anything with units of cents, and on your current spreadsheet it<br/>&gt; &gt; doesn&apos;t seem you are.<br/>&gt;<br/>&gt; I&apos;m not doing ATE, but I wanted to.  For that, you take the<br/>&gt; base n*d log of the error, right?</p><p>Maybe I don&apos;t know what you mean. What are you proposing, exactly,<br/>and how does it differ from TOP or what you did on your spreadsheet?</p><p>&gt; &gt; &gt; This reminds me that I never liked the minimax nature of<br/>&gt; &gt; &gt; TOP.  It&apos;s because...<br/>&gt; &gt; &gt;<br/>&gt; &gt; &gt; 3 3 3<br/>&gt; &gt; &gt; mean = 3<br/>&gt; &gt; &gt; max = 3<br/>&gt; &gt; &gt;<br/>&gt; &gt; &gt; 0 0 9<br/>&gt; &gt; &gt; mean = 3<br/>&gt; &gt; &gt; max = 9<br/>&gt; &gt; &gt;<br/>&gt; &gt; &gt; ...I think mean is closer to the truth here than max.  Though<br/>&gt; &gt; &gt; I&apos;m not aware of this ever having been established with a<br/>&gt; &gt; &gt; listening test.<br/>&gt; &gt;<br/>&gt; &gt; If you advocate the mean (or the sum, which amounts to the<br/>&gt; &gt; same thing as regards tuning comparisons), then you&apos;re<br/>&gt; &gt; advocating P=1.  Meanwhile, Gene&apos;s &quot;poptimal&quot; is based on<br/>&gt; &gt; a range 2&lt;=P&lt;=infinity.  Another reason for Gene to reconsider?<br/>&gt;<br/>&gt; I&apos;ve always agreed with John deLaubenfels that errors seem to<br/>&gt; get worse with the square of their size.  So I think I&apos;m a P=2<br/>&gt; guy.</p><p>Not necessarily. These are separate issues. If you agree with John<br/>deLaubenfels, you might square the final result of the calculation<br/>regardless of what P is. But P only tells you about how to assess the<br/>combined impact of different coexisting errors, and not at all about<br/>how to compare one set of errors with another set that&apos;s x times as<br/>large.</p><p>&gt; But it&apos;d be great to get some tetrads and triads to<br/>&gt; try to compare infinity with a low P.  It&apos;s not immediately<br/>&gt; obvious to me how to calculate examples like 009 vs. 333 since<br/>&gt; the pairwise errors in a chord are not independent.</p><p>So what?</p><p>&gt; &gt; The nice thing about minimax, though, is that once you&apos;ve<br/>&gt; &gt; established it over the intervals in a tuning system, you<br/>&gt; &gt; know that the minimax for any particular chords in the<br/>&gt; &gt; tuning system will be less than or equal to the tuning&apos;s<br/>&gt; &gt; minimax.  Not so for mean or for any intermediate value<br/>&gt; &gt; of P.<br/>&gt;<br/>&gt; Ok, that&apos;s a key point.  However, isn&apos;t the &quot;tuning&apos;s minimax&quot;<br/>&gt; here just another &quot;particular chord&quot;, ultimately?  It&apos;s nice<br/>&gt; to think of JI as a lattice, where none of the weighted errors<br/>&gt; exceeds a certain bound.  I agree that&apos;s nice.  But really it<br/>&gt; seems that only the primary intervals matter...</p><p>Meaning n*d &lt; 100, or something like that?</p><p>&gt; yes, I suppose<br/>&gt; mean says that a subset of your basic chord could be worse<br/>&gt; than the entire basic chord.</p><p>Well, something along those lines, at any rate.</p><p>&gt; That&apos;s a pain in the butt, but<br/>&gt; what if it corresponds to reality?</p><p>It certainly might.</p><p>&gt; I dunno, I hate to dig up<br/>&gt; the error thing, but it never sat quite right with me.  I<br/>&gt; know Gene and Graham have delivered TOP-like results based on<br/>&gt; RMS... I never took the time to see what those were like.</p><p>I know Graham did but I don&apos;t recall Gene getting involved.<br/>Meanwhile, I would have imagined an RMS (or sum-squared) version of<br/>Kees tuning (this is another interesting case to consider) would<br/>amount to circles replacing the hexagons in the chart I keep showing,<br/>and spheres replacing rhombic dodecahedra in a 7-limit version, but<br/>Gene seems to be implying I&apos;m wrong about the latter.</p></div><h3><a id=12551 href="#12551">ðŸ”—</a>Carl Lumma &#x3C;ekin@lumma.org&#x3E;</h3><span>8/29/2005 4:53:01 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>&gt;&gt; [see...<br/>&gt;&gt;<br/>&gt;&gt; <a href="http://launch.groups.yahoo.com/group/tuning/message/59914">http://launch.groups.yahoo.com/group/tuning/message/59914</a><br/>&gt;&gt;<br/>&gt;&gt; ...]<br/>&gt;&gt;<br/>&gt;&gt; &gt; &gt; &gt; &gt; I wanted to implement Absolute TOP error, but the Excel<br/>&gt;&gt; &gt; &gt; &gt; &gt; formulas got to be unwieldy, as I&apos;d seemingly have to use<br/>&gt;&gt; &gt; &gt; &gt; &gt; if statements to avoid catastrophe wherever the error<br/>&gt;&gt; &gt; &gt; &gt; &gt; from JI was zero.<br/>&gt;&gt; &gt; &gt; &gt;<br/>&gt;&gt; &gt; &gt; &gt; Why is that? Just use max(abs(...),abs(...),abs(...),...) and<br/>&gt;&gt; &gt; &gt; &gt; there should be no catastrophe. Of course, there&apos;s still a<br/>&gt;&gt; &gt; &gt; &gt; question as to what abs terms should be in this expression,<br/>&gt;&gt; &gt; &gt; &gt; but I would think you&apos;d probably be evaluating a particular<br/>&gt;&gt; &gt; &gt; &gt; triad so there should be three terms(?) . . .<br/>&gt;&gt; &gt; &gt;<br/>&gt;&gt; &gt; &gt; For ATE you need to do logs of errors.  When the errors are<br/>&gt;&gt; &gt; &gt; zero, Excel&apos;s log function blows up.<br/>&gt;&gt; &gt;<br/>&gt;&gt; &gt; My guess is that you&apos;re doing something wrong. What is the<br/>&gt;&gt; &gt; formula you&apos;re trying to use exactly? You shouldn&apos;t be taking<br/>&gt;&gt; &gt; the log of anything with units of cents, and on your current<br/>&gt;&gt; &gt; spreadsheet it doesn&apos;t seem you are.<br/>&gt;&gt;<br/>&gt;&gt; I&apos;m not doing ATE, but I wanted to.  For that, you take the<br/>&gt;&gt; base n*d log of the error, right?<br/>&gt;<br/>&gt;Maybe I don&apos;t know what you mean. What are you proposing, exactly,<br/>&gt;and how does it differ from TOP or what you did on your spreadsheet?</p><p><a href="http://groups.yahoo.com/group/tuning-math/message/10579">http://groups.yahoo.com/group/tuning-math/message/10579</a></p><p>...I think I parsed this right.</p><p>&gt;&gt; &gt; &gt; This reminds me that I never liked the minimax nature of<br/>&gt;&gt; &gt; &gt; TOP.  It&apos;s because...<br/>&gt;&gt; &gt; &gt;<br/>&gt;&gt; &gt; &gt; 3 3 3<br/>&gt;&gt; &gt; &gt; mean = 3<br/>&gt;&gt; &gt; &gt; max = 3<br/>&gt;&gt; &gt; &gt;<br/>&gt;&gt; &gt; &gt; 0 0 9<br/>&gt;&gt; &gt; &gt; mean = 3<br/>&gt;&gt; &gt; &gt; max = 9<br/>&gt;&gt; &gt; &gt;<br/>&gt;&gt; &gt; &gt; ...I think mean is closer to the truth here than max.  Though<br/>&gt;&gt; &gt; &gt; I&apos;m not aware of this ever having been established with a<br/>&gt;&gt; &gt; &gt; listening test.<br/>&gt;&gt; &gt;<br/>&gt;&gt; &gt; If you advocate the mean (or the sum, which amounts to the<br/>&gt;&gt; &gt; same thing as regards tuning comparisons), then you&apos;re<br/>&gt;&gt; &gt; advocating P=1.  Meanwhile, Gene&apos;s &quot;poptimal&quot; is based on<br/>&gt;&gt; &gt; a range 2&lt;=P&lt;=infinity.  Another reason for Gene to reconsider?<br/>&gt;&gt;<br/>&gt;&gt; I&apos;ve always agreed with John deLaubenfels that errors seem to<br/>&gt;&gt; get worse with the square of their size.  So I think I&apos;m a P=2<br/>&gt;&gt; guy.<br/>&gt;<br/>&gt;Not necessarily. These are separate issues. If you agree with John<br/>&gt;deLaubenfels, you might square the final result of the calculation<br/>&gt;regardless of what P is. But P only tells you about how to assess the<br/>&gt;combined impact of different coexisting errors, and not at all about<br/>&gt;how to compare one set of errors with another set that&apos;s x times as<br/>&gt;large.</p><p>Aha.  Very good to know.</p><p>&gt;&gt; But it&apos;d be great to get some tetrads and triads to<br/>&gt;&gt; try to compare infinity with a low P.  It&apos;s not immediately<br/>&gt;&gt; obvious to me how to calculate examples like 009 vs. 333 since<br/>&gt;&gt; the pairwise errors in a chord are not independent.<br/>&gt;<br/>&gt;So what?</p><p>I don&apos;t know how to easily generate test cases given this<br/>constraint.  If I could, I&apos;d listen to them.</p><p>&gt;&gt; &gt; The nice thing about minimax, though, is that once you&apos;ve<br/>&gt;&gt; &gt; established it over the intervals in a tuning system, you<br/>&gt;&gt; &gt; know that the minimax for any particular chords in the<br/>&gt;&gt; &gt; tuning system will be less than or equal to the tuning&apos;s<br/>&gt;&gt; &gt; minimax.  Not so for mean or for any intermediate value<br/>&gt;&gt; &gt; of P.<br/>&gt;&gt;<br/>&gt;&gt; Ok, that&apos;s a key point.  However, isn&apos;t the &quot;tuning&apos;s minimax&quot;<br/>&gt;&gt; here just another &quot;particular chord&quot;, ultimately?  It&apos;s nice<br/>&gt;&gt; to think of JI as a lattice, where none of the weighted errors<br/>&gt;&gt; exceeds a certain bound.  I agree that&apos;s nice.  But really it<br/>&gt;&gt; seems that only the primary intervals matter...<br/>&gt;<br/>&gt;Meaning n*d &lt; 100, or something like that?</p><p>Say you&apos;ve got an m-limit TOP tuning, I&apos;d call the &quot;primary<br/>intervals&quot; the n-odd-limit intervals where n is the smallest<br/>odd number &gt; m.</p><p>&gt;&gt; yes, I suppose<br/>&gt;&gt; mean says that a subset of your basic chord could be worse<br/>&gt;&gt; than the entire basic chord.<br/>&gt;<br/>&gt;Well, something along those lines, at any rate.<br/>&gt;<br/>&gt;&gt; That&apos;s a pain in the butt, but<br/>&gt;&gt; what if it corresponds to reality?<br/>&gt;<br/>&gt;It certainly might.<br/>&gt;<br/>&gt;&gt; I dunno, I hate to dig up<br/>&gt;&gt; the error thing, but it never sat quite right with me.  I<br/>&gt;&gt; know Gene and Graham have delivered TOP-like results based on<br/>&gt;&gt; RMS... I never took the time to see what those were like.<br/>&gt;<br/>&gt;I know Graham did but I don&apos;t recall Gene getting involved.<br/>&gt;Meanwhile, I would have imagined an RMS (or sum-squared) version of<br/>&gt;Kees tuning (this is another interesting case to consider) would<br/>&gt;amount to circles replacing the hexagons in the chart I keep showing,<br/>&gt;and spheres replacing rhombic dodecahedra in a 7-limit version, but<br/>&gt;Gene seems to be implying I&apos;m wrong about the latter.</p><p>I need to review the IM discussion we had about the Kees lattice...<br/>it&apos;s on my desktop in my to-do pile.</p><p>-Carl</p></div><h3><a id=12556 href="#12556">ðŸ”—</a>Paul Erlich &#x3C;perlich@aya.yale.edu&#x3E;</h3><span>8/29/2005 6:03:45 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Carl Lumma &lt;ekin@l...&gt; wrote:<br/>&gt; &gt;&gt; [see...<br/>&gt; &gt;&gt;<br/>&gt; &gt;&gt; <a href="http://launch.groups.yahoo.com/group/tuning/message/59914">http://launch.groups.yahoo.com/group/tuning/message/59914</a><br/>&gt; &gt;&gt;<br/>&gt; &gt;&gt; ...]<br/>&gt; &gt;&gt;<br/>&gt; &gt;&gt; &gt; &gt; &gt; &gt; I wanted to implement Absolute TOP error, but the Excel<br/>&gt; &gt;&gt; &gt; &gt; &gt; &gt; formulas got to be unwieldy, as I&apos;d seemingly have to use<br/>&gt; &gt;&gt; &gt; &gt; &gt; &gt; if statements to avoid catastrophe wherever the error<br/>&gt; &gt;&gt; &gt; &gt; &gt; &gt; from JI was zero.<br/>&gt; &gt;&gt; &gt; &gt; &gt;<br/>&gt; &gt;&gt; &gt; &gt; &gt; Why is that? Just use max(abs(...),abs(...),abs(...),...)<br/>and<br/>&gt; &gt;&gt; &gt; &gt; &gt; there should be no catastrophe. Of course, there&apos;s still a<br/>&gt; &gt;&gt; &gt; &gt; &gt; question as to what abs terms should be in this expression,<br/>&gt; &gt;&gt; &gt; &gt; &gt; but I would think you&apos;d probably be evaluating a particular<br/>&gt; &gt;&gt; &gt; &gt; &gt; triad so there should be three terms(?) . . .<br/>&gt; &gt;&gt; &gt; &gt;<br/>&gt; &gt;&gt; &gt; &gt; For ATE you need to do logs of errors.  When the errors are<br/>&gt; &gt;&gt; &gt; &gt; zero, Excel&apos;s log function blows up.<br/>&gt; &gt;&gt; &gt;<br/>&gt; &gt;&gt; &gt; My guess is that you&apos;re doing something wrong. What is the<br/>&gt; &gt;&gt; &gt; formula you&apos;re trying to use exactly? You shouldn&apos;t be taking<br/>&gt; &gt;&gt; &gt; the log of anything with units of cents, and on your current<br/>&gt; &gt;&gt; &gt; spreadsheet it doesn&apos;t seem you are.<br/>&gt; &gt;&gt;<br/>&gt; &gt;&gt; I&apos;m not doing ATE, but I wanted to.  For that, you take the<br/>&gt; &gt;&gt; base n*d log of the error, right?<br/>&gt; &gt;<br/>&gt; &gt;Maybe I don&apos;t know what you mean. What are you proposing, exactly,<br/>&gt; &gt;and how does it differ from TOP or what you did on your<br/>spreadsheet?<br/>&gt;<br/>&gt; <a href="http://groups.yahoo.com/group/tuning-math/message/10579">http://groups.yahoo.com/group/tuning-math/message/10579</a><br/>&gt;<br/>&gt; ...I think I parsed this right.</p><p>Oh. I had no idea that&apos;s what you meant by ATE. OK, here the error<br/>would have to be expressed as a frequency *ratio* (not necessarily a<br/>rational one) because the whole idea is to use the same type of log<br/>for both the Tenney part of the calculation and the &apos;cents&apos; part of<br/>the calculation. So if the error is zero cents, it&apos;s 1 when expressed<br/>as a frequency ratio. So you&apos;d be taking the log of 1 at a minimum;<br/>never of 0.</p><p>&gt; &gt;So what?<br/>&gt;<br/>&gt; I don&apos;t know how to easily generate test cases given this<br/>&gt; constraint.  If I could, I&apos;d listen to them.</p><p>Oh, you mean you can&apos;t find a 333 case or a 009 case. True enough --<br/>because of the constraint, you have to compare things which don&apos;t<br/>show as much difference under the different criteria.</p><p>&gt; &gt;&gt; &gt; The nice thing about minimax, though, is that once you&apos;ve<br/>&gt; &gt;&gt; &gt; established it over the intervals in a tuning system, you<br/>&gt; &gt;&gt; &gt; know that the minimax for any particular chords in the<br/>&gt; &gt;&gt; &gt; tuning system will be less than or equal to the tuning&apos;s<br/>&gt; &gt;&gt; &gt; minimax.  Not so for mean or for any intermediate value<br/>&gt; &gt;&gt; &gt; of P.<br/>&gt; &gt;&gt;<br/>&gt; &gt;&gt; Ok, that&apos;s a key point.  However, isn&apos;t the &quot;tuning&apos;s minimax&quot;<br/>&gt; &gt;&gt; here just another &quot;particular chord&quot;, ultimately?  It&apos;s nice<br/>&gt; &gt;&gt; to think of JI as a lattice, where none of the weighted errors<br/>&gt; &gt;&gt; exceeds a certain bound.  I agree that&apos;s nice.  But really it<br/>&gt; &gt;&gt; seems that only the primary intervals matter...<br/>&gt; &gt;<br/>&gt; &gt;Meaning n*d &lt; 100, or something like that?<br/>&gt;<br/>&gt; Say you&apos;ve got an m-limit TOP tuning, I&apos;d call the &quot;primary<br/>&gt; intervals&quot; the n-odd-limit intervals where n is the smallest<br/>&gt; odd number &gt; m.</p><p>Wow. Of course that runs against the whole grain of TOP . . . and why<br/>would you go to the next prime beyond the limit when m = 3, 5, 11,<br/>17, 29 . . . ? How do you determine the mapping for that prime, etc. ?</p><p>&gt; I need to review the IM discussion we had about the Kees lattice...<br/>&gt; it&apos;s on my desktop in my to-do pile.</p><p>Awesome. I gave you and especially Monz a lot of gems in IM.</p></div><h3><a id=12562 href="#12562">ðŸ”—</a>Carl Lumma &#x3C;ekin@lumma.org&#x3E;</h3><span>8/29/2005 6:13:46 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>&gt;&gt; <a href="http://groups.yahoo.com/group/tuning-math/message/10579">http://groups.yahoo.com/group/tuning-math/message/10579</a><br/>&gt;&gt;<br/>&gt;&gt; ...I think I parsed this right.<br/>&gt;<br/>&gt;Oh. I had no idea that&apos;s what you meant by ATE. OK, here the error<br/>&gt;would have to be expressed as a frequency *ratio* (not necessarily a<br/>&gt;rational one) because the whole idea is to use the same type of log<br/>&gt;for both the Tenney part of the calculation and the &apos;cents&apos; part of<br/>&gt;the calculation. So if the error is zero cents, it&apos;s 1 when expressed<br/>&gt;as a frequency ratio. So you&apos;d be taking the log of 1 at a minimum;<br/>&gt;never of 0.</p><p>Thanks!</p><p>&gt;&gt; &gt;So what?<br/>&gt;&gt;<br/>&gt;&gt; I don&apos;t know how to easily generate test cases given this<br/>&gt;&gt; constraint.  If I could, I&apos;d listen to them.<br/>&gt;<br/>&gt;Oh, you mean you can&apos;t find a 333 case or a 009 case. True enough --<br/>&gt;because of the constraint, you have to compare things which don&apos;t<br/>&gt;show as much difference under the different criteria.</p><p>I hate that.  :)</p><p>&gt;&gt; &gt;&gt; &gt; The nice thing about minimax, though, is that once you&apos;ve<br/>&gt;&gt; &gt;&gt; &gt; established it over the intervals in a tuning system, you<br/>&gt;&gt; &gt;&gt; &gt; know that the minimax for any particular chords in the<br/>&gt;&gt; &gt;&gt; &gt; tuning system will be less than or equal to the tuning&apos;s<br/>&gt;&gt; &gt;&gt; &gt; minimax.  Not so for mean or for any intermediate value<br/>&gt;&gt; &gt;&gt; &gt; of P.<br/>&gt;&gt; &gt;&gt;<br/>&gt;&gt; &gt;&gt; Ok, that&apos;s a key point.  However, isn&apos;t the &quot;tuning&apos;s minimax&quot;<br/>&gt;&gt; &gt;&gt; here just another &quot;particular chord&quot;, ultimately?  It&apos;s nice<br/>&gt;&gt; &gt;&gt; to think of JI as a lattice, where none of the weighted errors<br/>&gt;&gt; &gt;&gt; exceeds a certain bound.  I agree that&apos;s nice.  But really it<br/>&gt;&gt; &gt;&gt; seems that only the primary intervals matter...<br/>&gt;&gt; &gt;<br/>&gt;&gt; &gt;Meaning n*d &lt; 100, or something like that?<br/>&gt;&gt;<br/>&gt;&gt; Say you&apos;ve got an m-limit TOP tuning, I&apos;d call the &quot;primary<br/>&gt;&gt; intervals&quot; the n-odd-limit intervals where n is the smallest<br/>&gt;&gt; odd number &gt; m.<br/>&gt;<br/>&gt;Wow. Of course that runs against the whole grain of TOP . . . and why<br/>&gt;would you go to the next prime beyond the limit when m = 3, 5, 11,<br/>&gt;17, 29 . . . ?</p><p>The next odd.  9 for the 7-limit, etc.  I was just trying to say<br/>what you&apos;ve been saying all along, that 135/128 has no field of<br/>attraction and saying its weighted error is still less than something<br/>has little meaning.  15:8 has a field of attraction, but we shouldn&apos;t<br/>care about its error in the 5-limit.  If we do care, we should<br/>say so explicitly.</p><p>&gt;How do you determine the mapping for that prime, etc. ?</p><p>Er, I&apos;m just trying to clarify my point... this wasn&apos;t a serious<br/>proposal.</p><p>-Carl</p></div><h3><a id=12564 href="#12564">ðŸ”—</a>Paul Erlich &#x3C;perlich@aya.yale.edu&#x3E;</h3><span>8/29/2005 6:20:20 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Carl Lumma &lt;ekin@l...&gt; wrote:<br/>&gt; &gt;&gt; <a href="http://groups.yahoo.com/group/tuning-math/message/10579">http://groups.yahoo.com/group/tuning-math/message/10579</a><br/>&gt; &gt;&gt;<br/>&gt; &gt;&gt; ...I think I parsed this right.<br/>&gt; &gt;<br/>&gt; &gt;Oh. I had no idea that&apos;s what you meant by ATE. OK, here the error<br/>&gt; &gt;would have to be expressed as a frequency *ratio* (not necessarily<br/>a<br/>&gt; &gt;rational one) because the whole idea is to use the same type of<br/>log<br/>&gt; &gt;for both the Tenney part of the calculation and the &apos;cents&apos; part<br/>of<br/>&gt; &gt;the calculation. So if the error is zero cents, it&apos;s 1 when<br/>expressed<br/>&gt; &gt;as a frequency ratio. So you&apos;d be taking the log of 1 at a<br/>minimum;<br/>&gt; &gt;never of 0.<br/>&gt;<br/>&gt; Thanks!<br/>&gt;<br/>&gt; &gt;&gt; &gt;So what?<br/>&gt; &gt;&gt;<br/>&gt; &gt;&gt; I don&apos;t know how to easily generate test cases given this<br/>&gt; &gt;&gt; constraint.  If I could, I&apos;d listen to them.<br/>&gt; &gt;<br/>&gt; &gt;Oh, you mean you can&apos;t find a 333 case or a 009 case. True enough -<br/>-<br/>&gt; &gt;because of the constraint, you have to compare things which don&apos;t<br/>&gt; &gt;show as much difference under the different criteria.<br/>&gt;<br/>&gt; I hate that.  :)<br/>&gt;<br/>&gt; &gt;&gt; &gt;&gt; &gt; The nice thing about minimax, though, is that once you&apos;ve<br/>&gt; &gt;&gt; &gt;&gt; &gt; established it over the intervals in a tuning system, you<br/>&gt; &gt;&gt; &gt;&gt; &gt; know that the minimax for any particular chords in the<br/>&gt; &gt;&gt; &gt;&gt; &gt; tuning system will be less than or equal to the tuning&apos;s<br/>&gt; &gt;&gt; &gt;&gt; &gt; minimax.  Not so for mean or for any intermediate value<br/>&gt; &gt;&gt; &gt;&gt; &gt; of P.<br/>&gt; &gt;&gt; &gt;&gt;<br/>&gt; &gt;&gt; &gt;&gt; Ok, that&apos;s a key point.  However, isn&apos;t the &quot;tuning&apos;s minimax&quot;<br/>&gt; &gt;&gt; &gt;&gt; here just another &quot;particular chord&quot;, ultimately?  It&apos;s nice<br/>&gt; &gt;&gt; &gt;&gt; to think of JI as a lattice, where none of the weighted errors<br/>&gt; &gt;&gt; &gt;&gt; exceeds a certain bound.  I agree that&apos;s nice.  But really it<br/>&gt; &gt;&gt; &gt;&gt; seems that only the primary intervals matter...<br/>&gt; &gt;&gt; &gt;<br/>&gt; &gt;&gt; &gt;Meaning n*d &lt; 100, or something like that?<br/>&gt; &gt;&gt;<br/>&gt; &gt;&gt; Say you&apos;ve got an m-limit TOP tuning, I&apos;d call the &quot;primary<br/>&gt; &gt;&gt; intervals&quot; the n-odd-limit intervals where n is the smallest<br/>&gt; &gt;&gt; odd number &gt; m.<br/>&gt; &gt;<br/>&gt; &gt;Wow. Of course that runs against the whole grain of TOP . . . and<br/>why<br/>&gt; &gt;would you go to the next prime beyond the limit when m = 3, 5, 11,<br/>&gt; &gt;17, 29 . . . ?<br/>&gt;<br/>&gt; The next odd.  9 for the 7-limit, etc.  I was just trying to say<br/>&gt; what you&apos;ve been saying all along, that 135/128 has no field of<br/>&gt; attraction and saying its weighted error is still less than<br/>something<br/>&gt; has little meaning.  15:8 has a field of attraction, but we<br/>shouldn&apos;t<br/>&gt; care about its error in the 5-limit.  If we do care, we should<br/>&gt; say so explicitly.</p><p>So what&apos;s wrong with only including the ratios in the lattice n/d<br/>such that n*d &lt; 100 or something like that? Seems a lot more<br/>compatible with the spirit and assumptions of TOP.</p></div><h3><a id=12570 href="#12570">ðŸ”—</a>Carl Lumma &#x3C;ekin@lumma.org&#x3E;</h3><span>8/29/2005 7:44:17 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>&gt;&gt; &gt;&gt; Say you&apos;ve got an m-limit TOP tuning, I&apos;d call the &quot;primary<br/>&gt;&gt; &gt;&gt; intervals&quot; the n-odd-limit intervals where n is the smallest<br/>&gt;&gt; &gt;&gt; odd number &gt; m.<br/>&gt;&gt; &gt;<br/>&gt;&gt; &gt;Wow. Of course that runs against the whole grain of TOP . . . and<br/>&gt;&gt; &gt;why would you go to the next prime beyond the limit when<br/>&gt;&gt; &gt;m = 3, 5, 11, 17, 29 . . . ?<br/>&gt;&gt;<br/>&gt;&gt; The next odd.  9 for the 7-limit, etc.  I was just trying to say<br/>&gt;&gt; what you&apos;ve been saying all along, that 135/128 has no field of<br/>&gt;&gt; attraction and saying its weighted error is still less than<br/>&gt;something<br/>&gt;&gt; has little meaning.  15:8 has a field of attraction, but we<br/>&gt;shouldn&apos;t<br/>&gt;&gt; care about its error in the 5-limit.  If we do care, we should<br/>&gt;&gt; say so explicitly.<br/>&gt;<br/>&gt;So what&apos;s wrong with only including the ratios in the lattice n/d<br/>&gt;such that n*d &lt; 100 or something like that? Seems a lot more<br/>&gt;compatible with the spirit and assumptions of TOP.</p><p>Sounds good to me.</p><p>-Carl</p></div>