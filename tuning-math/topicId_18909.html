<!DOCTYPE html>
            <html>
            <head>
            <meta charset="utf-8">
                <meta name="viewport"
            content="width=device-width, height=device-height, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no">
                <meta http-equiv="x-ua-compatible" content="ie=edge">
                <title>Yahoo Tuning Groups Ultimate Backup tuning-math What are some high-numbered ET's that have extremely low error and are consistent to very high limits?</title>
                <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
            </head>
            <body>
            </body>
            </html>
        <a href="/tuning-math">back to list</a><h1>What are some high-numbered ET's that have extremely low error and are consistent to very high limits?</h1><h3><a id=18909 href="#18909">ðŸ”—</a>Mike Battaglia &#x3C;battaglia01@gmail.com&#x3E;</h3><span>2/25/2011 3:14:45 PM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>This would be really helpful for some of the research I&apos;ve been doing<br/>with &quot;fuzzy mapping,&quot; as I&apos;ve spoken about it on Facebook and the<br/>like. In this case, I represent intervals as impulses that lie across<br/>the number line. By representing the &quot;basis set&quot; of vectors in a fuzzy<br/>group as this minimal set of impulses and then convolving the signal<br/>with itself a bajillion times, the entire n-limit JI lattice can be<br/>computed. By then convolving the whole thing with a Gaussian, you end<br/>up getting some interesting results. If you expand these results into<br/>a prime-based Tenney lattice, it looks like this:</p><p><a href="http://www.mikebattagliamusic.com/music/contours.gif">http://www.mikebattagliamusic.com/music/contours.gif</a></p><p>Or this, if you weight each interval by complexity:</p><p><a href="http://www.mikebattagliamusic.com/music/contours2.gif">http://www.mikebattagliamusic.com/music/contours2.gif</a></p><p>The lines are pitch contours and the Euclidean subspace of the second<br/>graph that you get by taking the view from a flat running<br/>perpendicular to the origin is DC exactly, and the whole thing may or<br/>may not be workable to set up such that it exactly yields HE.</p><p>When you&apos;re doing this with discrete intervals, rounding error frankly<br/>makes life hell on earth. So it seems best to do these computations<br/>with respect to some highly-numbered &quot;universe ET,&quot; designed such that<br/>it&apos;s extremely consistent, such that if you go 10 steps out into the<br/>11-axis you might at most accrue a round-off error of a few cents. The<br/>accuracy of the calculations can be increased by using a larger<br/>universe ET, but consistency is what&apos;s most important here.</p><p>Can anyone suggest anything to go with? I hear the &quot;mina&quot; is good for<br/>this. I think something that&apos;s 2197-consistent would be good for<br/>starters, as it lets us go three steps out into the 13-axis with no<br/>roundoff error at all.</p><p>-Mike</p></div><h3><a id=18912 href="#18912">ðŸ”—</a>gdsecor &#x3C;gdsecor@yahoo.com&#x3E;</h3><span>2/25/2011 7:17:42 PM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Mike Battaglia &lt;battaglia01@...&gt; wrote:<br/>&gt;<br/>&gt; This would be really helpful for some of the research I&apos;ve been doing<br/>&gt; with &quot;fuzzy mapping,&quot; as I&apos;ve spoken about it on Facebook and the<br/>&gt; like. In this case, I represent intervals as impulses that lie across<br/>&gt; the number line. By representing the &quot;basis set&quot; of vectors in a fuzzy<br/>&gt; group as this minimal set of impulses and then convolving the signal<br/>&gt; with itself a bajillion times, the entire n-limit JI lattice can be<br/>&gt; computed. By then convolving the whole thing with a Gaussian, you end<br/>&gt; up getting some interesting results. If you expand these results into<br/>&gt; a prime-based Tenney lattice, it looks like this:<br/>&gt;<br/>&gt; <a href="http://www.mikebattagliamusic.com/music/contours.gif">http://www.mikebattagliamusic.com/music/contours.gif</a><br/>&gt;<br/>&gt; Or this, if you weight each interval by complexity:<br/>&gt;<br/>&gt; <a href="http://www.mikebattagliamusic.com/music/contours2.gif">http://www.mikebattagliamusic.com/music/contours2.gif</a><br/>&gt;<br/>&gt; The lines are pitch contours and the Euclidean subspace of the second<br/>&gt; graph that you get by taking the view from a flat running<br/>&gt; perpendicular to the origin is DC exactly, and the whole thing may or<br/>&gt; may not be workable to set up such that it exactly yields HE.<br/>&gt;<br/>&gt; When you&apos;re doing this with discrete intervals, rounding error frankly<br/>&gt; makes life hell on earth. So it seems best to do these computations<br/>&gt; with respect to some highly-numbered &quot;universe ET,&quot; designed such that<br/>&gt; it&apos;s extremely consistent, such that if you go 10 steps out into the<br/>&gt; 11-axis you might at most accrue a round-off error of a few cents. The<br/>&gt; accuracy of the calculations can be increased by using a larger<br/>&gt; universe ET, but consistency is what&apos;s most important here.<br/>&gt;<br/>&gt; Can anyone suggest anything to go with? I hear the &quot;mina&quot; is good for<br/>&gt; this.</p><p>The mina is a single degree of 2460-EDO (27-limit consistent), but that&apos;s only for practical calculations.  What you&apos;re looking for is something truly insane, such as 324296 (59-limit consistent) or 2901533 (131-limit consistent).  Here&apos;s how I found these numbers:<br/><a href="/tuning-math/message/17561">/tuning-math/message/17561</a></p><p>--George</p></div><h3><a id=18913 href="#18913">ðŸ”—</a>Mike Battaglia &#x3C;battaglia01@gmail.com&#x3E;</h3><span>2/25/2011 7:33:28 PM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On Fri, Feb 25, 2011 at 10:17 PM, gdsecor &lt;<a href="mailto:gdsecor@yahoo.com">gdsecor@yahoo.com</a>&gt; wrote:<br/>&gt;<br/>&gt; The mina is a single degree of 2460-EDO (27-limit consistent), but that&apos;s only for practical calculations. What you&apos;re looking for is something truly insane, such as 324296 (59-limit consistent) or 2901533 (131-limit consistent). Here&apos;s how I found these numbers:<br/>&gt; <a href="/tuning-math/message/17561">/tuning-math/message/17561</a></p><p>Maybe then it&apos;s not consistency that&apos;s important then. If we&apos;re in<br/>324296-EDO, each step corresponds to 0.0037 cents, so who cares about<br/>consistency at that point? Maybe what I&apos;m looking for is extremely low<br/>error, and I guess if that&apos;s the goal, the zeta integral tuning list<br/>is probably the way to go.</p><p>-Mike</p></div><h3><a id=18914 href="#18914">ðŸ”—</a>gdsecor &#x3C;gdsecor@yahoo.com&#x3E;</h3><span>2/25/2011 9:43:24 PM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Mike Battaglia &lt;battaglia01@...&gt; wrote:<br/>&gt;<br/>&gt; On Fri, Feb 25, 2011 at 10:17 PM, gdsecor &lt;gdsecor@...&gt; wrote:<br/>&gt; &gt;<br/>&gt; &gt; The mina is a single degree of 2460-EDO (27-limit consistent), but that&apos;s only for practical calculations. What you&apos;re looking for is something truly insane, such as 324296 (59-limit consistent) or 2901533 (131-limit consistent). Here&apos;s how I found these numbers:<br/>&gt; &gt; <a href="/tuning-math/message/17561">/tuning-math/message/17561</a><br/>&gt;<br/>&gt; Maybe then it&apos;s not consistency that&apos;s important then. If we&apos;re in<br/>&gt; 324296-EDO, each step corresponds to 0.0037 cents, so who cares about<br/>&gt; consistency at that point? Maybe what I&apos;m looking for is extremely low<br/>&gt; error, and I guess if that&apos;s the goal, the zeta integral tuning list<br/>&gt; is probably the way to go.<br/>&gt;<br/>&gt; -Mike</p><p>If it&apos;s extremely low error you want, then any number will do, but if you want to use integers, keep the size of the integers more manageable, and minimize the rounding error, then low *relative* error (&lt; 10% of your measuring unit) in the lower primes *and* consistency to the required odd limit is what you really need.  Minas are 27-limit consistent and have very low relative error where it&apos;s most needed: no rounding error up to 3^64, 5^8, and 7^5.</p><p>In rereading your prior message, you specified &quot;extremely consistent, such that if you go 10 steps out into the 11-axis you might at most accrue a round-off error of a few cents.  With minas, 11^10 accumulates to an error of 4 minas, which is slightly less than 2 cents.  If that&apos;s acceptable to you, then it looks as if minas might fill the bill after all.  In the survey of rational intervals that were tabulated in the Scala archive for the Sagittal notation project, I did not find any ratios within the 23 prime limit that suffered from any rounding error when the minas of the constituent primes were combined to give an aggregate total for each ratio.</p><p>Why don&apos;t you give 2460 a try?</p><p>BTW, what sort of tuning measure is given by the zeta integral tuning list?</p><p>--George</p></div><h3><a id=18915 href="#18915">ðŸ”—</a>Mike Battaglia &#x3C;battaglia01@gmail.com&#x3E;</h3><span>2/25/2011 9:50:37 PM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On Sat, Feb 26, 2011 at 12:43 AM, gdsecor &lt;<a href="mailto:gdsecor@yahoo.com">gdsecor@yahoo.com</a>&gt; wrote:<br/>&gt;<br/>&gt; If it&apos;s extremely low error you want, then any number will do, but if you want to use integers, keep the size of the integers more manageable, and minimize the rounding error, then low *relative* error (&lt; 10% of your measuring unit) in the lower primes *and* consistency to the required odd limit is what you really need. Minas are 27-limit consistent and have very low relative error where it&apos;s most needed: no rounding error up to 3^64, 5^8, and 7^5.</p><p>What do you mean by &quot;if you want to use integers?&quot; I want to use this<br/>approach to see if I can re-derive some common linear temperaments<br/>from this and see how they rank up to one another in a vaguely<br/>psychoacoustic sense.</p><p>&gt; In rereading your prior message, you specified &quot;extremely consistent, such that if you go 10 steps out into the 11-axis you might at most accrue a round-off error of a few cents. With minas, 11^10 accumulates to an error of 4 minas, which is slightly less than 2 cents. If that&apos;s acceptable to you, then it looks as if minas might fill the bill after all. In the survey of rational intervals that were tabulated in the Scala archive for the Sagittal notation project, I did not find any ratios within the 23 prime limit that suffered from any rounding error when the minas of the constituent primes were combined to give an aggregate total for each ratio.</p><p>That&apos;s fantastic. I&apos;ll have to see how sensitive all of this is to<br/>that, but so far that looks great. And this is what happens if you<br/>compare 10 * the mapping for 11 to the actual nearest mapping for<br/>11^10?</p><p>&gt; Why don&apos;t you give 2460 a try?<br/>&gt;<br/>&gt; BTW, what sort of tuning measure is given by the zeta integral tuning list?</p><p>It basically gives a list of ET&apos;s that successively give greater and<br/>greater accuracy for all primes, regardless of limit. At least that&apos;s<br/>what I think it does.</p><p>-Mike</p></div><h3><a id=18917 href="#18917">ðŸ”—</a>genewardsmith &#x3C;genewardsmith@sbcglobal.net&#x3E;</h3><span>2/25/2011 10:28:24 PM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Mike Battaglia &lt;battaglia01@...&gt; wrote:</p><p>&gt; It basically gives a list of ET&apos;s that successively give greater and<br/>&gt; greater accuracy for all primes, regardless of limit. At least that&apos;s<br/>&gt; what I think it does.</p><p>That would be impossible. But it doesn&apos;t optimize any specific prime limit; it weighs smaller primes more than larger ones.</p></div><h3><a id=18918 href="#18918">ðŸ”—</a>Mike Battaglia &#x3C;battaglia01@gmail.com&#x3E;</h3><span>2/25/2011 10:32:19 PM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On Sat, Feb 26, 2011 at 1:28 AM, genewardsmith<br/>&lt;<a href="mailto:genewardsmith@sbcglobal.net">genewardsmith@sbcglobal.net</a>&gt; wrote:<br/>&gt;<br/>&gt; --- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Mike Battaglia &lt;battaglia01@...&gt; wrote:<br/>&gt;<br/>&gt; &gt; It basically gives a list of ET&apos;s that successively give greater and<br/>&gt; &gt; greater accuracy for all primes, regardless of limit. At least that&apos;s<br/>&gt; &gt; what I think it does.<br/>&gt;<br/>&gt; That would be impossible. But it doesn&apos;t optimize any specific prime limit; it weighs smaller primes more than larger ones.</p><p>I thought everyone was talking about zeta error as giving us a measure<br/>of tuning error that didn&apos;t require any limit? Or is it just that it<br/>weighs smaller primes more than larger ones?</p><p>-Mike</p></div><h3><a id=18919 href="#18919">ðŸ”—</a>Mike Battaglia &#x3C;battaglia01@gmail.com&#x3E;</h3><span>2/25/2011 10:34:57 PM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On Sat, Feb 26, 2011 at 1:32 AM, Mike Battaglia &lt;<a href="mailto:battaglia01@gmail.com">battaglia01@gmail.com</a>&gt; wrote:<br/>&gt; On Sat, Feb 26, 2011 at 1:28 AM, genewardsmith<br/>&gt; &lt;<a href="mailto:genewardsmith@sbcglobal.net">genewardsmith@sbcglobal.net</a>&gt; wrote:<br/>&gt;&gt;<br/>&gt;&gt; --- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Mike Battaglia &lt;battaglia01@...&gt; wrote:<br/>&gt;&gt;<br/>&gt;&gt; &gt; It basically gives a list of ET&apos;s that successively give greater and<br/>&gt;&gt; &gt; greater accuracy for all primes, regardless of limit. At least that&apos;s<br/>&gt;&gt; &gt; what I think it does.<br/>&gt;&gt;<br/>&gt;&gt; That would be impossible. But it doesn&apos;t optimize any specific prime limit; it weighs smaller primes more than larger ones.<br/>&gt;<br/>&gt; I thought everyone was talking about zeta error as giving us a measure<br/>&gt; of tuning error that didn&apos;t require any limit? Or is it just that it<br/>&gt; weighs smaller primes more than larger ones?</p><p>In fact, to get into this more, how exactly does it weigh smaller<br/>primes more than larger primes? My half-assed knowledge of the zeta<br/>function, the Mellin transform, and rect functions tells me that there<br/>should be some kind of sinc-function weighting going on. Am I right?</p><p>-Mike</p></div><h3><a id=18925 href="#18925">ðŸ”—</a>genewardsmith &#x3C;genewardsmith@sbcglobal.net&#x3E;</h3><span>2/26/2011 12:53:06 PM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Mike Battaglia &lt;battaglia01@...&gt; wrote:</p><p>&gt; In fact, to get into this more, how exactly does it weigh smaller<br/>&gt; primes more than larger primes?</p><p>This might help:</p><p><a href="http://en.wikipedia.org/wiki/Riemann">http://en.wikipedia.org/wiki/Riemann</a>Â–Siegel_formula</p><p>Along the critical line, this gives a 1/sqrt(p) wieghting, more or less.</p><p>My half-assed knowledge of the zeta<br/>&gt; function, the Mellin transform, and rect functions tells me that there<br/>&gt; should be some kind of sinc-function weighting going on. Am I right?</p><p>Decades ago I was led to the zeta function starting from cosines, but starting with a weighted sum of sinc functions would certainly make sense. But I don&apos;t see any close connection with zeta(s+it).</p></div><h3><a id=18930 href="#18930">ðŸ”—</a>Mike Battaglia &#x3C;battaglia01@gmail.com&#x3E;</h3><span>2/27/2011 12:05:13 AM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On Sat, Feb 26, 2011 at 3:53 PM, genewardsmith<br/>&lt;<a href="mailto:genewardsmith@sbcglobal.net">genewardsmith@sbcglobal.net</a>&gt; wrote:<br/>&gt;<br/>&gt; --- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Mike Battaglia &lt;battaglia01@...&gt; wrote:<br/>&gt;<br/>&gt; &gt; In fact, to get into this more, how exactly does it weigh smaller<br/>&gt; &gt; primes more than larger primes?<br/>&gt;<br/>&gt; This might help:<br/>&gt;<br/>&gt; <a href="http://en.wikipedia.org/wiki/Riemannâ€“Siegel_formula">http://en.wikipedia.org/wiki/Riemannâ€“Siegel_formula</a><br/>&gt;<br/>&gt; Along the critical line, this gives a 1/sqrt(p) wieghting, more or less.</p><p>OK, I think I understand. I see that the gamma function keeps turning<br/>up here, although I&apos;m not quite sure why.</p><p>&gt; My half-assed knowledge of the zeta<br/>&gt; &gt; function, the Mellin transform, and rect functions tells me that there<br/>&gt; &gt; should be some kind of sinc-function weighting going on. Am I right?<br/>&gt;<br/>&gt; Decades ago I was led to the zeta function starting from cosines, but starting with a weighted sum of sinc functions would certainly make sense. But I don&apos;t see any close connection with zeta(s+it).</p><p>After thinking about this, it wouldn&apos;t be sinc at all - I don&apos;t know<br/>why I said that. But when you said starting from a sum of cosines -<br/>would these not be exponentially warped cosines, something like<br/>cos(e^x), since that&apos;s closer to what the basis vectors for the Mellin<br/>transform are?</p><p>-Mike</p></div><h3><a id=18931 href="#18931">ðŸ”—</a>genewardsmith &#x3C;genewardsmith@sbcglobal.net&#x3E;</h3><span>2/27/2011 6:42:59 AM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Mike Battaglia &lt;battaglia01@...&gt; wrote:</p><p>&gt; After thinking about this, it wouldn&apos;t be sinc at all - I don&apos;t know<br/>&gt; why I said that. But when you said starting from a sum of cosines -<br/>&gt; would these not be exponentially warped cosines, something like<br/>&gt; cos(e^x), since that&apos;s closer to what the basis vectors for the Mellin<br/>&gt; transform are?</p><p>Just plain old cosines. But I soon found I wanted to tweak that, and in the course of tweaking, the zeta function suggested itself. Then I went over the edge by crossing into the critical strip.</p></div><h3><a id=18934 href="#18934">ðŸ”—</a>gdsecor &#x3C;gdsecor@yahoo.com&#x3E;</h3><span>2/27/2011 8:26:28 PM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Mike Battaglia &lt;battaglia01@...&gt; wrote:<br/>&gt;<br/>&gt; On Sat, Feb 26, 2011 at 12:43 AM, gdsecor &lt;gdsecor@...&gt; wrote:<br/>&gt; &gt;<br/>&gt; ...<br/>&gt; &gt; In rereading your prior message, you specified &quot;extremely consistent, such that if you go 10 steps out into the 11-axis you might at most accrue a round-off error of a few cents. With minas, 11^10 accumulates to an error of 4 minas, which is slightly less than 2 cents. If that&apos;s acceptable to you, then it looks as if minas might fill the bill after all. In the survey of rational intervals that were tabulated in the Scala archive for the Sagittal notation project, I did not find any ratios within the 23 prime limit that suffered from any rounding error when the minas of the constituent primes were combined to give an aggregate total for each ratio.<br/>&gt;<br/>&gt; That&apos;s fantastic. I&apos;ll have to see how sensitive all of this is to<br/>&gt; that, but so far that looks great. And this is what happens if you<br/>&gt; compare 10 * the mapping for 11 to the actual nearest mapping for<br/>&gt; 11^10?</p><p>Yes.</p><p>--George</p></div>
                <script>
                    let monospace = false
                    $('button').on('click', function () {
                      if (monospace) {
                        $('p').css("font-family", "")
                      } else {
                        $('p').css("font-family", "monospace")
                      }
                      monospace = !monospace
                    })
                </script>
            