<a href="/tuning-math">back to list</a><h1>Exploring parametric badness</h1><h3><a id=17447 href="#17447">ðŸ”—</a>Graham Breed &#x3C;gbreed@gmail.com&#x3E;</h3><span>1/2/2009 8:04:37 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>I&apos;ve finally written a PDF about the badness measure I thought up the<br/>other year.  This is part of a series of articles that was supposed to<br/>be finished by now, but still has a long way to go.</p><p><a href="http://x31eq.com/badness.pdf">http://x31eq.com/badness.pdf</a></p><p>As usual, comments are welcome, and maybe you can identify some of the<br/>nameless temperaments.</p><p>                                Graham</p></div><h3><a id=17448 href="#17448">ðŸ”—</a>Carl Lumma &#x3C;carl@lumma.org&#x3E;</h3><span>1/2/2009 2:45:44 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Very good to see you carrying on.  Congratulations!  I love the<br/>first-person style and professional typesetting.  Have you considered<br/>submitting one of these to a journal?</p><p>For my own part, I&apos;ve decided to operate in &apos;bonehead simple&apos; mode<br/>with tuning stuff for the foreseeable future (even more boneheaded<br/>than before!).  I&apos;ll stick to things I can understand in one<br/>sentence and 2 seconds, and spend my energy putting them together.<br/>A hacker&apos;s approach, if you will.  It suits my limited brainpower<br/>and time resources, and everyone will be better off.</p><p>I looked up TOM-RMS in the glossary, and it pointed me to primerr.<br/>I searched that doc for &quot;TOP-RMS&quot;, and found it mainly in the<br/>legends of charts.  Oh, and you&apos;re missing a space in<br/>&quot;(See Primerrfor details.)&quot;  Also I think your citation style<br/>isn&apos;t consistent throughout the paper.</p><p>So, here&apos;s my code for TOP-max damage of ETs</p><p>(define top-damage<br/>   (lambda (val basis)<br/>      (let*<br/>         ((weights (map log2 basis))<br/>          (ji (map (lambda (x) (* x 1200)) weights))<br/>          (errors (map abs (map - ji (top-val val basis)))))<br/>      (apply max (map / errors weights)))))</p><p>I&apos;m sure you can follow that -- the only external function is<br/>top-val, and it returns one of those bastard vals containing<br/>nonintegers -- in this case, cents of the top tuning of the val.</p><p>What do I have to do to turn this into TOP-RMS?</p><p>If this is the answer I can&apos;t quite parse it.</p><p>  (let* ((mapping (append seed-mapping (list next-guess)))<br/>         (weighted-size (/ (* next-guess step-size) (car more-primes)))<br/>         ; the next few lines determine the type of error<br/>         (tot (+ tot weighted-size))<br/>         (tot2 (+ tot2 (* weighted-size weighted-size)))<br/>         (error (- (length mapping) (/ (* tot tot) tot2))))</p><p>-Carl</p><p>At 08:04 AM 1/2/2009, you wrote:<br/>&gt;I&apos;ve finally written a PDF about the badness measure I thought up the<br/>&gt;other year.  This is part of a series of articles that was supposed to<br/>&gt;be finished by now, but still has a long way to go.<br/>&gt;<br/>&gt;<a href="http://x31eq.com/badness.pdf">http://x31eq.com/badness.pdf</a><br/>&gt;<br/>&gt;As usual, comments are welcome, and maybe you can identify some of the<br/>&gt;nameless temperaments.<br/>&gt;<br/>&gt;<br/>&gt;                                Graham</p></div><h3><a id=17449 href="#17449">ðŸ”—</a>Herman Miller &#x3C;hmiller@IO.COM&#x3E;</h3><span>1/2/2009 5:24:57 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Graham Breed wrote:<br/>&gt; I&apos;ve finally written a PDF about the badness measure I thought up the<br/>&gt; other year.  This is part of a series of articles that was supposed to<br/>&gt; be finished by now, but still has a long way to go.<br/>&gt; &gt; <a href="http://x31eq.com/badness.pdf">http://x31eq.com/badness.pdf</a><br/>&gt; &gt; As usual, comments are welcome, and maybe you can identify some of the<br/>&gt; nameless temperaments.</p><p><a href="http://tonalsoft.com/enc/e/equal-temperament.aspx">http://tonalsoft.com/enc/e/equal-temperament.aspx</a> has a list of 5-limit temperaments. 53&amp;270 is vulture. I&apos;ve used &quot;vulture&quot; in the 7-limit for a 53&amp;58 temperament that has a different mapping of prime 7 -- 53&amp;270 doesn&apos;t look that great as a 7-limit temperament.</p><p>53&amp;58 vulture [&lt;1, 0, -6, 4], &lt;0, 4, 21, -3]&gt;<br/>TOP-max P = 1199.274449, G = 475.411671<br/>TOP-RMS P = 1199.307143, G = 475.361486</p><p>53&amp;270 [&lt;1, 0, -6, 25], &lt;0, 4, 21, -56]&gt;<br/>TOP-max P = 1199.923914, G = 475.518899<br/>TOP-RMS P = 1199.904982, G = 475.513479</p><p>7-limit 152&amp;171 is enneadecal.<br/>[&lt;19, 30, 44, 53], &lt;0, 1, 1, 3]&gt;<br/>TOP-max P = 63.160319, G = 7.152770<br/>TOP-RMS P = 63.159903, G = 7.143746</p><p>11-limit 72&amp;152 is octoid. I don&apos;t recall whether &quot;octoid&quot; was originally proposed as a name for a 7-limit temperament (in which case you&apos;ll want to call it octoid&apos;), or an 11-limit one.</p><p>[&lt;8, 13, 19, 23, 28], &lt;0, -3, -4, -5, -3]&gt;<br/>TOP-max P = 150.033735, G = 16.238470<br/>TOP-RMS P = 149.993205, G = 16.037109</p></div><h3><a id=17450 href="#17450">ðŸ”—</a>Graham Breed &#x3C;gbreed@gmail.com&#x3E;</h3><span>1/2/2009 7:14:43 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>2009/1/3 Carl Lumma &lt;<a href="mailto:carl@lumma.org">carl@lumma.org</a>&gt;:<br/>&gt; Very good to see you carrying on.  Congratulations!  I love the<br/>&gt; first-person style and professional typesetting.  Have you considered<br/>&gt; submitting one of these to a journal?</p><p>Bill Sethares suggested the complete search one might be publishable.<br/>But I haven&apos;t done any work towards it -- it&apos;s extra hassle.  The<br/>priorities getting things documented.  (Or &quot;published&quot; if you like.)</p><p>&gt; For my own part, I&apos;ve decided to operate in &apos;bonehead simple&apos; mode<br/>&gt; with tuning stuff for the foreseeable future (even more boneheaded<br/>&gt; than before!).  I&apos;ll stick to things I can understand in one<br/>&gt; sentence and 2 seconds, and spend my energy putting them together.<br/>&gt; A hacker&apos;s approach, if you will.  It suits my limited brainpower<br/>&gt; and time resources, and everyone will be better off.<br/>&gt;<br/>&gt; I looked up TOM-RMS in the glossary, and it pointed me to primerr.<br/>&gt; I searched that doc for &quot;TOP-RMS&quot;, and found it mainly in the<br/>&gt; legends of charts.  Oh, and you&apos;re missing a space in<br/>&gt; &quot;(See Primerrfor details.)&quot;  Also I think your citation style<br/>&gt; isn&apos;t consistent throughout the paper.</p><p>That looks like something I should have spotted a year ago.  Anyway,<br/>I&apos;ve changed the glossary to point to section 2 because that&apos;s all<br/>about TOP-RMS.</p><p>I think I use the Harvard citation standard except for the special<br/>cases where I say I don&apos;t.</p><p>&gt; So, here&apos;s my code for TOP-max damage of ETs<br/>&gt;<br/>&gt; (define top-damage<br/>&gt;   (lambda (val basis)<br/>&gt;      (let*<br/>&gt;         ((weights (map log2 basis))<br/>&gt;          (ji (map (lambda (x) (* x 1200)) weights))<br/>&gt;          (errors (map abs (map - ji (top-val val basis)))))<br/>&gt;      (apply max (map / errors weights)))))<br/>&gt;<br/>&gt; I&apos;m sure you can follow that -- the only external function is<br/>&gt; top-val, and it returns one of those bastard vals containing<br/>&gt; nonintegers -- in this case, cents of the top tuning of the val.<br/>&gt;<br/>&gt; What do I have to do to turn this into TOP-RMS?</p><p>I&apos;ll guess replace &quot;max&quot; with &quot;rms&quot;.  If there&apos;s no RMS function it needs to:</p><p>- square every element in the list<br/>- add them up<br/>- divide by the length of the list<br/>- square root</p><p>&gt; If this is the answer I can&apos;t quite parse it.<br/>&gt;<br/>&gt;  (let* ((mapping (append seed-mapping (list next-guess)))<br/>&gt;         (weighted-size (/ (* next-guess step-size) (car more-primes)))<br/>&gt;         ; the next few lines determine the type of error<br/>&gt;         (tot (+ tot weighted-size))<br/>&gt;         (tot2 (+ tot2 (* weighted-size weighted-size)))<br/>&gt;         (error (- (length mapping) (/ (* tot tot) tot2))))</p><p>No, that&apos;s part of the code for producing all equal temperaments<br/>within a given error.</p><p>                                Graham</p></div><h3><a id=17451 href="#17451">ðŸ”—</a>Graham Breed &#x3C;gbreed@gmail.com&#x3E;</h3><span>1/2/2009 7:17:56 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>2009/1/3 Herman Miller &lt;<a href="mailto:hmiller@io.com">hmiller@io.com</a>&gt;:</p><p>&gt; <a href="http://tonalsoft.com/enc/e/equal-temperament.aspx">http://tonalsoft.com/enc/e/equal-temperament.aspx</a> has a list of 5-limit<br/>&gt; temperaments. 53&amp;270 is vulture. I&apos;ve used &quot;vulture&quot; in the 7-limit for<br/>&gt; a 53&amp;58 temperament that has a different mapping of prime 7 -- 53&amp;270<br/>&gt; doesn&apos;t look that great as a 7-limit temperament.<br/>&gt;<br/>&gt; 53&amp;58 vulture [&lt;1, 0, -6, 4], &lt;0, 4, 21, -3]&gt;<br/>&gt; TOP-max P = 1199.274449, G = 475.411671<br/>&gt; TOP-RMS P = 1199.307143, G = 475.361486<br/>&gt;<br/>&gt; 53&amp;270 [&lt;1, 0, -6, 25], &lt;0, 4, 21, -56]&gt;<br/>&gt; TOP-max P = 1199.923914, G = 475.518899<br/>&gt; TOP-RMS P = 1199.904982, G = 475.513479</p><p>Thanks!  There&apos;s a kind of vulture in the 19-limit as well.</p><p>&gt; 7-limit 152&amp;171 is enneadecal.<br/>&gt; [&lt;19, 30, 44, 53], &lt;0, 1, 1, 3]&gt;<br/>&gt; TOP-max P = 63.160319, G = 7.152770<br/>&gt; TOP-RMS P = 63.159903, G = 7.143746<br/>&gt;<br/>&gt; 11-limit 72&amp;152 is octoid. I don&apos;t recall whether &quot;octoid&quot; was<br/>&gt; originally proposed as a name for a 7-limit temperament (in which case<br/>&gt; you&apos;ll want to call it octoid&apos;), or an 11-limit one.<br/>&gt;<br/>&gt; [&lt;8, 13, 19, 23, 28], &lt;0, -3, -4, -5, -3]&gt;<br/>&gt; TOP-max P = 150.033735, G = 16.238470<br/>&gt; TOP-RMS P = 149.993205, G = 16.037109</p><p>I put it in the 11-limit.  It also figures in the 13 and 17 limits.<br/>(The computer sorts all that out.)</p><p>                          Graham</p></div><h3><a id=17452 href="#17452">ðŸ”—</a>Graham Breed &#x3C;gbreed@gmail.com&#x3E;</h3><span>1/2/2009 9:27:24 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>2009/1/3 Carl Lumma &lt;<a href="mailto:carl@lumma.org">carl@lumma.org</a>&gt;:</p><p>&gt; So, here&apos;s my code for TOP-max damage of ETs<br/>&gt;<br/>&gt; (define top-damage<br/>&gt;   (lambda (val basis)<br/>&gt;      (let*<br/>&gt;         ((weights (map log2 basis))<br/>&gt;          (ji (map (lambda (x) (* x 1200)) weights))<br/>&gt;          (errors (map abs (map - ji (top-val val basis)))))<br/>&gt;      (apply max (map / errors weights)))))<br/>&gt;<br/>&gt; I&apos;m sure you can follow that -- the only external function is<br/>&gt; top-val, and it returns one of those bastard vals containing<br/>&gt; nonintegers -- in this case, cents of the top tuning of the val.</p><p>I don&apos;t see the optimization there.  TOP-max should be<br/>(max(E)-min(E))/(2+max(E)+min(E)) in algebraic form.</p><p>&gt; What do I have to do to turn this into TOP-RMS?</p><p>For the optimized calculation, it&apos;s (untested and probably unbalanced<br/>parentheses)</p><p>(/ (std (map / errors weights))<br/>   (rms (map / (top-val val basis) weights))))</p><p>where std is the standard deviation and rms is, well, the RMS.  I<br/>assume they&apos;re defined to take a list so you don&apos;t need &quot;apply&quot;.  For<br/>the standard deviation you can subtract the mean from each element in<br/>the list and then calculate the RMS.  If the rest isn&apos;t working, try</p><p>(std (map / errors weights))</p><p>to get the STD error (which is almost TOP-RMS).</p><p>I think I have the right calculation for &quot;w&quot;.  It&apos;s easier not to<br/>calculate the errors in both cases.</p><p>(let ((w (map / (top-val val basis) weights)))<br/>   (/ (std w) (rms w)))</p><p>Then multiply by 1200 to get cents per octave.</p><p>The equivalent for TOP-max is</p><p>(let ((w (map / (top-val val basis) weights)))<br/>   (/ (- (apply max w) (apply min w))<br/>      (+ (apply max w) (apply min w))))</p><p>I think these are the correct statistical functions:</p><p>(define (sqr x) (* x x))<br/>(define (mean s) (/ (apply + s) (length s)))<br/>(define (rms s) (sqrt (mean (map sqr s))))<br/>(define (std s) (sqrt (- (sqr (rms s)) (sqr (mean s)))))</p><p>                           Graham</p></div><h3><a id=17453 href="#17453">ðŸ”—</a>Carl Lumma &#x3C;carl@lumma.org&#x3E;</h3><span>1/2/2009 10:22:01 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Graham wrote:</p><p>&gt;I think I use the Harvard citation standard except for the special<br/>&gt;cases where I say I don&apos;t.</p><p>In the recent doc, I saw &quot;(Smith sevlat)&quot; and &quot;Smith (sevlat)&quot; I<br/>think, though it wasn&apos;t sevlat both times.  Neither one was linked,<br/>while most of the other citations were.</p><p>&gt;&gt; So, here&apos;s my code for TOP-max damage of ETs<br/>&gt;&gt;<br/>&gt;&gt; (define top-damage<br/>&gt;&gt;   (lambda (val basis)<br/>&gt;&gt;      (let*<br/>&gt;&gt;         ((weights (map log2 basis))<br/>&gt;&gt;          (ji (map (lambda (x) (* x 1200)) weights))<br/>&gt;&gt;          (errors (map abs (map - ji (top-val val basis)))))<br/>&gt;&gt;      (apply max (map / errors weights)))))<br/>&gt;&gt;<br/>&gt;&gt; I&apos;m sure you can follow that -- the only external function is<br/>&gt;&gt; top-val, and it returns one of those bastard vals containing<br/>&gt;&gt; nonintegers -- in this case, cents of the top tuning of the val.<br/>&gt;&gt;<br/>&gt;&gt; What do I have to do to turn this into TOP-RMS?<br/>&gt;<br/>&gt;I&apos;ll guess replace &quot;max&quot; with &quot;rms&quot;.</p><p>Is that all it is?  The rms of the weighted errors of the<br/>identities?  I think we&apos;ve been over this before.  :(</p><p>If so, it occurs to me that my other question about TOP-RMS that<br/>IIRC you said you still hadn&apos;t fully answered boils down to<br/>this: If a/b &lt;= c/d, where a and c are errors and b and d are<br/>weights, then for TOP-max</p><p>a/b &lt;= (a+c)/(b+d) &lt;= c/d</p><p>in the worst case, when errors add.  TOP-RMS is then</p><p>(a+c)/(b+d)  ??  sqrt((a/b)^2 + (c/d)^2)</p><p>Let&apos;s assume ?? is &lt;=, which is what we want.  So,</p><p>             ( a^2 d^2 + c^2 b^2 )<br/>...  &lt;=  sqrt( ----------------- )<br/>             (      b^2 d^2      )</p><p>(a+c)^2       a^2 d^2 + c^2 b^2<br/>--------  &lt;=  -----------------<br/>(b+d)^2            b^2 d^2</p><p>a^2 + 2ac + c^2      a^2 d^2 + c^2 b^2<br/>---------------  &lt;=  -----------------<br/>b^2 + 2bd + d^2           b^2 d^2</p><p>(a^2 b^2 c^2) + 2(a^2 c^2 bd)  &lt;=  (c^4 a^2) + (d^4 b^2) +<br/>2(c^3 a^2 d) + 2(d^3 b^2 c) + (b^2 c^2 d^2)</p><p>Which seems quite true.  Unless I made a mistake, which I<br/>probably did.  Does this make any sense?</p><p>&gt;&gt; If this is the answer I can&apos;t quite parse it.<br/>&gt;&gt;<br/>&gt;&gt; (let* ((mapping (append seed-mapping (list next-guess)))<br/>&gt;&gt;        (weighted-size (/ (* next-guess step-size) (car more-primes)))<br/>&gt;&gt;        ; the next few lines determine the type of error<br/>&gt;&gt;        (tot (+ tot weighted-size))<br/>&gt;&gt;        (tot2 (+ tot2 (* weighted-size weighted-size)))<br/>&gt;&gt;        (error (- (length mapping) (/ (* tot tot) tot2))))<br/>&gt;<br/>&gt;No, that&apos;s part of the code for producing all equal temperaments<br/>&gt;within a given error.</p><p>Could you copy the relevant part of the code here?</p><p>-Carl</p></div><h3><a id=17454 href="#17454">ðŸ”—</a>Carl Lumma &#x3C;carl@lumma.org&#x3E;</h3><span>1/2/2009 10:28:59 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Graham wrote:</p><p>&gt;&gt; So, here&apos;s my code for TOP-max damage of ETs<br/>&gt;&gt;<br/>&gt;&gt; (define top-damage<br/>&gt;&gt;   (lambda (val basis)<br/>&gt;&gt;      (let*<br/>&gt;&gt;         ((weights (map log2 basis))<br/>&gt;&gt;          (ji (map (lambda (x) (* x 1200)) weights))<br/>&gt;&gt;          (errors (map abs (map - ji (top-val val basis)))))<br/>&gt;&gt;      (apply max (map / errors weights)))))<br/>&gt;&gt;<br/>&gt;&gt; I&apos;m sure you can follow that -- the only external function is<br/>&gt;&gt; top-val, and it returns one of those bastard vals containing<br/>&gt;&gt; nonintegers -- in this case, cents of the top tuning of the val.<br/>&gt;<br/>&gt;I don&apos;t see the optimization there.  TOP-max should be<br/>&gt;(max(E)-min(E))/(2+max(E)+min(E)) in algebraic form.</p><p>I think you&apos;re talking about the usual trick for catching<br/>errors of the interior intervals, e.g. 5:3.  But I thought it<br/>wasn&apos;t needed for TOP, because in the worst case the errors<br/>add, and so do the weights.</p><p>Anyway, let&apos;s compare results.  I&apos;ve used this on several<br/>occasions and it seemed to work.</p><p>Successive improvements in 17-limit TOP damage.</p><p>       3    5    7   11   13   17<br/> ----------------------------------<br/> 2 : 33.0 77.3 77.3 77.3 77.6 77.6<br/> 3 : 30.2 30.2 61.0 61.0 61.0 61.0<br/> 4 : 33.0 33.0 33.0 40.0 41.0 41.0<br/> 5 :  5.7 19.8 21.4 30.2 30.2 32.8<br/> 6 : 30.2 30.2 30.2 30.2 35.6 35.6<br/> 7 :  5.1  9.4 20.0 20.0 20.0 20.0<br/> 9 : 11.2 14.2 14.2 14.2 14.2 14.7<br/>10 :  5.7 11.4 11.4 12.7 12.7 12.7<br/>12 :  0.6  3.6  6.1  7.6 12.5 12.5<br/>15 :  5.7  5.7  7.2  7.2  7.2  8.7<br/>19 :  2.3  2.3  3.8  6.3  6.3  6.4<br/>22 :  2.2  3.2  3.3  3.3  5.3  5.3<br/>26 :  3.1  3.7  3.8  4.1  4.1  4.1<br/>31 :  1.6  1.8  1.8  1.8  3.1  3.1<br/>41 :  0.2  1.4  1.4  1.9  2.4  2.7<br/>46 :  0.8  1.1  1.7  1.7  1.9  1.9<br/>58 :  0.5  1.5  1.5  1.5  1.5  1.6<br/>72 :  0.6  0.6  0.6  0.6  1.0  1.0</p><p>&gt;&gt; What do I have to do to turn this into TOP-RMS?<br/>&gt;<br/>&gt;For the optimized calculation, it&apos;s (untested and probably<br/>&gt;unbalanced parentheses)</p><p>...I&apos;ll come back to this once some of the more basic outstanding<br/>questions get put to bed.</p><p>-Carl</p></div><h3><a id=17455 href="#17455">ðŸ”—</a>Graham Breed &#x3C;gbreed@gmail.com&#x3E;</h3><span>1/4/2009 4:11:56 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>2009/1/3 Carl Lumma &lt;<a href="mailto:carl@lumma.org">carl@lumma.org</a>&gt;:<br/>&gt; Graham wrote:<br/>&gt;<br/>&gt;&gt;I think I use the Harvard citation standard except for the special<br/>&gt;&gt;cases where I say I don&apos;t.<br/>&gt;<br/>&gt; In the recent doc, I saw &quot;(Smith sevlat)&quot; and &quot;Smith (sevlat)&quot; I<br/>&gt; think, though it wasn&apos;t sevlat both times.  Neither one was linked,<br/>&gt; while most of the other citations were.</p><p>One&apos;s for referring to the article directly, like &quot;Smith said this&quot;.<br/>The other where you add the citation for something else, like<br/>&quot;lattices are really cool. (Smith)&quot;</p><p>&gt;&gt;&gt; So, here&apos;s my code for TOP-max damage of ETs<br/>&gt;&gt;&gt;<br/>&gt;&gt;&gt; (define top-damage<br/>&gt;&gt;&gt;   (lambda (val basis)<br/>&gt;&gt;&gt;      (let*<br/>&gt;&gt;&gt;         ((weights (map log2 basis))<br/>&gt;&gt;&gt;          (ji (map (lambda (x) (* x 1200)) weights))<br/>&gt;&gt;&gt;          (errors (map abs (map - ji (top-val val basis)))))<br/>&gt;&gt;&gt;      (apply max (map / errors weights)))))<br/>&gt;&gt;&gt;<br/>&gt;&gt;&gt; I&apos;m sure you can follow that -- the only external function is<br/>&gt;&gt;&gt; top-val, and it returns one of those bastard vals containing<br/>&gt;&gt;&gt; nonintegers -- in this case, cents of the top tuning of the val.<br/>&gt;&gt;&gt;<br/>&gt;&gt;&gt; What do I have to do to turn this into TOP-RMS?<br/>&gt;&gt;<br/>&gt;&gt;I&apos;ll guess replace &quot;max&quot; with &quot;rms&quot;.<br/>&gt;<br/>&gt; Is that all it is?  The rms of the weighted errors of the<br/>&gt; identities?  I think we&apos;ve been over this before.  :(</p><p>The &quot;O&quot; in TOP the way I do it is &quot;optimal&quot;.  So yes, it&apos;s the RMS of<br/>the weighted errors of the identities, but it should be the optimal<br/>one for any tuning of the temperament (class).</p><p>&gt; If so, it occurs to me that my other question about TOP-RMS that<br/>&gt; IIRC you said you still hadn&apos;t fully answered boils down to<br/>&gt; this: If a/b &lt;= c/d, where a and c are errors and b and d are<br/>&gt; weights, then for TOP-max<br/>&gt;<br/>&gt; a/b &lt;= (a+c)/(b+d) &lt;= c/d<br/>&gt;<br/>&gt; in the worst case, when errors add.  TOP-RMS is then<br/>&gt;<br/>&gt; (a+c)/(b+d)  ??  sqrt((a/b)^2 + (c/d)^2)<br/>&gt;<br/>&gt; Let&apos;s assume ?? is &lt;=, which is what we want.  So,<br/>&gt;<br/>&gt;             ( a^2 d^2 + c^2 b^2 )<br/>&gt; ...  &lt;=  sqrt( ----------------- )<br/>&gt;             (      b^2 d^2      )<br/>&gt;<br/>&gt; (a+c)^2       a^2 d^2 + c^2 b^2<br/>&gt; --------  &lt;=  -----------------<br/>&gt; (b+d)^2            b^2 d^2<br/>&gt;<br/>&gt; a^2 + 2ac + c^2      a^2 d^2 + c^2 b^2<br/>&gt; ---------------  &lt;=  -----------------<br/>&gt; b^2 + 2bd + d^2           b^2 d^2<br/>&gt;<br/>&gt; (a^2 b^2 c^2) + 2(a^2 c^2 bd)  &lt;=  (c^4 a^2) + (d^4 b^2) +<br/>&gt; 2(c^3 a^2 d) + 2(d^3 b^2 c) + (b^2 c^2 d^2)<br/>&gt;<br/>&gt; Which seems quite true.  Unless I made a mistake, which I<br/>&gt; probably did.  Does this make any sense?</p><p>I haven&apos;t followed it, but it should be.  The logic for RMS being less<br/>than the max value is that RMS is a kind of average.  The average is<br/>always going to be less than the worst case.  So if you take the<br/>TOP-max tuning, the weighted RMS must be less than the worst case,<br/>which is the TOP-max error.  The TOP-RMS will be for a different<br/>tuning but that, also being optimal, can only be smaller again.</p><p>&gt;&gt;&gt; If this is the answer I can&apos;t quite parse it.<br/>&gt;&gt;&gt;<br/>&gt;&gt;&gt; (let* ((mapping (append seed-mapping (list next-guess)))<br/>&gt;&gt;&gt;        (weighted-size (/ (* next-guess step-size) (car more-primes)))<br/>&gt;&gt;&gt;        ; the next few lines determine the type of error<br/>&gt;&gt;&gt;        (tot (+ tot weighted-size))<br/>&gt;&gt;&gt;        (tot2 (+ tot2 (* weighted-size weighted-size)))<br/>&gt;&gt;&gt;        (error (- (length mapping) (/ (* tot tot) tot2))))<br/>&gt;&gt;<br/>&gt;&gt;No, that&apos;s part of the code for producing all equal temperaments<br/>&gt;&gt;within a given error.<br/>&gt;<br/>&gt; Could you copy the relevant part of the code here?</p><p>That&apos;s what I put in the other message.  I don&apos;t think I have Scheme<br/>code for finding the TOP-RMS of ETs because I trust these functions to<br/>generate ETs within the limit.  Explaining those functions isn&apos;t easy,<br/>I&apos;m afraid.  I have to work it out on paper and even then there&apos;s some<br/>trial and error.</p><p>                       Graham</p></div><h3><a id=17456 href="#17456">ðŸ”—</a>Graham Breed &#x3C;gbreed@gmail.com&#x3E;</h3><span>1/4/2009 4:21:54 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>2009/1/3 Carl Lumma &lt;<a href="mailto:carl@lumma.org">carl@lumma.org</a>&gt;:<br/>&gt; Graham wrote:</p><p>&gt;&gt;I don&apos;t see the optimization there.  TOP-max should be<br/>&gt;&gt;(max(E)-min(E))/(2+max(E)+min(E)) in algebraic form.<br/>&gt;<br/>&gt; I think you&apos;re talking about the usual trick for catching<br/>&gt; errors of the interior intervals, e.g. 5:3.  But I thought it<br/>&gt; wasn&apos;t needed for TOP, because in the worst case the errors<br/>&gt; add, and so do the weights.</p><p>It isn&apos;t needed for TOP because the optimization takes care of it.<br/>That formula takes you directly to the optimal error without needing<br/>the optimal scale stretch.  It happens that you can simplify it to</p><p>[max(E) - min(E)]/2</p><p>which ignores the optimal scale stretch but catches the interior<br/>intervals anyway.</p><p>&gt; Anyway, let&apos;s compare results.  I&apos;ve used this on several<br/>&gt; occasions and it seemed to work.<br/>&gt;<br/>&gt; Successive improvements in 17-limit TOP damage.<br/>&gt;<br/>&gt;       3    5    7   11   13   17<br/>&gt;  ----------------------------------<br/>&gt;  2 : 33.0 77.3 77.3 77.3 77.6 77.6<br/>&gt;  3 : 30.2 30.2 61.0 61.0 61.0 61.0<br/>&gt;  4 : 33.0 33.0 33.0 40.0 41.0 41.0<br/>&gt;  5 :  5.7 19.8 21.4 30.2 30.2 32.8<br/>&gt;  6 : 30.2 30.2 30.2 30.2 35.6 35.6<br/>&gt;  7 :  5.1  9.4 20.0 20.0 20.0 20.0<br/>&gt;  9 : 11.2 14.2 14.2 14.2 14.2 14.7<br/>&gt; 10 :  5.7 11.4 11.4 12.7 12.7 12.7<br/>&gt; 12 :  0.6  3.6  6.1  7.6 12.5 12.5<br/>&gt; 15 :  5.7  5.7  7.2  7.2  7.2  8.7<br/>&gt; 19 :  2.3  2.3  3.8  6.3  6.3  6.4<br/>&gt; 22 :  2.2  3.2  3.3  3.3  5.3  5.3<br/>&gt; 26 :  3.1  3.7  3.8  4.1  4.1  4.1<br/>&gt; 31 :  1.6  1.8  1.8  1.8  3.1  3.1<br/>&gt; 41 :  0.2  1.4  1.4  1.9  2.4  2.7<br/>&gt; 46 :  0.8  1.1  1.7  1.7  1.9  1.9<br/>&gt; 58 :  0.5  1.5  1.5  1.5  1.5  1.6<br/>&gt; 72 :  0.6  0.6  0.6  0.6  1.0  1.0</p><p>That does look right, and certainly not what you&apos;d get if you weren&apos;t<br/>optimizing.  Here are my figures</p><p> 2: 33.0  77.3  77.3  77.3  79.6  79.6<br/> 3: 30.2  30.2  39.8  39.8  46.7  46.7<br/> 4: 33.0  33.0  33.0  37.5  37.5  37.5<br/> 5:  5.7  19.8  21.4  30.2  25.5  25.5<br/> 6: 30.2  30.2  30.2  30.2  30.2  30.2<br/> 7:  5.1   9.4  20.2  20.2  20.0  20.0<br/> 9: 11.2  14.2  14.2  14.2  14.2  14.7<br/>10:  5.7  11.4  11.4  12.7  12.7  12.7<br/>12:  0.6   3.6   6.1   7.6   8.6   8.6<br/>15:  5.7   5.7   7.2   7.2   7.2   8.3<br/>19:  2.3   2.3   3.8   6.3   6.3   6.7<br/>22:  2.2   3.2   3.3   3.3   5.3   5.3<br/>26:  3.1   3.7   3.8   4.1   4.1   4.1<br/>31:  1.6   1.8   1.8   1.8   3.1   3.1<br/>41:  0.2   1.4   1.4   1.9   2.4   2.7<br/>46:  0.8   1.1   1.7   1.7   1.9   1.9<br/>58:  0.5   1.5   1.5   1.5   1.5   1.6<br/>72:  0.6   0.6   0.6   0.6   1.0   1.0</p><p>                    Graham</p></div><h3><a id=17457 href="#17457">ðŸ”—</a>Carl Lumma &#x3C;carl@lumma.org&#x3E;</h3><span>1/4/2009 8:22:27 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Graham wrote:</p><p>&gt;&gt;&gt;&gt; What do I have to do to turn this into TOP-RMS?<br/>&gt;&gt;&gt;<br/>&gt;&gt;&gt;I&apos;ll guess replace &quot;max&quot; with &quot;rms&quot;.<br/>&gt;&gt;<br/>&gt;&gt; Is that all it is?  The rms of the weighted errors of the<br/>&gt;&gt; identities?  I think we&apos;ve been over this before.  :(<br/>&gt;<br/>&gt;The &quot;O&quot; in TOP the way I do it is &quot;optimal&quot;.  So yes, it&apos;s the RMS of<br/>&gt;the weighted errors of the identities, but it should be the optimal<br/>&gt;one for any tuning of the temperament (class).</p><p>Understood.</p><p>&gt;&gt; If so, it occurs to me that my other question about TOP-RMS that<br/>&gt;&gt; IIRC you said you still hadn&apos;t fully answered boils down to<br/>&gt;&gt; this: If a/b &lt;= c/d, where a and c are errors and b and d are<br/>&gt;&gt; weights, then for TOP-max<br/>&gt;&gt;<br/>&gt;&gt; a/b &lt;= (a+c)/(b+d) &lt;= c/d<br/>&gt;&gt;<br/>&gt;&gt; in the worst case, when errors add.  TOP-RMS is then<br/>&gt;&gt;<br/>&gt;&gt; (a+c)/(b+d)  ??  sqrt((a/b)^2 + (c/d)^2)<br/>&gt;&gt;<br/>&gt;&gt; Let&apos;s assume ?? is &lt;=, which is what we want.  So,<br/>&gt;&gt;<br/>&gt;&gt;             ( a^2 d^2 + c^2 b^2 )<br/>&gt;&gt; ...  &lt;=  sqrt( ----------------- )<br/>&gt;&gt;             (      b^2 d^2      )<br/>&gt;&gt;<br/>&gt;&gt; (a+c)^2       a^2 d^2 + c^2 b^2<br/>&gt;&gt; --------  &lt;=  -----------------<br/>&gt;&gt; (b+d)^2            b^2 d^2<br/>&gt;&gt;<br/>&gt;&gt; a^2 + 2ac + c^2      a^2 d^2 + c^2 b^2<br/>&gt;&gt; ---------------  &lt;=  -----------------<br/>&gt;&gt; b^2 + 2bd + d^2           b^2 d^2<br/>&gt;&gt;<br/>&gt;&gt; (a^2 b^2 c^2) + 2(a^2 c^2 bd)  &lt;=  (c^4 a^2) + (d^4 b^2) +<br/>&gt;&gt; 2(c^3 a^2 d) + 2(d^3 b^2 c) + (b^2 c^2 d^2)<br/>&gt;&gt;<br/>&gt;&gt; Which seems quite true.  Unless I made a mistake, which I<br/>&gt;&gt; probably did.  Does this make any sense?<br/>&gt;<br/>&gt;I haven&apos;t followed it, but it should be.  The logic for RMS being<br/>&gt;less than the max value is that RMS is a kind of average.</p><p>The above is an argument that, e.g. in the 5-limit, the RMS<br/>of the Tenney-weighted errors of 3 &amp; 5 would be *greater than*<br/>or equal to the weighted error of 5/3 or 15/8.  That is,<br/>RMS-primes would give an upper bound on the weighted errors of<br/>these compound intervals.  Ideally this would be extended to<br/>all intervals, as in Max-primes.  Otherwise, we might start<br/>looking for a weighting (other than log Tenney Height) which<br/>satisfied such an inequality for RMS-primes.</p><p>&gt;The average is always going to be less than the worst case.  So<br/>&gt;if you take the TOP-max tuning, the weighted RMS must be less<br/>&gt;than the worst case, which is the TOP-max error.  The TOP-RMS<br/>&gt;will be for a different tuning but that, also being optimal, can<br/>&gt;only be smaller again.</p><p>Right, but this sounds like it is not desirable.  Don&apos;t we<br/>want an *upper* bound to be quickly computable from the primes?</p><p>-Carl</p></div><h3><a id=17458 href="#17458">ðŸ”—</a>Carl Lumma &#x3C;carl@lumma.org&#x3E;</h3><span>1/4/2009 9:41:10 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Graham wrote:</p><p>&gt;&gt;&gt;&gt;(define top-damage<br/>&gt;&gt;&gt;&gt;   (lambda (val basis)<br/>&gt;&gt;&gt;&gt;      (let*<br/>&gt;&gt;&gt;&gt;         ((weights (map log2 basis))<br/>&gt;&gt;&gt;&gt;          (ji (map (lambda (x) (* x 1200)) weights))<br/>&gt;&gt;&gt;&gt;          (errors (map abs (map - ji (top-val val basis)))))<br/>&gt;&gt;&gt;&gt;      (apply max (map / errors weights)))))<br/>&gt;&gt;&gt;&gt;<br/>&gt;&gt;&gt;<br/>&gt;&gt;&gt; I don&apos;t see the optimization there.  TOP-max should be<br/>&gt;&gt;&gt; (max(E)-min(E))/(2+max(E)+min(E)) in algebraic form.<br/>&gt;&gt;<br/>&gt;&gt; I think you&apos;re talking about the usual trick for catching<br/>&gt;&gt; errors of the interior intervals, e.g. 5:3.  But I thought it<br/>&gt;&gt; wasn&apos;t needed for TOP, because in the worst case the errors<br/>&gt;&gt; add, and so do the weights.<br/>&gt;<br/>&gt;It isn&apos;t needed for TOP because the optimization takes care of it.<br/>&gt;That formula takes you directly to the optimal error without needing<br/>&gt;the optimal scale stretch.  It happens that you can simplify it to<br/>&gt;<br/>&gt;[max(E) - min(E)]/2<br/>&gt;<br/>&gt;which ignores the optimal scale stretch but catches the interior<br/>&gt;intervals anyway.</p><p>As shown in the code, I simply take the max weighted error among<br/>the primes to generate the below table.  Not max-min/2.</p><p>&gt;&gt; Anyway, let&apos;s compare results.  I&apos;ve used this on several<br/>&gt;&gt; occasions and it seemed to work.<br/>&gt;&gt;<br/>&gt;&gt; Successive improvements in 17-limit TOP damage.<br/>&gt;&gt;<br/>&gt;&gt;       3    5    7   11   13   17<br/>&gt;&gt;  ----------------------------------<br/>&gt;&gt;  2 : 33.0 77.3 77.3 77.3 77.6 77.6<br/>&gt;&gt;  3 : 30.2 30.2 61.0 61.0 61.0 61.0<br/>&gt;&gt;  4 : 33.0 33.0 33.0 40.0 41.0 41.0<br/>&gt;&gt;  5 :  5.7 19.8 21.4 30.2 30.2 32.8<br/>&gt;&gt;  6 : 30.2 30.2 30.2 30.2 35.6 35.6<br/>&gt;&gt;  7 :  5.1  9.4 20.0 20.0 20.0 20.0<br/>&gt;&gt;  9 : 11.2 14.2 14.2 14.2 14.2 14.7<br/>&gt;&gt; 10 :  5.7 11.4 11.4 12.7 12.7 12.7<br/>&gt;&gt; 12 :  0.6  3.6  6.1  7.6 12.5 12.5<br/>&gt;&gt; 15 :  5.7  5.7  7.2  7.2  7.2  8.7<br/>&gt;&gt; 19 :  2.3  2.3  3.8  6.3  6.3  6.4<br/>&gt;&gt; 22 :  2.2  3.2  3.3  3.3  5.3  5.3<br/>&gt;&gt; 26 :  3.1  3.7  3.8  4.1  4.1  4.1<br/>&gt;&gt; 31 :  1.6  1.8  1.8  1.8  3.1  3.1<br/>&gt;&gt; 41 :  0.2  1.4  1.4  1.9  2.4  2.7<br/>&gt;&gt; 46 :  0.8  1.1  1.7  1.7  1.9  1.9<br/>&gt;&gt; 58 :  0.5  1.5  1.5  1.5  1.5  1.6<br/>&gt;&gt; 72 :  0.6  0.6  0.6  0.6  1.0  1.0<br/>&gt;<br/>&gt;That does look right, and certainly not what you&apos;d get if you weren&apos;t<br/>&gt;optimizing.  Here are my figures<br/>&gt;<br/>&gt; 2: 33.0  77.3  77.3  77.3  79.6  79.6<br/>&gt; 3: 30.2  30.2  39.8  39.8  46.7  46.7<br/>&gt; 4: 33.0  33.0  33.0  37.5  37.5  37.5<br/>&gt; 5:  5.7  19.8  21.4  30.2  25.5  25.5<br/>&gt; 6: 30.2  30.2  30.2  30.2  30.2  30.2<br/>&gt; 7:  5.1   9.4  20.2  20.2  20.0  20.0<br/>&gt; 9: 11.2  14.2  14.2  14.2  14.2  14.7<br/>&gt;10:  5.7  11.4  11.4  12.7  12.7  12.7<br/>&gt;12:  0.6   3.6   6.1   7.6   8.6   8.6<br/>&gt;15:  5.7   5.7   7.2   7.2   7.2   8.3<br/>&gt;19:  2.3   2.3   3.8   6.3   6.3   6.7<br/>&gt;22:  2.2   3.2   3.3   3.3   5.3   5.3<br/>&gt;26:  3.1   3.7   3.8   4.1   4.1   4.1<br/>&gt;31:  1.6   1.8   1.8   1.8   3.1   3.1<br/>&gt;41:  0.2   1.4   1.4   1.9   2.4   2.7<br/>&gt;46:  0.8   1.1   1.7   1.7   1.9   1.9<br/>&gt;58:  0.5   1.5   1.5   1.5   1.5   1.6<br/>&gt;72:  0.6   0.6   0.6   0.6   1.0   1.0</p><p>I get 12.49595001136964 for the 17-limit TOP damage of<br/>12-ET.  You&apos;re getting 8.6.  I&apos;m using only patent vals<br/>here, I think.  &lt;12 19 28 34 42 44 49| in this case.</p><p>Yup, that looks like the porblem.  You&apos;re no-doubt<br/>using &lt;12 19 28 34 42 45 49| to get 8.599414873810039.</p><p>Let&apos;s try 19-ET&apos;s 17-limit damage.  I used<br/>&lt;19 30 44 53 66 70 78| to get 6.441057506662558, and<br/>this time it happens to be the best val and your figure<br/>is higher at 6.7.  There are a few like this.  Know why?</p><p>-Carl</p></div><h3><a id=17459 href="#17459">ðŸ”—</a>Graham Breed &#x3C;gbreed@gmail.com&#x3E;</h3><span>1/4/2009 9:46:03 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>2009/1/5 Carl Lumma &lt;<a href="mailto:carl@lumma.org">carl@lumma.org</a>&gt;:</p><p>&gt; Let&apos;s try 19-ET&apos;s 17-limit damage.  I used<br/>&gt; &lt;19 30 44 53 66 70 78| to get 6.441057506662558, and<br/>&gt; this time it happens to be the best val and your figure<br/>&gt; is higher at 6.7.  There are a few like this.  Know why?</p><p>I was finding the best mapping for TOP-RMS.  Here&apos;s the table using<br/>the best TOP-max mappings:</p><p> 2: 33.0  77.3  77.3  77.3  77.6  77.6<br/> 3: 30.2  30.2  39.8  39.8  45.3  45.3<br/> 4: 33.0  33.0  33.0  37.5  37.5  37.5<br/> 5:  5.7  19.8  21.4  25.5  25.5  25.5<br/> 6: 30.2  30.2  30.2  30.2  30.2  30.2<br/> 7:  5.1   9.4  20.0  20.0  20.0  20.0<br/> 9: 11.2  14.2  14.2  14.2  14.2  14.7<br/>10:  5.7  11.4  11.4  12.7  12.7  12.7<br/>12:  0.6   3.6   6.1   7.6   8.6   8.6<br/>15:  5.7   5.7   7.2   7.2   7.2   8.3<br/>19:  2.3   2.3   3.8   6.3   6.3   6.4<br/>22:  2.2   3.2   3.3   3.3   5.3   5.3<br/>26:  3.1   3.7   3.8   4.1   4.1   4.1<br/>31:  1.6   1.8   1.8   1.8   3.1   3.1<br/>41:  0.2   1.4   1.4   1.9   2.4   2.7<br/>46:  0.8   1.1   1.7   1.7   1.9   1.9<br/>58:  0.5   1.5   1.5   1.5   1.5   1.6<br/>72:  0.6   0.6   0.6   0.6   1.0   1.0</p><p>                   Graham</p></div><h3><a id=17460 href="#17460">ðŸ”—</a>Graham Breed &#x3C;gbreed@gmail.com&#x3E;</h3><span>1/4/2009 11:18:12 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>2009/1/5 Carl Lumma &lt;<a href="mailto:carl@lumma.org">carl@lumma.org</a>&gt;:<br/>&gt; Graham wrote:</p><p>&gt;&gt;&gt; If so, it occurs to me that my other question about TOP-RMS that<br/>&gt;&gt;&gt; IIRC you said you still hadn&apos;t fully answered boils down to<br/>&gt;&gt;&gt; this: If a/b &lt;= c/d, where a and c are errors and b and d are<br/>&gt;&gt;&gt; weights, then for TOP-max<br/>&gt;&gt;&gt;<br/>&gt;&gt;&gt; a/b &lt;= (a+c)/(b+d) &lt;= c/d<br/>&gt;&gt;&gt;<br/>&gt;&gt;&gt; in the worst case, when errors add.  TOP-RMS is then<br/>&gt;&gt;&gt;<br/>&gt;&gt;&gt; (a+c)/(b+d)  ??  sqrt((a/b)^2 + (c/d)^2)<br/>&gt;&gt;&gt;<br/>&gt;&gt;&gt; Let&apos;s assume ?? is &lt;=, which is what we want.  So,<br/>&gt;&gt;&gt;<br/>&gt;&gt;&gt;             ( a^2 d^2 + c^2 b^2 )<br/>&gt;&gt;&gt; ...  &lt;=  sqrt( ----------------- )<br/>&gt;&gt;&gt;             (      b^2 d^2      )<br/>&gt;&gt;&gt;<br/>&gt;&gt;&gt; (a+c)^2       a^2 d^2 + c^2 b^2<br/>&gt;&gt;&gt; --------  &lt;=  -----------------<br/>&gt;&gt;&gt; (b+d)^2            b^2 d^2<br/>&gt;&gt;&gt;<br/>&gt;&gt;&gt; a^2 + 2ac + c^2      a^2 d^2 + c^2 b^2<br/>&gt;&gt;&gt; ---------------  &lt;=  -----------------<br/>&gt;&gt;&gt; b^2 + 2bd + d^2           b^2 d^2<br/>&gt;&gt;&gt;<br/>&gt;&gt;&gt; (a^2 b^2 c^2) + 2(a^2 c^2 bd)  &lt;=  (c^4 a^2) + (d^4 b^2) +<br/>&gt;&gt;&gt; 2(c^3 a^2 d) + 2(d^3 b^2 c) + (b^2 c^2 d^2)<br/>&gt;&gt;&gt;<br/>&gt;&gt;&gt; Which seems quite true.  Unless I made a mistake, which I<br/>&gt;&gt;&gt; probably did.  Does this make any sense?</p><p>I get 2 a b^2 c d^2 &lt;= a^2 d^4 + 2 a^2 b d^3 + b^4 c^2 + 2 b^3 c^2 d.<br/>That may still be wrong but I don&apos;t see how you can get a^2 b^2 c^2.</p><p>&gt;&gt;I haven&apos;t followed it, but it should be.  The logic for RMS being<br/>&gt;&gt;less than the max value is that RMS is a kind of average.<br/>&gt;<br/>&gt; The above is an argument that, e.g. in the 5-limit, the RMS<br/>&gt; of the Tenney-weighted errors of 3 &amp; 5 would be *greater than*<br/>&gt; or equal to the weighted error of 5/3 or 15/8.  That is,<br/>&gt; RMS-primes would give an upper bound on the weighted errors of<br/>&gt; these compound intervals.  Ideally this would be extended to<br/>&gt; all intervals, as in Max-primes.  Otherwise, we might start<br/>&gt; looking for a weighting (other than log Tenney Height) which<br/>&gt; satisfied such an inequality for RMS-primes.</p><p>Why?</p><p>&gt;&gt;The average is always going to be less than the worst case.  So<br/>&gt;&gt;if you take the TOP-max tuning, the weighted RMS must be less<br/>&gt;&gt;than the worst case, which is the TOP-max error.  The TOP-RMS<br/>&gt;&gt;will be for a different tuning but that, also being optimal, can<br/>&gt;&gt;only be smaller again.<br/>&gt;<br/>&gt; Right, but this sounds like it is not desirable.  Don&apos;t we<br/>&gt; want an *upper* bound to be quickly computable from the primes?</p><p>I don&apos;t know what you want.  You said this came from a question you<br/>asked at some unspecified time.  If you want the worst error, you can<br/>always calculate the worst error.</p><p>Knowing the TOP-RMS is smaller than TOP-max means if you can find all<br/>the temperament classes in some range with TOP-RMS error below a given<br/>value, you know it also contains all classes in the same range with<br/>TOP-max below the same value.  Assuming you&apos;re interested in TOP-max<br/>for some reason, that&apos;s useful because it&apos;s easier to search for low<br/>TOP-RMS errors.</p><p>                             Graham</p></div><h3><a id=17461 href="#17461">ðŸ”—</a>Carl Lumma &#x3C;carl@lumma.org&#x3E;</h3><span>1/5/2009 12:27:54 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Graham wrote:<br/>&gt;&gt;&gt;&gt; a^2 + 2ac + c^2      a^2 d^2 + c^2 b^2<br/>&gt;&gt;&gt;&gt; ---------------  &lt;=  -----------------<br/>&gt;&gt;&gt;&gt; b^2 + 2bd + d^2           b^2 d^2<br/>&gt;&gt;&gt;&gt;<br/>&gt;&gt;&gt;&gt; (a^2 b^2 c^2) + 2(a^2 c^2 bd)  &lt;=  (c^4 a^2) + (d^4 b^2) +<br/>&gt;&gt;&gt;&gt; 2(c^3 a^2 d) + 2(d^3 b^2 c) + (b^2 c^2 d^2)<br/>&gt;&gt;&gt;&gt;<br/>&gt;&gt;&gt;&gt; Which seems quite true.  Unless I made a mistake, which I<br/>&gt;&gt;&gt;&gt; probably did.  Does this make any sense?<br/>&gt;<br/>&gt;I get 2 a b^2 c d^2 &lt;= a^2 d^4 + 2 a^2 b d^3 + b^4 c^2 + 2 b^3 c^2 d.<br/>&gt;That may still be wrong but I don&apos;t see how you can get a^2 b^2 c^2.</p><p>I used<br/><a href="http://xrjunque.nom.es/precis/polycalc.aspx">http://xrjunque.nom.es/precis/polycalc.aspx</a></p><p>Now I&apos;m getting<br/>(a^2*b^2*d^2)+(b^2*c^2*d^2)+(b^2*d^2*2ac) &lt;=<br/>(a^4*d^2)+(c^4*b^2)+(a^3*d^2*2c)+(c^3*b^2*2a)+(a^2*b^2*c^2)+(a^2*c^2*d^2)</p><p>&gt;&gt;&gt;I haven&apos;t followed it, but it should be.  The logic for RMS being<br/>&gt;&gt;&gt;less than the max value is that RMS is a kind of average.<br/>&gt;&gt;<br/>&gt;&gt; The above is an argument that, e.g. in the 5-limit, the RMS<br/>&gt;&gt; of the Tenney-weighted errors of 3 &amp; 5 would be *greater than*<br/>&gt;&gt; or equal to the weighted error of 5/3 or 15/8.  That is,<br/>&gt;&gt; RMS-primes would give an upper bound on the weighted errors of<br/>&gt;&gt; these compound intervals.  Ideally this would be extended to<br/>&gt;&gt; all intervals, as in Max-primes.  Otherwise, we might start<br/>&gt;&gt; looking for a weighting (other than log Tenney Height) which<br/>&gt;&gt; satisfied such an inequality for RMS-primes.<br/>&gt;<br/>&gt;Why?</p><p>The whole point of prime-based error is that it&apos;s a shortcut to<br/>measuring all the intervals.  Ideally for Max-primes one uses an<br/>error weighting that makes it come out equal to to Max-all.<br/>Tenney weighting happens to do that.  For RMS-primes the natural<br/>extension would be to use a weighting that makes it come out<br/>equal to RMS-all.  But then there&apos;s the question of how to<br/>define &quot;all&quot;... does the RMS converge?  I think you talk about<br/>this in one of your papers.  Here I was thinking an upper bound<br/>would be good, but maybe that doesn&apos;t make sense.</p><p>&gt;Knowing the TOP-RMS is smaller than TOP-max means if you can find all<br/>&gt;the temperament classes in some range with TOP-RMS error below a given<br/>&gt;value, you know it also contains all classes in the same range with<br/>&gt;TOP-max below the same value.  Assuming you&apos;re interested in TOP-max<br/>&gt;for some reason, that&apos;s useful because it&apos;s easier to search for low<br/>&gt;TOP-RMS errors.</p><p>You&apos;re probably right.</p><p>-Carl</p></div><h3><a id=17462 href="#17462">ðŸ”—</a>Graham Breed &#x3C;gbreed@gmail.com&#x3E;</h3><span>1/5/2009 1:07:53 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>2009/1/5 Carl Lumma &lt;<a href="mailto:carl@lumma.org">carl@lumma.org</a>&gt;:</p><p>&gt; The whole point of prime-based error is that it&apos;s a shortcut to<br/>&gt; measuring all the intervals.  Ideally for Max-primes one uses an<br/>&gt; error weighting that makes it come out equal to to Max-all.<br/>&gt; Tenney weighting happens to do that.  For RMS-primes the natural<br/>&gt; extension would be to use a weighting that makes it come out<br/>&gt; equal to RMS-all.  But then there&apos;s the question of how to<br/>&gt; define &quot;all&quot;... does the RMS converge?  I think you talk about<br/>&gt; this in one of your papers.  Here I was thinking an upper bound<br/>&gt; would be good, but maybe that doesn&apos;t make sense.</p><p>Any Tenney limit, or the intersection of any Tenney and prime limits,<br/>is a particular set of prime weights for an RMS calculation.  So the<br/>optimal RMS over all intervals is the same as the optimal RMS for<br/>given weights of the prime intervals.  These weights tend to the<br/>Tenney weights the complexity tends to infinity, if you weight all the<br/>intervals equally.</p><p>I think you still get Tenney weighting for a big family of weightings<br/>as the complexity approaches to infinity.  It depends on intervals of<br/>similar complexity having similar weight.</p><p>The reason it matters how you approach infinity is that Farey limits<br/>are of a different form.  They can&apos;t be done with simple prime weights<br/>at all.  You need a matrix to specify cross-weights.  But such a<br/>matrix still doesn&apos;t add much to the complexity of the calculation.  I<br/>don&apos;t know what the RMS converges to in this case.</p><p>So TOP-RMS, or weighted-prime RMS in general, is consistent with<br/>Tenney limits.  It means intervals like 30:1 are treated equally with<br/>6:5.  As long as you optimize the scale stretch that&apos;s probably good<br/>enough.  It&apos;s the argument for not bothering with STD errors unless<br/>they&apos;re simpler in a given context.  The applicability is that you<br/>don&apos;t know exactly what you want so you guess some numbers that are<br/>likely to work.</p><p>                           Graham</p></div><h3><a id=17463 href="#17463">ðŸ”—</a>Carl Lumma &#x3C;carl@lumma.org&#x3E;</h3><span>1/5/2009 1:41:54 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Graham wrote:</p><p>&gt;&gt; The whole point of prime-based error is that it&apos;s a shortcut to<br/>&gt;&gt; measuring all the intervals.  Ideally for Max-primes one uses an<br/>&gt;&gt; error weighting that makes it come out equal to to Max-all.<br/>&gt;&gt; Tenney weighting happens to do that.  For RMS-primes the natural<br/>&gt;&gt; extension would be to use a weighting that makes it come out<br/>&gt;&gt; equal to RMS-all.  But then there&apos;s the question of how to<br/>&gt;&gt; define &quot;all&quot;... does the RMS converge?  I think you talk about<br/>&gt;&gt; this in one of your papers.  Here I was thinking an upper bound<br/>&gt;&gt; would be good, but maybe that doesn&apos;t make sense.<br/>&gt;<br/>&gt;Any Tenney limit, or the intersection of any Tenney and prime limits,<br/>&gt;is a particular set of prime weights for an RMS calculation.</p><p>Yes, that&apos;s what I remember from your paper.  Except the other<br/>day when I was looking at it again, the tables seemed to show<br/>Farey limits intsead.</p><p>&gt;So the<br/>&gt;optimal RMS over all intervals is the same as the optimal RMS for<br/>&gt;given weights of the prime intervals.  These weights tend to the<br/>&gt;Tenney weights the complexity tends to infinity,</p><p>You&apos;ve proven this then?  I don&apos;t know why you keep saying<br/>&quot;optimal&quot;, since that to me means a tuning.  Hopefully what<br/>you&apos;re describing here is valid for any tuning I&apos;d like to<br/>measure.</p><p>&gt;if you weight all the intervals equally.<br/>&gt;<br/>&gt;I think you still get Tenney weighting for a big family of weightings<br/>&gt;as the complexity approaches to infinity.  It depends on intervals of<br/>&gt;similar complexity having similar weight.</p><p>I don&apos;t know how to parse this... you seem to be talking about<br/>two different but simultaneous sets of weightings.</p><p>&gt;The reason it matters how you approach infinity is that Farey limits<br/>&gt;are of a different form.  They can&apos;t be done with simple prime weights<br/>&gt;at all.  You need a matrix to specify cross-weights.  But such a<br/>&gt;matrix still doesn&apos;t add much to the complexity of the calculation.  I<br/>&gt;don&apos;t know what the RMS converges to in this case.</p><p>Yes, well Tenney limits are all I care about here.</p><p>-Carl</p></div><h3><a id=17464 href="#17464">ðŸ”—</a>Graham Breed &#x3C;gbreed@gmail.com&#x3E;</h3><span>1/5/2009 2:05:15 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>2009/1/5 Carl Lumma &lt;<a href="mailto:carl@lumma.org">carl@lumma.org</a>&gt;:<br/>&gt; Graham wrote:</p><p>&gt;&gt;Any Tenney limit, or the intersection of any Tenney and prime limits,<br/>&gt;&gt;is a particular set of prime weights for an RMS calculation.<br/>&gt;<br/>&gt; Yes, that&apos;s what I remember from your paper.  Except the other<br/>&gt; day when I was looking at it again, the tables seemed to show<br/>&gt; Farey limits intsead.</p><p>There are tables for both.</p><p>&gt;&gt;So the<br/>&gt;&gt;optimal RMS over all intervals is the same as the optimal RMS for<br/>&gt;&gt;given weights of the prime intervals.  These weights tend to the<br/>&gt;&gt;Tenney weights the complexity tends to infinity,<br/>&gt;<br/>&gt; You&apos;ve proven this then?  I don&apos;t know why you keep saying<br/>&gt; &quot;optimal&quot;, since that to me means a tuning.  Hopefully what<br/>&gt; you&apos;re describing here is valid for any tuning I&apos;d like to<br/>&gt; measure.</p><p>If you&apos;re looking for temperament classes you naturally compare them<br/>with their optimal tunings.  The computation is the same order of<br/>complexity regardless of how many intervals you started with.  It only<br/>depends on the number of primes.</p><p>Going by equation (5) in composite.pdf it looks like the straight RMS<br/>also only depends on the metric in equation (7).  So optimal errors<br/>aren&apos;t special here.  They happened to be the kind I was interested<br/>in.</p><p>I haven&apos;t proven the limit to infinity but it obviously works.</p><p>&gt;&gt;if you weight all the intervals equally.<br/>&gt;&gt;<br/>&gt;&gt;I think you still get Tenney weighting for a big family of weightings<br/>&gt;&gt;as the complexity approaches to infinity.  It depends on intervals of<br/>&gt;&gt;similar complexity having similar weight.<br/>&gt;<br/>&gt; I don&apos;t know how to parse this... you seem to be talking about<br/>&gt; two different but simultaneous sets of weightings.</p><p>Start with n intervals defined on d primes.  Put the weights in a<br/>matrix called W, which is nxd or dxn whichever way you hold it up.<br/>There&apos;s another matrix G which is dxd and defines the same problem<br/>using only the prime intervals.</p><p>&gt;&gt;The reason it matters how you approach infinity is that Farey limits<br/>&gt;&gt;are of a different form.  They can&apos;t be done with simple prime weights<br/>&gt;&gt;at all.  You need a matrix to specify cross-weights.  But such a<br/>&gt;&gt;matrix still doesn&apos;t add much to the complexity of the calculation.  I<br/>&gt;&gt;don&apos;t know what the RMS converges to in this case.<br/>&gt;<br/>&gt; Yes, well Tenney limits are all I care about here.</p><p>So then it&apos;s easy.  The matrix G is already diagonalized.  It gives<br/>you a set of prime weights for a TOP-RMS-like error.  And the higher<br/>the complexity the more it looks like TOP.</p><p>                           Graham</p></div><h3><a id=17465 href="#17465">ðŸ”—</a>Carl Lumma &#x3C;carl@lumma.org&#x3E;</h3><span>1/5/2009 2:11:47 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Graham wrote:</p><p>&gt;Going by equation (5) in composite.pdf it looks like the straight RMS<br/>&gt;also only depends on the metric in equation (7).  So optimal errors<br/>&gt;aren&apos;t special here.  They happened to be the kind I was interested<br/>&gt;in.</p><p>OK.</p><p>&gt;I haven&apos;t proven the limit to infinity but it obviously works.</p><p>OK.</p><p>&gt;So then it&apos;s easy.  The matrix G is already diagonalized.  It gives<br/>&gt;you a set of prime weights for a TOP-RMS-like error.  And the higher<br/>&gt;the complexity the more it looks like TOP.</p><p>What&apos;s the primary advantage, as you see it, to TOP-RMS over<br/>TOP-Max?</p><p>-Carl</p></div><h3><a id=17466 href="#17466">ðŸ”—</a>Graham Breed &#x3C;gbreed@gmail.com&#x3E;</h3><span>1/5/2009 4:50:34 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>2009/1/5 Carl Lumma &lt;<a href="mailto:carl@lumma.org">carl@lumma.org</a>&gt;:</p><p>&gt; What&apos;s the primary advantage, as you see it, to TOP-RMS over<br/>&gt; TOP-Max?</p><p>That it&apos;s easier to work with the optimizations algebraically.  I<br/>think the badness in the title is a very interesting function and<br/>should be studied as pure mathematics.  But I haven&apos;t found it in that<br/>context.</p><p>                          Graham</p></div><h3><a id=17467 href="#17467">ðŸ”—</a>Carl Lumma &#x3C;carl@lumma.org&#x3E;</h3><span>1/6/2009 3:23:46 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Graham wrote:</p><p>&gt;I was finding the best mapping for TOP-RMS.  Here&apos;s the<br/>&gt;table using the best TOP-max mappings:<br/>&gt;<br/>&gt;  2: 33.0  77.3  77.3  77.3  77.6  77.6<br/>&gt;  3: 30.2  30.2  39.8  39.8  45.3  45.3<br/>&gt;  4: 33.0  33.0  33.0  37.5  37.5  37.5<br/>&gt;  5:  5.7  19.8  21.4  25.5  25.5  25.5<br/>&gt;  6: 30.2  30.2  30.2  30.2  30.2  30.2<br/>&gt;  7:  5.1   9.4  20.0  20.0  20.0  20.0<br/>&gt;  9: 11.2  14.2  14.2  14.2  14.2  14.7<br/>&gt; 10:  5.7  11.4  11.4  12.7  12.7  12.7<br/>&gt; 12:  0.6   3.6   6.1   7.6   8.6   8.6<br/>&gt; 15:  5.7   5.7   7.2   7.2   7.2   8.3<br/>&gt; 19:  2.3   2.3   3.8   6.3   6.3   6.4<br/>&gt; 22:  2.2   3.2   3.3   3.3   5.3   5.3<br/>&gt; 26:  3.1   3.7   3.8   4.1   4.1   4.1<br/>&gt; 31:  1.6   1.8   1.8   1.8   3.1   3.1<br/>&gt; 41:  0.2   1.4   1.4   1.9   2.4   2.7<br/>&gt; 46:  0.8   1.1   1.7   1.7   1.9   1.9<br/>&gt; 58:  0.5   1.5   1.5   1.5   1.5   1.6<br/>&gt; 72:  0.6   0.6   0.6   0.6   1.0   1.0<br/>&gt;<br/>&gt;                   Graham</p><p>My numbers agree, though this no longer shows all<br/>the successive improvements in 17-limit damage.<br/>Here&apos;s the complete list:</p><p> (2 (33.0 77.3 77.3 77.3 77.6 77.6))<br/> (3 (30.2 30.2 39.8 39.8 45.3 45.3))<br/> (4 (33.0 33.0 33.0 37.5 37.5 37.5))<br/> (5 (5.7 19.8 21.4 25.5 25.5 25.5))<br/> (7 (5.1 9.4 20.0 20.0 20.0 20.0))<br/> (8 (15.0 15.0 15.0 15.0 15.0 15.0))<br/> (9 (11.2 14.2 14.2 14.2 14.2 14.7))<br/> (10 (5.7 11.4 11.4 12.7 12.7 12.7))<br/> (12 (0.6 3.6 6.1 7.6 8.6 8.6))<br/> (15 (5.7 5.7 7.2 7.2 7.2 8.3))<br/> (17 (1.2 8.0 8.0 8.0 8.0 8.0))<br/> (19 (2.3 2.3 3.8 6.3 6.3 6.4))<br/> (22 (2.2 3.2 3.3 3.3 5.3 5.3))<br/> (26 (3.1 3.7 3.8 4.1 4.1 4.1))<br/> (27 (2.9 2.9 2.9 3.8 3.8 3.8))<br/> (29 (0.5 3.5 3.5 3.5 3.5 3.5))<br/> (31 (1.6 1.8 1.8 1.8 3.1 3.1))<br/> (39 (1.8 2.9 2.9 2.9 2.9 2.9))<br/> (41 (0.2 1.4 1.4 1.9 2.4 2.7))<br/> (46 (0.8 1.1 1.7 1.7 1.9 1.9))<br/> (58 (0.5 1.5 1.5 1.5 1.5 1.6))<br/> (72 (0.6 0.6 0.6 0.6 1.0 1.0))</p><p>-Carl</p></div>