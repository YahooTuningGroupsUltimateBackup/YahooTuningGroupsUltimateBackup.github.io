<a href="/tuning-math">back to list</a><h1>Heuristics (Was: Hi Dave K.)</h1><h3>graham@microtonal.co.uk</h3><span>1/21/2002 4:20:00 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>In-Reply-To: &lt;<a href="mailto:a2g36a+7sl3@eGroups.com">a2g36a+7sl3@eGroups.com</a>&gt;<br/>Gene:<br/>&gt; &gt; I don&apos;t know. What I&apos;d like to know is what a version of your<br/>&gt; &gt;heuristic would be which applies to sets of commas--is this what you<br/>&gt; &gt;are aiming at?</p><p>Paul:<br/>&gt; Eventually. It would probably involve some definition of the dot<br/>&gt; product of the commas in a tri-taxicab metric. But I like to start<br/>&gt; simple, and perhaps if we can formulate the right error measure in 5-<br/>&gt; limit, we can generalize it and use it for 7-limit even without<br/>&gt; knowing how one would apply the heuristic.</p><p>My experience of generating and sorting linear temperaments from the 5- to<br/>the 21-limit is that the &quot;right&quot; error metric for one can be wildly<br/>inappropriate for others.</p><p>One assumption behind the heuristic is that the error is proportional to<br/>the size/complexity of the unison vector.  If you measure complexity as<br/>the number of consonant intervals, that&apos;s the best case of tempering it<br/>out.  Higher-limit linear temperaments tend not to be best cases, but the<br/>proportionality might still work.  At least if you can magically produce<br/>orthogonal unison vectors.  I&apos;ll have to look at lattice theory more.</p><p>The other assumption is that the octave-specific Tenney metric<br/>approximates the number of consonant intervals a comma&apos;s composed of.  I&apos;m<br/>not sure how closely this holds.  The Tenney metric is a good match for<br/>the first-order odd limit of small intervals.  But extended limits can<br/>behave differently.</p><p>For example, 2401:2400 works well in the 7-limit because the numerator<br/>only involves 7, so it has a complexity of 4 despite being fairly complex<br/>and superparticular.  Whereas a comma involving 11**4, or 14641, still<br/>only has a complexity of 4 in the 11-limit.  So if you could get a<br/>superparticular like that, it&apos;d lead to a much smaller error.</p><p>It should follow that 5**4:(13*3*2**4) or 625:624 will be particularly<br/>inefficient between the 13- and 23-limits relative to what the heuristic<br/>would predict.  It still has a complexity of 4, whereas 13**3 is already<br/>2197 and 23**2 is 529.  Yes, 12168:12167 is a 23-limit comma with a<br/>complexity of 3.  (8*9*13*13):(13**3).</p><p>I&apos;d prefer to see a heuristic for how complex a temperament produced for a<br/>set of unison vectors or pair of ETs will be.  Or one for how small the<br/>error will be when it&apos;s generated by ETs.</p><p>                           Graham</p></div><h3>paulerlich &#x3C;paul@stretch-music.com&#x3E;</h3><span>1/22/2002 4:22:50 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., graham@m... wrote:</p><p>&gt; My experience of generating and sorting linear temperaments from<br/>the 5- to<br/>&gt; the 21-limit is that the &quot;right&quot; error metric for one can be wildly<br/>&gt; inappropriate for others.</p><p>Can you give an example?</p><p>&gt; One assumption behind the heuristic is that the error is<br/>proportional to<br/>&gt; the size/complexity of the unison vector.</p><p>You can call it an assumption, if you wish -- I&apos;ve verified its<br/>approximate correctness for all 10 (wildly different) temperaments<br/>I&apos;ve tried, against Gene&apos;s rms measures.</p><p>&gt; If you measure complexity as<br/>&gt; the number of consonant intervals, that&apos;s the best case of<br/>tempering it<br/>&gt; out.</p><p>What does that mean?</p><p>&gt; Higher-limit linear temperaments tend not to be best cases, but the<br/>&gt; proportionality might still work.  At least if you can magically<br/>produce<br/>&gt; orthogonal unison vectors.  I&apos;ll have to look at lattice theory<br/>more.</p><p>Well, so far I&apos;ve only considered the case where one unison vector is<br/>tempered out.</p><p>&gt; The other assumption is that the octave-specific Tenney metric<br/>&gt; approximates the number of consonant intervals a comma&apos;s composed<br/>of.  I&apos;m<br/>&gt; not sure how closely this holds.</p><p>This is based on the Kees van Prooijen lattice metric, and again its<br/>good approximation was verified relative to Gene&apos;s rms measure.</p><p>&gt; The Tenney metric is a good match for<br/>&gt; the first-order odd limit of small intervals.  But extended limits<br/>can<br/>&gt; behave differently.<br/>&gt;<br/>&gt; For example, 2401:2400 works well in the 7-limit because the<br/>numerator<br/>&gt; only involves 7, so it has a complexity of 4 despite being fairly<br/>complex<br/>&gt; and superparticular.</p><p>This is only one possible complexity measure, not the one Gene&apos;s<br/>currently using, which already showed a good match with the<br/>heuristic. A better one awaits . . .</p><p>&gt; Whereas a comma involving 11**4, or 14641, still<br/>&gt; only has a complexity of 4 in the 11-limit.  So if you could get a<br/>&gt; superparticular like that, it&apos;d lead to a much smaller error.</p><p>You&apos;re missing the lattice justification for the heuristic. No wonder<br/>you&apos;re skeptical!</p><p>&gt; It should follow that 5**4:(13*3*2**4) or 625:624 will be<br/>particularly<br/>&gt; inefficient between the 13- and 23-limits relative to what the<br/>heuristic<br/>&gt; would predict.</p><p>Why? Try a 2D system based on 5 and 13. The heuristics should work<br/>fine, especially if you weight ratios of 13 as less important than<br/>ratios of 5.</p></div><h3>graham@microtonal.co.uk</h3><span>1/22/2002 8:43:00 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>In-Reply-To: &lt;<a href="mailto:a2jliq+9hrb@eGroups.com">a2jliq+9hrb@eGroups.com</a>&gt;<br/>Me:<br/>&gt; &gt; My experience of generating and sorting linear temperaments from<br/>&gt; the 5- to<br/>&gt; &gt; the 21-limit is that the &quot;right&quot; error metric for one can be wildly<br/>&gt; &gt; inappropriate for others.</p><p>Paul:<br/>&gt; Can you give an example?</p><p>The first run through of my temperament generator, when I was using<br/>step-cents gave absurdly complex and accurate 5-limit temperaments.  Using<br/>only consistent ETs works well enough up to the 15-limit, but beyond that<br/>optimal temperaments are missed.  At least with the current metrics.</p><p>Me:<br/>&gt; &gt; One assumption behind the heuristic is that the error is<br/>&gt; proportional to<br/>&gt; &gt; the size/complexity of the unison vector.</p><p>Paul:<br/>&gt; You can call it an assumption, if you wish -- I&apos;ve verified its<br/>&gt; approximate correctness for all 10 (wildly different) temperaments<br/>&gt; I&apos;ve tried, against Gene&apos;s rms measures.</p><p>How many dimensions?</p><p>Me:<br/>&gt; &gt; If you measure complexity as<br/>&gt; &gt; the number of consonant intervals, that&apos;s the best case of<br/>&gt; tempering it<br/>&gt; &gt; out.</p><p>Paul:<br/>&gt; What does that mean?</p><p>It&apos;s the microtemperament formula.  Last time I mentioned it, you pointed<br/>me to one of your own messages.  For the minimax temperament, tempering<br/>out one unison vector, the error is the size of the comma divided by the<br/>number of consonances making it up.  When you&apos;re tempering out more than<br/>one comma, the result will typically be worse than the best case for any<br/>of the commas on their own.  But it can never be better than for only one<br/>comma.</p><p>Paul:<br/>&gt; Well, so far I&apos;ve only considered the case where one unison vector is<br/>&gt; tempered out.</p><p>I&apos;m only questioning size/complexity as a heuristic when you have more<br/>than one unison vector.  It might still work then.</p><p>&gt; &gt; The other assumption is that the octave-specific Tenney metric<br/>&gt; &gt; approximates the number of consonant intervals a comma&apos;s composed<br/>&gt; of.  I&apos;m<br/>&gt; &gt; not sure how closely this holds.<br/>&gt;<br/>&gt; This is based on the Kees van Prooijen lattice metric, and again its<br/>&gt; good approximation was verified relative to Gene&apos;s rms measure.</p><p>&gt;From the exposition I have, &apos;The &quot;length&quot; of a unison vector<br/>... in the Tenney lattice with taxicab metric ... is proportional to ...<br/>the &quot;number&quot; ... of consonant intervals making<br/>up that unison vector.&apos;  That&apos;s what I&apos;m disagreeing with.  Why does the<br/>KvP metric behave differently?</p><p>Me:<br/>&gt; &gt; For example, 2401:2400 works well in the 7-limit because the<br/>&gt; numerator<br/>&gt; &gt; only involves 7, so it has a complexity of 4 despite being fairly<br/>&gt; complex<br/>&gt; &gt; and superparticular.</p><p>Paul:<br/>&gt; This is only one possible complexity measure, not the one Gene&apos;s<br/>&gt; currently using, which already showed a good match with the<br/>&gt; heuristic. A better one awaits . . .</p><p>It&apos;s a complexity measure based on</p><p>1)  The odd limit</p><p>2)  Minimax tuning</p><p>I thought we agreed that (1) was as good as any simple, all-purpose,<br/>numerical dissonance metric.  Also that it gave the same results as the<br/>octave-specific Tenney metric (or product limit) for small intervals.  I&apos;m<br/>not prepared to abandon this solely in order to make your heuristic work.</p><p>I use (2) because it&apos;s simple to find the rule, at least for only one<br/>commatic unison vector.  I expect RMS optimisation would give similar<br/>results provided all consonances are treated equally.  If this isn&apos;t the<br/>case, I want a good reason why.</p><p>Me:<br/>&gt; &gt; Whereas a comma involving 11**4, or 14641, still<br/>&gt; &gt; only has a complexity of 4 in the 11-limit.  So if you could get a<br/>&gt; &gt; superparticular like that, it&apos;d lead to a much smaller error.</p><p>Paul:<br/>&gt; You&apos;re missing the lattice justification for the heuristic. No wonder<br/>&gt; you&apos;re skeptical!</p><p>I&apos;m working with the precise theory I already have.  And you&apos;re asking me<br/>to give it up for a heuristic?</p><p>Me:<br/>&gt; &gt; It should follow that 5**4:(13*3*2**4) or 625:624 will be<br/>&gt; particularly<br/>&gt; &gt; inefficient between the 13- and 23-limits relative to what the<br/>&gt; heuristic<br/>&gt; &gt; would predict.</p><p>Paul:<br/>&gt; Why? Try a 2D system based on 5 and 13. The heuristics should work<br/>&gt; fine, especially if you weight ratios of 13 as less important than<br/>&gt; ratios of 5.</p><p>Yes, it&apos;ll work fine as long as you fudge the metric to get it to work.<br/>Making ratios of 13 &quot;less important&quot; means allowing them to be more out of<br/>tune.  My experience is that the more complex intervals get, the more<br/>accurately they have to be tuned to sound right.</p><p>A planar temperament optimising the minimax would give exactly<br/>1200*log2(625/624)/4 = 0.7 cents for the worst interval.  In fact, I think<br/>that&apos;s with 13:8 just so 5:4 and 13:10 are both out by 0.7 cents.  Other<br/>methods are hardly likely to make anything badly out of tune, but that&apos;s<br/>fourth-order, superparticular, planar temperaments for you.</p><p>How is one temperament supposed to work or not work according to a<br/>heuristic that only states a proportionality?  My rule gives exact<br/>results, and it works.  But only when one unison vector is being tempered<br/>out.  Actually, not always then.  For example 9*3 would be two consonances<br/>in the 9-limit but should be weighted as 1.5.  But the difference between<br/>1.5 and 2 is less than that between 5 and 23.</p><p>                    Graham</p></div><h3>paulerlich &#x3C;paul@stretch-music.com&#x3E;</h3><span>1/22/2002 9:05:34 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., graham@m... wrote:<br/>&gt; In-Reply-To: &lt;a2jliq+9hrb@e...&gt;<br/>&gt; Me:<br/>&gt; &gt; &gt; My experience of generating and sorting linear temperaments<br/>from<br/>&gt; &gt; the 5- to<br/>&gt; &gt; &gt; the 21-limit is that the &quot;right&quot; error metric for one can be<br/>wildly<br/>&gt; &gt; &gt; inappropriate for others.<br/>&gt;<br/>&gt; Paul:<br/>&gt; &gt; Can you give an example?<br/>&gt;<br/>&gt; The first run through of my temperament generator, when I was using<br/>&gt; step-cents gave absurdly complex and accurate 5-limit<br/>temperaments.  Using<br/>&gt; only consistent ETs works well enough up to the 15-limit, but<br/>beyond that<br/>&gt; optimal temperaments are missed.  At least with the current metrics.</p><p>What does any of this have to do with the validity of the heuristics?<br/>You seem to be talking about goodness/badness, as well as the<br/>generating-from-ETs-missed-some issue, neither of which have anything<br/>to do with the validity of the heuristics. Of course, once you define<br/>a goodness/badness measure, you should be able to use the heuristic<br/>for step/complexity, combined with the heuristic for cents/error, to<br/>approximate that goodness/badness measure.</p><p>&gt; Me:<br/>&gt; &gt; &gt; One assumption behind the heuristic is that the error is<br/>&gt; &gt; proportional to<br/>&gt; &gt; &gt; the size/complexity of the unison vector.<br/>&gt;<br/>&gt; Paul:<br/>&gt; &gt; You can call it an assumption, if you wish -- I&apos;ve verified its<br/>&gt; &gt; approximate correctness for all 10 (wildly different)<br/>temperaments<br/>&gt; &gt; I&apos;ve tried, against Gene&apos;s rms measures.<br/>&gt;<br/>&gt; How many dimensions?</p><p>These were all 5-limit linear temperaments.</p><p>&gt;<br/>&gt; I&apos;m only questioning size/complexity as a heuristic</p><p>Hmm . . . you may be misunderstanding something. Can you clarify what<br/>you mean by this?</p><p>&gt; when you have more<br/>&gt; than one unison vector.</p><p>More than one tempered out? Why don&apos;t we focus on the case of just<br/>one tempered out first.</p><p>&gt; &gt; &gt; The other assumption is that the octave-specific Tenney metric<br/>&gt; &gt; &gt; approximates the number of consonant intervals a comma&apos;s<br/>composed<br/>&gt; &gt; of.  I&apos;m<br/>&gt; &gt; &gt; not sure how closely this holds.<br/>&gt; &gt;<br/>&gt; &gt; This is based on the Kees van Prooijen lattice metric, and again<br/>its<br/>&gt; &gt; good approximation was verified relative to Gene&apos;s rms measure.<br/>&gt;<br/>&gt; &gt;From the exposition I have, &apos;The &quot;length&quot; of a unison vector<br/>&gt; ... in the Tenney lattice with taxicab metric ... is proportional<br/>to ...<br/>&gt; the &quot;number&quot; ... of consonant intervals making<br/>&gt; up that unison vector.&apos;  That&apos;s what I&apos;m disagreeing with.</p><p>Why are you disagreeing? Note that &quot;number&quot; is _weighted_ -- more<br/>complex consonances are longer and count as &quot;fewer&quot; consonances.</p><p>?<br/>&gt;<br/>&gt; Me:<br/>&gt; &gt; &gt; For example, 2401:2400 works well in the 7-limit because the<br/>&gt; &gt; numerator<br/>&gt; &gt; &gt; only involves 7, so it has a complexity of 4 despite being<br/>fairly<br/>&gt; &gt; complex<br/>&gt; &gt; &gt; and superparticular.<br/>&gt;<br/>&gt; Paul:<br/>&gt; &gt; This is only one possible complexity measure, not the one Gene&apos;s<br/>&gt; &gt; currently using, which already showed a good match with the<br/>&gt; &gt; heuristic. A better one awaits . . .<br/>&gt;<br/>&gt; It&apos;s a complexity measure based on<br/>&gt;<br/>&gt; 1)  The odd limit<br/>&gt;<br/>&gt; 2)  Minimax tuning<br/>&gt;<br/>&gt; I thought we agreed that (1) was as good as any simple, all-<br/>purpose,<br/>&gt; numerical dissonance metric.  Also that it gave the same results as<br/>the<br/>&gt; octave-specific Tenney metric (or product limit) for small<br/>intervals.  I&apos;m<br/>&gt; not prepared to abandon this solely in order to make your heuristic<br/>work.</p><p>My heuristic says the complexity is proportional to log(d), where d<br/>is either the numerator or denominator (since they&apos;re close). Since<br/>either n or d is the odd limit, my heuristic is equivalent to (1). So<br/>you wouldn&apos;t be abandoning anything.</p><p>&gt; I use (2) because it&apos;s simple to find the rule, at least for only<br/>one<br/>&gt; commatic unison vector.  I expect RMS optimisation would give<br/>similar<br/>&gt; results provided all consonances are treated equally.</p><p>RMS optimiziation gave similar results to my heuristic -- so what&apos;s<br/>the problem?<br/>&gt;<br/>&gt; Yes, it&apos;ll work fine as long as you fudge the metric to get it to<br/>work.<br/>&gt; Making ratios of 13 &quot;less important&quot; means allowing them to be more<br/>out of<br/>&gt; tune.  My experience is that the more complex intervals get, the<br/>more<br/>&gt; accurately they have to be tuned to sound right.</p><p>Well, this is the age-old question. It depends what you mean<br/>by &quot;sounds right&quot;. We&apos;ve spent so much time discussing this in the<br/>past, how this could go either way . . . personally, I don&apos;t find<br/>ratios of 13 to be &quot;meaningful&quot; as isolated dyads, and in the context<br/>of big otonalities, you can notice mistuning in the most consonant<br/>ratios more easily than mistuning in the 13 identity.</p><p>&gt; How is one temperament supposed to work or not work according to a<br/>&gt; heuristic that only states a proportionality?</p><p>I calculated the constants of proportionality for both heuristics for<br/>10 vastly different temperaments, using Gene&apos;s rms optimized results,<br/>and the constants of proportionality for each heuristic were all<br/>within a factor of 2 of one another. Did you miss that post?</p></div><h3>paulerlich &#x3C;paul@stretch-music.com&#x3E;</h3><span>1/22/2002 9:06:37 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., graham@m... wrote:</p><p>&gt; My experience is that the more complex intervals get, the more<br/>&gt; accurately they have to be tuned to sound right.</p><p>So perhaps you&apos;d like to temper the octaves most of all?</p></div><h3>graham@microtonal.co.uk</h3><span>1/22/2002 9:44:00 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>In-Reply-To: &lt;<a href="mailto:a2k66t+5ccs@eGroups.com">a2k66t+5ccs@eGroups.com</a>&gt;<br/>paulerlich wrote:</p><p>&gt; --- In tuning-math@y..., graham@m... wrote:<br/>&gt;<br/>&gt; &gt; My experience is that the more complex intervals get, the more<br/>&gt; &gt; accurately they have to be tuned to sound right.<br/>&gt;<br/>&gt; So perhaps you&apos;d like to temper the octaves most of all?</p><p>I&apos;ve mostly used octave-equivalent systems so far, so the opportunity<br/>doesn&apos;t present itself.  Making the octaves worse would also make the most<br/>complex intervals worse, and some instruments don&apos;t allow you to do so<br/>anyway.  Besides, I treat octaves and fifths as special cases.  But this<br/>is certainly something to look at in the future.</p><p>Oh, and if we&apos;re getting into specifics, a system with 11:8, 9:7, 9:8 and<br/>11:7 tends to leave 8 on a par with 7, 11 and 9.  So 2 would only end up<br/>with a third the error of 7 and 11.</p><p>                Graham</p></div><h3>graham@microtonal.co.uk</h3><span>1/22/2002 9:44:00 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>In-Reply-To: &lt;<a href="mailto:a2k64u+qmc3@eGroups.com">a2k64u+qmc3@eGroups.com</a>&gt;<br/>paulerlich wrote:</p><p>&gt; What does any of this have to do with the validity of the heuristics?<br/>&gt; You seem to be talking about goodness/badness, as well as the<br/>&gt; generating-from-ETs-missed-some issue, neither of which have anything<br/>&gt; to do with the validity of the heuristics. Of course, once you define<br/>&gt; a goodness/badness measure, you should be able to use the heuristic<br/>&gt; for step/complexity, combined with the heuristic for cents/error, to<br/>&gt; approximate that goodness/badness measure.</p><p>I&apos;m saying that one dimensional results don&apos;t usually generalise well to<br/>more complex cases.</p><p>Me:<br/>&gt; &gt; I&apos;m only questioning size/complexity as a heuristic</p><p>Paul:<br/>&gt; Hmm . . . you may be misunderstanding something. Can you clarify what<br/>&gt; you mean by this?</p><p>Me:<br/>&gt; &gt; when you have more<br/>&gt; &gt; than one unison vector.</p><p>Paul:<br/>&gt; More than one tempered out? Why don&apos;t we focus on the case of just<br/>&gt; one tempered out first.</p><p>Yes, that&apos;s fine, we agree on that case.  That&apos;s why I said I wasn&apos;t<br/>questioning it.</p><p>Me:<br/>&gt; &gt; &gt;From the exposition I have, &apos;The &quot;length&quot; of a unison vector<br/>&gt; &gt; ... in the Tenney lattice with taxicab metric ... is proportional<br/>&gt; to ...<br/>&gt; &gt; the &quot;number&quot; ... of consonant intervals making<br/>&gt; &gt; up that unison vector.&apos;  That&apos;s what I&apos;m disagreeing with.</p><p>Paul:<br/>&gt; Why are you disagreeing? Note that &quot;number&quot; is _weighted_ -- more<br/>&gt; complex consonances are longer and count as &quot;fewer&quot; consonances.</p><p>I was assuming that numbers were numbers and didn&apos;t carry weights.  I<br/>thought that was the difference between numbers and amounts.</p><p>&gt; My heuristic says the complexity is proportional to log(d), where d<br/>&gt; is either the numerator or denominator (since they&apos;re close). Since<br/>&gt; either n or d is the odd limit, my heuristic is equivalent to (1). So<br/>&gt; you wouldn&apos;t be abandoning anything.</p><p>The examples I gave before show that the Tenney length of a unison vector<br/>isn&apos;t a good predictor of the smallest number of intervals within a given<br/>odd limit that make it up.  The numerator and denominator being close<br/>simply mean that the Tenney metric will be a predictor of the odd limit<br/>*for that interval*.  It works differently when you look at combinations<br/>of intervals.</p><p>&gt; RMS optimiziation gave similar results to my heuristic -- so what&apos;s<br/>&gt; the problem?</p><p>I assume there&apos;s no problem with RMS as opposed to minimax.  If your<br/>results agree, there&apos;s no problem.</p><p>&gt; Well, this is the age-old question. It depends what you mean<br/>&gt; by &quot;sounds right&quot;. We&apos;ve spent so much time discussing this in the<br/>&gt; past, how this could go either way . . . personally, I don&apos;t find<br/>&gt; ratios of 13 to be &quot;meaningful&quot; as isolated dyads, and in the context<br/>&gt; of big otonalities, you can notice mistuning in the most consonant<br/>&gt; ratios more easily than mistuning in the 13 identity.</p><p>Yes, it&apos;s not something I would normally pursue.  I work on the<br/>simplest-case metric that all intervals deemed consonant are treated<br/>equally in tuning.  I can then do the fine tuning by ear.  But if you&apos;re<br/>suggesting something that will only work with the opposite weighting to<br/>what I now prefer, I&apos;ll disagree with it.</p><p>&gt; &gt; How is one temperament supposed to work or not work according to a<br/>&gt; &gt; heuristic that only states a proportionality?<br/>&gt;<br/>&gt; I calculated the constants of proportionality for both heuristics for<br/>&gt; 10 vastly different temperaments, using Gene&apos;s rms optimized results,<br/>&gt; and the constants of proportionality for each heuristic were all<br/>&gt; within a factor of 2 of one another. Did you miss that post?</p><p>I obviously didn&apos;t pay much attention to it.  Do you have a rough figure<br/>for &quot;Erlich&apos;s constant&quot; then?  A factor of 2 still sounds a bit wayward.</p><p>                   Graham</p></div><h3>paulerlich &#x3C;paul@stretch-music.com&#x3E;</h3><span>1/22/2002 9:47:04 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., graham@m... wrote:<br/>&gt; In-Reply-To: &lt;a2k66t+5ccs@e...&gt;<br/>&gt; paulerlich wrote:<br/>&gt;<br/>&gt; &gt; --- In tuning-math@y..., graham@m... wrote:<br/>&gt; &gt;<br/>&gt; &gt; &gt; My experience is that the more complex intervals get, the more<br/>&gt; &gt; &gt; accurately they have to be tuned to sound right.<br/>&gt; &gt;<br/>&gt; &gt; So perhaps you&apos;d like to temper the octaves most of all?<br/>&gt;<br/>&gt; I&apos;ve mostly used octave-equivalent systems so far, so the<br/>opportunity<br/>&gt; doesn&apos;t present itself.  Making the octaves worse would also make<br/>the most<br/>&gt; complex intervals worse,</p><p>Huh? And if this is true, why wouldn&apos;t this be true of, say, ratios<br/>of 5?</p><p>&gt; and some instruments don&apos;t allow you to do so<br/>&gt; anyway.</p><p>?</p></div><h3>paulerlich &#x3C;paul@stretch-music.com&#x3E;</h3><span>1/22/2002 9:56:38 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., graham@m... wrote:</p><p>&gt; Me:<br/>&gt; &gt; &gt; &gt;From the exposition I have, &apos;The &quot;length&quot; of a unison vector<br/>&gt; &gt; &gt; ... in the Tenney lattice with taxicab metric ... is<br/>proportional<br/>&gt; &gt; to ...<br/>&gt; &gt; &gt; the &quot;number&quot; ... of consonant intervals making<br/>&gt; &gt; &gt; up that unison vector.&apos;  That&apos;s what I&apos;m disagreeing with.<br/>&gt;<br/>&gt; Paul:<br/>&gt; &gt; Why are you disagreeing? Note that &quot;number&quot; is _weighted_ -- more<br/>&gt; &gt; complex consonances are longer and count as &quot;fewer&quot; consonances.<br/>&gt;<br/>&gt; I was assuming that numbers were numbers and didn&apos;t carry weights.</p><p>Note that I put &quot;number&quot; in quotes.</p><p>&gt; &gt; My heuristic says the complexity is proportional to log(d), where<br/>d<br/>&gt; &gt; is either the numerator or denominator (since they&apos;re close).<br/>Since<br/>&gt; &gt; either n or d is the odd limit, my heuristic is equivalent to<br/>(1). So<br/>&gt; &gt; you wouldn&apos;t be abandoning anything.<br/>&gt;<br/>&gt; The examples I gave before show that the Tenney length of a unison<br/>vector<br/>&gt; isn&apos;t a good predictor of the smallest number of intervals within a<br/>given<br/>&gt; odd limit that make it up.</p><p>But I&apos;ve always argued that the complexity measure should be<br/>weighted. It&apos;s easier to hear progressions by 3/2 than progressions<br/>by 5/4 . . .</p><p>&gt; The numerator and denominator being close<br/>&gt; simply mean that the Tenney metric will be a predictor of the odd<br/>limit<br/>&gt; *for that interval*.  It works differently when you look at<br/>combinations<br/>&gt; of intervals.</p><p>Again, just focusing on linear temperaments from a &quot;two-dimensional&quot;<br/>just lattice for now . . .</p><p>&gt; Yes, it&apos;s not something I would normally pursue.  I work on the<br/>&gt; simplest-case metric that all intervals deemed consonant are<br/>treated<br/>&gt; equally in tuning.  I can then do the fine tuning by ear.  But if<br/>you&apos;re<br/>&gt; suggesting something that will only work with the opposite<br/>weighting to<br/>&gt; what I now prefer, I&apos;ll disagree with it.</p><p>Maybe we each have to write our own paper, then. I&apos;m hoping someone<br/>will help me with the math for mine . . .</p><p>&gt; &gt; &gt; How is one temperament supposed to work or not work according<br/>to a<br/>&gt; &gt; &gt; heuristic that only states a proportionality?<br/>&gt; &gt;<br/>&gt; &gt; I calculated the constants of proportionality for both heuristics<br/>for<br/>&gt; &gt; 10 vastly different temperaments, using Gene&apos;s rms optimized<br/>results,<br/>&gt; &gt; and the constants of proportionality for each heuristic were all<br/>&gt; &gt; within a factor of 2 of one another. Did you miss that post?<br/>&gt;<br/>&gt; I obviously didn&apos;t pay much attention to it.</p><p><a href="http://groups.yahoo.com/group/tuning-math/message/2491">http://groups.yahoo.com/group/tuning-math/message/2491</a><br/>&quot;Expand Messages&quot; as usual.</p><p>&gt; A factor of 2 still sounds a bit wayward.</p><p>Not bad at all considering the wide range of complexities of these<br/>temperaments . . . but I&apos;m still hunting for the &quot;natural&quot; set of<br/>definitions of &quot;error&quot; and &quot;complexity&quot; that will make the heuristic<br/>work real real good. Once you&apos;ve found a good temperament, changing<br/>its error function is not going to change its goodness very much. So<br/>why not look for a mathematically pretty way to find good<br/>temperaments? That&apos;s something I&apos;m interested in, at any rate.</p></div><h3>graham@microtonal.co.uk</h3><span>1/22/2002 10:00:00 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>In-Reply-To: &lt;<a href="mailto:a2k8io+j4al@eGroups.com">a2k8io+j4al@eGroups.com</a>&gt;<br/>Me:<br/>&gt; &gt; I&apos;ve mostly used octave-equivalent systems so far, so the<br/>&gt; opportunity<br/>&gt; &gt; doesn&apos;t present itself.  Making the octaves worse would also make<br/>&gt; the most<br/>&gt; &gt; complex intervals worse,</p><p>Paul:<br/>&gt; Huh? And if this is true, why wouldn&apos;t this be true of, say, ratios<br/>&gt; of 5?</p><p>It would be true in a 25-limit system.  Also, where 3 is involved, in a<br/>15-limit system, although I&apos;m not sure how the maths work out for that.<br/>So far, I&apos;ve only tuned up 11-limit systems.</p><p>&gt; &gt; and some instruments don&apos;t allow you to do so<br/>&gt; &gt; anyway.<br/>&gt;<br/>&gt; ?</p><p>I have a Korg X5D (currently being repaired) which only supports octave<br/>based tuning tables.  If I want to use it, everything else has to fall in<br/>line.</p><p>            Graham</p></div><h3>genewardsmith &#x3C;genewardsmith@juno.com&#x3E;</h3><span>1/22/2002 2:44:06 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;paulerlich&quot; &lt;paul@s...&gt; wrote:</p><p>&gt; Maybe we each have to write our own paper, then. I&apos;m hoping someone<br/>&gt; will help me with the math for mine . . .</p><p>We could make a deal--we each help the other guy with what they need help on the most. :)</p><p>So<br/>&gt; why not look for a mathematically pretty way to find good<br/>&gt; temperaments? That&apos;s something I&apos;m interested in, at any rate.</p><p>I&apos;d like to see a quick and easy estimate which inputs a wedgie and outputs a badness measure; a second pass could then refine that.</p></div><h3>dkeenanuqnetau &#x3C;d.keenan@uq.net.au&#x3E;</h3><span>1/22/2002 3:00:17 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Can you guys please drop the &quot;(Was: Hi Dave K.)&quot; from the title of<br/>this thread. I have so little time to spend on tuning at the moment<br/>that I&apos;m only reading posts that have my name in them. (in the body<br/>text is fine). But the search finds it whether in the body or the<br/>title and this thread is driving me crazy.</p><p>Thanks.</p><p>By the way, I didn&apos;t have a clue what &quot;taxicab error&quot; was. I&apos;m glad if<br/>Gene found a way to give it meaning. :-)</p></div><h3>paulerlich &#x3C;paul@stretch-music.com&#x3E;</h3><span>1/22/2002 3:01:37 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;dkeenanuqnetau&quot; &lt;d.keenan@u...&gt; wrote:</p><p>&gt; I&apos;m glad if<br/>&gt; Gene found a way to give it meaning.</p><p>Haven&apos;t understood it, as of yet . . .</p><p> :-)</p></div>