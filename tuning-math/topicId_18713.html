<a href="/tuning-math">back to list</a><h1>Reproducing HE exactly vs coming up with a sensible model</h1><h3>Mike Battaglia &#x3C;battaglia01@gmail.com&#x3E;</h3><span>1/29/2011 7:27:30 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>If you&apos;ve been to the HE Convolution Theorem page recently, you may have<br/>noticed it says that the proof is broken. I noticed a pretty major oversight<br/>which had invalidated a lot of it. I realized this after trying to come up<br/>with a perfectly correlated output for Paul&apos;s HE - I soon discovered that<br/>something was wrong with my model as far as exactly replicating HE is<br/>concerned. In light of that, I sought to work things out and really see if<br/>HE has anything to do with a convolution at all.</p><p>After some time, I finally got to the following horrid looking summation:</p><p>[image:<br/>latex2png.2.php?z=100&amp;eq=H%28d%29%20%3D%20-\frac{1}{%28G_s\star%20K%29%28d%29}*\left%28\sum_{i}{\left[%28G_s\star\frac{\delta_{cents%28i%29}}{sqrt%28i_{num}*i_{den}%29}%29%28d%29*log%28%28G_s\star\frac{\delta_{cents%28i%29}}{sqrt%28i_{num}*i_{den}%29}%29%28d%29%29\right]}-\sum_i{\left[%28G_s\star\frac{\delta_{cents%28i%29}}{sqrt%28i_{num}*i_{den}%29}%29%28d%29*log%28%28G_s\star%20K%29%28d%29%29\right]}\right%29]</p><p>About 4 hours and something like 34 steps later, I had finally managed to<br/>work it down to three convolutions, and I think this is as best as it&apos;s<br/>going to get:</p><p>[image:<br/>latex2png.2.php?z=100&amp;eq=H(d)%20%3D%20-\frac{W_2(d)}{W(d)}%2B\frac{W_3(d)}{2s^2W(d)}%2BlogW(d)]</p><p>If you can&apos;t see HTML, click here:</p><p>Horrid integral:<br/><a href="http://www.sitmo.com/gg/latex/latex2png.2.php?z=100&eq=H%28d%29%20%3D%20-\frac{1}{%28G_s\star%20K%29%28d%29}*\left%28\sum_{i}{\left[%28G_s\star\frac{\delta_{cents%28i%29}">http://www.sitmo.com/gg/latex/latex2png.2.php?z=100&eq=H%28d%29%20%3D%20-\frac{1}{%28G_s\star%20K%29%28d%29}*\left%28\sum_{i}{\left[%28G_s\star\frac{\delta_{cents%28i%29}</a>}{sqrt%28i_{num}*i_{den}%29}%29%28d%29*log%28%28G_s\star\frac{\delta_{cents%28i%29}}{sqrt%28i_{num}*i_{den}%29}%29%28d%29%29\right]}-\sum_i{\left[%28G_s\star\frac{\delta_{cents%28i%29}}{sqrt%28i_{num}*i_{den}%29}%29%28d%29*log%28%28G_s\star%20K%29%28d%29%29\right]}\right%29</p><p>End result:<br/><a href="http://www.sitmo.com/gg/latex/latex2png.2.php?z=100&eq=H%28d%29%20%3D%20-\frac{W_2%28d%29}{W%28d%29}%2B\frac{W_3%28d%29}">http://www.sitmo.com/gg/latex/latex2png.2.php?z=100&eq=H%28d%29%20%3D%20-\frac{W_2%28d%29}{W%28d%29}%2B\frac{W_3%28d%29}</a>{2s<br/>^2W%28d%29}%2BlogW%28d%29</p><p>So each of those W_n(d)&apos;s are different preconvolved vectors that you can<br/>manipulate to regenerate the original H(d) curve, putting us still in<br/>O(nlogn) time. All of them should have the same minima and maxima of the<br/>final HE curve, but look slightly different themselves. This is the result<br/>for sqrt(n*d) widths, and I&apos;m not going to try and work it out for<br/>mediant-to-mediant widths.</p><p>So now that I&apos;ve spent all of this time doing that, this is what I have to<br/>ask all of you:<br/>- Before realizing the error in my proof, I erroneously stated that the one<br/>simple convolution would yield HE exactly. Now it looks like we&apos;re up to<br/>three, but we should now have a one to one correspondence with this and good<br/>ol&apos; legit classic HE.<br/>- Well, that is, we have a correspondence, if I didn&apos;t screw it up again.<br/>- Well, that is, we have a correspondence, if round-off error doesn&apos;t<br/>accumulate differently than Paul&apos;s code.<br/>- Well, that is, we have a correspondence, if I manage to even figure out<br/>how to code this whole thing properly.<br/>- Well, that is, we have a correspondence, if I ever somehow come across a<br/>free 8 hour block to actually code this in MATLAB to begin with.<br/>- And then there&apos;s the issue of whether all HE data plots are themselves<br/>perfectly correlated, which Carl claims yes to, but Paul&apos;s code says no.</p><p>So my question to all of you is: what is the purpose of me doing any of this<br/>at all, when I already have a perfectly good model that can probably be<br/>computed 1,000 times as fast, is already finished and coded, appears<br/>well-behaved, yields all of the proper minima and maxima and general<br/>characteristics of the curve that everyone was trying to engineer HE to give<br/>anyway, looks almost identical to a scaled version of HE, certainly holds<br/>some psychoacoustically validity even in its embryonic stage, enables us to<br/>start exploring tetrads and such straight away, naturally ties into the<br/>proposed &quot;fuzzy regular mapping&quot; structure I&apos;ve been talking about, etc?</p><p>The 1-convolution model, which I&apos;ll go back to calling &quot;DC&quot; again, is an<br/>approximation of the 3-convolution model, which assuming I haven&apos;t screwed<br/>up tonight&apos;s work, is what HE is actually doing under the hood. Exactly how<br/>much of an approximation could be turned into a well-defined mathematical<br/>statement. So DC is obviously related to HE in some sense. Call it &quot;a fast<br/>HE approximation but not actually HE&quot; if you want.</p><p>Rather than waste any more time trying to replicate HE, I&apos;m tomorrow going<br/>to post some examples of what the model spits out with 1/(n*d) heights, a<br/>Farey series generator, and s=1.0%.</p><p>-Mike</p></div><h3>genewardsmith &#x3C;genewardsmith@sbcglobal.net&#x3E;</h3><span>1/29/2011 12:22:18 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Mike Battaglia &lt;battaglia01@...&gt; wrote:</p><p>&gt; So now that I&apos;ve spent all of this time doing that, this is what I have to<br/>&gt; ask all of you:<br/>&gt; - Before realizing the error in my proof, I erroneously stated that the one<br/>&gt; simple convolution would yield HE exactly. Now it looks like we&apos;re up to<br/>&gt; three, but we should now have a one to one correspondence with this and good<br/>&gt; ol&apos; legit classic HE.<br/>&gt; - Well, that is, we have a correspondence, if I didn&apos;t screw it up again.<br/>&gt; - Well, that is, we have a correspondence, if round-off error doesn&apos;t<br/>&gt; accumulate differently than Paul&apos;s code.<br/>&gt; - Well, that is, we have a correspondence, if I manage to even figure out<br/>&gt; how to code this whole thing properly.<br/>&gt; - Well, that is, we have a correspondence, if I ever somehow come across a<br/>&gt; free 8 hour block to actually code this in MATLAB to begin with.<br/>&gt; - And then there&apos;s the issue of whether all HE data plots are themselves<br/>&gt; perfectly correlated, which Carl claims yes to, but Paul&apos;s code says no.<br/>&gt;<br/>&gt; So my question to all of you is: what is the purpose of me doing any of this<br/>&gt; at all, when I already have a perfectly good model that can probably be<br/>&gt; computed 1,000 times as fast, is already finished and coded, appears<br/>&gt; well-behaved, yields all of the proper minima and maxima and general<br/>&gt; characteristics of the curve that everyone was trying to engineer HE to give<br/>&gt; anyway, looks almost identical to a scaled version of HE, certainly holds<br/>&gt; some psychoacoustically validity even in its embryonic stage, enables us to<br/>&gt; start exploring tetrads and such straight away, naturally ties into the<br/>&gt; proposed &quot;fuzzy regular mapping&quot; structure I&apos;ve been talking about, etc?</p><p>Beats me. But I&apos;m not Paul or Carl, I&apos;m the guy who got you convolving ?(x), which is obviously evil. A function quick to compute and which Maple or Pari could work with would mean other people might find a use for the results. Does your web page, wherever it is, lay out what, exactly, you are convolving with a Gaussian?</p></div><h3>Mike Battaglia &#x3C;battaglia01@gmail.com&#x3E;</h3><span>1/29/2011 6:19:20 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On Sat, Jan 29, 2011 at 3:22 PM, genewardsmith<br/>&lt;<a href="mailto:genewardsmith@sbcglobal.net">genewardsmith@sbcglobal.net</a>&gt; wrote:<br/>&gt;<br/>&gt; Beats me. But I&apos;m not Paul or Carl, I&apos;m the guy who got you convolving ?(x), which is obviously evil. A function quick to compute and which Maple or Pari could work with would mean other people might find a use for the results. Does your web page, wherever it is, lay out what, exactly, you are convolving with a Gaussian?</p><p>The original model was to convolve a &quot;basis kernel&quot; with a Gaussian.<br/>At one point I thought that HE itself, as derived from the entropy<br/>summation, could be represented as the convolution of a certain<br/>weird-looking kernel with a Gaussian, but what I&apos;m saying in my above<br/>message is that I screwed it up pretty bad.</p><p>Outside of trying to apply the original convolution technique to speed<br/>up HE exactly, at one point I was messing with the idea of just making<br/>the basis kernel actually equal to a bunch of impulses of height n*d.<br/>This yields something that looks almost exactly like harmonic entropy,<br/>and I thought for a while that it was. Turns out that it&apos;s not, but<br/>it&apos;s really close. There do seem to be strict bounds on the<br/>approximation; e.g. using n*d heights yields a reasonable curve, but<br/>with sqrt(n*d) heights things don&apos;t converge correctly. I think it was<br/>1/log(n*d+1) heights that make it look very similar to HE and is<br/>computable in under a second.</p><p>BTW, I almost sent you a message about this last night, as I was so<br/>frustrated with the derivation, to see if you could help me out with<br/>it. In the middle of my message I figured out a way to keep going and<br/>finished it, but now I&apos;m paranoid that I&apos;ve screwed something up<br/>again. As a PS in this message, I asked if you could send a version of<br/>?(2^x) that went from -1 to 2, but you didn&apos;t get the PS, because I<br/>didn&apos;t send the message.</p><p>My MATLAB-fu isn&apos;t strong enough to figure out the interpolation for<br/>the exponential version, so if you can send it again that would be<br/>appreciated.</p><p>-Mike</p></div>