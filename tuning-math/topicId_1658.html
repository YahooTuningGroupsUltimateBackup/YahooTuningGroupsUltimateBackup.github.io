<a href="/tuning-math">back to list</a><h1>Re: The grooviest linear temperaments for 7-limit music</h1><h3>David C Keenan &#x3C;d.keenan@uq.net.au&#x3E;</h3><span>12/5/2001 4:19:26 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>I haven&apos;t read any of the messages about this in tuning-math. I&apos;m purely responding to Paul&apos;s summary and subsequent responses by Paul and Gene on the tuning list.</p><p>--- In tuning@y..., &quot;paulerlich&quot; &lt;paul@s...&gt; wrote:<br/>&gt; --- In tuning@y..., &quot;dkeenanuqnetau&quot; &lt;D.KEENAN@U...&gt; wrote:<br/>&gt; &gt; Thanks for this summary Paul, but ...<br/>&gt;<br/>&gt; You mean you haven&apos;t been on tuning-math@y... ? Get thee<br/>&gt; hence :)<br/>&gt;<br/>&gt; &gt; &gt; He proposed a &apos;badness&apos; measure defined as<br/>&gt; &gt; &gt;<br/>&gt; &gt; &gt; step^3 cent<br/>&gt; &gt; &gt;<br/>&gt; &gt; &gt; where step is a measure of the typical number of notes in a<br/>scale<br/>&gt; &gt; for<br/>&gt; &gt; &gt; this temperament (given any desired degree of harmonic depth),<br/>&gt; &gt;<br/>&gt; &gt; What the heck does that mean?<br/>&gt;<br/>&gt; step is the RMS of the numbers of generators required to get to each<br/>&gt; ratio of the tonality diamond from the 1/1, I think.</p><p>This is good. More comprehensive than what Graham and I were using.</p><p>&gt; &gt; How does he justify cubing it?<br/>&gt;<br/>--- In tuning@y..., &quot;ideaofgod&quot; &lt;genewardsmith@j...&gt; wrote:<br/>&gt; An order of growth estimate shows there should be an infinite list<br/>&gt; for step^2, but not neccesarily for anything higher, and looking far<br/>&gt; out makes it clear step^3 gives a finite list. What this means, of<br/>&gt; course, is that in some sense step^2 is the right way to measure<br/>&gt; goodness.</p><p>Yes! Only squared, not cubed.</p><p>&gt; Step^3 weighs the small systems more heavily, and that is<br/>&gt; why we see so many of them to start with.</p><p>I believe the way to fix this is not to go to step^3 (I don&apos;t think there&apos;s any human-perception-or-cognition-based justification for doing that), but instead to correct the raw cents to some kind of dissonance or justness measure (more on this below).</p><p>&gt; &gt; &gt; and<br/>&gt; &gt; &gt; cent is a measure of the deviation from JI &apos;consonances&apos; in<br/>cents.<br/>&gt; &gt;<br/>&gt; &gt; Yes but which measure of deviation? minimum maximum absolute or<br/>&gt; &gt; minimum root mean squared or something else?<br/>&gt;<br/>&gt; RMS</p><p>Fine.</p><p>&gt; &gt; How does he justify not applying a human sensory correction to<br/>this?<br/>&gt;<br/>&gt; A human sensory correction?</p><p>Yes. Once the deviation goes past about 20 cents it&apos;s irrelevant how big it is, and a 0.1 cent deviation does not sound 10 times better than a 1.0 cent deviation, it sounds about the same. I suggest this figure-of-demerit.</p><p>step^2 * exp((cents/k)^2), where k is somewhere between 5 and 15 cents</p><p>I think this will give a ranking of temperaments that corresponds more to how composers or performers would rank them.</p><p>-- Dave Keenan<br/>Brisbane, Australia<br/><a href="http://uq.net.au/~zzdkeena">http://uq.net.au/~zzdkeena</a><br/>-- A country which has dangled the sword of nuclear holocaust over the world for half a century and claims that someone else invented terrorism is a country out of touch with reality. --John K. Stoner</p></div><h3>paulerlich &#x3C;paul@stretch-music.com&#x3E;</h3><span>12/5/2001 4:35:04 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., David C Keenan &lt;d.keenan@u...&gt; wrote:</p><p>&gt; &gt; An order of growth estimate shows there should be an infinite<br/>list<br/>&gt; &gt; for step^2, but not neccesarily for anything higher, and looking<br/>far<br/>&gt; &gt; out makes it clear step^3 gives a finite list. What this means,<br/>of<br/>&gt; &gt; course, is that in some sense step^2 is the right way to measure<br/>&gt; &gt; goodness.<br/>&gt;<br/>&gt; Yes! Only squared, not cubed.<br/>&gt;<br/>&gt; &gt; Step^3 weighs the small systems more heavily, and that is<br/>&gt; &gt; why we see so many of them to start with.<br/>&gt;<br/>&gt; I believe the way to fix this is not to go to step^3 (I don&apos;t think<br/>there&apos;s any human-perception-or-cognition-based justification for<br/>doing that),</p><p>What human-perception-or-cognition-based justification is there for<br/>using step^2 ???</p><p>&gt; Yes. Once the deviation goes past about 20 cents it&apos;s irrelevant &gt;<br/>how big it is,</p><p>That&apos;s not true -- you&apos;re ignoring both adaptive tuning and adaptive<br/>timbring.</p><p>&gt;and a 0.1 cent deviation does not sound 10 times better than a 1.0<br/>&gt;cent deviation, it sounds about the same.</p><p>In my own musical endeavors, this is true, but with all the strict-JI<br/>obsessed people out there, a 0.1 cent deviation may end up being 10<br/>times more interesting than a 1.0 cent deviation.</p><p>&gt; I suggest this figure-of-&gt;demerit.<br/>&gt;<br/>&gt; step^2 [...]</p><p>Again, what on earth does step^2 tell you about how composers and<br/>performers would rate a temperament? OK, step^2 is the number of<br/>possible dyads in the typical scale. Step^3 is the number of possible<br/>triads. Why is the former so much more &quot;human-perception-or-cognition-<br/>based&quot; to you than the latter?</p><p>As for the other part, the dissonance measure . . . by doing it<br/>Gene&apos;s way, we&apos;re going to end up with all the most interesting<br/>temperaments for a wide variety of different ranges, from &quot;you&apos;ll<br/>never hear a beat&quot; to &quot;wafso-just&quot; to &quot;quasi-just&quot; to &quot;tempered&quot;<br/>to &quot;needing adaptive tuning/timbring&quot;. Thus our top 30 or whatever<br/>will have much of interest to all different schools of microtonal<br/>composers.</p></div><h3>dkeenanuqnetau &#x3C;d.keenan@uq.net.au&#x3E;</h3><span>12/5/2001 5:22:04 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;paulerlich&quot; &lt;paul@s...&gt; wrote:<br/>&gt; --- In tuning-math@y..., David C Keenan &lt;d.keenan@u...&gt; wrote:<br/>&gt; &gt; Yes. Once the deviation goes past about 20 cents it&apos;s irrelevant &gt;<br/>&gt; how big it is,<br/>&gt;<br/>&gt; That&apos;s not true -- you&apos;re ignoring both adaptive tuning and adaptive<br/>&gt; timbring.</p><p>You can adaptively tune or timbre just about anything, so it seems<br/>like we _should_ ignore it.</p><p>&gt; &gt;and a 0.1 cent deviation does not sound 10 times better than a 1.0<br/>&gt; &gt;cent deviation, it sounds about the same.<br/>&gt;<br/>&gt; In my own musical endeavors, this is true, but with all the<br/>strict-JI<br/>&gt; obsessed people out there, a 0.1 cent deviation may end up being 10<br/>&gt; times more interesting than a 1.0 cent deviation.</p><p>A strict JI obsessed person will not be the slightest bit interested<br/>in linear temperaments, or at least that has been my experience. If<br/>they are at all interested then think they will be quite happy to have<br/>a 1c error rather than a 0.1c one if it lets them halve (actually<br/>divide by 10^(1/3)) the number of notes in the scale. Given that 1c is<br/>way below the typical accuracy of non-electronic instruments.</p><p>&gt; &gt; I suggest this figure-of-&gt;demerit.<br/>&gt; &gt;<br/>&gt; &gt; step^2 [...]<br/>&gt;<br/>&gt; Again, what on earth does step^2 tell you about how composers and<br/>&gt; performers would rate a temperament? OK, step^2 is the number of<br/>&gt; possible dyads in the typical scale. Step^3 is the number of<br/>possible<br/>&gt; triads. Why is the former so much more<br/>&quot;human-perception-or-cognition-<br/>&gt; based&quot; to you than the latter?</p><p>Ok. Maybe I don&apos;t have good argument for that. Try</p><p>step^3 * exp((cents/k)^2)</p><p>&gt; As for the other part, the dissonance measure . . . by doing it<br/>&gt; Gene&apos;s way, we&apos;re going to end up with all the most interesting<br/>&gt; temperaments for a wide variety of different ranges, from &quot;you&apos;ll<br/>&gt; never hear a beat&quot; to &quot;wafso-just&quot; to &quot;quasi-just&quot; to &quot;tempered&quot;<br/>&gt; to &quot;needing adaptive tuning/timbring&quot;. Thus our top 30 or whatever<br/>&gt; will have much of interest to all different schools of microtonal<br/>&gt; composers.</p><p>I think it has some extreme cases that are of interest to no one. This<br/>can be fixed.</p></div><h3>paulerlich &#x3C;paul@stretch-music.com&#x3E;</h3><span>12/5/2001 5:33:09 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;dkeenanuqnetau&quot; &lt;d.keenan@u...&gt; wrote:</p><p>&gt; &gt; &gt; Yes. Once the deviation goes past about 20 cents it&apos;s<br/>irrelevant &gt;<br/>&gt; &gt; how big it is,<br/>&gt; &gt;<br/>&gt; &gt; That&apos;s not true -- you&apos;re ignoring both adaptive tuning and<br/>adaptive<br/>&gt; &gt; timbring.<br/>&gt;<br/>&gt; You can adaptively tune or timbre just about anything,</p><p>Not true -- in adaptive tuning, you don&apos;t want the horizontal shifts<br/>to be too big, or you lose the melodic coherence of the scale; and in<br/>adaptive timbring, you don&apos;t want the partials to deviate too far<br/>from a harmonic series, or you&apos;ll lose the sense that each note has a<br/>definite pitch.</p><p>&gt; A strict JI obsessed person will not be the slightest bit<br/>interested<br/>&gt; in linear temperaments, or at least that has been my experience. If<br/>&gt; they are at all interested then think they will be quite happy to<br/>have<br/>&gt; a 1c error rather than a 0.1c one if it lets them halve (actually<br/>&gt; divide by 10^(1/3)) the number of notes in the scale.</p><p>You don&apos;t know that for sure. But look, I myself was trying to get<br/>Gene to adopt some exponential, rather than polynomial, function of<br/>the number of notes in the scale. He resisted . . .</p><p>&gt; Given that 1c is<br/>&gt; way below the typical accuracy of non-electronic instruments.</p><p>Hey, it won&apos;t be the first time a feature of tuning that is highly<br/>removed from most musicians&apos; possible realm of experience has gotten<br/>published!</p><p>&gt;<br/>&gt; &gt; &gt; I suggest this figure-of-&gt;demerit.<br/>&gt; &gt; &gt;<br/>&gt; &gt; &gt; step^2 [...]<br/>&gt; &gt;<br/>&gt; &gt; Again, what on earth does step^2 tell you about how composers and<br/>&gt; &gt; performers would rate a temperament? OK, step^2 is the number of<br/>&gt; &gt; possible dyads in the typical scale. Step^3 is the number of<br/>&gt; possible<br/>&gt; &gt; triads. Why is the former so much more<br/>&gt; &quot;human-perception-or-cognition-<br/>&gt; &gt; based&quot; to you than the latter?<br/>&gt;<br/>&gt; Ok. Maybe I don&apos;t have good argument for that. Try<br/>&gt;<br/>&gt; step^3 * exp((cents/k)^2)</p><p>That&apos;s the _last_ conclusion I wanted you to reach!</p><p>&gt; I think it has some extreme cases that are of interest to no one.<br/>This<br/>&gt; can be fixed.</p><p>I tried to argue this point to Gene, but he seems to really like<br/>Ennealimmal. Hey, if we&apos;re getting mathematical elegance with this<br/>criterion, and all our favorite systems are showing up (I&apos;m still<br/>waiting for double-diatonic ~26), shouldn&apos;t we be willing to pay the<br/>price of letting the guy who&apos;s doing all the work get his favorite<br/>system in too?</p></div><h3>D.Stearns &#x3C;STEARNS@CAPECOD.NET&#x3E;</h3><span>12/6/2001 8:53:37 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Personally I&apos;d feel much better if everyone could somehow agree what<br/>was the overall most sensible measure regardless of the results!</p><p>In Gene&apos;s case, I would hope that it would be some elegant internal<br/>consistency that ties the whole deal together. I&apos;d personally settle<br/>for that even if the results were a tad exotic.</p><p>Of course it might help if I understood it all a bit better too! I<br/>feel like I&apos;m getting there though, I just wish Gene were a little bit<br/>more generous with the narrative--either that or someone else besides<br/>him were saying the same things slightly differently... that helps me<br/>sometimes too.</p><p>--Dan Stearns</p><p>----- Original Message -----<br/>From: &quot;paulerlich&quot; &lt;<a href="mailto:paul@stretch-music.com">paul@stretch-music.com</a>&gt;<br/>To: &lt;<a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>&gt;<br/>Sent: Wednesday, December 05, 2001 5:33 PM<br/>Subject: [tuning-math] Re: The grooviest linear temperaments for<br/>7-limit music</p><p>&gt; --- In tuning-math@y..., &quot;dkeenanuqnetau&quot; &lt;d.keenan@u...&gt; wrote:<br/>&gt;<br/>&gt; &gt; &gt; &gt; Yes. Once the deviation goes past about 20 cents it&apos;s<br/>&gt; irrelevant &gt;<br/>&gt; &gt; &gt; how big it is,<br/>&gt; &gt; &gt;<br/>&gt; &gt; &gt; That&apos;s not true -- you&apos;re ignoring both adaptive tuning and<br/>&gt; adaptive<br/>&gt; &gt; &gt; timbring.<br/>&gt; &gt;<br/>&gt; &gt; You can adaptively tune or timbre just about anything,<br/>&gt;<br/>&gt; Not true -- in adaptive tuning, you don&apos;t want the horizontal shifts<br/>&gt; to be too big, or you lose the melodic coherence of the scale; and<br/>in<br/>&gt; adaptive timbring, you don&apos;t want the partials to deviate too far<br/>&gt; from a harmonic series, or you&apos;ll lose the sense that each note has<br/>a<br/>&gt; definite pitch.<br/>&gt;<br/>&gt; &gt; A strict JI obsessed person will not be the slightest bit<br/>&gt; interested<br/>&gt; &gt; in linear temperaments, or at least that has been my experience.<br/>If<br/>&gt; &gt; they are at all interested then think they will be quite happy to<br/>&gt; have<br/>&gt; &gt; a 1c error rather than a 0.1c one if it lets them halve (actually<br/>&gt; &gt; divide by 10^(1/3)) the number of notes in the scale.<br/>&gt;<br/>&gt; You don&apos;t know that for sure. But look, I myself was trying to get<br/>&gt; Gene to adopt some exponential, rather than polynomial, function of<br/>&gt; the number of notes in the scale. He resisted . . .<br/>&gt;<br/>&gt; &gt; Given that 1c is<br/>&gt; &gt; way below the typical accuracy of non-electronic instruments.<br/>&gt;<br/>&gt; Hey, it won&apos;t be the first time a feature of tuning that is highly<br/>&gt; removed from most musicians&apos; possible realm of experience has gotten<br/>&gt; published!<br/>&gt;<br/>&gt; &gt;<br/>&gt; &gt; &gt; &gt; I suggest this figure-of-&gt;demerit.<br/>&gt; &gt; &gt; &gt;<br/>&gt; &gt; &gt; &gt; step^2 [...]<br/>&gt; &gt; &gt;<br/>&gt; &gt; &gt; Again, what on earth does step^2 tell you about how composers<br/>and<br/>&gt; &gt; &gt; performers would rate a temperament? OK, step^2 is the number of<br/>&gt; &gt; &gt; possible dyads in the typical scale. Step^3 is the number of<br/>&gt; &gt; possible<br/>&gt; &gt; &gt; triads. Why is the former so much more<br/>&gt; &gt; &quot;human-perception-or-cognition-<br/>&gt; &gt; &gt; based&quot; to you than the latter?<br/>&gt; &gt;<br/>&gt; &gt; Ok. Maybe I don&apos;t have good argument for that. Try<br/>&gt; &gt;<br/>&gt; &gt; step^3 * exp((cents/k)^2)<br/>&gt;<br/>&gt; That&apos;s the _last_ conclusion I wanted you to reach!<br/>&gt;<br/>&gt; &gt; I think it has some extreme cases that are of interest to no one.<br/>&gt; This<br/>&gt; &gt; can be fixed.<br/>&gt;<br/>&gt; I tried to argue this point to Gene, but he seems to really like<br/>&gt; Ennealimmal. Hey, if we&apos;re getting mathematical elegance with this<br/>&gt; criterion, and all our favorite systems are showing up (I&apos;m still<br/>&gt; waiting for double-diatonic ~26), shouldn&apos;t we be willing to pay the<br/>&gt; price of letting the guy who&apos;s doing all the work get his favorite<br/>&gt; system in too?<br/>&gt;<br/>&gt;<br/>&gt; ------------------------ Yahoo! Groups<br/>Sponsor ---------------------~--&gt;<br/>&gt; Tiny Wireless Camera under $80!<br/>&gt; Order Now! FREE VCR Commander!<br/>&gt; Click Here - Only 1 Day Left!<br/>&gt; <a href="http://us.click.yahoo.com/75YKVC/7.PDAA/ySSFAA/wHYolB/TM">http://us.click.yahoo.com/75YKVC/7.PDAA/ySSFAA/wHYolB/TM</a><br/>&gt; --------------------------------------------------------------------<br/>-~-&gt;<br/>&gt;<br/>&gt; To unsubscribe from this group, send an email to:<br/>&gt; <a href="mailto:tuning-math-unsubscribe@yahoogroups.com">tuning-math-unsubscribe@yahoogroups.com</a><br/>&gt;<br/>&gt;<br/>&gt;<br/>&gt; Your use of Yahoo! Groups is subject to<br/><a href="http://docs.yahoo.com/info/terms/">http://docs.yahoo.com/info/terms/</a><br/>&gt;<br/>&gt;</p></div><h3>paulerlich &#x3C;paul@stretch-music.com&#x3E;</h3><span>12/5/2001 5:56:20 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;D.Stearns&quot; &lt;STEARNS@C...&gt; wrote:</p><p>&gt; Personally I&apos;d feel much better if everyone could somehow agree what<br/>&gt; was the overall most sensible measure regardless of the results!</p><p>Fat chance :)</p><p>&gt; In Gene&apos;s case, I would hope that it would be some elegant internal<br/>&gt; consistency that ties the whole deal together. I&apos;d personally settle<br/>&gt; for that even if the results were a tad exotic.</p><p>I feel the same way.</p><p>&gt; Of course it might help if I understood it all a bit better too! I<br/>&gt; feel like I&apos;m getting there though, I just wish Gene were a little<br/>bit<br/>&gt; more generous with the narrative--either that or someone else<br/>besides<br/>&gt; him were saying the same things slightly differently... that helps<br/>me<br/>&gt; sometimes too.</p><p>I think he&apos;s the only one who understands abstract algebra around<br/>here, so in a lot of cases, that isn&apos;t really possible,<br/>unfortunately . . . of course, I should study up on it, but I should<br/>also make more music, and get more sleep, and . . .</p></div><h3>genewardsmith &#x3C;genewardsmith@juno.com&#x3E;</h3><span>12/5/2001 6:45:38 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;paulerlich&quot; &lt;paul@s...&gt; wrote:</p><p>&gt; You don&apos;t know that for sure. But look, I myself was trying to get<br/>&gt; Gene to adopt some exponential, rather than polynomial, function of<br/>&gt; the number of notes in the scale. He resisted . . .</p><p>You wanted to have exponential growth for the &quot;step&quot; factor, and Dave<br/>for the &quot;cents&quot; factor, which have opposite tendencies; Dave seems to<br/>want to filter the very things out on the low end that you wanted<br/>included.</p><p>If we added an exponential growth to &quot;cents&quot;, I would suggest<br/>trying k sinh (cents/k) for various k.</p><p>&gt; &gt; Given that 1c is<br/>&gt; &gt; way below the typical accuracy of non-electronic instruments.<br/>&gt;<br/>&gt; Hey, it won&apos;t be the first time a feature of tuning that is highly<br/>&gt; removed from most musicians&apos; possible realm of experience has<br/>gotten<br/>&gt; published!</p><p>It seems to me it is quite relevant to the strict JI school of<br/>thought. I got roasted for mentioning Partch in such a connection,<br/>but it&apos;s hard to see what theoretical objection he could raise to 45<br/>notes of ennealimmal in the 7-limit.</p><p>&gt; I tried to argue this point to Gene, but he seems to really like<br/>&gt; Ennealimmal. Hey, if we&apos;re getting mathematical elegance with this<br/>&gt; criterion, and all our favorite systems are showing up (I&apos;m still<br/>&gt; waiting for double-diatonic ~26), shouldn&apos;t we be willing to pay<br/>the<br/>&gt; price of letting the guy who&apos;s doing all the work get his favorite<br/>&gt; system in too?</p><p>I think the only way you will get rid of Ennealimmal is to have an<br/>upper-end cut-off, and you said you wanted none. Sorry, you are stuck<br/>with it, and it has nothing to do with my liking it really. I&apos;ve<br/>never even tried it!</p></div><h3>genewardsmith &#x3C;genewardsmith@juno.com&#x3E;</h3><span>12/5/2001 6:53:30 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;D.Stearns&quot; &lt;STEARNS@C...&gt; wrote:</p><p>&gt; In Gene&apos;s case, I would hope that it would be some elegant internal<br/>&gt; consistency that ties the whole deal together. I&apos;d personally settle<br/>&gt; for that even if the results were a tad exotic.</p><p>Elegant internal consistency suggests to me steps^2 cents as a<br/>measure, but that would need an upper cut-off. We do it for ets,<br/>however, so I don&apos;t see that as a bif deal myself.</p><p>&gt; Of course it might help if I understood it all a bit better too! I<br/>&gt; feel like I&apos;m getting there though, I just wish Gene were a little<br/>bit<br/>&gt; more generous with the narrative--either that or someone else<br/>besides<br/>&gt; him were saying the same things slightly differently... that helps<br/>me<br/>&gt; sometimes too.</p><p>I&apos;m hoping Paul will absorb it all and start coming out with his own<br/>interpretations, but I can&apos;t get him to compute a wedge product. :)</p></div><h3>paulerlich &#x3C;paul@stretch-music.com&#x3E;</h3><span>12/5/2001 6:59:36 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;genewardsmith&quot; &lt;genewardsmith@j...&gt; wrote:</p><p>&gt; You wanted to have exponential growth for the &quot;step&quot; factor, and<br/>Dave<br/>&gt; for the &quot;cents&quot; factor,</p><p>I think you misunderstood Dave -- he wanted the *goodness* for the<br/>cents factor to be a Gaussian.</p></div><h3>paulerlich &#x3C;paul@stretch-music.com&#x3E;</h3><span>12/5/2001 7:00:40 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;genewardsmith&quot; &lt;genewardsmith@j...&gt; wrote:<br/>&gt; --- In tuning-math@y..., &quot;D.Stearns&quot; &lt;STEARNS@C...&gt; wrote:<br/>&gt;<br/>&gt; &gt; In Gene&apos;s case, I would hope that it would be some elegant<br/>internal<br/>&gt; &gt; consistency that ties the whole deal together. I&apos;d personally<br/>settle<br/>&gt; &gt; for that even if the results were a tad exotic.<br/>&gt;<br/>&gt; Elegant internal consistency suggests to me steps^2 cents as a<br/>&gt; measure, but that would need an upper cut-off. We do it for ets,<br/>&gt; however, so I don&apos;t see that as a bif deal myself.</p><p>Who&apos;s we?<br/>&gt;<br/>&gt; &gt; Of course it might help if I understood it all a bit better too! I<br/>&gt; &gt; feel like I&apos;m getting there though, I just wish Gene were a<br/>little<br/>&gt; bit<br/>&gt; &gt; more generous with the narrative--either that or someone else<br/>&gt; besides<br/>&gt; &gt; him were saying the same things slightly differently... that<br/>helps<br/>&gt; me<br/>&gt; &gt; sometimes too.<br/>&gt;<br/>&gt; I&apos;m hoping Paul will absorb it all and start coming out with his<br/>own<br/>&gt; interpretations, but I can&apos;t get him to compute a wedge product. :)</p><p>I&apos;ll take a look at it again when I get a chance.</p></div><h3>genewardsmith &#x3C;genewardsmith@juno.com&#x3E;</h3><span>12/5/2001 9:55:39 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;paulerlich&quot; &lt;paul@s...&gt; wrote:</p><p>&gt; I think you misunderstood Dave -- he wanted the *goodness* for the<br/>&gt; cents factor to be a Gaussian.</p><p>I don&apos;t think penalizing a system for being good can possibly be<br/>defended, so I&apos;m at a loss here.</p></div><h3>genewardsmith &#x3C;genewardsmith@juno.com&#x3E;</h3><span>12/5/2001 9:57:46 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;dkeenanuqnetau&quot; &lt;d.keenan@u...&gt; wrote:</p><p>&gt; Ok. Maybe I don&apos;t have good argument for that. Try<br/>&gt;<br/>&gt; step^3 * exp((cents/k)^2)</p><p>This looks like hyper-exponential growth penalizing badness, not<br/>goodness.</p></div><h3>dkeenanuqnetau &#x3C;d.keenan@uq.net.au&#x3E;</h3><span>12/5/2001 10:35:18 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;genewardsmith&quot; &lt;genewardsmith@j...&gt; wrote:<br/>&gt; --- In tuning-math@y..., &quot;paulerlich&quot; &lt;paul@s...&gt; wrote:<br/>&gt;<br/>&gt; &gt; I think you misunderstood Dave -- he wanted the *goodness* for the<br/>&gt; &gt; cents factor to be a Gaussian.<br/>&gt;<br/>&gt; I don&apos;t think penalizing a system for being good can possibly be<br/>&gt; defended, so I&apos;m at a loss here.</p><p>I&apos;m not sure who is confused about what.</p><p>gaussian(x) = exp(-(x/k)^2)<br/>goodness = gaussian(cents_error)<br/>badness = 1/goodness<br/>        = 1/exp(-(cents_error/k)^2)<br/>        = exp((cents_error/k)^2)</p><p>sinh might be fine too. I&apos;m not familiar.</p><p>The problems, as I see them, are<br/>(a) some temperaments that require ridiculously numbers of notes are<br/>near the top of the list only because they have errors of a fraction of<br/>a cent, but once it&apos;s less than about a cent, this should not be enough<br/>to redeeem them. And<br/>(b) some others with ridiculously large errors are near the top of the<br/>list only because they come out needing few notes.</p><p>I think that the first can be fixed by applying a function to the cents<br/>error that treats all very small errors as being equal, and the latter<br/>might be fixed by dropping back from steps^3 to steps^2.</p><p>-- Dave Keenan</p></div><h3>graham@microtonal.co.uk</h3><span>12/6/2001 3:16:00 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Paul wrote:</p><p>&gt; As for the other part, the dissonance measure . . . by doing it<br/>&gt; Gene&apos;s way, we&apos;re going to end up with all the most interesting<br/>&gt; temperaments for a wide variety of different ranges, from &quot;you&apos;ll<br/>&gt; never hear a beat&quot; to &quot;wafso-just&quot; to &quot;quasi-just&quot; to &quot;tempered&quot;<br/>&gt; to &quot;needing adaptive tuning/timbring&quot;. Thus our top 30 or whatever<br/>&gt; will have much of interest to all different schools of microtonal<br/>&gt; composers.</p><p>Oh, if you think one list can please everybody.  I&apos;d rather ask people<br/>what they want, and produce a short list that&apos;s likely to have their ideal<br/>temperament on it.  That&apos;s why I keep up the .key and .micro files.  Most<br/>importantly, why I release all the source code for a Free platform so that<br/>anybody can try out their own ideas.  Nothing Gene&apos;s done so far couldn&apos;t<br/>have been done by modifying that code.</p><p>                 Graham</p></div><h3>graham@microtonal.co.uk</h3><span>12/6/2001 3:16:00 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Dave Keenan wrote:</p><p>&gt; (b) some others with ridiculously large errors are near the top of the<br/>&gt; list only because they come out needing few notes.<br/>&gt;<br/>&gt; I think that the first can be fixed by applying a function to the cents<br/>&gt; error that treats all very small errors as being equal, and the latter<br/>&gt; might be fixed by dropping back from steps^3 to steps^2.</p><p>No, you get ridiculously large errors near the top with steps^2 as well.</p><p>               Graham</p></div><h3>graham@microtonal.co.uk</h3><span>12/6/2001 3:16:00 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Dan Stearns:<br/>&gt; &gt; Of course it might help if I understood it all a bit better too! I<br/>&gt; &gt; feel like I&apos;m getting there though, I just wish Gene were a little<br/>&gt; bit<br/>&gt; &gt; more generous with the narrative--either that or someone else<br/>&gt; besides<br/>&gt; &gt; him were saying the same things slightly differently... that helps<br/>&gt; me<br/>&gt; &gt; sometimes too.</p><p>Paul Erlich:<br/>&gt; I think he&apos;s the only one who understands abstract algebra around<br/>&gt; here, so in a lot of cases, that isn&apos;t really possible,<br/>&gt; unfortunately . . . of course, I should study up on it, but I should<br/>&gt; also make more music, and get more sleep, and . . .</p><p>Most of the results Gene&apos;s getting don&apos;t require anything I don&apos;t<br/>understand.  So I said all these things differently a few months ago.  If<br/>you want to catch up, try getting the source code from<br/>&lt;<a href="http://www.microtonal.co.uk/temper.html">http://www.microtonal.co.uk/temper.html</a>&gt; and an interpreter and try<br/>puzzling it out.  I haven&apos;t had any feedback at all on readability, so I<br/>don&apos;t know easy it&apos;ll be for a newbie.</p><p>The method shouldn&apos;t be difficult for Dan to understand.  You generate a<br/>linear temperament from two equal temperaments.  That&apos;s exactly like<br/>finding an MOS on the scale tree, except you have to do it for all<br/>consonant intervals instead of only the octave.</p><p>The wedge products are more difficult, but I don&apos;t see them as being at<br/>all important in this context.  Working with unison vectors is more<br/>trouble.  I&apos;ve got code for that at<br/>&lt;<a href="http://www.microtonal.co.uk/vectors.html">http://www.microtonal.co.uk/vectors.html</a>&gt;.  Going from temperaments to<br/>unison vectors is an outstanding problem that Gene might have solved, but<br/>I haven&apos;t seen any source code yet.</p><p>                  Graham</p></div><h3>genewardsmith &#x3C;genewardsmith@juno.com&#x3E;</h3><span>12/6/2001 1:46:07 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., graham@m... wrote:</p><p>&gt; The wedge products are more difficult, but I don&apos;t see them as<br/>being at<br/>&gt; all important in this context.  Working with unison vectors is more<br/>&gt; trouble.</p><p>If working with unison vectors is more trouble, why not wedge<br/>products? The wedgie is good for the following reasons:</p><p>(1) It is easy to compute, given a either pair of ets, a pair of<br/>unison vectors, or a generator map.</p><p>(2) It uniquely defines the temperament, so that temperaments<br/>obtained by any method can be merged into one list.</p><p>(3) It automatically eliminates torsion problems.</p><p>(4) Given the wedgie, it is easy to compute assoicated ets, a<br/>generating pair of unison vectors, or a generator map. Hence it is<br/>easy to go from any one of these to any other.</p><p>(5) By adding or subtracting wedgies we can produce new temperaments.</p><p>Given all of that, I think you are missing a bet by dismissing them;<br/>they could easily be incorporated into your code.</p><p>I&apos;ve got code for that at<br/>&gt; &lt;<a href="http://www.microtonal.co.uk/vectors.html">http://www.microtonal.co.uk/vectors.html</a>&gt;.  Going from<br/>temperaments to<br/>&gt; unison vectors is an outstanding problem that Gene might have<br/>solved, but<br/>&gt; I haven&apos;t seen any source code yet.</p><p>I don&apos;t know what good Maple code will do, but here it is:</p><p>findcoms := proc(l)<br/>local p,q,r,p1,q1,r1,s,u,v,w;<br/>s := igcd(l[1], l[2], l[6]);<br/>u := [l[6]/s, -l[2]/s, l[1]/s,0];<br/>v := [p,q,r,1];<br/>w := w7l(u,v);<br/>s := isolve({l[1]-w[1],l[2]-w[2],l[3]-w[3],l[4]-w[4],l[5]-w[5],l[6]-w<br/>[6]});<br/>s := subs(_N1=0,s);<br/>p1 := subs(s,p);<br/>q1 := subs(s,q);<br/>r1 := subs(s,r);<br/>v := 2^p1 * 3^q1 * 5^r1 * 7;<br/>if v &lt; 1 then v := 1/v fi;<br/>w := 2^u[1] * 3^u[2] * 5^u[3];<br/>if w &lt; 1 then w := 1/w fi;<br/>[w, v] end:</p><p>coms := proc(l)<br/>local v;<br/>v := findcoms(l);<br/>com7(v[1],v[2]) end:</p><p>&quot;w7l&quot; takes two vectors representing intervals, and computes the<br/>wegdge product. &quot;isolve&quot; gives integer solutions to a linear<br/>equation; I get an undeterminded varable &quot;_N1&quot; in this way which I<br/>can set equal to any integer, so I set it to 0. The pair of unisons<br/>returned in this way can be LLL reduced by the &quot;com7&quot; function, which<br/>takes a pair of intervals and LLL reduces them.</p></div><h3>paulerlich &#x3C;paul@stretch-music.com&#x3E;</h3><span>12/6/2001 6:36:36 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., graham@m... wrote:<br/>&gt; Dan Stearns:<br/>&gt; &gt; &gt; Of course it might help if I understood it all a bit better<br/>too! I<br/>&gt; &gt; &gt; feel like I&apos;m getting there though, I just wish Gene were a<br/>little<br/>&gt; &gt; bit<br/>&gt; &gt; &gt; more generous with the narrative--either that or someone else<br/>&gt; &gt; besides<br/>&gt; &gt; &gt; him were saying the same things slightly differently... that<br/>helps<br/>&gt; &gt; me<br/>&gt; &gt; &gt; sometimes too.<br/>&gt;<br/>&gt; Paul Erlich:<br/>&gt; &gt; I think he&apos;s the only one who understands abstract algebra around<br/>&gt; &gt; here, so in a lot of cases, that isn&apos;t really possible,<br/>&gt; &gt; unfortunately . . . of course, I should study up on it, but I<br/>should<br/>&gt; &gt; also make more music, and get more sleep, and . . .<br/>&gt;<br/>&gt; Most of the results Gene&apos;s getting don&apos;t require anything I don&apos;t<br/>&gt; understand.  So I said all these things differently a few months<br/>ago.  If<br/>&gt; you want to catch up, try getting the source code from<br/>&gt; &lt;<a href="http://www.microtonal.co.uk/temper.html">http://www.microtonal.co.uk/temper.html</a>&gt; and an interpreter and<br/>try<br/>&gt; puzzling it out.  I haven&apos;t had any feedback at all on readability,<br/>so I<br/>&gt; don&apos;t know easy it&apos;ll be for a newbie.<br/>&gt;<br/>&gt; The method shouldn&apos;t be difficult for Dan to understand.  You<br/>generate a<br/>&gt; linear temperament from two equal temperaments.</p><p>I _really hope_ that that&apos;s not what all or even most of Gene&apos;s<br/>narrative has been about!!</p><p>&gt; That&apos;s exactly like<br/>&gt; finding an MOS on the scale tree, except you have to do it for all<br/>&gt; consonant intervals instead of only the octave.</p><p>This I don&apos;t see at all. Don&apos;t you mean &quot;all fractions 1/N of an<br/>octave&quot; rather than &quot;all consonant intervals&quot;?</p><p>&gt; The wedge products are more difficult, but I don&apos;t see them as<br/>being at<br/>&gt; all important in this context.</p><p>Well then, when Dan asks about what is going on here, and you come<br/>back saying you already understood it all a few months ago, you&apos;re<br/>actually making a very selective reply to Dan&apos;s question, aren&apos;t you?</p></div><h3>paulerlich &#x3C;paul@stretch-music.com&#x3E;</h3><span>12/6/2001 6:48:30 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;genewardsmith&quot; &lt;genewardsmith@j...&gt; wrote:<br/>&gt; --- In tuning-math@y..., graham@m... wrote:<br/>&gt;<br/>&gt; &gt; The wedge products are more difficult, but I don&apos;t see them as<br/>&gt; being at<br/>&gt; &gt; all important in this context.  Working with unison vectors is<br/>more<br/>&gt; &gt; trouble.<br/>&gt;<br/>&gt; If working with unison vectors is more trouble, why not wedge<br/>&gt; products? The wedgie is good for the following reasons:<br/>&gt;<br/>&gt; (1) It is easy to compute, given a either pair of ets, a pair of<br/>&gt; unison vectors, or a generator map.<br/>&gt;<br/>&gt; (2) It uniquely defines the temperament, so that temperaments<br/>&gt; obtained by any method can be merged into one list.<br/>&gt;<br/>&gt; (3) It automatically eliminates torsion problems.<br/>&gt;<br/>&gt; (4) Given the wedgie, it is easy to compute assoicated ets, a<br/>&gt; generating pair of unison vectors, or a generator map. Hence it is<br/>&gt; easy to go from any one of these to any other.<br/>&gt;<br/>&gt; (5) By adding or subtracting wedgies we can produce new<br/>temperaments.<br/>&gt;<br/>&gt; Given all of that, I think you are missing a bet by dismissing<br/>them;<br/>&gt; they could easily be incorporated into your code.<br/>&gt;<br/>&gt; I&apos;ve got code for that at<br/>&gt; &gt; &lt;<a href="http://www.microtonal.co.uk/vectors.html">http://www.microtonal.co.uk/vectors.html</a>&gt;.  Going from<br/>&gt; temperaments to<br/>&gt; &gt; unison vectors is an outstanding problem that Gene might have<br/>&gt; solved, but<br/>&gt; &gt; I haven&apos;t seen any source code yet.<br/>&gt;<br/>&gt; I don&apos;t know what good Maple code will do, but here it is:<br/>&gt;<br/>&gt; findcoms := proc(l)<br/>&gt; local p,q,r,p1,q1,r1,s,u,v,w;<br/>&gt; s := igcd(l[1], l[2], l[6]);<br/>&gt; u := [l[6]/s, -l[2]/s, l[1]/s,0];<br/>&gt; v := [p,q,r,1];<br/>&gt; w := w7l(u,v);<br/>&gt; s := isolve({l[1]-w[1],l[2]-w[2],l[3]-w[3],l[4]-w[4],l[5]-w[5],l[6]-<br/>w<br/>&gt; [6]});<br/>&gt; s := subs(_N1=0,s);<br/>&gt; p1 := subs(s,p);<br/>&gt; q1 := subs(s,q);<br/>&gt; r1 := subs(s,r);<br/>&gt; v := 2^p1 * 3^q1 * 5^r1 * 7;<br/>&gt; if v &lt; 1 then v := 1/v fi;<br/>&gt; w := 2^u[1] * 3^u[2] * 5^u[3];<br/>&gt; if w &lt; 1 then w := 1/w fi;<br/>&gt; [w, v] end:<br/>&gt;<br/>&gt; coms := proc(l)<br/>&gt; local v;<br/>&gt; v := findcoms(l);<br/>&gt; com7(v[1],v[2]) end:<br/>&gt;<br/>&gt; &quot;w7l&quot; takes two vectors representing intervals, and computes the<br/>&gt; wegdge product. &quot;isolve&quot; gives integer solutions to a linear<br/>&gt; equation; I get an undeterminded varable &quot;_N1&quot; in this way which I<br/>&gt; can set equal to any integer, so I set it to 0.</p><p>The solutions represent?</p><p>&gt; The pair of unisons<br/>&gt; returned in this way can be LLL reduced by the &quot;com7&quot; function,<br/>which<br/>&gt; takes a pair of intervals and LLL reduces them.</p><p>Why not TM-reduce them?</p></div><h3>dkeenanuqnetau &#x3C;d.keenan@uq.net.au&#x3E;</h3><span>12/6/2001 7:23:14 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;paulerlich&quot; &lt;paul@s...&gt; wrote:<br/>&gt; --- In tuning-math@y..., &quot;D.Stearns&quot; &lt;STEARNS@C...&gt; wrote:<br/>&gt;<br/>&gt; &gt; Personally I&apos;d feel much better if everyone could somehow agree<br/>what<br/>&gt; &gt; was the overall most sensible measure regardless of the results!<br/>&gt;<br/>&gt; Fat chance :)<br/>&gt;<br/>&gt; &gt; In Gene&apos;s case, I would hope that it would be some elegant<br/>internal<br/>&gt; &gt; consistency that ties the whole deal together. I&apos;d personally<br/>settle<br/>&gt; &gt; for that even if the results were a tad exotic.<br/>&gt;<br/>&gt; I feel the same way.</p><p>It&apos;s nice to have pretty looking (i.e. simple) fomulae but we can<br/>hardly ignore the fact that we&apos;re trying to come up with a list of<br/>linear temperaments that will be of interest to the largest possible<br/>number of human beings. Unfortunately human perception and cognition<br/>is messy to model mathematically, not well established experimentally<br/>and highly variable between individuals. But I&apos;m sure we can come up<br/>with something that is both reasonably elegant mathematically and that<br/>we (in this forum) can all agree isn&apos;t too bad. We certainly do it<br/>without trying some out and looking at the results!</p><p>We should probably hone the badness metric using 5-limit, where the<br/>most experience exists.</p></div><h3>paulerlich &#x3C;paul@stretch-music.com&#x3E;</h3><span>12/6/2001 7:50:46 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;dkeenanuqnetau&quot; &lt;d.keenan@u...&gt; wrote:</p><p>&gt; But I&apos;m sure we can come up<br/>&gt; with something that is both reasonably elegant mathematically and<br/>that<br/>&gt; we (in this forum) can all agree isn&apos;t too bad.</p><p>I felt that way about steps^3 cents, except where was 12+14?</p><p>&gt; We certainly do it<br/>&gt; without trying some out and looking at the results!</p><p>You mean a priori? The more arbitrary parameters we put into it, the<br/>more we&apos;ll have to rely on particular assumption on how someone is<br/>going to be making music, and this assumtion will be violated for the<br/>next person. The top 25 or 40 according to a very generalized<br/>criterion will best serve to present the _pattern_ of this whole<br/>endeavor, upon which any musician can base their _own_ evaluation,<br/>and if they don&apos;t want to, at least pick off one or two temperaments<br/>that interest them.</p><p>But I have a nagging suspicion that there are even more &quot;slippery&quot;<br/>ones out there, especially on the ultra-simple end of things . . .</p><p>I suspect we can use step^2 cents and cut it off at some point where<br/>there&apos;s a long gap in the step-cent plane. For example, the next<br/>point out after Ennealimmal is probably a long way out, so we can<br/>probably put a cutoff there. As for simple temperaments with large<br/>errors, I suspect there are more than Gene and Graham have found so<br/>far that would end up looking good on this criterion, so it may end<br/>up making sense to place another cutoff there . . . but I want to be<br/>sure we&apos;ve caught all the slippery fish before we decide that.</p><p>I would still like to see the &quot;step&quot; thing weighted -- there should<br/>be something very mathematically and acoustically elegant about doing<br/>it that way (if defined correctly) since we are using the Tenney<br/>lattice after all!<br/>&gt;<br/>&gt; We should probably hone the badness metric using 5-limit, where the<br/>&gt; most experience exists.</p><p>Yes, I was just going to say we should write the whole paper first in<br/>the 5-limit.</p></div><h3>dkeenanuqnetau &#x3C;d.keenan@uq.net.au&#x3E;</h3><span>12/6/2001 8:18:34 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;paulerlich&quot; &lt;paul@s...&gt; wrote:<br/>&gt; --- In tuning-math@y..., &quot;dkeenanuqnetau&quot; &lt;d.keenan@u...&gt; wrote:<br/>&gt;<br/>&gt; &gt; But I&apos;m sure we can come up<br/>&gt; &gt; with something that is both reasonably elegant mathematically and<br/>&gt; that<br/>&gt; &gt; we (in this forum) can all agree isn&apos;t too bad.<br/>&gt;<br/>&gt; I felt that way about steps^3 cents, except where was 12+14?<br/>&gt;<br/>&gt; &gt; We certainly do it<br/>&gt; &gt; without trying some out and looking at the results!</p><p>Oops! That should have been</p><p>We certainly _can&apos;t_ do it without trying some out and looking at the<br/>results!</p><p>&gt; You mean a priori? The more arbitrary parameters we put into it, the<br/>&gt; more we&apos;ll have to rely on particular assumption on how someone is<br/>&gt; going to be making music, and this assumtion will be violated for<br/>the<br/>&gt; next person.</p><p>&quot;Not putting in&quot; an arbitrary parameter is usually equivalent to<br/>putting it in but giving it an even more arbitrary value like 0 or 1.</p></div><h3>paulerlich &#x3C;paul@stretch-music.com&#x3E;</h3><span>12/6/2001 8:30:35 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;dkeenanuqnetau&quot; &lt;d.keenan@u...&gt; wrote:<br/>&gt; --- In tuning-math@y..., &quot;paulerlich&quot; &lt;paul@s...&gt; wrote:</p><p>&gt; &gt; You mean a priori? The more arbitrary parameters we put into it,<br/>the<br/>&gt; &gt; more we&apos;ll have to rely on particular assumption on how someone<br/>is<br/>&gt; &gt; going to be making music, and this assumtion will be violated for<br/>&gt; the<br/>&gt; &gt; next person.<br/>&gt;<br/>&gt; &quot;Not putting in&quot; an arbitrary parameter is usually equivalent to<br/>&gt; putting it in but giving it an even more arbitrary value like 0 or<br/>1.</p><p>Well, I think Gene is saying that step^2 cents is clearly the right<br/>measure of &quot;remarkability&quot;.</p></div><h3>genewardsmith &#x3C;genewardsmith@juno.com&#x3E;</h3><span>12/6/2001 8:35:25 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;paulerlich&quot; &lt;paul@s...&gt; wrote:</p><p>&gt; The solutions represent?</p><p>I take the 5-limit comma defined by the temperament, and then find<br/>another comma 2^p 3^q 5^r 7 such that the wedgie of this and the 5-<br/>limit comma is the correct wedgie, that means these two commas define<br/>the temperament.</p><p>&gt; &gt; The pair of unisons<br/>&gt; &gt; returned in this way can be LLL reduced by the &quot;com7&quot; function,<br/>&gt; which<br/>&gt; &gt; takes a pair of intervals and LLL reduces them.<br/>&gt;<br/>&gt; Why not TM-reduce them?</p><p>I&apos;d always LLL reduce them first.</p></div><h3>paulerlich &#x3C;paul@stretch-music.com&#x3E;</h3><span>12/6/2001 8:56:08 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;genewardsmith&quot; &lt;genewardsmith@j...&gt; wrote:<br/>&gt; --- In tuning-math@y..., &quot;paulerlich&quot; &lt;paul@s...&gt; wrote:<br/>&gt;<br/>&gt; &gt; The solutions represent?<br/>&gt;<br/>&gt; I take the 5-limit comma defined by the temperament, and then find<br/>&gt; another comma 2^p 3^q 5^r 7 such that the wedgie of this and the 5-<br/>&gt; limit comma is the correct wedgie, that means these two commas<br/>define<br/>&gt; the temperament.<br/>&gt;<br/>&gt;<br/>&gt; &gt; &gt; The pair of unisons<br/>&gt; &gt; &gt; returned in this way can be LLL reduced by the &quot;com7&quot; function,<br/>&gt; &gt; which<br/>&gt; &gt; &gt; takes a pair of intervals and LLL reduces them.<br/>&gt; &gt;<br/>&gt; &gt; Why not TM-reduce them?<br/>&gt;<br/>&gt; I&apos;d always LLL reduce them first.</p><p>How come?</p></div><h3>genewardsmith &#x3C;genewardsmith@juno.com&#x3E;</h3><span>12/6/2001 9:17:35 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;paulerlich&quot; &lt;paul@s...&gt; wrote:</p><p>&gt; &gt; I&apos;d always LLL reduce them first.<br/>&gt;<br/>&gt; How come?</p><p>Because it makes the TM reduction dead easy.</p></div><h3>dkeenanuqnetau &#x3C;d.keenan@uq.net.au&#x3E;</h3><span>12/6/2001 9:18:59 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;paulerlich&quot; &lt;paul@s...&gt; wrote:<br/>&gt; Well, I think Gene is saying that step^2 cents is clearly the right<br/>&gt; measure of &quot;remarkability&quot;.</p><p>Huh? &quot;Remarkability&quot; sounds like a kind of goodness. Step^2 * cents is<br/>obviously a form of badness. I think I&apos;ve already explained why no<br/>product of poynomials of these two things will ever be acceptable to<br/>me, at least not without cutoffs applied to them first. And I<br/>understand Gene to be saying that he wants at least an upper cutoff on<br/>&quot;steps&quot; (which seems like a bad name to me since it suggests scale<br/>steps, I prefer &quot;num_gens&quot; or just &quot;gens&quot;).</p><p>  gens^2 * cents<br/>gives exactly the same ranking as<br/>  log(gens^2 * cents)     [where the log base is arbitrary]<br/>because log(x) is monotonically increasing. Right?<br/>Now<br/>  log(gens^2 * cents)<br/>= log(gens^2) + log(cents)<br/>= 2*log(gens) + log(cents)</p><p>So this says that a doubling of the number of generators is twice as<br/>bad as a doubling of the error. And previously someone suggested it<br/>was 3 times as bad. You&apos;ve arbitrarity decided that only the<br/>logarithms are comparable (when cents is already a logarithmic<br/>quantity) and you arbitrarily decided that the constant of<br/>proportionality between them must be an integer!</p><p>So what&apos;s wrong with k*steps + cents? The basic idea here is that the<br/>unit of badness is the cent and we decide for a given odd-limit how<br/>many cents the error would need to be reduced for you to tolerate an<br/>extra generator in the width of your tetrads (or whatever), or how<br/>many generators you&apos;d need to reduce the tetrad (or whatever) width by<br/>in order to tolerate another cent of error.</p><p>Or maybe you think that a _doubling_ of the number of generators is<br/>worth a fixed number of cents. i.e. badness = k*log(gens) + cents</p><p>But always you must decide a value for one parameter k that gives the<br/>proportionality between gens and cents because there is no<br/>relationship between their two units of measurement apart from the one<br/>that comes through human experience. Or at least I can&apos;t see any.</p></div><h3>genewardsmith &#x3C;genewardsmith@juno.com&#x3E;</h3><span>12/6/2001 9:22:38 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;paulerlich&quot; &lt;paul@s...&gt; wrote:</p><p>&gt; Yes, I was just going to say we should write the whole paper first<br/>in<br/>&gt; the 5-limit.</p><p>There&apos;s not much to the 5-limit--it basically is a mere comma search,<br/>and that can be done expeditiously using a decent 5-limit notation.</p></div><h3>paulerlich &#x3C;paul@stretch-music.com&#x3E;</h3><span>12/6/2001 9:34:10 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;dkeenanuqnetau&quot; &lt;d.keenan@u...&gt; wrote:<br/>&gt; --- In tuning-math@y..., &quot;paulerlich&quot; &lt;paul@s...&gt; wrote:<br/>&gt; &gt; Well, I think Gene is saying that step^2 cents is clearly the<br/>right<br/>&gt; &gt; measure of &quot;remarkability&quot;.<br/>&gt;<br/>&gt; Huh? &quot;Remarkability&quot; sounds like a kind of goodness. Step^2 * cents<br/>is<br/>&gt; obviously a form of badness.</p><p>Right, but it&apos;s the _objective_ kind. Not the kind that has anything<br/>to do with any particular musician&apos;s desiderata. It&apos;s the only<br/>measure that doesn&apos;t favor a certain range of acceptable values for<br/>error or for complexity. It only favors the best examples within each<br/>range. The particular users of our findings can then decide what<br/>range suits them best. Within any narrow range, all reasonable<br/>measures will give the same ranking.</p><p>This is kind of like using Tenney complexity to determine the seed<br/>set for harmonic entropy -- with different complexity measures the<br/>overall slope of the curve changes, changing the consonance ranking<br/>of intervals of different sizes, but the consonance ranking of nearby<br/>intervals remains the same regardless of how complexity is defined<br/>(as long as the 2-by-2 matrix formed by the numbers in adjacent seed<br/>fractions always has a determinant of 1).</p><p>&gt; I think I&apos;ve already explained why no<br/>&gt; product of poynomials of these two things will ever be acceptable<br/>to<br/>&gt; me, at least not without cutoffs applied to them first.<br/>&gt; And I<br/>&gt; understand Gene to be saying that he wants at least an upper cutoff</p><p>Yes -- I discussed the situation a few messages back. We use an<br/>objective measure, and cut things off in a nice wide gap.</p><p>&gt; on<br/>&gt; &quot;steps&quot; (which seems like a bad name to me since it suggests scale<br/>&gt; steps, I prefer &quot;num_gens&quot; or just &quot;gens&quot;).</p><p>Yes.</p></div><h3>paulerlich &#x3C;paul@stretch-music.com&#x3E;</h3><span>12/6/2001 9:34:40 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;genewardsmith&quot; &lt;genewardsmith@j...&gt; wrote:<br/>&gt; --- In tuning-math@y..., &quot;paulerlich&quot; &lt;paul@s...&gt; wrote:<br/>&gt;<br/>&gt; &gt; Yes, I was just going to say we should write the whole paper<br/>first<br/>&gt; in<br/>&gt; &gt; the 5-limit.<br/>&gt;<br/>&gt; There&apos;s not much to the 5-limit--it basically is a mere comma<br/>search,<br/>&gt; and that can be done expeditiously using a decent 5-limit notation.</p><p>A decent 5-limit notation?</p></div><h3>dkeenanuqnetau &#x3C;d.keenan@uq.net.au&#x3E;</h3><span>12/6/2001 10:00:40 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;paulerlich&quot; &lt;paul@s...&gt; wrote:<br/>&gt; --- In tuning-math@y..., &quot;dkeenanuqnetau&quot; &lt;d.keenan@u...&gt; wrote:<br/>&gt; &gt; --- In tuning-math@y..., &quot;paulerlich&quot; &lt;paul@s...&gt; wrote:<br/>&gt; &gt; &gt; Well, I think Gene is saying that step^2 cents is clearly the<br/>&gt; right<br/>&gt; &gt; &gt; measure of &quot;remarkability&quot;.<br/>&gt; &gt;<br/>&gt; &gt; Huh? &quot;Remarkability&quot; sounds like a kind of goodness. Step^2 *<br/>cents<br/>&gt; is<br/>&gt; &gt; obviously a form of badness.<br/>&gt;<br/>&gt; Right, but it&apos;s the _objective_ kind. Not the kind that has anything<br/>&gt; to do with any particular musician&apos;s desiderata.</p><p>Paul! You seem to have ignored the most of the rest of my message.</p><p>What the heck is _objective_ about deciding that a doubling of the<br/>number of generators is twice as bad as a doubling of the error. It&apos;s<br/>completely arbitrary.</p><p>&gt; It&apos;s the only<br/>&gt; measure that doesn&apos;t favor a certain range of acceptable values for<br/>&gt; error or for complexity. It only favors the best examples within<br/>each<br/>&gt; range.</p><p>What _objective_ reason is there, to choose it over gens^3 * cents or<br/>gens^2.3785 * cents?</p></div><h3>paulerlich &#x3C;paul@stretch-music.com&#x3E;</h3><span>12/6/2001 10:23:45 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;dkeenanuqnetau&quot; &lt;d.keenan@u...&gt; wrote:</p><p>&gt; Paul! You seem to have ignored the most of the rest of my message.</p><p>Not at all.</p><p>&gt; &gt; It&apos;s the only<br/>&gt; &gt; measure that doesn&apos;t favor a certain range of acceptable values<br/>for<br/>&gt; &gt; error or for complexity. It only favors the best examples within<br/>&gt; each<br/>&gt; &gt; range.<br/>&gt;<br/>&gt; What _objective_ reason is there, to choose it over gens^3 * cents<br/>or<br/>&gt; gens^2.3785 * cents?</p><p>Because those measures give an overall &quot;slope&quot; to the results, in<br/>analogy to what the Farey series seeding does to harmonic entropy.</p></div><h3>genewardsmith &#x3C;genewardsmith@juno.com&#x3E;</h3><span>12/6/2001 10:34:59 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;genewardsmith&quot; &lt;genewardsmith@j...&gt; wrote:<br/>&gt; --- In tuning-math@y..., &quot;paulerlich&quot; &lt;paul@s...&gt; wrote:<br/>&gt;<br/>&gt; &gt; The solutions represent?<br/>&gt;<br/>&gt; I take the 5-limit comma defined by the temperament, and then find<br/>&gt; another comma 2^p 3^q 5^r 7 such that the wedgie of this and the 5-<br/>&gt; limit comma is the correct wedgie, that means these two commas<br/>define<br/>&gt; the temperament.</p><p>This should be 2^p 3^q 5^r 7^s where s is gcd(a,b,c), and the 5-limit<br/>comma is 2^a 3^b 5^c.</p></div><h3>genewardsmith &#x3C;genewardsmith@juno.com&#x3E;</h3><span>12/6/2001 10:37:45 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;paulerlich&quot; &lt;paul@s...&gt; wrote:</p><p>&gt; Yes -- I discussed the situation a few messages back. We use an<br/>&gt; objective measure, and cut things off in a nice wide gap.</p><p>You are thinking that gens^2 cents, and Ennealimmal as the shut-off<br/>point, would be a good plan?</p></div><h3>dkeenanuqnetau &#x3C;d.keenan@uq.net.au&#x3E;</h3><span>12/6/2001 10:42:45 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;paulerlich&quot; &lt;paul@s...&gt; wrote:<br/>&gt; --- In tuning-math@y..., &quot;dkeenanuqnetau&quot; &lt;d.keenan@u...&gt; wrote:<br/>&gt; &gt; &gt; It&apos;s the only<br/>&gt; &gt; &gt; measure that doesn&apos;t favor a certain range of acceptable values<br/>&gt; for<br/>&gt; &gt; &gt; error or for complexity. It only favors the best examples within<br/>&gt; &gt; each<br/>&gt; &gt; &gt; range.<br/>&gt; &gt;<br/>&gt; &gt; What _objective_ reason is there, to choose it over gens^3 * cents<br/>&gt; or<br/>&gt; &gt; gens^2.3785 * cents?<br/>&gt;<br/>&gt; Because those measures give an overall &quot;slope&quot; to the results, in<br/>&gt; analogy to what the Farey series seeding does to harmonic entropy.</p><p>What&apos;s objective about that? A certain slope may be _real_. i.e.<br/>humans on average may experience it that way, in which case the &quot;flat&quot;<br/>case will really be favouring one extreme.</p><p>I understand what the slope is in the HE case, but what slope are you<br/>talking about re badness of linear temperament? Badness wrt what?</p></div><h3>genewardsmith &#x3C;genewardsmith@juno.com&#x3E;</h3><span>12/6/2001 10:47:57 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;paulerlich&quot; &lt;paul@s...&gt; wrote:</p><p>&gt; &gt; There&apos;s not much to the 5-limit--it basically is a mere comma<br/>&gt; search,<br/>&gt; &gt; and that can be done expeditiously using a decent 5-limit<br/>notation.</p><p>&gt; A decent 5-limit notation?</p><p>We could search (16/15)^a (25/24)^b (81/80)^c to start out with, and<br/>go to something more extreme if wanted.</p></div><h3>paulerlich &#x3C;paul@stretch-music.com&#x3E;</h3><span>12/6/2001 10:49:02 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;genewardsmith&quot; &lt;genewardsmith@j...&gt; wrote:<br/>&gt; --- In tuning-math@y..., &quot;paulerlich&quot; &lt;paul@s...&gt; wrote:<br/>&gt;<br/>&gt; &gt; Yes -- I discussed the situation a few messages back. We use an<br/>&gt; &gt; objective measure, and cut things off in a nice wide gap.<br/>&gt;<br/>&gt; You are thinking that gens^2 cents, and Ennealimmal as the shut-off<br/>&gt; point, would be a good plan?</p><p>Possibly, though since gens and cents are two dimensions, we really<br/>need a shuf-off _curve_, don&apos;t we?</p></div><h3>genewardsmith &#x3C;genewardsmith@juno.com&#x3E;</h3><span>12/6/2001 10:51:02 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;dkeenanuqnetau&quot; &lt;d.keenan@u...&gt; wrote:</p><p>&gt; I understand what the slope is in the HE case, but what slope are<br/>you<br/>&gt; talking about re badness of linear temperament? Badness wrt what?</p><p>What is the problem with a &quot;flat&quot; system and a cutoff? It doesn&apos;t<br/>commit to any particular theory about what humans are like and what<br/>they should want, and I think that&apos;s a good plan.</p></div><h3>paulerlich &#x3C;paul@stretch-music.com&#x3E;</h3><span>12/6/2001 10:52:39 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;genewardsmith&quot; &lt;genewardsmith@j...&gt; wrote:<br/>&gt; --- In tuning-math@y..., &quot;paulerlich&quot; &lt;paul@s...&gt; wrote:<br/>&gt;<br/>&gt; &gt; &gt; There&apos;s not much to the 5-limit--it basically is a mere comma<br/>&gt; &gt; search,<br/>&gt; &gt; &gt; and that can be done expeditiously using a decent 5-limit<br/>&gt; notation.<br/>&gt;<br/>&gt; &gt; A decent 5-limit notation?<br/>&gt;<br/>&gt; We could search (16/15)^a (25/24)^b (81/80)^c to start out with,<br/>and<br/>&gt; go to something more extreme if wanted.</p><p>More extreme? I&apos;m not getting this.</p></div><h3>paulerlich &#x3C;paul@stretch-music.com&#x3E;</h3><span>12/6/2001 10:51:43 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;dkeenanuqnetau&quot; &lt;d.keenan@u...&gt; wrote:</p><p>&gt; &gt; Because those measures give an overall &quot;slope&quot; to the results, in<br/>&gt; &gt; analogy to what the Farey series seeding does to harmonic entropy.<br/>&gt;<br/>&gt; What&apos;s objective about that? A certain slope may be _real_. i.e.<br/>&gt; humans on average may experience it that way, in which case<br/>the &quot;flat&quot;<br/>&gt; case will really be favouring one extreme.</p><p>But I don&apos;t feel comfortable deciding that for anyone.</p><p>&gt; I understand what the slope is in the HE case, but what slope are<br/>you<br/>&gt; talking about re badness of linear temperament? Badness wrt what?</p><p>Both step and cent.</p></div><h3>genewardsmith &#x3C;genewardsmith@juno.com&#x3E;</h3><span>12/6/2001 10:53:15 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;paulerlich&quot; &lt;paul@s...&gt; wrote:</p><p>&gt; Possibly, though since gens and cents are two dimensions, we really<br/>&gt; need a shuf-off _curve_, don&apos;t we?</p><p>If we bound one of them and gens^2 cents, we&apos;ve bound the other;<br/>that&apos;s what I&apos;d do.</p></div><h3>paulerlich &#x3C;paul@stretch-music.com&#x3E;</h3><span>12/6/2001 10:54:04 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;genewardsmith&quot; &lt;genewardsmith@j...&gt; wrote:<br/>&gt; --- In tuning-math@y..., &quot;dkeenanuqnetau&quot; &lt;d.keenan@u...&gt; wrote:<br/>&gt;<br/>&gt; &gt; I understand what the slope is in the HE case, but what slope are<br/>&gt; you<br/>&gt; &gt; talking about re badness of linear temperament? Badness wrt what?<br/>&gt;<br/>&gt; What is the problem with a &quot;flat&quot; system and a cutoff?</p><p>Dave is trying to understand why this _is_ a flat system.</p><p>&gt; It doesn&apos;t<br/>&gt; commit to any particular theory about what humans are like and what<br/>&gt; they should want, and I think that&apos;s a good plan.</p><p>Thank you.</p></div><h3>paulerlich &#x3C;paul@stretch-music.com&#x3E;</h3><span>12/6/2001 10:59:08 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;genewardsmith&quot; &lt;genewardsmith@j...&gt; wrote:<br/>&gt; --- In tuning-math@y..., &quot;paulerlich&quot; &lt;paul@s...&gt; wrote:<br/>&gt;<br/>&gt; &gt; Possibly, though since gens and cents are two dimensions, we<br/>really<br/>&gt; &gt; need a shuf-off _curve_, don&apos;t we?<br/>&gt;<br/>&gt; If we bound one of them and gens^2 cents, we&apos;ve bound the other;<br/>&gt; that&apos;s what I&apos;d do.</p><p>Hmm . . . so if we simply put an upper bound on the RMS cents error,<br/>we&apos;ll have a closed search? That doesn&apos;t seem right . . .</p></div><h3>dkeenanuqnetau &#x3C;d.keenan@uq.net.au&#x3E;</h3><span>12/6/2001 11:00:21 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;genewardsmith&quot; &lt;genewardsmith@j...&gt; wrote:<br/>&gt; --- In tuning-math@y..., &quot;dkeenanuqnetau&quot; &lt;d.keenan@u...&gt; wrote:<br/>&gt;<br/>&gt; &gt; I understand what the slope is in the HE case, but what slope are<br/>&gt; you<br/>&gt; &gt; talking about re badness of linear temperament? Badness wrt what?<br/>&gt;<br/>&gt; What is the problem with a &quot;flat&quot; system and a cutoff?</p><p>I may be able to answer that when someone explains what is flat with<br/>respect to what.</p><p> It doesn&apos;t<br/>&gt; commit to any particular theory about what humans are like and what<br/>&gt; they should want, and I think that&apos;s a good plan.</p><p>Don&apos;t the cutoffs have to be based on a theory about what humans are<br/>like?</p><p>If a &quot;flat&quot; system was miles from anything related what humans are<br/>like, would you still be interested in it?</p><p>I don&apos;t think you can avoid this choice. You must publish a finite<br/>list. If you include more of certain extremes, you must omit more<br/>of the middle-of-the-road.</p></div><h3>genewardsmith &#x3C;genewardsmith@juno.com&#x3E;</h3><span>12/6/2001 11:03:27 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;paulerlich&quot; &lt;paul@s...&gt; wrote:</p><p>&gt; &gt; We could search (16/15)^a (25/24)^b (81/80)^c to start out with,<br/>&gt; and<br/>&gt; &gt; go to something more extreme if wanted.<br/>&gt;<br/>&gt; More extreme? I&apos;m not getting this.</p><p>(78732/78125)^a (32805/32768)^b (2109375/2097152)^c also gives the<br/>5-limit, but is better for finding much smaller commas, to take a<br/>more or less random example.</p></div><h3>paulerlich &#x3C;paul@stretch-music.com&#x3E;</h3><span>12/6/2001 11:05:05 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;dkeenanuqnetau&quot; &lt;d.keenan@u...&gt; wrote:<br/>&gt; --- In tuning-math@y..., &quot;genewardsmith&quot; &lt;genewardsmith@j...&gt; wrote:</p><p>&gt; &gt; It doesn&apos;t<br/>&gt; &gt; commit to any particular theory about what humans are like and<br/>what<br/>&gt; &gt; they should want, and I think that&apos;s a good plan.<br/>&gt;<br/>&gt; Don&apos;t the cutoffs have to be based on a theory about what humans<br/>are<br/>&gt; like?</p><p>I&apos;m suggesting we place the cutoffs where we find big gaps, and<br/>comfortably outside any system that has been used to date.<br/>&gt;<br/>&gt; If a &quot;flat&quot; system was miles from anything related what humans are<br/>&gt; like, would you still be interested in it?</p><p>Again, any system that is &quot;best&quot; according to a &quot;human&quot; criterion<br/>will show up as &quot;best in its neighborhood&quot; under a flat criterion.</p></div><h3>paulerlich &#x3C;paul@stretch-music.com&#x3E;</h3><span>12/6/2001 11:08:44 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;genewardsmith&quot; &lt;genewardsmith@j...&gt; wrote:<br/>&gt; --- In tuning-math@y..., &quot;paulerlich&quot; &lt;paul@s...&gt; wrote:<br/>&gt;<br/>&gt; &gt; &gt; We could search (16/15)^a (25/24)^b (81/80)^c to start out<br/>with,<br/>&gt; &gt; and<br/>&gt; &gt; &gt; go to something more extreme if wanted.<br/>&gt; &gt;<br/>&gt; &gt; More extreme? I&apos;m not getting this.<br/>&gt;<br/>&gt; (78732/78125)^a (32805/32768)^b (2109375/2097152)^c also gives the<br/>&gt; 5-limit, but is better for finding much smaller commas, to take a<br/>&gt; more or less random example.</p><p>Once a, b, and c are big enough, the original choice of commas will<br/>do little to induce any tendency of smallness or largeness in the<br/>result, correct?</p></div><h3>dkeenanuqnetau &#x3C;d.keenan@uq.net.au&#x3E;</h3><span>12/6/2001 11:11:53 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;paulerlich&quot; &lt;paul@s...&gt; wrote:<br/>&gt; --- In tuning-math@y..., &quot;dkeenanuqnetau&quot; &lt;d.keenan@u...&gt; wrote:<br/>&gt;<br/>&gt; &gt; &gt; Because those measures give an overall &quot;slope&quot; to the results,<br/>in<br/>&gt; &gt; &gt; analogy to what the Farey series seeding does to harmonic<br/>entropy.<br/>&gt; &gt;<br/>&gt; &gt; What&apos;s objective about that? A certain slope may be _real_. i.e.<br/>&gt; &gt; humans on average may experience it that way, in which case<br/>&gt; the &quot;flat&quot;<br/>&gt; &gt; case will really be favouring one extreme.<br/>&gt;<br/>&gt; But I don&apos;t feel comfortable deciding that for anyone.</p><p>But you _are_ deciding it. You can&apos;t help but decide it, unless you<br/>intend to publish an infinite list. No matter what you do there will<br/>be someone who thinks there&apos;s a lot of fluff in there and you missed<br/>out some others. They aren&apos;t going to be impressed by any argument<br/>that &quot;our metric is &apos;objective&apos; or &apos;flat&apos;&quot;.</p><p>&gt; &gt; I understand what the slope is in the HE case, but what slope are<br/>&gt; you<br/>&gt; &gt; talking about re badness of linear temperament? Badness wrt what?<br/>&gt;<br/>&gt; Both step and cent.</p><p>Huh? Obviously any badness metric _must_ slope down towards (0,0) on<br/>the (cents,gens) plain. If you make the gens and cents axes<br/>logarithmic then badness = gens^k * cents is simply a tilted plane.<br/>The only way you can decide on whether it should tilt more towards<br/>gens or cents (the exponent k) is through human considerations.</p></div><h3>dkeenanuqnetau &#x3C;d.keenan@uq.net.au&#x3E;</h3><span>12/6/2001 11:16:27 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;paulerlich&quot; &lt;paul@s...&gt; wrote:<br/>&gt; --- In tuning-math@y..., &quot;dkeenanuqnetau&quot; &lt;d.keenan@u...&gt; wrote:<br/>&gt; &gt; If a &quot;flat&quot; system was miles from anything related what humans are<br/>&gt; &gt; like, would you still be interested in it?<br/>&gt;<br/>&gt; Again, any system that is &quot;best&quot; according to a &quot;human&quot; criterion<br/>&gt; will show up as &quot;best in its neighborhood&quot; under a flat criterion.</p><p>But some neighbourhoods may be so disadvantaged that their best<br/>doesn&apos;t even make it into the list.</p></div><h3>genewardsmith &#x3C;genewardsmith@juno.com&#x3E;</h3><span>12/6/2001 11:25:50 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;paulerlich&quot; &lt;paul@s...&gt; wrote:</p><p>&gt; Hmm . . . so if we simply put an upper bound on the RMS cents<br/>error,<br/>&gt; we&apos;ll have a closed search? That doesn&apos;t seem right . . .</p><p>I was suggesting a *lower* bound on RMS cents as one possibility.</p><p>If with all quantities positive we have g^2 c &lt; A and c &gt; B, then<br/>1/c &lt; 1/B, and so g^2 &lt; A/B and g &lt; sqrt(A/B). However, it probably<br/>makes more sense to use g&gt;=1, so that if g^2 c &lt;= A then c &lt;= A.</p></div><h3>paulerlich &#x3C;paul@stretch-music.com&#x3E;</h3><span>12/6/2001 11:26:24 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;dkeenanuqnetau&quot; &lt;d.keenan@u...&gt; wrote:<br/>&gt; --- In tuning-math@y..., &quot;paulerlich&quot; &lt;paul@s...&gt; wrote:<br/>&gt; &gt; --- In tuning-math@y..., &quot;dkeenanuqnetau&quot; &lt;d.keenan@u...&gt; wrote:<br/>&gt; &gt;<br/>&gt; &gt; &gt; &gt; Because those measures give an overall &quot;slope&quot; to the<br/>results,<br/>&gt; in<br/>&gt; &gt; &gt; &gt; analogy to what the Farey series seeding does to harmonic<br/>&gt; entropy.<br/>&gt; &gt; &gt;<br/>&gt; &gt; &gt; What&apos;s objective about that? A certain slope may be _real_.<br/>i.e.<br/>&gt; &gt; &gt; humans on average may experience it that way, in which case<br/>&gt; &gt; the &quot;flat&quot;<br/>&gt; &gt; &gt; case will really be favouring one extreme.<br/>&gt; &gt;<br/>&gt; &gt; But I don&apos;t feel comfortable deciding that for anyone.<br/>&gt;<br/>&gt; But you _are_ deciding it. You can&apos;t help but decide it, unless you<br/>&gt; intend to publish an infinite list. No matter what you do there<br/>will<br/>&gt; be someone who thinks there&apos;s a lot of fluff in there and you<br/>missed<br/>&gt; out some others. They aren&apos;t going to be impressed by any argument<br/>&gt; that &quot;our metric is &apos;objective&apos; or &apos;flat&apos;&quot;.</p><p>We won&apos;t be missing out on anyone&apos;s &quot;best&quot; (unless they are really<br/>far out on the plane, beyond the big gap where we will establish the<br/>cutoff). Then they can come up with their own criterion and get their<br/>own ranking. But at least we&apos;ll have something for everyone.</p><p>&gt; &gt; &gt; I understand what the slope is in the HE case, but what slope<br/>are<br/>&gt; &gt; you<br/>&gt; &gt; &gt; talking about re badness of linear temperament? Badness wrt<br/>what?<br/>&gt; &gt;<br/>&gt; &gt; Both step and cent.<br/>&gt;<br/>&gt; Huh? Obviously any badness metric _must_ slope down towards (0,0)<br/>on<br/>&gt; the (cents,gens) plain.</p><p>The badness metric does, but the results don&apos;t. The results have a<br/>similar distribution everywhere on the plane, but only when gens^2<br/>cents is the badness metric.</p></div><h3>paulerlich &#x3C;paul@stretch-music.com&#x3E;</h3><span>12/6/2001 11:28:22 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;dkeenanuqnetau&quot; &lt;d.keenan@u...&gt; wrote:<br/>&gt; --- In tuning-math@y..., &quot;paulerlich&quot; &lt;paul@s...&gt; wrote:<br/>&gt; &gt; --- In tuning-math@y..., &quot;dkeenanuqnetau&quot; &lt;d.keenan@u...&gt; wrote:<br/>&gt; &gt; &gt; If a &quot;flat&quot; system was miles from anything related what humans<br/>are<br/>&gt; &gt; &gt; like, would you still be interested in it?<br/>&gt; &gt;<br/>&gt; &gt; Again, any system that is &quot;best&quot; according to a &quot;human&quot; criterion<br/>&gt; &gt; will show up as &quot;best in its neighborhood&quot; under a flat criterion.<br/>&gt;<br/>&gt; But some neighbourhoods may be so disadvantaged that their best<br/>&gt; doesn&apos;t even make it into the list.</p><p>That won&apos;t happen -- that&apos;s the point of the &quot;flat&quot; criterion. Only<br/>the neighborhoods outside our cutoff will be disadvantaged, but at<br/>least this will be explicit.</p></div><h3>paulerlich &#x3C;paul@stretch-music.com&#x3E;</h3><span>12/6/2001 11:34:36 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;genewardsmith&quot; &lt;genewardsmith@j...&gt; wrote:<br/>&gt; --- In tuning-math@y..., &quot;paulerlich&quot; &lt;paul@s...&gt; wrote:<br/>&gt;<br/>&gt; &gt; Hmm . . . so if we simply put an upper bound on the RMS cents<br/>&gt; error,<br/>&gt; &gt; we&apos;ll have a closed search? That doesn&apos;t seem right . . .<br/>&gt;<br/>&gt; I was suggesting a *lower* bound on RMS cents as one possibility.</p><p>Oh . . . well I don&apos;t think we should frame it _that_ way!</p><p>&gt; If with all quantities positive we have g^2 c &lt; A and c &gt; B, then<br/>&gt; 1/c &lt; 1/B, and so g^2 &lt; A/B and g &lt; sqrt(A/B). However, it probably<br/>&gt; makes more sense to use g&gt;=1, so that if g^2 c &lt;= A then c &lt;= A.</p><p>Are you saying that using g&gt;=1 is enough to make this a closed search?</p></div><h3>dkeenanuqnetau &#x3C;d.keenan@uq.net.au&#x3E;</h3><span>12/6/2001 11:55:23 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;paulerlich&quot; &lt;paul@s...&gt; wrote:<br/>&gt; --- In tuning-math@y..., &quot;dkeenanuqnetau&quot; &lt;d.keenan@u...&gt; wrote:<br/>&gt; &gt; Huh? Obviously any badness metric _must_ slope down towards (0,0)<br/>&gt; on<br/>&gt; &gt; the (cents,gens) plain.<br/>&gt;<br/>&gt; The badness metric does, but the results don&apos;t. The results have a<br/>&gt; similar distribution everywhere on the plane, but only when gens^2<br/>&gt; cents is the badness metric.</p><p>You&apos;re not making any sense. The results are all just discrete points<br/>in the badness surface with respect to gens and cents, so they have<br/>exactly the same slope. The results have a similar distribution of<br/>what? Everywhere on what plane?</p></div><h3>genewardsmith &#x3C;genewardsmith@juno.com&#x3E;</h3><span>12/6/2001 11:56:54 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;dkeenanuqnetau&quot; &lt;d.keenan@u...&gt; wrote:</p><p>&gt; I may be able to answer that when someone explains what is flat<br/>with<br/>&gt; respect to what.</p><p>Paul did that. An analogy would be to use n^(4/3) cents when seaching<br/>for 7-limit ets; this will give you a list which does not favor<br/>either high or low numbers n, but it has nothing to do with human<br/>perception, and you would use a different exponent in a different<br/>prime limit--n^2 cents in the 3-limit, n^(3/2) cents in the 5-limit,<br/>and so forth.</p><p>&gt;  It doesn&apos;t<br/>&gt; &gt; commit to any particular theory about what humans are like and<br/>what<br/>&gt; &gt; they should want, and I think that&apos;s a good plan.<br/>&gt;<br/>&gt; Don&apos;t the cutoffs have to be based on a theory about what humans<br/>are<br/>&gt; like?</p><p>I don&apos;t think you can have much of a theory about what a bunch of<br/>cranky individualists might like, but I hope we could cut it off when<br/>the difference could no longer be percieved. Can anyone hear the<br/>difference between Ennealimmal and just?</p><p>&gt; If a &quot;flat&quot; system was miles from anything related what humans are<br/>&gt; like, would you still be interested in it?</p><p>I might, most people would not be. I&apos;ve discovered though that even<br/>the large, &quot;useless&quot; ets have uses.</p></div><h3>paulerlich &#x3C;paul@stretch-music.com&#x3E;</h3><span>12/7/2001 12:03:05 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;dkeenanuqnetau&quot; &lt;d.keenan@u...&gt; wrote:<br/>&gt; --- In tuning-math@y..., &quot;paulerlich&quot; &lt;paul@s...&gt; wrote:<br/>&gt; &gt; --- In tuning-math@y..., &quot;dkeenanuqnetau&quot; &lt;d.keenan@u...&gt; wrote:<br/>&gt; &gt; &gt; Huh? Obviously any badness metric _must_ slope down towards<br/>(0,0)<br/>&gt; &gt; on<br/>&gt; &gt; &gt; the (cents,gens) plain.<br/>&gt; &gt;<br/>&gt; &gt; The badness metric does, but the results don&apos;t. The results have<br/>a<br/>&gt; &gt; similar distribution everywhere on the plane, but only when<br/>gens^2<br/>&gt; &gt; cents is the badness metric.<br/>&gt;<br/>&gt; You&apos;re not making any sense. The results are all just discrete<br/>points<br/>&gt; in the badness surface with respect to gens and cents, so they have<br/>&gt; exactly the same slope. The results have a similar distribution of<br/>&gt; what? Everywhere on what plane?</p><p>I see Gene is, at this very moment, doing a good job explaining these<br/>issues to you; meanwhile, my brain is toast.</p></div><h3>genewardsmith &#x3C;genewardsmith@juno.com&#x3E;</h3><span>12/7/2001 12:06:28 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;paulerlich&quot; &lt;paul@s...&gt; wrote:<br/>&gt; --- In tuning-math@y..., &quot;genewardsmith&quot; &lt;genewardsmith@j...&gt; wrote:<br/>&gt; &gt; --- In tuning-math@y..., &quot;paulerlich&quot; &lt;paul@s...&gt; wrote:<br/>&gt; &gt;<br/>&gt; &gt; &gt; &gt; We could search (16/15)^a (25/24)^b (81/80)^c to start out<br/>&gt; with,<br/>&gt; &gt; &gt; and<br/>&gt; &gt; &gt; &gt; go to something more extreme if wanted.<br/>&gt; &gt; &gt;<br/>&gt; &gt; &gt; More extreme? I&apos;m not getting this.<br/>&gt; &gt;<br/>&gt; &gt; (78732/78125)^a (32805/32768)^b (2109375/2097152)^c also gives<br/>the<br/>&gt; &gt; 5-limit, but is better for finding much smaller commas, to take a<br/>&gt; &gt; more or less random example.<br/>&gt;<br/>&gt; Once a, b, and c are big enough, the original choice of commas will<br/>&gt; do little to induce any tendency of smallness or largeness in the<br/>&gt; result, correct?</p><p>(78732/78125)^53 (32805/32768)^(-84) (2109375/2097152)^65 = 2</p><p>I wouldn&apos;t search that far myself.</p></div><h3>paulerlich &#x3C;paul@stretch-music.com&#x3E;</h3><span>12/7/2001 12:20:04 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;genewardsmith&quot; &lt;genewardsmith@j...&gt; wrote:<br/>&gt; --- In tuning-math@y..., &quot;paulerlich&quot; &lt;paul@s...&gt; wrote:<br/>&gt; &gt; --- In tuning-math@y..., &quot;genewardsmith&quot; &lt;genewardsmith@j...&gt;</p><p>&gt; &gt; &gt; (78732/78125)^a (32805/32768)^b (2109375/2097152)^c also gives<br/>&gt; the<br/>&gt; &gt; &gt; 5-limit, but is better for finding much smaller commas, to take<br/>a<br/>&gt; &gt; &gt; more or less random example.<br/>&gt; &gt;<br/>&gt; &gt; Once a, b, and c are big enough, the original choice of commas<br/>will<br/>&gt; &gt; do little to induce any tendency of smallness or largeness in the<br/>&gt; &gt; result, correct?<br/>&gt;<br/>&gt; (78732/78125)^53 (32805/32768)^(-84) (2109375/2097152)^65 = 2<br/>&gt;<br/>&gt; I wouldn&apos;t search that far myself.</p><p>How do you know you wouldn&apos;t be missing any good ones?</p></div><h3>genewardsmith &#x3C;genewardsmith@juno.com&#x3E;</h3><span>12/7/2001 12:27:10 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;paulerlich&quot; &lt;paul@s...&gt; wrote:</p><p>&gt; &gt; If with all quantities positive we have g^2 c &lt; A and c &gt; B, then<br/>&gt; &gt; 1/c &lt; 1/B, and so g^2 &lt; A/B and g &lt; sqrt(A/B). However, it<br/>probably<br/>&gt; &gt; makes more sense to use g&gt;=1, so that if g^2 c &lt;= A then c &lt;= A.</p><p>&gt; Are you saying that using g&gt;=1 is enough to make this a closed<br/>search?</p><p>All it does is put an upper limit on how far out of tune the worst<br/>cases can be, so we really need to bound c below or g above to get a<br/>finite search.</p></div><h3>genewardsmith &#x3C;genewardsmith@juno.com&#x3E;</h3><span>12/7/2001 12:33:25 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;paulerlich&quot; &lt;paul@s...&gt; wrote:</p><p>&gt; How do you know you wouldn&apos;t be missing any good ones?</p><p>You&apos;d need bounds on what counted for good; I&apos;ll think about it.</p></div><h3>dkeenanuqnetau &#x3C;d.keenan@uq.net.au&#x3E;</h3><span>12/7/2001 12:35:53 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;genewardsmith&quot; &lt;genewardsmith@j...&gt; wrote:<br/>&gt; --- In tuning-math@y..., &quot;dkeenanuqnetau&quot; &lt;d.keenan@u...&gt; wrote:<br/>&gt;<br/>&gt; &gt; I may be able to answer that when someone explains what is flat<br/>&gt; with<br/>&gt; &gt; respect to what.<br/>&gt;<br/>&gt; Paul did that.</p><p>Not in any way that makes any sense to me. I don&apos;t think Pauk<br/>really understands it either and may be starting to realise that.</p><p>I&apos;m starting to wonder if there&apos;s a conspiracy here to make me think<br/>I&apos;m going crazy. :-) Is anyone else getting this &quot;gens^2 * cents is<br/>the only &apos;flat&apos; metric&quot; thing?</p><p>&gt; An analogy would be to use n^(4/3) cents when<br/>seaching<br/>&gt; for 7-limit ets; this will give you a list which does not favor<br/>&gt; either high or low numbers n,</p><p>I&apos;m sorry. This makes no sense to me either. _How_ would you use<br/>n^(4/3) cents? Can you prove this to me? Or better still just prove<br/>whatever it is you are trying to say about gens^2 * cents being a<br/>&quot;flat&quot; badness metric for linear temperaments.</p><p>&gt; I don&apos;t think you can have much of a theory about what a bunch of<br/>&gt; cranky individualists might like, but I hope we could cut it off<br/>when<br/>&gt; the difference could no longer be percieved. Can anyone hear the<br/>&gt; difference between Ennealimmal and just?</p><p>Well that is precisely a theory about humans, as opposed to say<br/>grasshoppers or rocks or computers.</p><p>If you guys can&apos;t explain this to me, I don&apos;t think you&apos;ve got much<br/>chance of getting published in a refereed journal. It doesn&apos;t involve<br/>anything beyond high school math.</p></div><h3>genewardsmith &#x3C;genewardsmith@juno.com&#x3E;</h3><span>12/7/2001 1:11:20 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;dkeenanuqnetau&quot; &lt;d.keenan@u...&gt; wrote:</p><p>&gt; &gt; An analogy would be to use n^(4/3) cents when<br/>&gt; seaching<br/>&gt; &gt; for 7-limit ets; this will give you a list which does not favor<br/>&gt; &gt; either high or low numbers n,</p><p>&gt; I&apos;m sorry. This makes no sense to me either. _How_ would you use<br/>&gt; n^(4/3) cents? Can you prove this to me?</p><p>The argument for n^(4/3) is required in order to get the argument for<br/>gens^2 cents, so this is the place to start. The argument comes from<br/>the theory of simultaneous Diophantine approximation, where it is<br/>shown that there is a constant c, depending on d, such that for any d<br/>irrational numbers x1, x2, ... xd there will be an infinite number of<br/>solutions n to</p><p>n^(1+1/d) |xi - pi/n| &lt; c</p><p>In the case of the 7-limit, we want to simultaneously approximate<br/>log2(3), log2(5) and log2(7), so d=3.</p><p>&gt; If you guys can&apos;t explain this to me, I don&apos;t think you&apos;ve got much<br/>&gt; chance of getting published in a refereed journal. It doesn&apos;t<br/>involve<br/>&gt; anything beyond high school math.</p><p>Explain what? Diophantine approximation, or why to use that<br/>theoretical basis, or what? *What* doesn&apos;t involve more than high<br/>school math? The theorem I mentioned isn&apos;t hard to prove but it does<br/>use Dirichlet&apos;s pidgeonhole principle, which is also not hard but<br/>which you probably did not learn in high school and which I would not<br/>propose to discuss in the pages of a music journal, given that I have<br/>reason to think that there is a limit to how much math they would<br/>find acceptable.</p></div><h3>dkeenanuqnetau &#x3C;d.keenan@uq.net.au&#x3E;</h3><span>12/7/2001 1:50:55 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;genewardsmith&quot; &lt;genewardsmith@j...&gt; wrote:<br/>&gt; --- In tuning-math@y..., &quot;dkeenanuqnetau&quot; &lt;d.keenan@u...&gt; wrote:<br/>&gt;<br/>&gt; &gt; &gt; An analogy would be to use n^(4/3) cents when<br/>&gt; &gt; seaching<br/>&gt; &gt; &gt; for 7-limit ets; this will give you a list which does not favor<br/>&gt; &gt; &gt; either high or low numbers n,<br/>&gt;<br/>&gt; &gt; I&apos;m sorry. This makes no sense to me either. _How_ would you use<br/>&gt; &gt; n^(4/3) cents? Can you prove this to me?<br/>&gt;<br/>&gt; The argument for n^(4/3) is required in order to get the argument<br/>for<br/>&gt; gens^2 cents, so this is the place to start. The argument comes from<br/>&gt; the theory of simultaneous Diophantine approximation,</p><p>Oh damn. Ok forget about proving it to me. Just please try to get me<br/>to understand what it is you are saying. I just thought that getting<br/>you to prove it to me my be the easiest way for me to understand what<br/>it was I had asked you to prove. Apparently not.</p><p>So ... What is n? What is a 7-limit et? How does one use n^(4/3) to<br/>get a list of them? How would one check to see whether the list<br/>favours high or low n.</p><p>&gt; &gt; If you guys can&apos;t explain this to me, I don&apos;t think you&apos;ve got<br/>much<br/>&gt; &gt; chance of getting published in a refereed journal. It doesn&apos;t<br/>&gt; involve<br/>&gt; &gt; anything beyond high school math.<br/>&gt;<br/>&gt; Explain what? Diophantine approximation, or why to use that<br/>&gt; theoretical basis, or what? *What* doesn&apos;t involve more than high<br/>&gt; school math?</p><p>Your (and Paul&apos;s) statements so far about badness metrics and<br/>flatness.</p><p>&gt; The theorem I mentioned isn&apos;t hard to prove but it does<br/>&gt; use Dirichlet&apos;s pidgeonhole principle, which is also not hard but<br/>&gt; which you probably did not learn in high school and which I would<br/>not<br/>&gt; propose to discuss in the pages of a music journal, given that I<br/>have<br/>&gt; reason to think that there is a limit to how much math they would<br/>&gt; find acceptable.</p><p>Agreed.</p><p>But surely you can get me to understand what you actually mean by<br/>&quot;flat&quot; here. I may well be prepared to just believe the theorem as<br/>stated, if I can understand what it means.</p><p>But no matter what you come up with I can&apos;t see how you can get past<br/>the fact that gens and cents are fundamentally incomensurable<br/>quantities, so somewhere there has to be a parameter that says how bad<br/>they are relative to each other.</p><p>Currently you are saying that doubling gens is twice as bad as<br/>doubling cents. Why? What if 99% of humans don&apos;t experience it like<br/>that.</p><p>And why should they both be treated logarithmically? k*log(gens) +<br/>log(cents) gives the same ranking as gens^2 * cents when k=2. Why not<br/>use k*gens + cents. e.g. if badness was simply gens + cents and you<br/>listed everything with badness not more than 30 then you don&apos;t need<br/>any additional cutoffs. You automatically eliminate anything with gens<br/>&gt; 30 or cents &gt; 30 (actually cents &gt; 29 because gens can&apos;t go below<br/>1).</p></div><h3>genewardsmith &#x3C;genewardsmith@juno.com&#x3E;</h3><span>12/7/2001 12:47:31 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;dkeenanuqnetau&quot; &lt;d.keenan@u...&gt; wrote:</p><p>&gt; So ... What is n? What is a 7-limit et? How does one use n^(4/3) to<br/>&gt; get a list of them? How would one check to see whether the list<br/>&gt; favours high or low n.</p><p>&quot;n&quot; is how many steps to the octave, or in other words what 2 is<br/>mapped to. By a &quot;7-limit et&quot; I mean something which maps 7-limit<br/>intervals to numbers of steps in a consistent way. Since we are<br/>looking for the best, we can safely restrict these to what we get by<br/>rounding n*log2(3), n*log2(5) and n*log2(7) to the nearest integer,<br/>and defining the n-et as the map one gets from this.</p><p>Let&apos;s call this map &quot;h&quot;; for the 12-et, h(2)=12, h(3)=19, h(5)=28 and<br/>h(7)=34; this entails that h(5/3) = h(5)-h(3) = 9, h(7/3)=15 and<br/>h(7/5)=6. I can now measure the relative badness of &quot;h&quot; by taking the<br/>sum, or maximum, or rms, of the differences of |h(3)-n*log2(3)|,<br/>|h(5)-n*log2(5)|, |h(7)-n*log2(7)|, |h(5/3)-n*log2(5/3)|,<br/>|h(7/3)-n*log2(7/3)| and |h(7/5)-n*log2(7/5)|.</p><p>This measure of badness is flat in the sense that the density is the<br/>same everywhere, so that we would be selecting about the same number<br/>of ets in a range around 12 as we would in a range around 1200. I<br/>don&apos;t really want this sort of &quot;flatness&quot;, so I use the theory of<br/>Diophantine approximation to tell we that if I multiply this badness<br/>by the cube root of n, so that the density falls off at a rate of<br/>n^(-1/3), I will still get an infinite list of ets, but if I make it<br/>fall off faster I probably won&apos;t. I can use either the maximum of the<br/>above numbers, or the sum, or the rms, and the same conclusion holds;<br/>in fact, I can look at the 9-limit instead of the 7-limit and the<br/>same conclusion holds. If I look at the maximum, and multiply by 1200<br/>so we are looking at units of n^(4/3) cents, I get the following list<br/>of ets which come out as less than 1000, for n going from 1 to 2000:</p><p>1     884.3587134<br/>2     839.4327178<br/>4     647.3739047<br/>5     876.4669184<br/>9     920.6653451<br/>10    955.6795096<br/>12    910.1603254<br/>15    994.0402775<br/>31    580.7780905<br/>41    892.0787789<br/>72    892.7193923<br/>99    716.7738001<br/>171   384.2612749<br/>270   615.9368489<br/>342   968.2768986<br/>441   685.5766666<br/>1578  989.4999106</p><p>This list just keeps on going, so I cut it off at 2000. I might look<br/>at it, and decide that it doesn&apos;t have some important ets on it, such<br/>as 19,22 and 27; I decide to put those on, not really caring about<br/>any other range, by raising the ante to 1200; I then get the<br/>following additions:</p><p>3     1154.683345<br/>6     1068.957518<br/>19    1087.886603<br/>22    1078.033523<br/>27    1108.589256<br/>68    1090.046322<br/>130   1182.191130<br/>140   1091.565279<br/>202   1143.628876<br/>612   1061.222492<br/>1547  1190.434242</p><p>My decision to add 19,22, and 27 leads me to add 3 and 6 at the low<br/>end, and 68 and so forth at the high end. It tells me that if I&apos;m<br/>interested in 27 in the range around 31, I should also be interested<br/>in 68 in the range around 72, in 140 and 202 around 171, 612 around<br/>441, and 1547 near 1578. That&apos;s the sort of &quot;flatness&quot; Paul was<br/>talking about; it doesn&apos;t favor one range over another.</p><p>&gt; But no matter what you come up with I can&apos;t see how you can get<br/>past<br/>&gt; the fact that gens and cents are fundamentally incomensurable<br/>&gt; quantities, so somewhere there has to be a parameter that says how<br/>bad<br/>&gt; they are relative to each other.</p><p>&quot;n&quot; and cents are incommeasurable also, and n^(4/3) is only right for<br/>the 7 and 9 limits, and wrong for everything else, so I don&apos;t think<br/>this is the issue if we adopt this point of view.</p><p>Why not<br/>&gt; use k*gens + cents. e.g. if badness was simply gens + cents and you<br/>&gt; listed everything with badness not more than 30 then you don&apos;t need<br/>&gt; any additional cutoffs. You automatically eliminate anything with<br/>gens<br/>&gt; &gt; 30 or cents &gt; 30 (actually cents &gt; 29 because gens can&apos;t go below<br/>&gt; 1).</p><p>Gens^3 cents also automatically cuts things off, but I rather like<br/>the idea of keeping it &quot;flat&quot; in the above sense and doing the<br/>cutting off deliberately, it seems more objective.</p></div><h3>paulerlich &#x3C;paul@stretch-music.com&#x3E;</h3><span>12/7/2001 4:47:17 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;genewardsmith&quot; &lt;genewardsmith@j...&gt; wrote:<br/>&gt; --- In tuning-math@y..., &quot;paulerlich&quot; &lt;paul@s...&gt; wrote:<br/>&gt;<br/>&gt; &gt; &gt; If with all quantities positive we have g^2 c &lt; A and c &gt; B,<br/>then<br/>&gt; &gt; &gt; 1/c &lt; 1/B, and so g^2 &lt; A/B and g &lt; sqrt(A/B). However, it<br/>&gt; probably<br/>&gt; &gt; &gt; makes more sense to use g&gt;=1, so that if g^2 c &lt;= A then c &lt;= A.<br/>&gt;<br/>&gt; &gt; Are you saying that using g&gt;=1 is enough to make this a closed<br/>&gt; search?<br/>&gt;<br/>&gt; All it does is put an upper limit on how far out of tune the worst<br/>&gt; cases can be, so we really need to bound c below or g above to get<br/>a<br/>&gt; finite search.</p><p>So do you still stand by this statement:</p><p>&quot;If we bound one of them and gens^2 cents, we&apos;ve bound the other;<br/>that&apos;s what I&apos;d do.&quot;</p><p>(which you wrote after I said that a single cufoff point wouldn&apos;t be<br/>enough, that we would need a cutoff curve)?</p></div><h3>dkeenanuqnetau &#x3C;d.keenan@uq.net.au&#x3E;</h3><span>12/7/2001 5:48:14 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Thanks Gene, for taking the time to explain this in a way that a<br/>mere computer scientist can understand. :-)</p><p>--- In tuning-math@y..., &quot;genewardsmith&quot; &lt;genewardsmith@j...&gt; wrote:<br/>&gt; --- In tuning-math@y..., &quot;dkeenanuqnetau&quot; &lt;d.keenan@u...&gt; wrote:<br/>&gt;<br/>&gt; &gt; So ... What is n? What is a 7-limit et? How does one use n^(4/3)<br/>to<br/>&gt; &gt; get a list of them? How would one check to see whether the list<br/>&gt; &gt; favours high or low n.<br/>&gt;<br/>&gt; &quot;n&quot; is how many steps to the octave, or in other words what 2 is<br/>&gt; mapped to. By a &quot;7-limit et&quot; I mean something which maps 7-limit<br/>&gt; intervals to numbers of steps in a consistent way. Since we are<br/>&gt; looking for the best, we can safely restrict these to what we get by<br/>&gt; rounding n*log2(3), n*log2(5) and n*log2(7) to the nearest integer,<br/>&gt; and defining the n-et as the map one gets from this.</p><p>OK so far.</p><p>&gt; Let&apos;s call this map &quot;h&quot;;<br/>&gt; for the 12-et, h(2)=12, h(3)=19, h(5)=28<br/>and<br/>&gt; h(7)=34; this entails that h(5/3) = h(5)-h(3) = 9, h(7/3)=15 and<br/>&gt; h(7/5)=6.</p><p>Fine.</p><p>&gt; I can now measure the relative badness of &quot;h&quot; by taking the<br/>&gt; sum, or maximum, or rms, of the differences of |h(3)-n*log2(3)|,<br/>&gt; |h(5)-n*log2(5)|, |h(7)-n*log2(7)|, |h(5/3)-n*log2(5/3)|,<br/>&gt; |h(7/3)-n*log2(7/3)| and |h(7/5)-n*log2(7/5)|.</p><p>I&apos;d say this is just one component of badness. Its the error expressed<br/>as a proportion of the step size. The number of steps in the  octave n<br/>has an effect on badness independent of the relative error.</p><p>&gt; This measure of badness is flat in the sense that the density is the<br/>&gt; same everywhere, so that we would be selecting about the same number<br/>&gt; of ets in a range around 12 as we would in a range around 1200.</p><p>Yes. I believe this. See the two charts near the end of<br/><a href="http://uq.net.au/~zzdkeena/Music/EqualTemperedMusicalScales.htm">http://uq.net.au/~zzdkeena/Music/EqualTemperedMusicalScales.htm</a><br/>although it uses a weighting error that only includes the primes<br/>(only the &quot;rooted&quot; intervals) that I now find dubious.</p><p>&gt; I don&apos;t really want this sort of &quot;flatness&quot;,</p><p>Hardly anyone would. Not without some additional penalty for large n,<br/>even if it&apos;s just a crude sudden cutoff. But _why_ don&apos;t you want this<br/>sort of flatness? Did you reject it on &quot;objective&quot; grounds? Is there<br/>some other sort of flatness that you _do_ want? If so, what is it? How<br/>many sorts of flatness are there and how did you choose between them?</p><p>&gt; so I use the theory of<br/>&gt; Diophantine approximation to tell we that if I multiply this badness<br/>&gt; by the cube root of n, so that the density falls off at a rate of<br/>&gt; n^(-1/3), I will still get an infinite list of ets, but if I make it<br/>&gt; fall off faster I probably won&apos;t.</p><p>Here&apos;s where the real leap-of-faith occurs.</p><p>First of all, I take it that when you say you will (or wont) &quot;get an<br/>infinite list of ets&quot;, you mean &quot;when the list is limited to ETs whose<br/>badness does not exceed a given badness limit, greater than zero&quot;.</p><p>There are an infinite number of ways of defining badness to achieve a<br/>finite list with a cutoff only on badness itself. Most of these will<br/>produce a finite list that is of of absolutely no interest to 99.99%<br/>of the population (of people who are interested in the topic at all).</p><p>Why do you immediately leap to the theory of Diophantine approximation<br/>as giving the best way to achieve a finite list?</p><p>I think a good way to achieve it is simply to add an amount k*n to the<br/>error in cents (absolute, not relative to step size). I suggest<br/>initially trying a k of about 0.5 cents per step.</p><p>The only way to tell if this is better than something based on the<br/>theory of Diophantine equations is to suck it and see. Some of us have<br/>been on the tuning lists long enough to know what a lot of other<br/>people find useful or interesting, even though we don&apos;t necessarily<br/>find them so ourselves.</p><p>&gt; I can use either the maximum of<br/>the<br/>&gt; above numbers, or the sum, or the rms, and the same conclusion<br/>holds;<br/>&gt; in fact, I can look at the 9-limit instead of the 7-limit and the<br/>&gt; same conclusion holds. If I look at the maximum, and multiply by<br/>1200<br/>&gt; so we are looking at units of n^(4/3) cents, I get the following<br/>list<br/>&gt; of ets which come out as less than 1000, for n going from 1 to 2000:<br/>&gt;<br/>&gt; 1     884.3587134<br/>&gt; 2     839.4327178<br/>&gt; 4     647.3739047<br/>&gt; 5     876.4669184<br/>&gt; 9     920.6653451<br/>&gt; 10    955.6795096<br/>&gt; 12    910.1603254<br/>&gt; 15    994.0402775<br/>&gt; 31    580.7780905<br/>&gt; 41    892.0787789<br/>&gt; 72    892.7193923<br/>&gt; 99    716.7738001<br/>&gt; 171   384.2612749<br/>&gt; 270   615.9368489<br/>&gt; 342   968.2768986<br/>&gt; 441   685.5766666<br/>&gt; 1578  989.4999106<br/>&gt;<br/>&gt; This list just keeps on going, so I cut it off at 2000. I might look<br/>&gt; at it, and decide that it doesn&apos;t have some important ets on it,<br/>such<br/>&gt; as 19,22 and 27; I decide to put those on, not really caring about<br/>&gt; any other range, by raising the ante to 1200; I then get the<br/>&gt; following additions:<br/>&gt;<br/>&gt; 3     1154.683345<br/>&gt; 6     1068.957518<br/>&gt; 19    1087.886603<br/>&gt; 22    1078.033523<br/>&gt; 27    1108.589256<br/>&gt; 68    1090.046322<br/>&gt; 130   1182.191130<br/>&gt; 140   1091.565279<br/>&gt; 202   1143.628876<br/>&gt; 612   1061.222492<br/>&gt; 1547  1190.434242<br/>&gt;<br/>&gt; My decision to add 19,22, and 27 leads me to add 3 and 6 at the low<br/>&gt; end, and 68 and so forth at the high end. It tells me that if I&apos;m<br/>&gt; interested in 27 in the range around 31, I should also be interested<br/>&gt; in 68 in the range around 72, in 140 and 202 around 171, 612 around<br/>&gt; 441, and 1547 near 1578. That&apos;s the sort of &quot;flatness&quot; Paul was<br/>&gt; talking about; it doesn&apos;t favor one range over another.</p><p>But this is nonsense. It simply isn&apos;t true that 3, 6, 612 and 1547 are<br/>of approximately equal interest to 19, 22 and 27. Sure you&apos;ll always<br/>be able to find one person who&apos;ll say they are. But ask anyone who has<br/>actually used 19-tET or 22-tET when they plan to try 3-tET or<br/>1547-tET. It&apos;s just a joke. I suspect you&apos;ve been seduced by the<br/>beauty of the math and forgotten your actual purpose. This metric<br/>clearly favours both very small and very large n over middle ones.</p><p>&gt; &gt; But no matter what you come up with I can&apos;t see how you can get<br/>&gt; past<br/>&gt; &gt; the fact that gens and cents are fundamentally incomensurable<br/>&gt; &gt; quantities, so somewhere there has to be a parameter that says how<br/>&gt; bad<br/>&gt; &gt; they are relative to each other.<br/>&gt;<br/>&gt; &quot;n&quot; and cents are incommeasurable also,</p><p>Yes.</p><p>&gt; and n^(4/3) is only right for<br/>&gt; the 7 and 9 limits, and wrong for everything else, so I don&apos;t think<br/>&gt; this is the issue if we adopt this point of view.<br/>&gt;<br/>&gt; Why not<br/>&gt; &gt; use k*gens + cents. e.g. if badness was simply gens + cents and<br/>you<br/>&gt; &gt; listed everything with badness not more than 30 then you don&apos;t<br/>need<br/>&gt; &gt; any additional cutoffs. You automatically eliminate anything with<br/>&gt; gens<br/>&gt; &gt; &gt; 30 or cents &gt; 30 (actually cents &gt; 29 because gens can&apos;t go<br/>below<br/>&gt; &gt; 1).<br/>&gt;<br/>&gt; Gens^3 cents also automatically cuts things off, but I rather like<br/>&gt; the idea of keeping it &quot;flat&quot; in the above sense and doing the<br/>&gt; cutting off deliberately, it seems more objective.</p><p>_Seems_ more objective? You mean that subjectively, to you, it seems<br/>more objective?</p><p>Well I&apos;m afraid that it seems to me that this quest for an &quot;objective&quot;<br/>badness metric (with ad hoc cutoffs) is the silliest thing I&apos;ve heard<br/>in quite a while.</p><p>If you&apos;re combining two or more incomensurable quantities into a<br/>single badness metric, the choice of the constant of proportionality<br/>between them (and the choice of whether this constant should relate<br/>the plain quantities or their logarithms or whatever) should be<br/>decided so that as many people as possible agree that it actually<br/>gives something like what they perceive as badness, even if its only<br/>roughly so.</p><p>An isobad that passes near 3, 6, 19, 22, 612 and 1547, isn&apos;t one. The<br/>fact that its based on the theory of Diophantine equations is utterly<br/>irrelevant.</p></div><h3>paulerlich &#x3C;paul@stretch-music.com&#x3E;</h3><span>12/7/2001 6:22:56 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;dkeenanuqnetau&quot; &lt;d.keenan@u...&gt; wrote:</p><p>&gt; But this is nonsense. It simply isn&apos;t true that 3, 6, 612 and 1547<br/>are<br/>&gt; of approximately equal interest to 19, 22 and 27. Sure you&apos;ll<br/>always<br/>&gt; be able to find one person who&apos;ll say they are. But ask anyone who<br/>has<br/>&gt; actually used 19-tET or 22-tET when they plan to try 3-tET or<br/>&gt; 1547-tET. It&apos;s just a joke.</p><p>For the third or fourth time Dave, this isn&apos;t intended to appeal to<br/>any one person, but rather to the widest possible audience. Since<br/>this is a &quot;flat&quot; measure, it will rank the systems in the _vicinity_<br/>of *your* #1 system, the same way you would, whoever *you* happen to<br/>be. But it makes absolutely no preference for one end of the spectrum<br/>over another, or the middle. That&apos;s what makes it flat<br/>and &quot;objective&quot;. Look at Gene&apos;s list for 7-limit ETs again. Can it be<br/>denied that 31-tET is by far the best _in its vicinity_, and 171-tET<br/>is by far the best _in its vicinity_?</p></div><h3>paulerlich &#x3C;paul@stretch-music.com&#x3E;</h3><span>12/7/2001 7:27:45 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;genewardsmith&quot; &lt;genewardsmith@j...&gt; wrote:<br/>&gt; --- In tuning-math@y..., &quot;paulerlich&quot; &lt;paul@s...&gt; wrote:<br/>&gt;<br/>&gt; &gt; So do you still stand by this statement:<br/>&gt; &gt;<br/>&gt; &gt; &quot;If we bound one of them and gens^2 cents, we&apos;ve bound the other;<br/>&gt; &gt; that&apos;s what I&apos;d do.&quot;<br/>&gt; &gt;<br/>&gt; &gt; (which you wrote after I said that a single cufoff point wouldn&apos;t<br/>&gt; be<br/>&gt; &gt; enough, that we would need a cutoff curve)?<br/>&gt;<br/>&gt; Sure. I think bounding g makes the most sense, since we can<br/>calculate<br/>&gt; it more easily. I&apos;ve been thinking about how one might calculate<br/>&gt; cents without going through the map stage, but for gens we can get<br/>it<br/>&gt; immediately from the wedgie with no trouble.</p><p>I don&apos;t immediately know what &quot;the map stage&quot; means, but I&apos;ve been<br/>thinking that, in regarding to &quot;standardizing the wedge product&quot;, we<br/>might want to use something that has the Tenney lattice built in.</p><p>&gt; We could then toss<br/>&gt; anything with too high a gens figure before even calculating<br/>anything<br/>&gt; else, which should help.</p><p>So I&apos;m not getting where g&gt;=1 comes into all this.</p></div><h3>genewardsmith &#x3C;genewardsmith@juno.com&#x3E;</h3><span>12/7/2001 7:39:09 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;paulerlich&quot; &lt;paul@s...&gt; wrote:</p><p>&gt; So I&apos;m not getting where g&gt;=1 comes into all this.</p><p>What I wrote was confused, but you&apos;ve already replied, I see. Bounding<br/>g from below is easy, since it bounds itself. Bounding it from above<br/>could mean just setting a bound, or bounding g^2 c; I think just<br/>setting an upper bound to it makes a lot of sense.</p></div><h3>dkeenanuqnetau &#x3C;d.keenan@uq.net.au&#x3E;</h3><span>12/7/2001 7:48:56 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;paulerlich&quot; &lt;paul@s...&gt; wrote:<br/>&gt; --- In tuning-math@y..., &quot;dkeenanuqnetau&quot; &lt;d.keenan@u...&gt; wrote:<br/>&gt;<br/>&gt; &gt; But this is nonsense. It simply isn&apos;t true that 3, 6, 612 and 1547<br/>&gt; are<br/>&gt; &gt; of approximately equal interest to 19, 22 and 27. Sure you&apos;ll<br/>&gt; always<br/>&gt; &gt; be able to find one person who&apos;ll say they are. But ask anyone who<br/>&gt; has<br/>&gt; &gt; actually used 19-tET or 22-tET when they plan to try 3-tET or<br/>&gt; &gt; 1547-tET. It&apos;s just a joke.<br/>&gt;<br/>&gt; For the third or fourth time Dave, this isn&apos;t intended to appeal to<br/>&gt; any one person, but rather to the widest possible audience.</p><p>But that&apos;s exactly my intention too. I&apos;m trying to help you find a<br/>metric that will appeal, not to me, but to all those people whose<br/>divergent views I&apos;ve read on the tuning list over the years. I&apos;m<br/>simply claiming that your metric is seriously flawed in acheiving your<br/>intended goal. Practically _nobody_ thinks 3,6,612,1547 are equally as<br/>good or bad or interesting as 19 or 22. If you include fluff like that<br/>then there will be less room for ETs of interest to actual humans.</p><p>&gt; Since<br/>&gt; this is a &quot;flat&quot; measure, it will rank the systems in the _vicinity_<br/>&gt; of *your* #1 system, the same way you would, whoever *you* happen to<br/>&gt; be. But it makes absolutely no preference for one end of the<br/>spectrum<br/>&gt; over another, or the middle. That&apos;s what makes it flat<br/>&gt; and &quot;objective&quot;.</p><p>You seem to be arguing in circles.</p><p>&gt; Look at Gene&apos;s list for 7-limit ETs again. Can it<br/>be<br/>&gt; denied that 31-tET is by far the best _in its vicinity_, and 171-tET<br/>&gt; is by far the best _in its vicinity_?</p><p>Of course I don&apos;t deny that. I claim that it is irrelevant. _Any_ old<br/>half-baked way of monotonically combining steps and cents into a<br/>badness metric will be the same as any other, _locally_. You said the<br/>same yourself in regard to your HE curves. Maybe you need more sleep.<br/>:-)</p><p>Since when does merely local behaviour determine if something is<br/>_flat_ or not?</p><p>In any case, I don&apos;t think you understand Gene&apos;s particular kind of<br/>flatness, you certainly weren&apos;t able to explain it to me, as Gene has<br/>now done. This particular kind of &quot;flatness&quot; is just one of many.<br/>There&apos;s nothing objective about a decision to favour it, and then to<br/>ad hoc introduce additional cutoffs besides the one for badness.</p></div><h3>paulerlich &#x3C;paul@stretch-music.com&#x3E;</h3><span>12/7/2001 7:55:30 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;genewardsmith&quot; &lt;genewardsmith@j...&gt; wrote:<br/>&gt; --- In tuning-math@y..., &quot;paulerlich&quot; &lt;paul@s...&gt; wrote:<br/>&gt;<br/>&gt; &gt; So I&apos;m not getting where g&gt;=1 comes into all this.<br/>&gt;<br/>&gt; What I wrote was confused, but you&apos;ve already replied, I see.<br/>Bounding<br/>&gt; g from below is easy, since it bounds itself. Bounding it from<br/>above<br/>&gt; could mean just setting a bound, or bounding g^2 c; I think just<br/>&gt; setting an upper bound to it makes a lot of sense.</p><p>Yes -- g could play the role than N plays in your ET lists. One would<br/>order the results by g, give the g^2 c score for each (or not), and<br/>give about a page of nice musician-friendly information on each.</p><p>Gene, there are a lot of outstanding questions and comments . . . I<br/>wanted to know if there would have been a lot more &quot;slippery&quot; ones<br/>had you included simpler unison vectors in your source list . . . I<br/>want to use a Tenney-distance weighted &quot;gens&quot; measure . . . but for<br/>now, a master list would be great. Can someone produce such a list,<br/>with columns for &quot;cents&quot; and &quot;gens&quot; at least as currently defined?<br/>I&apos;d like to try to find omissions.</p></div><h3>genewardsmith &#x3C;genewardsmith@juno.com&#x3E;</h3><span>12/7/2001 8:00:12 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;dkeenanuqnetau&quot; &lt;d.keenan@u...&gt; wrote:<br/>&gt; I&apos;d say this is just one component of badness. Its the error<br/>expressed<br/>&gt; as a proportion of the step size. The number of steps in the<br/>octave n<br/>&gt; has an effect on badness independent of the relative error.</p><p>Then you should be happier with an extra cube root of n adjustment.</p><p>&gt; Hardly anyone would. Not without some additional penalty for large<br/>n,<br/>&gt; even if it&apos;s just a crude sudden cutoff. But _why_ don&apos;t you want<br/>this<br/>&gt; sort of flatness?</p><p>Because my interest isn&apos;t independent of size--you need more at<br/>higher levels to make me care.</p><p>Did you reject it on &quot;objective&quot; grounds? Is there<br/>&gt; some other sort of flatness that you _do_ want? If so, what is it?<br/>How<br/>&gt; many sorts of flatness are there and how did you choose between<br/>them?</p><p>You could use the Riemann Zeta function and the omega estimates based<br/>on the assumption of the Riemann hypothesis and do it that way, if<br/>you liked. Or there are no doubt other ways; this one seems the<br/>simplest and it gets the job done, and the alternatives would have a<br/>certain family resemblence.</p><p>&gt; Why do you immediately leap to the theory of Diophantine<br/>approximation<br/>&gt; as giving the best way to achieve a finite list?</p><p>It gives me a measure which is connected to the nature of the<br/>problem, which is a Diophantine approximation problem, which seems to<br/>make a lot of sense both in practice and theory to me, if not to you.</p><p>&gt; I think a good way to achieve it is simply to add an amount k*n to<br/>the<br/>&gt; error in cents (absolute, not relative to step size). I suggest<br/>&gt; initially trying a k of about 0.5 cents per step.</p><p>Should I muck around in the dark until I make this measure behave in<br/>a way something like the measure I already have behaves, which would<br/>be both pointless and inelegant, or is there something about it to<br/>recommend it?</p><p>&gt; The only way to tell if this is better than something based on the<br/>&gt; theory of Diophantine equations is to suck it and see.</p><p>Better how? The measure I already have does exactly what I&apos;d want a<br/>measure to do.</p><p>Some of us have<br/>&gt; been on the tuning lists long enough to know what a lot of other<br/>&gt; people find useful or interesting, even though we don&apos;t necessarily<br/>&gt; find them so ourselves.</p><p>One of the advantages of the measure I&apos;m using is that it accomodates<br/>this well.</p><p>&gt; But this is nonsense. It simply isn&apos;t true that 3, 6, 612 and 1547<br/>are<br/>&gt; of approximately equal interest to 19, 22 and 27.</p><p>I&apos;m not trying to measure your interest, I&apos;m only saying if you want<br/>to look at a certain range, look at these.</p><p>Sure you&apos;ll always<br/>&gt; be able to find one person who&apos;ll say they are. But ask anyone who<br/>has<br/>&gt; actually used 19-tET or 22-tET when they plan to try 3-tET or<br/>&gt; 1547-tET. It&apos;s just a joke.</p><p>The 4-et is actually interesting in connection with the 7-limit, as<br/>the 3-et is with the 5-limit, and the large ets have uses other than<br/>tuning up a set of marimbas as well.</p><p> I suspect you&apos;ve been seduced by the<br/>&gt; beauty of the math and forgotten your actual purpose. This metric<br/>&gt; clearly favours both very small and very large n over middle ones.</p><p>In other words, the range *you* happen to care about is the only<br/>interesting range; it&apos;s that which I was regarding as not objective.</p><p>&gt; An isobad that passes near 3, 6, 19, 22, 612 and 1547, isn&apos;t one.</p><p>An isobad which passes near 3, 6, 19, 22, 612 and 1547 makes a lot of<br/>sense to me, so I think I would probably *not* like your alternative<br/>as well.</p></div><h3>paulerlich &#x3C;paul@stretch-music.com&#x3E;</h3><span>12/7/2001 8:03:48 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;dkeenanuqnetau&quot; &lt;d.keenan@u...&gt; wrote:<br/>&gt; --- In tuning-math@y..., &quot;paulerlich&quot; &lt;paul@s...&gt; wrote:<br/>&gt; &gt; --- In tuning-math@y..., &quot;dkeenanuqnetau&quot; &lt;d.keenan@u...&gt; wrote:<br/>&gt; &gt;<br/>&gt; &gt; &gt; But this is nonsense. It simply isn&apos;t true that 3, 6, 612 and<br/>1547<br/>&gt; &gt; are<br/>&gt; &gt; &gt; of approximately equal interest to 19, 22 and 27. Sure you&apos;ll<br/>&gt; &gt; always<br/>&gt; &gt; &gt; be able to find one person who&apos;ll say they are. But ask anyone<br/>who<br/>&gt; &gt; has<br/>&gt; &gt; &gt; actually used 19-tET or 22-tET when they plan to try 3-tET or<br/>&gt; &gt; &gt; 1547-tET. It&apos;s just a joke.<br/>&gt; &gt;<br/>&gt; &gt; For the third or fourth time Dave, this isn&apos;t intended to appeal<br/>to<br/>&gt; &gt; any one person, but rather to the widest possible audience.<br/>&gt;<br/>&gt; But that&apos;s exactly my intention too. I&apos;m trying to help you find a<br/>&gt; metric that will appeal, not to me, but to all those people whose<br/>&gt; divergent views I&apos;ve read on the tuning list over the years. I&apos;m<br/>&gt; simply claiming that your metric is seriously flawed in acheiving<br/>your<br/>&gt; intended goal. Practically _nobody_ thinks 3,6,612,1547 are equally<br/>as<br/>&gt; good or bad or interesting as 19 or 22. If you include fluff like<br/>that<br/>&gt; then there will be less room for ETs of interest to actual humans.</p><p>Dave, if you don&apos;t have a cutoff, you&apos;d have an infinite number of<br/>ETs better than 1547. Of course there has to be a cutoff.</p><p>&gt;<br/>&gt; &gt; Look at Gene&apos;s list for 7-limit ETs again. Can it<br/>&gt; be<br/>&gt; &gt; denied that 31-tET is by far the best _in its vicinity_, and 171-<br/>tET<br/>&gt; &gt; is by far the best _in its vicinity_?<br/>&gt;<br/>&gt; Of course I don&apos;t deny that. I claim that it is irrelevant. _Any_<br/>old<br/>&gt; half-baked way of monotonically combining steps and cents into a<br/>&gt; badness metric will be the same as any other, _locally_. You said<br/>the<br/>&gt; same yourself in regard to your HE curves. Maybe you need more<br/>sleep.<br/>&gt; :-)</p><p>I mean that only Gene&apos;s measure tells you exactly _how much_ better a<br/>system is than the systems in their vicinity, _in units of_ the<br/>average differences between different systems in their vicinity.</p><p>&gt; Since when does merely local behaviour determine if something is<br/>&gt; _flat_ or not?</p><p>It doesn&apos;t.</p><p>&gt; In any case, I don&apos;t think you understand Gene&apos;s particular kind of<br/>&gt; flatness, you certainly weren&apos;t able to explain it to me, as Gene<br/>has<br/>&gt; now done. This particular kind of &quot;flatness&quot; is just one of many.</p><p>I&apos;d like to see a list of ETs, as far as you&apos;d like to take it, above<br/>some cutoff different from Gene&apos;s, that shows this kind of behavior<br/>(not just the flatness of the measure itself, but also the flatness<br/>of the size of the wiggles).</p></div><h3>graham@microtonal.co.uk</h3><span>12/7/2001 9:01:00 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Gene wrote:</p><p>&gt; Sure. I think bounding g makes the most sense, since we can calculate<br/>&gt; it more easily. I&apos;ve been thinking about how one might calculate<br/>&gt; cents without going through the map stage, but for gens we can get it<br/>&gt; immediately from the wedgie with no trouble. We could then toss<br/>&gt; anything with too high a gens figure before even calculating anything<br/>&gt; else, which should help.</p><p>My program throws out bad temperaments before doing the optimization, if<br/>that&apos;s what you&apos;re suggesting.  It&apos;s on of the changes I made this, er,<br/>yesterday morning.  It does make a difference, but not much now my<br/>optimization&apos;s faster.  Big chunks of time are being spent generating the<br/>ETs and formatting the results currently.</p><p>           Graham</p></div><h3>dkeenanuqnetau &#x3C;d.keenan@uq.net.au&#x3E;</h3><span>12/7/2001 9:54:48 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;genewardsmith&quot; &lt;genewardsmith@j...&gt; wrote:<br/>&gt; --- In tuning-math@y..., &quot;dkeenanuqnetau&quot; &lt;d.keenan@u...&gt; wrote:<br/>&gt; &gt; I&apos;d say this is just one component of badness. Its the error<br/>&gt; expressed<br/>&gt; &gt; as a proportion of the step size. The number of steps in the<br/>&gt; octave n<br/>&gt; &gt; has an effect on badness independent of the relative error.<br/>&gt;<br/>&gt; Then you should be happier with an extra cube root of n adjustment.</p><p>Yes I am. But still way from as happy as I think most people would be<br/>with something not based on k*log(gens) + log(cents) but instead on<br/>k*gens + cents (or maybe something else).</p><p>&gt; &gt; But _why_ don&apos;t you want this<br/>&gt; &gt; sort of flatness?<br/>&gt;<br/>&gt; Because my interest isn&apos;t independent of size--you need more at<br/>&gt; higher levels to make me care.</p><p>Indeed.</p><p>&gt; Did you reject it on &quot;objective&quot; grounds? Is there<br/>&gt; &gt; some other sort of flatness that you _do_ want? If so, what is it?<br/>&gt; How<br/>&gt; &gt; many sorts of flatness are there and how did you choose between<br/>&gt; them?<br/>&gt;<br/>&gt; You could use the Riemann Zeta function and the omega estimates<br/>based<br/>&gt; on the assumption of the Riemann hypothesis and do it that way, if<br/>&gt; you liked. Or there are no doubt other ways; this one seems the<br/>&gt; simplest and it gets the job done, and the alternatives would have a<br/>&gt; certain family resemblence.</p><p>But there&apos;s nothing &quot;objective&quot; about these decisions. You&apos;re just<br/>finding stuff so it matches what you think everyone likes. Right?</p><p>&gt; &gt; Why do you immediately leap to the theory of Diophantine<br/>&gt; approximation<br/>&gt; &gt; as giving the best way to achieve a finite list?<br/>&gt;<br/>&gt; It gives me a measure which is connected to the nature of the<br/>&gt; problem, which is a Diophantine approximation problem, which seems<br/>to<br/>&gt; make a lot of sense both in practice and theory to me, if not to<br/>you.</p><p>There are probably many such things &quot;connected to the nature of the<br/>problem&quot; which give entirely different results.</p><p>&gt; &gt; I think a good way to achieve it is simply to add an amount k*n to<br/>&gt; the<br/>&gt; &gt; error in cents (absolute, not relative to step size). I suggest<br/>&gt; &gt; initially trying a k of about 0.5 cents per step.<br/>&gt;<br/>&gt; Should I muck around in the dark until I make this measure behave in<br/>&gt; a way something like the measure I already have behaves, which would<br/>&gt; be both pointless and inelegant, or is there something about it to<br/>&gt; recommend it?</p><p>Yes. The fact that I&apos;ve been reading the tuning list and thinking<br/>about and discussing these things with others for many years. So it&apos;s<br/>hardly groping in the dark. I&apos;m not saying this particular one I<br/>pulled out of the air is the one most representative of all views, but<br/>I do know that we can do a lot better than your current proposal.</p><p>&gt; &gt; The only way to tell if this is better than something based on the<br/>&gt; &gt; theory of Diophantine equations is to suck it and see.<br/>&gt;<br/>&gt; Better how? The measure I already have does exactly what I&apos;d want a<br/>&gt; measure to do.</p><p>Answered below.</p><p>&gt; Some of us have<br/>&gt; &gt; been on the tuning lists long enough to know what a lot of other<br/>&gt; &gt; people find useful or interesting, even though we don&apos;t<br/>necessarily<br/>&gt; &gt; find them so ourselves.<br/>&gt;<br/>&gt; One of the advantages of the measure I&apos;m using is that it<br/>accomodates<br/>&gt; this well.</p><p>How do you know that?</p><p>&gt; &gt; But this is nonsense. It simply isn&apos;t true that 3, 6, 612 and 1547<br/>&gt; are<br/>&gt; &gt; of approximately equal interest to 19, 22 and 27.<br/>&gt;<br/>&gt; I&apos;m not trying to measure your interest,</p><p>I keep saying that I&apos;m trying to consider as wide a set of interests<br/>as possible. You and Paul keep accusing me of only trying to serve my<br/>own interests. I accept that you&apos;re trying to consider as wide a set<br/>of interests as possible, I just claim that you&apos;re failing.</p><p>&gt; I&apos;m only saying if you want<br/>&gt; to look at a certain range, look at these.</p><p>Yes, but some _ranges_ are more interesting than others and so if you<br/>include an equal number in every range then you won&apos;t be including<br/>enough in the most interesting ranges. It isn&apos;t just _my_ prejudice<br/>that there are more ETs of interest in the vicinity of 26-tET than<br/>there are in the vicinity of 3-tET or 1550-tET. It&apos;s practically<br/>everyone&apos;s.</p><p>&gt; Sure you&apos;ll always<br/>&gt; &gt; be able to find one person who&apos;ll say they are. But ask anyone who<br/>&gt; has<br/>&gt; &gt; actually used 19-tET or 22-tET when they plan to try 3-tET or<br/>&gt; &gt; 1547-tET. It&apos;s just a joke.<br/>&gt;<br/>&gt; The 4-et is actually interesting in connection with the 7-limit, as<br/>&gt; the 3-et is with the 5-limit, and the large ets have uses other than<br/>&gt; tuning up a set of marimbas as well.</p><p>Those are good points, which maybe says that my metric is too harsh on<br/>the extremes, but I still say yours is way too soft. There&apos;s got to be<br/>something pretty damn exceptional about an ET greater than 100 for it<br/>to be of interest. But note that our badness metric is only based on<br/>steps and cents (or gens and cents for temperaments) so we can&apos;t claim<br/>that our metric should include some exceptional high ET if it&apos;s<br/>exceptional property has nothing to do with the magnitude of the<br/>number of steps or the cents error.</p><p>&gt;  I suspect you&apos;ve been seduced by the<br/>&gt; &gt; beauty of the math and forgotten your actual purpose. This metric<br/>&gt; &gt; clearly favours both very small and very large n over middle ones.<br/>&gt;<br/>&gt; In other words, the range *you* happen to care about is the only<br/>&gt; interesting range; it&apos;s that which I was regarding as not objective.</p><p>There you go again. Accusing me of only trying to serve my own<br/>interests.</p><p>&gt; &gt; An isobad that passes near 3, 6, 19, 22, 612 and 1547, isn&apos;t one.<br/>&gt;<br/>&gt; An isobad which passes near 3, 6, 19, 22, 612 and 1547 makes a lot<br/>of<br/>&gt; sense to me, so I think I would probably *not* like your alternative<br/>&gt; as well.</p><p>Whether you or I would like it, isn&apos;t the point. The only way this<br/>could be settled is by some kind of experiment or survey, say on the<br/>tuning list.</p><p>We could put together two lists of ETs of roughly equally &quot;badness&quot;.<br/>One using your metric, one using mine. They should contain the same<br/>number of ETs (you&apos;ve already given a suitable list of 11). They<br/>should have as many ETs as possible in common. We would tell people<br/>the 7-limit rms error of each and the number of steps per octave in<br/>each, but nothing more. Then we&apos;d ask them to choose which list was a<br/>better example of a list of ETs of approximately equal 7-limit<br/>goodness, badness, usefulness, interestingness or whatever you want to<br/>call it, based only on considerations of the number of steps and the<br/>error.</p><p>We could even ask them to rate each list on a scale of 1 to 10<br/>according to how well they think each list manages to capture equal<br/>7-limit interestingness or whatever, based only on considerations of<br/>the number of steps and the error.</p><p>Here they are:</p><p>ET List 1</p><p>Steps   7-limit<br/>per     RMS<br/>octave  error (cents)<br/>---------------------<br/>3       176.9<br/>6        66.9<br/>19       12.7<br/>22        8.6<br/>27        7.9<br/>68        2.4<br/>130       1.1<br/>140       1.0<br/>202       0.61<br/>612       0.15<br/>1547      0.040</p><p>ET list 2</p><p>Steps   7-limit<br/>per     RMS<br/>octave  error (cents)<br/>---------------------<br/>15       18.5<br/>19       12.7<br/>22        8.6<br/>24       15.1<br/>26       10.4<br/>27        7.9<br/>31        4.0<br/>35        9.9<br/>36        8.6<br/>37        7.6<br/>41        4.2</p><p>Do we really need to do the experiment? Paul?</p></div><h3>dkeenanuqnetau &#x3C;d.keenan@uq.net.au&#x3E;</h3><span>12/7/2001 10:16:46 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;paulerlich&quot; &lt;paul@s...&gt; wrote:<br/>&gt; Dave, if you don&apos;t have a cutoff, you&apos;d have an infinite number of<br/>&gt; ETs better than 1547. Of course there has to be a cutoff.</p><p>Yes. This just shows that this isn&apos;t a very good badness metric.<br/>A decent badness metric would not need a cutoff in anything but<br/>badness in order to arrive at a finite list.</p><p>&gt; I mean that only Gene&apos;s measure tells you exactly _how much_ better<br/>a<br/>&gt; system is than the systems in their vicinity,</p><p>How do you know it does that? &quot;Exactly&quot;?</p><p>&gt; _in units of_ the<br/>&gt; average differences between different systems in their vicinity.</p><p>I don&apos;t understand that bit. Can you explain.</p><p>&gt; I&apos;d like to see a list of ETs, as far as you&apos;d like to take it,<br/>above<br/>&gt; some cutoff different from Gene&apos;s, that shows this kind of behavior<br/>&gt; (not just the flatness of the measure itself, but also the flatness<br/>&gt; of the size of the wiggles).</p><p>But why ever do you think the size of the wiggles should be flat? I<br/>think it is quite expected that the size of the wiggles in badness<br/>around 1-tET to 9-tET are _much_ bigger than the wiggles around 60-tET<br/>to 69-tET. Apparently you agree that the wiggles around 100000-tET are<br/>completely irrelevant, since you&apos;re happy to have a cutoff in<br/>steps, somewhere below that.</p></div><h3>genewardsmith &#x3C;genewardsmith@juno.com&#x3E;</h3><span>12/7/2001 10:42:50 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;dkeenanuqnetau&quot; &lt;d.keenan@u...&gt; wrote:</p><p>&gt; ET list 2<br/>&gt;<br/>&gt; Steps   7-limit<br/>&gt; per     RMS<br/>&gt; octave  error (cents)<br/>&gt; ---------------------<br/>&gt; 15       18.5<br/>&gt; 19       12.7<br/>&gt; 22        8.6<br/>&gt; 24       15.1<br/>&gt; 26       10.4<br/>&gt; 27        7.9<br/>&gt; 31        4.0<br/>&gt; 35        9.9<br/>&gt; 36        8.6<br/>&gt; 37        7.6<br/>&gt; 41        4.2</p><p>If you&apos;re going to do this, let&apos;s at least do it right and use the<br/>right list:</p><p>1   884.3587134<br/>2   839.4327178<br/>4   647.3739047<br/>5   876.4669184<br/>9   920.6653451<br/>10   955.6795096<br/>12   910.1603254<br/>15   994.0402775<br/>31   580.7780905<br/>41   892.0787789<br/>72   892.7193923<br/>99   716.7738001<br/>171   384.2612749<br/>270   615.9368489<br/>342   968.2768986<br/>441   685.5766666<br/>1578   989.4999106</p><p>The first point to note is that the two lists are clearly not<br/>intended to do the same thing. The second is that while you object to<br/>this characterization, your list seems to want to do our thinking for<br/>us more than mine; you&apos;ve decided the important place to look is<br/>around 27. The third thing to notice is that if you want to look at a<br/>limited range, you always can. Suppose I look from 10 to 50 and see<br/>what the top 11 are, using my measure:</p><p>10  .796<br/>12  .758<br/>15  .828<br/>16 1.113<br/>19  .906<br/>22  .898<br/>26 1.122<br/>27  .924<br/>31  .484<br/>41  .743<br/>46 1.181</p><p>I&apos;m afraid I like this list better than yours, but your milage may<br/>vary.</p></div><h3>dkeenanuqnetau &#x3C;d.keenan@uq.net.au&#x3E;</h3><span>12/7/2001 11:14:09 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;genewardsmith&quot; &lt;genewardsmith@j...&gt; wrote:<br/>&gt; --- In tuning-math@y..., &quot;dkeenanuqnetau&quot; &lt;d.keenan@u...&gt; wrote:<br/>&gt;<br/>&gt; &gt; ET list 2<br/>&gt; &gt;<br/>&gt; &gt; Steps   7-limit<br/>&gt; &gt; per     RMS<br/>&gt; &gt; octave  error (cents)<br/>&gt; &gt; ---------------------<br/>&gt; &gt; 15       18.5<br/>&gt; &gt; 19       12.7<br/>&gt; &gt; 22        8.6<br/>&gt; &gt; 24       15.1<br/>&gt; &gt; 26       10.4<br/>&gt; &gt; 27        7.9<br/>&gt; &gt; 31        4.0<br/>&gt; &gt; 35        9.9<br/>&gt; &gt; 36        8.6<br/>&gt; &gt; 37        7.6<br/>&gt; &gt; 41        4.2<br/>&gt;<br/>&gt; If you&apos;re going to do this, let&apos;s at least do it right and use the<br/>&gt; right list:<br/>&gt;<br/>&gt; 1   884.3587134<br/>&gt; 2   839.4327178<br/>&gt; 4   647.3739047<br/>&gt; 5   876.4669184<br/>&gt; 9   920.6653451<br/>&gt; 10   955.6795096<br/>&gt; 12   910.1603254<br/>&gt; 15   994.0402775<br/>&gt; 31   580.7780905<br/>&gt; 41   892.0787789<br/>&gt; 72   892.7193923<br/>&gt; 99   716.7738001<br/>&gt; 171   384.2612749<br/>&gt; 270   615.9368489<br/>&gt; 342   968.2768986<br/>&gt; 441   685.5766666<br/>&gt; 1578   989.4999106</p><p>But this doesn&apos;t look like an approximate isobad. It looks like a list<br/>of ETs less than a certain badness. i.e. it&apos;s a top 17. Right?</p><p>We can do it that way if you like. So I&apos;ll have to give my top 17. I<br/>wasn&apos;t proposing that we give the badness measure (since it was meant<br/>to be an isobad). But I guess we could if it&apos;s a top 17. However I<br/>don&apos;t want people distracted by 9 significant digits of badness.<br/>Couldn&apos;t we normalise to a 10 point scale and only give whole numbers.<br/>And you need to supply the RMS error.</p><p>&gt; The first point to note is that the two lists are clearly not<br/>&gt; intended to do the same thing.</p><p>Mine is intended to pack the maximum number of ETs likely to be of<br/>interest to musicians, composers, music theorists etc. who are<br/>interested in 7-limit music, into a list of a given size. Maybe you<br/>need to explain what yours is intended to do.</p><p>&gt; The second is that while you object to<br/>&gt; this characterization, your list seems to want to do our thinking<br/>for<br/>&gt; us more than mine; you&apos;ve decided the important place to look is<br/>&gt; around 27.</p><p>Not at all. It just comes out that way. I simply decided that an extra<br/>note per octave was worth about the same badness as an increase of 0.5<br/>cent in the RMS error. This comes thru experience and tuning list<br/>discussions.</p><p>&gt; The third thing to notice is that if you want to look at<br/>a<br/>&gt; limited range, you always can. Suppose I look from 10 to 50 and see<br/>&gt; what the top 11 are, using my measure:<br/>&gt;<br/>&gt; 10  .796<br/>&gt; 12  .758<br/>&gt; 15  .828<br/>&gt; 16 1.113<br/>&gt; 19  .906<br/>&gt; 22  .898<br/>&gt; 26 1.122<br/>&gt; 27  .924<br/>&gt; 31  .484<br/>&gt; 41  .743<br/>&gt; 46 1.181</p><p>Sure. I can do that too.</p><p>&gt; I&apos;m afraid I like this list better than yours, but your milage may<br/>&gt; vary.</p><p>I might like it better than mine too.  Mine&apos;s still got problems. But<br/>you had to arbitrarily limit it to 10&lt;n&lt;50 to get this list. This is<br/>clearly doing our thinking for us.</p><p>I thought we we&apos;re talking about a single published list, not a piece<br/>of software that lets you enter your favourite limits.</p></div><h3>genewardsmith &#x3C;genewardsmith@juno.com&#x3E;</h3><span>12/7/2001 11:23:40 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;dkeenanuqnetau&quot; &lt;d.keenan@u...&gt; wrote:</p><p>&gt; But this doesn&apos;t look like an approximate isobad. It looks like a<br/>list<br/>&gt; of ETs less than a certain badness. i.e. it&apos;s a top 17. Right?</p><p>Right, but your list looked like a top 11 in a certain range also.</p><p>&gt;<br/>&gt; We can do it that way if you like. So I&apos;ll have to give my top 17.<br/>I<br/>&gt; wasn&apos;t proposing that we give the badness measure (since it was<br/>meant<br/>&gt; to be an isobad).</p><p>The things on your list didn&apos;t make sense to me as an isobad, and I<br/>didn&apos;t know that was what it was supposed to be. Trying a top n and<br/>comparing makes more sense to me, but I need to pick a range.</p><p>&gt; Mine is intended to pack the maximum number of ETs likely to be of<br/>&gt; interest to musicians, composers, music theorists etc. who are<br/>&gt; interested in 7-limit music, into a list of a given size.</p><p>It needs work.</p><p>Maybe you<br/>&gt; need to explain what yours is intended to do.</p><p>Mine is intended to show what the relatively best 7-limit ets are, in<br/>a measurement which has the logarithmic flatness I describe in<br/>another posting.</p><p>&gt; I might like it better than mine too.  Mine&apos;s still got problems.<br/>But<br/>&gt; you had to arbitrarily limit it to 10&lt;n&lt;50 to get this list. This<br/>is<br/>&gt; clearly doing our thinking for us.</p><p>And I can reduce that problem to essentially nil, by putting in a<br/>high cut-off and leaving it at that. You are stuck with it as an<br/>intrinsic feature.</p></div><h3>dkeenanuqnetau &#x3C;d.keenan@uq.net.au&#x3E;</h3><span>12/8/2001 12:21:24 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;genewardsmith&quot; &lt;genewardsmith@j...&gt; wrote:<br/>&gt; --- In tuning-math@y..., &quot;dkeenanuqnetau&quot; &lt;d.keenan@u...&gt; wrote:<br/>&gt;<br/>&gt; &gt; But this doesn&apos;t look like an approximate isobad. It looks like a<br/>&gt; list<br/>&gt; &gt; of ETs less than a certain badness. i.e. it&apos;s a top 17. Right?<br/>&gt;<br/>&gt; Right, but your list looked like a top 11 in a certain range also.</p><p>It happens to also be the top 11 by the 0.5*steps + cents metric, but<br/>not limited to any range.</p><p>&gt; &gt; We can do it that way if you like. So I&apos;ll have to give my top 17.<br/>&gt; I<br/>&gt; &gt; wasn&apos;t proposing that we give the badness measure (since it was<br/>&gt; meant<br/>&gt; &gt; to be an isobad).<br/>&gt;<br/>&gt; The things on your list didn&apos;t make sense to me as an isobad,</p><p>Obviously they wouldn&apos;t, given what your isobad looked like.</p><p>&gt; and I<br/>&gt; didn&apos;t know that was what it was supposed to be.</p><p>I thought I made that pretty clear.</p><p>&gt; Trying a top n and<br/>&gt; comparing makes more sense to me,</p><p>Fine.</p><p>&gt; but I need to pick a range.</p><p>Objectively of course. Ha ha. If you have to pick a range then your<br/>so-called badness metric obviously isn&apos;t really a badness metric at<br/>all!</p><p>&gt; &gt; Mine is intended to pack the maximum number of ETs likely to be of<br/>&gt; &gt; interest to musicians, composers, music theorists etc. who are<br/>&gt; &gt; interested in 7-limit music, into a list of a given size.<br/>&gt;<br/>&gt; It needs work.</p><p>I think I said that.</p><p>&gt; Mine is intended to show what the relatively best 7-limit ets are,<br/>in<br/>&gt; a measurement which has the logarithmic flatness I describe in<br/>&gt; another posting.</p><p>Even if you and Paul are the only folks on the planet who find that<br/>interesting? In that case I think its very misleading to call it a<br/>badness metric when it only gives relative badness _locally_.</p><p>&gt; &gt; I might like it better than mine too.  Mine&apos;s still got problems.<br/>&gt; But<br/>&gt; &gt; you had to arbitrarily limit it to 10&lt;n&lt;50 to get this list. This<br/>&gt; is<br/>&gt; &gt; clearly doing our thinking for us.<br/>&gt;<br/>&gt; And I can reduce that problem to essentially nil, by putting in a<br/>&gt; high cut-off and leaving it at that.</p><p>How high? How will this fix the problem that folks will assume you&apos;re<br/>saying that 3-tET and 1547-tET are about as useful as 22-tET for<br/>7-limit.</p><p>&gt; You are stuck with it as an<br/>&gt; intrinsic feature.</p><p>And a damn fine feature it is too. :-) Seriously, mine was proposed<br/>without any great amount of research or deliberation to show that it<br/>is easy to find alternatives that do _much_ better than yours<br/>_globally_ and about the same _locally_.</p></div><h3>genewardsmith &#x3C;genewardsmith@juno.com&#x3E;</h3><span>12/8/2001 1:20:22 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;dkeenanuqnetau&quot; &lt;d.keenan@u...&gt; wrote:<br/>&gt; --- In tuning-math@y..., &quot;genewardsmith&quot; &lt;genewardsmith@j...&gt; wrote:<br/>&gt; &gt; --- In tuning-math@y..., &quot;dkeenanuqnetau&quot; &lt;d.keenan@u...&gt; wrote:<br/>&gt; &gt;<br/>&gt; &gt; &gt; But this doesn&apos;t look like an approximate isobad. It looks like<br/>a<br/>&gt; &gt; list<br/>&gt; &gt; &gt; of ETs less than a certain badness. i.e. it&apos;s a top 17. Right?<br/>&gt; &gt;<br/>&gt; &gt; Right, but your list looked like a top 11 in a certain range also.<br/>&gt;<br/>&gt; It happens to also be the top 11 by the 0.5*steps + cents metric,<br/>but<br/>&gt; not limited to any range.</p><p>You could describe my top 11 in the range from 10 to 50 as the top 11<br/>using a measure which multipies by a function equal to 1 from 10 to<br/>50, and 10^n otherwise, which we multiply by our badness measure and<br/>so end up with a top 11 &quot;not limited by range&quot;. The difference is<br/>that you have blurry outlines to your chosen region, which seems to<br/>me to be a bad thing, not a good one. It allows you to imagine you<br/>have not chosen a range, which hardly clarifies matters, since in<br/>effect you have.</p><p>&gt; Objectively of course. Ha ha. If you have to pick a range then your<br/>&gt; so-called badness metric obviously isn&apos;t really a badness metric at<br/>&gt; all!</p><p>See above; I can screw it up in an _ad hoc_ way and make it a screwed-<br/>up, _ad hoc_ measure also, but why should I want to?</p><p>&gt; Even if you and Paul are the only folks on the planet who find that<br/>&gt; interesting? In that case I think its very misleading to call it a<br/>&gt; badness metric when it only gives relative badness _locally_.</p><p>Global relative badness means what, exactly? This makes no sense to<br/>me.</p><p>&gt; How high? How will this fix the problem that folks will assume<br/>you&apos;re<br/>&gt; saying that 3-tET and 1547-tET are about as useful as 22-tET for<br/>&gt; 7-limit.</p><p>I think you would be one of the very few who looked at it that way.<br/>After all, this is hardly the first time such a thing has been done.</p></div><h3>dkeenanuqnetau &#x3C;d.keenan@uq.net.au&#x3E;</h3><span>12/8/2001 2:34:50 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;genewardsmith&quot; &lt;genewardsmith@j...&gt; wrote:<br/>&gt; --- In tuning-math@y..., &quot;dkeenanuqnetau&quot; &lt;d.keenan@u...&gt; wrote:<br/>&gt; &gt; Even if you and Paul are the only folks on the planet who find<br/>that<br/>&gt; &gt; interesting? In that case I think its very misleading to call it a<br/>&gt; &gt; badness metric when it only gives relative badness _locally_.<br/>&gt;<br/>&gt; Global relative badness means what, exactly? This makes no sense to<br/>&gt; me.</p><p>It means if two ETs have around the same badness number then are are<br/>about as bad as each other, no matter how far apart they are on the<br/>spectrum.</p><p>&gt; &gt; How high? How will this fix the problem that folks will assume<br/>&gt; you&apos;re<br/>&gt; &gt; saying that 3-tET and 1547-tET are about as useful as 22-tET for<br/>&gt; &gt; 7-limit.<br/>&gt;<br/>&gt; I think you would be one of the very few who looked at it that way.<br/>&gt; After all, this is hardly the first time such a thing has been done.</p><p>Ok. So I&apos;m the only person who will assume that two ETs with about the<br/>same badness number are roughly as bad as each other. In that case, I<br/>shant bother you any more. We are apparently speakimg different<br/>languages.</p></div><h3>genewardsmith &#x3C;genewardsmith@juno.com&#x3E;</h3><span>12/8/2001 11:44:42 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;dkeenanuqnetau&quot; &lt;d.keenan@u...&gt; wrote:</p><p>&gt; &gt; Global relative badness means what, exactly? This makes no sense<br/>to<br/>&gt; &gt; me.<br/>&gt;<br/>&gt; It means if two ETs have around the same badness number then are<br/>are<br/>&gt; about as bad as each other, no matter how far apart they are on the<br/>&gt; spectrum.</p><p>This strikes me as subjective to the point of being meaningless.</p></div><h3>graham@microtonal.co.uk</h3><span>12/9/2001 8:02:00 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Gene wrote:<br/>&gt; I don&apos;t know what good Maple code will do, but here it is:<br/>&gt;<br/>&gt; findcoms := proc(l)<br/>&gt; local p,q,r,p1,q1,r1,s,u,v,w;</p><p>More descriptive variable names might help.  Is l the wedge invariant?</p><p>&gt; s := igcd(l[1], l[2], l[6]);<br/>&gt; u := [l[6]/s, -l[2]/s, l[1]/s,0];</p><p>Presumably this is simplifying the octave-equivalent part?</p><p>&gt; v := [p,q,r,1];</p><p>What values do p, q and r have?  Is it important?</p><p>&gt; w := w7l(u,v);</p><p>&gt; &quot;w7l&quot; takes two vectors representing intervals, and computes the<br/>&gt; wegdge product.</p><p>So w is the wedge product of u and v, whatever they are.</p><p>&gt; s := isolve({l[1]-w[1],l[2]-w[2],l[3]-w[3],l[4]-w[4],l[5]-w[5],l[6]-w<br/>&gt; [6]});</p><p>&gt; &quot;isolve&quot; gives integer solutions to a linear<br/>&gt; equation;</p><p>Oh, that sounds useful.</p><p>&gt; s := subs(_N1=0,s);</p><p>&gt; I get an undeterminded varable &quot;_N1&quot; in this way which I<br/>&gt; can set equal to any integer, so I set it to 0.</p><p>Okay.</p><p>&gt; p1 := subs(s,p);<br/>&gt; q1 := subs(s,q);<br/>&gt; r1 := subs(s,r);</p><p>What about this?</p><p>&gt; v := 2^p1 * 3^q1 * 5^r1 * 7;</p><p>And here ^ is exponentiation instead of a wedge product.</p><p>&gt; if v &lt; 1 then v := 1/v fi;</p><p>So v must be a ratio, and you want it to be ascending.</p><p>&gt; w := 2^u[1] * 3^u[2] * 5^u[3];<br/>&gt; if w &lt; 1 then w := 1/w fi;</p><p>Same for w.</p><p>&gt; [w, v] end:</p><p>And that&apos;s the result, is it?  Two unison vectors?</p><p>&gt; coms := proc(l)<br/>&gt; local v;<br/>&gt; v := findcoms(l);<br/>&gt; com7(v[1],v[2]) end:</p><p>&gt; The pair of unisons<br/>&gt; returned in this way can be LLL reduced by the &quot;com7&quot; function, which<br/>&gt; takes a pair of intervals and LLL reduces them.</p><p>That makes sense.  Return the reduced results of the other function.</p><p>&gt; &quot;w7l&quot; takes two vectors representing intervals, and computes the<br/>&gt; wegdge product. &quot;isolve&quot; gives integer solutions to a linear<br/>&gt; equation; I get an undeterminded varable &quot;_N1&quot; in this way which I<br/>&gt; can set equal to any integer, so I set it to 0.  The pair of unisons<br/>&gt; returned in this way can be LLL reduced by the &quot;com7&quot; function, which<br/>&gt; takes a pair of intervals and LLL reduces them.</p><p>Looks like the magic is being done by &quot;isolve&quot; which I presume is built-in<br/>to Maple.</p><p>                Graham</p></div><h3>genewardsmith &#x3C;genewardsmith@juno.com&#x3E;</h3><span>12/9/2001 1:44:58 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., graham@m... wrote:<br/>&gt; Gene wrote:<br/>&gt; &gt; I don&apos;t know what good Maple code will do, but here it is:<br/>&gt; &gt;<br/>&gt; &gt; findcoms := proc(l)<br/>&gt; &gt; local p,q,r,p1,q1,r1,s,u,v,w;<br/>&gt;<br/>&gt; More descriptive variable names might help.  Is l the wedge<br/>invariant?</p><p>Yes.</p><p>&gt; &gt; s := igcd(l[1], l[2], l[6]);<br/>&gt; &gt; u := [l[6]/s, -l[2]/s, l[1]/s,0];<br/>&gt;<br/>&gt; Presumably this is simplifying the octave-equivalent part?</p><p>&quot;s&quot; is the gcd of the first, second and sixth coordinates of the<br/>wedgie, these are the ones used to construct the 5-limit comma. I<br/>divide out by s, and get u, which is a vector representing this comma.</p><p>&gt; &gt; v := [p,q,r,1];<br/>&gt;<br/>&gt; What values do p, q and r have?  Is it important?</p><p>p, q, and r are indeterminates, and the &quot;1&quot; above should be &quot;s&quot;, the<br/>gcd I obtained before.</p><p>Here is a more recent version, which should be used instead of the<br/>old one as a reference:</p><p>findcoms := proc(l)<br/>local p,q,r,p1,q1,r1,s,t,u,v,w;<br/>s := igcd(l[1], l[2], l[6]);<br/>u := [l[6]/s, -l[2]/s, l[1]/s,0];<br/>v := [p,q,r,s];<br/>w := w7l(u,v);<br/>t := isolve({l[1]-w[1],l[2]-w[2],l[3]-w[3],l[4]-w[4],l[5]-w[5],l[6]-w<br/>[6]});<br/>t := subs(_N1=0,t);<br/>p1 := subs(t,p);<br/>q1 := subs(t,q);<br/>r1 := subs(t,r);<br/>v := 2^p1 * 3^q1 * 5^r1 * 7^s;<br/>if v &lt; 1 then v := 1/v fi;<br/>w := 2^u[1] * 3^u[2] * 5^u[3];<br/>if w &lt; 1 then w := 1/w fi;<br/>[w, v] end:</p><p>&gt; So w is the wedge product of u and v, whatever they are.</p><p>Right, and &quot;u&quot; is the 5-limit comma, while &quot;v&quot; is undetermined aside<br/>from the fact that the power of 7 is &quot;s&quot;.</p><p>&gt; &gt; s := isolve({l[1]-w[1],l[2]-w[2],l[3]-w[3],l[4]-w[4],l[5]-w[5],l<br/>[6]-w<br/>&gt; &gt; [6]});<br/>&gt;<br/>&gt; &gt; &quot;isolve&quot; gives integer solutions to a linear<br/>&gt; &gt; equation;<br/>&gt;<br/>&gt; Oh, that sounds useful.</p><p>It is; a linear Diophantine equation routine would be a good thing to<br/>acquire.</p><p>&gt; &gt; p1 := subs(s,p);<br/>&gt; &gt; q1 := subs(s,q);<br/>&gt; &gt; r1 := subs(s,r);<br/>&gt;<br/>&gt; What about this?</p><p>I&apos;ve now re-named &quot;s&quot; (bad programming style if I was going to<br/>publish the code, but I didn&apos;t write it with that in mind) to be the<br/>set of solutions of the linear Diophantine equation. In my newer<br/>version, that is &quot;t&quot;; t is a particular solution, and I substitute<br/>this solution into the indeterminates, getting a specific value. It&apos;s<br/>Maple-specific idiocy, and you would no doubt do something different<br/>using Python.</p><p>&gt; &gt; v := 2^p1 * 3^q1 * 5^r1 * 7;<br/>&gt;<br/>&gt; And here ^ is exponentiation instead of a wedge product.</p><p>Right, and 7 should be &quot;7^s&quot;.</p><p>&gt; &gt; if v &lt; 1 then v := 1/v fi;<br/>&gt;<br/>&gt; So v must be a ratio, and you want it to be ascending.</p><p>I just like to standardize things.</p><p>&gt; &gt; w := 2^u[1] * 3^u[2] * 5^u[3];<br/>&gt; &gt; if w &lt; 1 then w := 1/w fi;<br/>&gt;<br/>&gt; Same for w.<br/>&gt;<br/>&gt; &gt; [w, v] end:<br/>&gt;<br/>&gt; And that&apos;s the result, is it?  Two unison vectors?</p><p>Correct; two unison vectors free of torsion problems which define the<br/>linear temperament.</p><p>&gt; Looks like the magic is being done by &quot;isolve&quot; which I presume is<br/>built-in<br/>&gt; to Maple.</p><p>It&apos;s a built-in Maple function; however much of the magic can still<br/>be had by solving the system over the rationals, because part of the<br/>magic was to start out in such a way that torsion problems would be<br/>exterminated. One way to solve a linear Diophantine system is to<br/>solve over the rationals, and then solve the congruence conditions<br/>required to give an integer solution, in fact. You might look in<br/>Niven and Zuckerman if you have a copy for linear Diophantine<br/>equations.</p></div><h3>paulerlich &#x3C;paul@stretch-music.com&#x3E;</h3><span>12/9/2001 7:19:17 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;dkeenanuqnetau&quot; &lt;d.keenan@u...&gt; wrote:<br/>&gt; --- In tuning-math@y..., &quot;paulerlich&quot; &lt;paul@s...&gt; wrote:<br/>&gt; &gt; Dave, if you don&apos;t have a cutoff, you&apos;d have an infinite number<br/>of<br/>&gt; &gt; ETs better than 1547. Of course there has to be a cutoff.<br/>&gt;<br/>&gt; Yes. This just shows that this isn&apos;t a very good badness metric.<br/>&gt; A decent badness metric would not need a cutoff in anything but<br/>&gt; badness in order to arrive at a finite list.<br/>&gt;<br/>&gt; &gt; I mean that only Gene&apos;s measure tells you exactly _how much_<br/>better<br/>&gt; a<br/>&gt; &gt; system is than the systems in their vicinity,<br/>&gt;<br/>&gt; How do you know it does that? &quot;Exactly&quot;?</p><p>Sure, in a limit-probability sense. How many digits did Gene report?<br/>Anyhow, I&apos;ll have to refer you to Gene on the details of how it does<br/>that.</p><p>I&apos;d just like this paper to have some very simple systems with large<br/>errors, where a combined adaptive-tuning &amp; adaptive-timbre approach<br/>would be needed, as well as systems to satisfy people like Rami<br/>Vitale, for whom even the _melodic_ distinctions of 225:224 cannot be<br/>tempered out.</p></div><h3>paulerlich &#x3C;paul@stretch-music.com&#x3E;</h3><span>12/9/2001 7:26:35 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning-math@y..., &quot;dkeenanuqnetau&quot; &lt;d.keenan@u...&gt; wrote:</p><p>&gt; But why ever do you think the size of the wiggles should be flat? I<br/>&gt; think it is quite expected that the size of the wiggles in badness<br/>&gt; around 1-tET to 9-tET are _much_ bigger than the wiggles around 60-<br/>tET<br/>&gt; to 69-tET.</p><p>The two ranges would gave to be the same size logarithmically, for<br/>example 1-tET to 9-tET and 10-tET to 90-tET.</p></div>