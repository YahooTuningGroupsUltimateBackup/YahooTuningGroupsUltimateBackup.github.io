<a href="/tuning-math">back to list</a><h1>Poor man's harmonic entropy?</h1><h3><a id=6499 href="#6499">ðŸ”—</a>Gene Ward Smith &#x3C;gwsmith@svpal.org&#x3E;</h3><span>7/20/2003 12:49:55 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>If x is a positive real number representing an interval, it&apos;s<br/>suggested that Pc(x) = exp((log(p/q)-x)^2/2c)) can model the<br/>probability that x is heard as p/q; here c is a parameter. If we take<br/>the sum</p><p>sum q^(-d) Pc(x)</p><p>over positive rationals p/q, then it isn&apos;t hard to see that this<br/>converges absolutely for high enough values of d--anything above 2,<br/>at any rate.</p><p>A problem with this is that it mixes multiplicative and implicitly<br/>additive distance measures, since |log(p/q)-x| is multiplicative,<br/>while q does not depend on the octave and, like the Farey sequence,<br/>is implicitly additive.</p></div><h3><a id=6500 href="#6500">ðŸ”—</a>Gene Ward Smith &#x3C;gwsmith@svpal.org&#x3E;</h3><span>7/21/2003 4:09:38 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, &quot;Gene Ward Smith&quot; &lt;gwsmith@s...&gt;<br/>wrote:<br/>&gt; If x is a positive real number representing an interval, it&apos;s<br/>&gt; suggested that Pc(x) = exp((log(p/q)-x)^2/2c)) can model the<br/>&gt; probability that x is heard as p/q; here c is a parameter. If we<br/>take<br/>&gt; the sum<br/>&gt;<br/>&gt; sum q^(-d) Pc(x)<br/>&gt;<br/>&gt; over positive rationals p/q, then it isn&apos;t hard to see that this<br/>&gt; converges absolutely for high enough values of d--anything above 2,<br/>&gt; at any rate.</p><p>I think maybe the plan should be to get a continuous function the<br/>Tenney Height way, by</p><p>sum_{p/q &gt; 0} Pc(x, p/q)/(p*q)</p></div><h3><a id=6515 href="#6515">ðŸ”—</a>Carl Lumma &#x3C;ekin@lumma.org&#x3E;</h3><span>7/23/2003 11:15:09 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Gene wrote...</p><p>&gt;&gt;If x is a positive real number representing an interval, it&apos;s<br/>&gt;&gt;suggested that Pc(x) = exp((log(p/q)-x)^2/2c)) can model the<br/>&gt;&gt;probability that x is heard as p/q; here c is a parameter. If<br/>&gt;&gt;we take the sum<br/>&gt;&gt;<br/>&gt;&gt;sum q^(-d) Pc(x)<br/>&gt;&gt;<br/>&gt;&gt;over positive rationals p/q, then it isn&apos;t hard to see that<br/>&gt;&gt;this converges absolutely for high enough values of d--anything<br/>&gt;&gt;above 2, at any rate.</p><p>Why are you summing?  Presumably to get harmonic entropy for x,<br/>which is the entropy of the distribution of probabilities for all<br/>p/q.  Does the q^(-d) term do that, and if so, how?</p><p>&gt;&gt;A problem with this is that it mixes multiplicative and<br/>&gt;&gt;implicitly additive distance measures, since |log(p/q)-x| is<br/>&gt;&gt;multiplicative, while q does not depend on the octave and,<br/>&gt;&gt;like the Farey sequence, is implicitly additive.<br/>&gt;<br/>&gt;I think maybe the plan should be to get a continuous function<br/>&gt;the Tenney Height way, by<br/>&gt;<br/>&gt;sum_{p/q &gt; 0} Pc(x, p/q)/(p*q)</p><p>Um, not clear how this could possibly work.  Paul empirically<br/>verified that p*q approximates the &quot;width&quot; (and also the entropy?)<br/>for x.  Where I&apos;m totally at a loss for how to define &quot;width&quot;.</p><p>Anyway, goal number 1 is to do extend things to triads and<br/>up.  Where I think p*q*r is supposed tell you something about the<br/>space around triads on a 2-D plot...  or something.  It&apos;s been<br/>a long time...</p><p>-Carl</p></div><h3><a id=6516 href="#6516">ðŸ”—</a>Gene Ward Smith &#x3C;gwsmith@svpal.org&#x3E;</h3><span>7/23/2003 1:13:02 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Carl Lumma &lt;ekin@l...&gt; wrote:<br/>&gt; Gene wrote...<br/>&gt;<br/>&gt; &gt;&gt;If x is a positive real number representing an interval, it&apos;s<br/>&gt; &gt;&gt;suggested that Pc(x) = exp((log(p/q)-x)^2/2c)) can model the<br/>&gt; &gt;&gt;probability that x is heard as p/q; here c is a parameter. If<br/>&gt; &gt;&gt;we take the sum<br/>&gt; &gt;&gt;<br/>&gt; &gt;&gt;sum q^(-d) Pc(x)<br/>&gt; &gt;&gt;<br/>&gt; &gt;&gt;over positive rationals p/q, then it isn&apos;t hard to see that<br/>&gt; &gt;&gt;this converges absolutely for high enough values of d--anything<br/>&gt; &gt;&gt;above 2, at any rate.<br/>&gt;<br/>&gt; Why are you summing?  Presumably to get harmonic entropy for x,<br/>&gt; which is the entropy of the distribution of probabilities for all<br/>&gt; p/q.  Does the q^(-d) term do that, and if so, how?</p><p>I&apos;ve replace the q^(-d) with (pq)^(-d), and I think taking d=1 is<br/>fine. The weighting gives more weight to the better consonances, and<br/>it makes the series converge to a continuous function. What values of<br/>c have mostly been used? A graph would be nice.</p><p>&gt; &gt;I think maybe the plan should be to get a continuous function<br/>&gt; &gt;the Tenney Height way, by<br/>&gt; &gt;<br/>&gt; &gt;sum_{p/q &gt; 0} Pc(x, p/q)/(p*q)<br/>&gt;<br/>&gt; Um, not clear how this could possibly work.  Paul empirically<br/>&gt; verified that p*q approximates the &quot;width&quot; (and also the entropy?)<br/>&gt; for x.  Where I&apos;m totally at a loss for how to define &quot;width&quot;.</p><p>I&apos;m not clear why it wouldn&apos;t work.</p><p>&gt; Anyway, goal number 1 is to do extend things to triads and<br/>&gt; up.  Where I think p*q*r is supposed tell you something about the<br/>&gt; space around triads on a 2-D plot...  or something.  It&apos;s been<br/>&gt; a long time...</p><p>You could take a similar sum over all p:q:r:</p><p>F(x) = sum_{p:q:r reduced} 1/(pqr) (Pc(x, p/q)+Pc(x, p/r)+Pc(x,r/q))</p></div><h3><a id=6517 href="#6517">ðŸ”—</a>Paul Erlich &#x3C;perlich@aya.yale.edu&#x3E;</h3><span>7/23/2003 1:52:55 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Carl Lumma &lt;ekin@l...&gt; wrote:</p><p>&gt; Um, not clear how this could possibly work.  Paul empirically<br/>&gt; verified that p*q approximates the &quot;width&quot;</p><p>that&apos;s 1/sqrt(p*q), carl. i also verified that for triads, the &quot;area&quot;<br/>is approximately 1/cuberoot(p*q*r), for p:q:r in lowest terms . . .</p><p>the total set of dyads or triads in each case is delimited by a very<br/>high (much higher than the p*q or p*q*r above) maximum value for the<br/>product of the terms. this (&quot;tenney&quot; as opposed to &quot;farey&quot;) is the<br/>only rule that gives a &quot;uniform&quot; (trendless) density over dyad space<br/>or triad space.</p><p>&gt; (and also the entropy?)</p><p>yes, if p and q are small enough, log(p*q) + c approximates the<br/>entropy. tenney&apos;s harmonic distance function is log(p*q).</p><p>&gt; for x.  Where I&apos;m totally at a loss for how to define &quot;width&quot;.</p><p>in harmonic entropy, you can use mediant-to-mediant width, or you can<br/>just use midpoint-to-midpoint width (which generalizes to voronoi<br/>cells for triads).</p><p>&gt; Anyway, goal number 1 is to do extend things to triads and<br/>&gt; up.  Where I think p*q*r is supposed tell you something about the<br/>&gt; space around triads on a 2-D plot...  or something.  It&apos;s been<br/>&gt; a long time...</p><p>yup, we&apos;ve done that on the harmonic entropy list.</p></div><h3><a id=6518 href="#6518">ðŸ”—</a>Carl Lumma &#x3C;ekin@lumma.org&#x3E;</h3><span>7/23/2003 2:42:20 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Hooray!</p><p>&gt;&gt; Um, not clear how this could possibly work.  Paul empirically<br/>&gt;&gt; verified that p*q approximates the &quot;width&quot;<br/>&gt;<br/>&gt;that&apos;s 1/sqrt(p*q), carl.</p><p>Sure.</p><p>&gt;i also verified that for triads, the &quot;area&quot; is approximately<br/>&gt;1/cuberoot(p*q*r), for p:q:r in lowest terms . . .</p><p>I thought the rationals were infinitely dense.  So how do you<br/>define &quot;width&quot;?</p><p>&gt;the total set of dyads or triads in each case is delimited by a very<br/>&gt;high (much higher than the p*q or p*q*r above) maximum value for the<br/>&gt;product of the terms. this (&quot;tenney&quot; as opposed to &quot;farey&quot;) is the<br/>&gt;only rule that gives a &quot;uniform&quot; (trendless) density over dyad space<br/>&gt;or triad space.</p><p>Thanks for the recap.</p><p>But don&apos;t we want to eventually say the total set is infinite?<br/>Can we still define &quot;width&quot; then?</p><p>-Carl</p></div><h3><a id=6519 href="#6519">ðŸ”—</a>shelly roberts &#x3C;naughty_nina_4u@yahoo.com&#x3E;</h3><span>7/23/2003 3:14:26 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Carl,thanks for your reply, but it doesn&apos;t make a bit of sense....thanks, shelly</p><p>Carl Lumma &lt;<a href="mailto:ekin@lumma.org">ekin@lumma.org</a>&gt; wrote:Gene wrote...</p><p>&gt;&gt;If x is a positive real number representing an interval, it&apos;s<br/>&gt;&gt;suggested that Pc(x) = exp((log(p/q)-x)^2/2c)) can model the<br/>&gt;&gt;probability that x is heard as p/q; here c is a parameter. If<br/>&gt;&gt;we take the sum<br/>&gt;&gt;<br/>&gt;&gt;sum q^(-d) Pc(x)<br/>&gt;&gt;<br/>&gt;&gt;over positive rationals p/q, then it isn&apos;t hard to see that<br/>&gt;&gt;this converges absolutely for high enough values of d--anything<br/>&gt;&gt;above 2, at any rate.</p><p>Why are you summing?  Presumably to get harmonic entropy for x,<br/>which is the entropy of the distribution of probabilities for all<br/>p/q.  Does the q^(-d) term do that, and if so, how?</p><p>&gt;&gt;A problem with this is that it mixes multiplicative and<br/>&gt;&gt;implicitly additive distance measures, since |log(p/q)-x| is<br/>&gt;&gt;multiplicative, while q does not depend on the octave and,<br/>&gt;&gt;like the Farey sequence, is implicitly additive.<br/>&gt;<br/>&gt;I think maybe the plan should be to get a continuous function<br/>&gt;the Tenney Height way, by<br/>&gt;<br/>&gt;sum_{p/q &gt; 0} Pc(x, p/q)/(p*q)</p><p>Um, not clear how this could possibly work.  Paul empirically<br/>verified that p*q approximates the &quot;width&quot; (and also the entropy?)<br/>for x.  Where I&apos;m totally at a loss for how to define &quot;width&quot;.</p><p>Anyway, goal number 1 is to do extend things to triads and<br/>up.  Where I think p*q*r is supposed tell you something about the<br/>space around triads on a 2-D plot...  or something.  It&apos;s been<br/>a long time...</p><p>-Carl</p><p>Yahoo! Groups SponsorADVERTISEMENT</p><p>To unsubscribe from this group, send an email to:<br/><a href="mailto:tuning-math-unsubscribe@yahoogroups.com">tuning-math-unsubscribe@yahoogroups.com</a></p><p>Your use of Yahoo! Groups is subject to the Yahoo! Terms of Service.</p><p>---------------------------------<br/>Do you Yahoo!?<br/>Yahoo! SiteBuilder - Free, easy-to-use web site design software</p></div><h3><a id=6520 href="#6520">ðŸ”—</a>Paul Erlich &#x3C;perlich@aya.yale.edu&#x3E;</h3><span>7/23/2003 3:25:43 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Carl Lumma &lt;ekin@l...&gt; wrote:<br/>&gt; Hooray!<br/>&gt;<br/>&gt; &gt;&gt; Um, not clear how this could possibly work.  Paul empirically<br/>&gt; &gt;&gt; verified that p*q approximates the &quot;width&quot;<br/>&gt; &gt;<br/>&gt; &gt;that&apos;s 1/sqrt(p*q), carl.<br/>&gt;<br/>&gt; Sure.<br/>&gt;<br/>&gt; &gt;i also verified that for triads, the &quot;area&quot; is approximately<br/>&gt; &gt;1/cuberoot(p*q*r), for p:q:r in lowest terms . . .<br/>&gt;<br/>&gt; I thought the rationals were infinitely dense.</p><p>sorry, i should have said *proportional to*, the width is<br/>*proportional* to 1/sqrt(p*q) (for p and q not too large), and the<br/>harmonic entropy is *proportional* to log(p*q) (for p and q quite<br/>small).</p><p>&gt; But don&apos;t we want to eventually say the total set is infinite?</p><p>yes, we want to take the limit.</p><p>&gt; Can we still define &quot;width&quot; then?</p><p>yes, the width will go to zero in the limit, but the whole entropy<br/>expression may still converge (or some function of it may), as you<br/>should know from calculus.</p></div><h3><a id=6521 href="#6521">ðŸ”—</a>Carl Lumma &#x3C;ekin@lumma.org&#x3E;</h3><span>7/23/2003 5:05:34 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>&gt;Carl, thanks for your reply, but it doesn&apos;t make a bit of<br/>&gt;sense....thanks, shelly</p><p>Hi Shelly.  Does Gene&apos;s original post make sense to you?<br/>How long have you been on this list?</p><p>-Carl</p></div><h3><a id=6522 href="#6522">ðŸ”—</a>Carl Lumma &#x3C;ekin@lumma.org&#x3E;</h3><span>7/23/2003 5:06:44 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>&gt;&gt;&gt;I think maybe the plan should be to get a continuous function<br/>&gt;&gt;&gt;the Tenney Height way, by<br/>&gt;&gt;&gt;<br/>&gt;&gt;&gt;sum_{p/q &gt; 0} Pc(x, p/q)/(p*q)<br/>&gt;&gt;<br/>&gt;&gt;Um, not clear how this could possibly work.  Paul empirically<br/>&gt;&gt;verified that p*q approximates the &quot;width&quot; (and also the<br/>&gt;&gt;entropy?) for x.  Where I&apos;m totally at a loss for how to<br/>&gt;&gt;define &quot;width&quot;.<br/>&gt;<br/>&gt;I&apos;m not clear why it wouldn&apos;t work.</p><p>Do you just see this stuff, or does your thought process<br/>involve multiple steps?</p><p>-Carl</p></div><h3><a id=6523 href="#6523">ðŸ”—</a>Carl Lumma &#x3C;ekin@lumma.org&#x3E;</h3><span>7/23/2003 5:07:15 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>&gt;&gt; Can we still define &quot;width&quot; then?<br/>&gt;<br/>&gt;yes, the width will go to zero in the limit, but the whole entropy<br/>&gt;expression may still converge (or some function of it may), as you<br/>&gt;should know from calculus.</p><p>Ok, good.  So are there any open problems in harmonic entropy?<br/>Would it be accurate to say we&apos;ve empirically verified the p*q*r<br/>stuff, but that we don&apos;t have a clean picture of why it works?</p><p>-Carl</p></div><h3><a id=6524 href="#6524">ðŸ”—</a>Gene Ward Smith &#x3C;gwsmith@svpal.org&#x3E;</h3><span>7/23/2003 10:01:04 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, &quot;Carl Lumma&quot; &lt;ekin@l...&gt; wrote:</p><p>&gt; Do you just see this stuff, or does your thought process<br/>&gt; involve multiple steps?</p><p>Experience tells me I could be completely out to lunch, working on a<br/>different problem than the one I think I am, seeing things as obvious<br/>which aren&apos;t, or mired in a host of other problems. Do you understand<br/>I&apos;m working with an expression which, at least, involves all rational<br/>intervals and converges to a continuous function? It seems to me that<br/>has to be worth something.</p></div><h3><a id=6525 href="#6525">ðŸ”—</a>Paul Erlich &#x3C;perlich@aya.yale.edu&#x3E;</h3><span>7/23/2003 11:16:14 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, &quot;Carl Lumma&quot; &lt;ekin@l...&gt; wrote:<br/>&gt; &gt;&gt; Can we still define &quot;width&quot; then?<br/>&gt; &gt;<br/>&gt; &gt;yes, the width will go to zero in the limit, but the whole entropy<br/>&gt; &gt;expression may still converge (or some function of it may), as you<br/>&gt; &gt;should know from calculus.<br/>&gt;<br/>&gt; Ok, good.  So are there any open problems in harmonic entropy?</p><p>yup -- summarized them for gene a while back.</p><p>&gt; Would it be accurate to say we&apos;ve empirically verified the p*q*r<br/>&gt; stuff, but that we don&apos;t have a clean picture of why it works?<br/>&gt;<br/>&gt; -Carl</p><p>i&apos;m sure gene could tell us why we get 1/cuberoot(p*q*r) works. as<br/>for the entropy for the very simplest triads being log(p*q*r)+c, that<br/>actually hasn&apos;t been verified yet. i&apos;m hoping gene will help us do it<br/>analytically rather than numerically . . .</p></div><h3><a id=6526 href="#6526">ðŸ”—</a>monz@attglobal.net</h3><span>7/24/2003 12:26:26 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>hi Gene,</p><p>&gt; From: Gene Ward Smith [<a href="mailto:gwsmith@svpal.org">mailto:gwsmith@svpal.org</a>]<br/>&gt; Sent: Wednesday, July 23, 2003 10:01 PM<br/>&gt; To: <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a><br/>&gt; Subject: [tuning-math] Re: Poor man&apos;s harmonic entropy?<br/>&gt;<br/>&gt;<br/>&gt; --- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, &quot;Carl Lumma&quot; &lt;ekin@l...&gt; wrote:<br/>&gt;<br/>&gt; &gt; Do you just see this stuff, or does your thought process<br/>&gt; &gt; involve multiple steps?<br/>&gt;<br/>&gt; Experience tells me I could be completely out<br/>&gt; to lunch, working on a different problem than<br/>&gt; the one I think I am, seeing things as obvious<br/>&gt; which aren&apos;t, or mired in a host of other problems.<br/>&gt; Do you understand I&apos;m working with an expression<br/>&gt; which, at least, involves all rational intervals<br/>&gt; and converges to a continuous function? It seems<br/>&gt; to me that has to be worth something.</p><p>i really haven&apos;t been following this thread, or<br/>any developments in harmonic entropy theory since<br/>around early 2000, but my intuition has a sense<br/>that you&apos;re onto something good here.  can you<br/>elaborate and then explain the math a little?</p><p>PS to paul -- i&apos;d like to update my sonic-arts<br/>pages on harmonic entropy so that they reflect<br/>some of the further developments of the theory.<br/>can you write an addendum to my current pages?<br/>i can just add it on at the bottom.</p><p>-monz</p></div><h3><a id=6527 href="#6527">ðŸ”—</a>Carl Lumma &#x3C;ekin@lumma.org&#x3E;</h3><span>7/24/2003 12:54:39 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>&gt;&gt; Do you just see this stuff, or does your thought process<br/>&gt;&gt; involve multiple steps?<br/>&gt;<br/>&gt;Experience tells me I could be completely out to lunch, working<br/>&gt;on a different problem than the one I think I am, seeing things<br/>&gt;as obvious which aren&apos;t, or mired in a host of other problems.</p><p>:)</p><p>&gt;Do you understand I&apos;m working with an expression which, at least,<br/>&gt;involves all rational intervals and converges to a continuous<br/>&gt;function?</p><p>Yes indeed.  Though I don&apos;t see how you know it converges.  Did<br/>you test a few values?  No, you say it &quot;isn&apos;t hard to see&quot; that<br/>it does... maybe you can walk us through it.</p><p>&gt;It seems to me that has to be worth something.</p><p>No argument here.</p><p>-Carl</p></div><h3><a id=6528 href="#6528">ðŸ”—</a>Paul Erlich &#x3C;perlich@aya.yale.edu&#x3E;</h3><span>7/24/2003 1:51:55 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, &lt;monz@a...&gt; wrote:</p><p>&gt; PS to paul -- i&apos;d like to update my sonic-arts<br/>&gt; pages on harmonic entropy so that they reflect<br/>&gt; some of the further developments of the theory.<br/>&gt; can you write an addendum to my current pages?<br/>&gt; i can just add it on at the bottom.<br/>&gt;<br/>&gt;<br/>&gt;<br/>&gt; -monz</p><p>this exchange from an e-mail from me to you dated apr. 14th:</p><p>*******************************************************************</p><p>&gt;if any text or links should be added to my harmonic entropy<br/>&gt;definition, would you be so kind as to send them over? :)</p><p>could you add, right before &quot;certain chords of three or more notes&quot;,<br/>the following:</p><p>assuming an error distribution that follows an exponential decay on<br/>either side of the actual interval, instead of the usual default bell<br/>curve, yields harmonic entropy curves that have pointy, instead of<br/>round, local minima. accentuating the differences among the more<br/>dissonant intervals by taking the exponential of the entropy (in<br/>information theory, the exponential of the entropy is the so-<br/>called &quot;alphabet size&quot;), and assuming a tuning resolution<br/>representing the best human ears (s=0.6%), this &quot;pointy&quot; assumption<br/>lets us paint the most generous possible picture (within the harmonic<br/>entropy paradigm) for the ability to distinguish complex ratios by<br/>their relative consonance:</p><p>{reproduce<br/><a href="http://groups.yahoo.com/group/harmonic_entropy/files/dyadic/margo.gif">http://groups.yahoo.com/group/harmonic_entropy/files/dyadic/margo.gif</a>}</p><p>thanks,<br/>paul</p><p>********************************************************************</p><p>also, on any of the harmonic entropy pages, you might want to display</p><p><a href="http://groups.yahoo.com/group/harmonic_entropy/files/trivoro.gif">http://groups.yahoo.com/group/harmonic_entropy/files/trivoro.gif</a></p><p>the 2-dimensional space here is triad space, just like on the graphs<br/>on your eqtemp page. the center of each cell represents a triad a:b:c<br/>such that a*b*c is less than a million, and the cell itself contains<br/>all (and only) points that are closer to its center than to the<br/>center of any other cell. the largest cells are the ones with the<br/>smallest value of a*b*c, as shown more clearly in this closeup:</p><p><a href="http://groups.yahoo.com/group/harmonic_entropy/files/Erlich/fun.gif">http://groups.yahoo.com/group/harmonic_entropy/files/Erlich/fun.gif</a></p><p>the area of each cell as a function of the geometric mean of a, b,<br/>and c, in other words cuberoot(a*b*c), is shown at</p><p><a href="http://groups.yahoo.com/group/harmonic_entropy/files/triadic.gif">http://groups.yahoo.com/group/harmonic_entropy/files/triadic.gif</a></p><p>showing that the areas are proportional to 1/cuberoot(a*b*c), at<br/>least for a*b*c not too large.</p><p>finally, there&apos;s a bunch of stuff that can go on the &quot;old ideas&quot; page<br/>to connect them better to the &quot;new ideas&quot; assumed in the definition<br/>page. let me get back to you on that.</p></div><h3><a id=6529 href="#6529">ðŸ”—</a>Gene Ward Smith &#x3C;gwsmith@svpal.org&#x3E;</h3><span>7/24/2003 2:45:57 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, &quot;Paul Erlich&quot; &lt;perlich@a...&gt;<br/>wrote:</p><p>&gt; i&apos;m sure gene could tell us why we get 1/cuberoot(p*q*r) works.</p><p>I can? I don&apos;t even know what you mean.</p></div><h3><a id=6530 href="#6530">ðŸ”—</a>Gene Ward Smith &#x3C;gwsmith@svpal.org&#x3E;</h3><span>7/24/2003 3:07:09 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Carl Lumma &lt;ekin@l...&gt; wrote:</p><p>&gt; Yes indeed.  Though I don&apos;t see how you know it converges.  Did<br/>&gt; you test a few values?  No, you say it &quot;isn&apos;t hard to see&quot; that<br/>&gt; it does... maybe you can walk us through it.</p><p>Sorry!</p><p>Assume d&gt;1 and chop everything up into octaves. For the 1-2 octave,<br/>for a given denominator q of p/q, compare to the sum</p><p>(p_i q)^(-d) (p_0/q + ... + p_phi(q)/q)</p><p>where p_0 = q and we go through values p_i relatively prime to q. Our<br/>terms are all positive, and this expression is less than</p><p>q^(-2d) (q/q + (q+1)/q + ... + (2*q-1)/q) &lt; 2q^(-d)</p><p>Since d&gt;1, this converges by comparison to the Zeta function<br/>Dirichlet series 1+2^(-d) + 3^(-d) + ... Hence, the sum of the series<br/>over the octave is bounded by 2 Zeta(d), and in fact for each octave,<br/>the sum of the functions of x is bounded by 2 Zeta(d) M_O, where M_O<br/>is the maximum of Ps(x, p/q) over the ocatve O. The normal<br/>distribution tends rapidly to zero, so you have a uniformly<br/>convergent series of continuous functions summing over the octaves,<br/>leading to a continuous function.</p><p>This is the sort of thing which was in my head; maybe it can be made<br/>clearer.</p></div><h3><a id=6531 href="#6531">ðŸ”—</a>Graham Breed &#x3C;graham@microtonal.co.uk&#x3E;</h3><span>7/24/2003 5:50:40 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Gene Ward Smith wrote:</p><p>&gt; Assume d&gt;1 and chop everything up into octaves. For the 1-2 octave, &gt; for a given denominator q of p/q, compare to the sum<br/>&gt; &gt; (p_i q)^(-d) (p_0/q + ... + p_phi(q)/q)<br/>&gt; &gt; where p_0 = q and we go through values p_i relatively prime to q. Our &gt; terms are all positive, and this expression is less than<br/>&gt; &gt; q^(-2d) (q/q + (q+1)/q + ... + (2*q-1)/q) &lt; 2q^(-d)</p><p>Does that mean the original sum is over only those p/q in their lowest terms?</p><p>&gt; Since d&gt;1, this converges by comparison to the Zeta function &gt; Dirichlet series 1+2^(-d) + 3^(-d) + ... Hence, the sum of the series &gt; over the octave is bounded by 2 Zeta(d), and in fact for each octave,<br/>&gt; the sum of the functions of x is bounded by 2 Zeta(d) M_O, where M_O &gt; is the maximum of Ps(x, p/q) over the ocatve O. The normal &gt; distribution tends rapidly to zero, so you have a uniformly &gt; convergent series of continuous functions summing over the octaves, &gt; leading to a continuous function.</p><p>If c &lt; 0.</p><p>                         Graham</p></div><h3><a id=6532 href="#6532">ðŸ”—</a>Paul Erlich &#x3C;perlich@aya.yale.edu&#x3E;</h3><span>7/24/2003 11:35:40 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, &quot;Gene Ward Smith&quot; &lt;gwsmith@s...&gt;<br/>wrote:<br/>&gt; --- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, &quot;Paul Erlich&quot; &lt;perlich@a...&gt;<br/>&gt; wrote:<br/>&gt;<br/>&gt; &gt; i&apos;m sure gene could tell us why we get 1/cuberoot(p*q*r) works.<br/>&gt;<br/>&gt; I can? I don&apos;t even know what you mean.</p><p>where did you lose me? i thought the last few posts were quite clear,<br/>in particular the graphs that show the above to be true.</p></div><h3><a id=6533 href="#6533">ðŸ”—</a>Gene Ward Smith &#x3C;gwsmith@svpal.org&#x3E;</h3><span>7/24/2003 1:12:11 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Graham Breed &lt;graham@m...&gt; wrote:</p><p>Does that mean the original sum is over only those p/q in their<br/>lowest<br/>&gt; terms?</p><p>Of course.</p></div>