<a href="/tuning-math">back to list</a><h1>Yet another octave-stretching method</h1><h3><a id=12834 href="#12834">ðŸ”—</a>Gene Ward Smith &#x3C;gwsmith@svpal.org&#x3E;</h3><span>10/7/2005 11:43:04 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Here&apos;s yet another method for stretching octaves which could be<br/>interesting. I&apos;ll explain it by way of an example.</p><p>The projections for 7-limit meantone form a four-parameter family.<br/>Within that family, we can solve for the projection which is closest<br/>to the identity according to some metric. I solved using the<br/>unweighted L2 metric, but make no claim that is the best choice. The<br/>result was</p><p>[|117/446 73/223 58/223 -61/446&gt;,<br/>|73/223 93/223 80/223 -19/223&gt;,<br/>|58/223 80/223 88/223 46/223&gt;,<br/>|-61/446 -19/223 46/223 413/446&gt;]</p><p>Applying this to &lt;1 log2(3) log2(5) log2(7)| gives a meantone tuning<br/>with an octave stretch of 1.34 cents, a fifth of 697.22 cents, a<br/>twevlth of 1898.56 cents and so forth. Pretty reasonable looking values.</p></div><h3><a id=12840 href="#12840">ðŸ”—</a>Graham Breed &#x3C;gbreed@gmail.com&#x3E;</h3><span>10/9/2005 7:07:31 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Gene Ward Smith wrote:<br/>&gt; Here&apos;s yet another method for stretching octaves which could be<br/>&gt; interesting. I&apos;ll explain it by way of an example.<br/>&gt; &gt; The projections for 7-limit meantone form a four-parameter family.<br/>&gt; Within that family, we can solve for the projection which is closest<br/>&gt; to the identity according to some metric. I solved using the<br/>&gt; unweighted L2 metric, but make no claim that is the best choice. The<br/>&gt; result was</p><p>You lost me there.  Is an L2 metric like the least squares optimization?</p><p>&gt; [|117/446 73/223 58/223 -61/446&gt;,<br/>&gt; |73/223 93/223 80/223 -19/223&gt;,<br/>&gt; |58/223 80/223 88/223 46/223&gt;,<br/>&gt; |-61/446 -19/223 46/223 413/446&gt;]</p><p>I really have no idea where this comes from.  I notice that it&apos;s equal to its transpose, and that each row and column roughly adds up to 1.  I did work out a quantity that you could be minimizing, but it looked like it had too many unknowns.</p><p>&gt; Applying this to &lt;1 log2(3) log2(5) log2(7)| gives a meantone tuning<br/>&gt; with an octave stretch of 1.34 cents, a fifth of 697.22 cents, a<br/>&gt; twevlth of 1898.56 cents and so forth. Pretty reasonable looking values.</p><p>I can see how you get that from the matrix.  I&apos;m guessing this has similar implications to the weighted least-squares.  But it&apos;s mathematically distinct, and you&apos;re putting the weighting in at a later stage.  I can&apos;t see it as simpler, or more valid than the weighted least-squares.  But it&apos;ll probably give reasonable results.</p><p>                Graham</p></div><h3><a id=12841 href="#12841">ðŸ”—</a>Gene Ward Smith &#x3C;gwsmith@svpal.org&#x3E;</h3><span>10/9/2005 7:58:51 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Graham Breed &lt;gbreed@g...&gt; wrote:</p><p>&gt; You lost me there.  Is an L2 metric like the least squares optimization?</p><p>I meant by that the Frobenius norm I defined in a subsequent post: the<br/>square root of the sum of the squares of the matrix coefficients.</p><p>&gt; &gt; [|117/446 73/223 58/223 -61/446&gt;,<br/>&gt; &gt; |73/223 93/223 80/223 -19/223&gt;,<br/>&gt; &gt; |58/223 80/223 88/223 46/223&gt;,<br/>&gt; &gt; |-61/446 -19/223 46/223 413/446&gt;]<br/>&gt;<br/>&gt; I really have no idea where this comes from.  I notice that it&apos;s equal<br/>&gt; to its transpose, and that each row and column roughly adds up to 1.</p><p>If you read the rows as exponents (which is why I wrote them<br/>monzo-fashion) you&apos;ll see they are appromimations to the primes; for<br/>instance 2^(117/446) 3^(73/223) 5^(58/223) 7^(-61/446) is nearly 2, etc.</p><p>&gt; I can see how you get that from the matrix.  I&apos;m guessing this has<br/>&gt; similar implications to the weighted least-squares.  But it&apos;s<br/>&gt; mathematically distinct, and you&apos;re putting the weighting in at a later<br/>&gt; stage.  I can&apos;t see it as simpler, or more valid than the weighted<br/>&gt; least-squares.  But it&apos;ll probably give reasonable results.</p><p>It&apos;s something like a weighted least-squares, but it has a different<br/>origin.</p></div>