<!DOCTYPE html>
            <html>
            <head>
            <meta charset="utf-8">
                <meta name="viewport"
            content="width=device-width, height=device-height, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no">
                <meta http-equiv="x-ua-compatible" content="ie=edge">
                <title>Yahoo Tuning Groups Ultimate Backup tuning-math Parametric scalar badness</title>
                <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
            </head>
            <body>
            </body>
            </html>
        <a href="/tuning-math">back to list</a><h1>Parametric scalar badness</h1><h3><a id=16955 href="#16955">ðŸ”—</a>Graham Breed &#x3C;gbreed@gmail.com&#x3E;</h3><span>2/8/2008 1:20:32 AM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>In my errors and complexities paper (which I&apos;ve finally managed to upload in &quot;revised final&quot; version to <a href="http://x31eq.com/primerr.pdf">http://x31eq.com/primerr.pdf</a> ) I introduced a badness function that takes a free parameter, called epsilon. (Equations 81 and 82, page 18.)</p><p>Here are the octave sizes for the best equal temperaments with under 10,000 notes to the octave</p><p>5-limit<br/>0.01:  3   0.003: 12   0.001: 12   0.0003: 53   0.0001: 53</p><p>7-limit<br/>0.01:  4   0.003: 12   0.001: 19   0.0003: 72   0.0001:171</p><p>11-limit<br/>0.01:  3   0.003: 12   0.001: 31   0.0003: 72   0.0001: 72</p><p>13-limit<br/>0.01:  4   0.003:  9   0.001: 31   0.0003: 72   0.0001:270</p><p>17-limit<br/>0.01:  4   0.003: 10   0.001: 31   0.0003: 72   0.0001: 72</p><p>19-limit<br/>0.01:  3   0.003:  9   0.001: 27   0.0003: 72   0.0001:270</p><p>In each case it looks like there&apos;s a sensible trade-off between complexity and error.  I can&apos;t prove that there aren&apos;t any better ETs with a stupidly large number of notes, but it&apos;s looking that way.</p><p>For another example, the complete set of 11-limit ETs with a 0.001-badness below 0.07 is:</p><p>12, 15, 22, 27, 31, 41, 46</p><p>11-limit ETs with a 0.0001-badness below 0.04 are:</p><p>31, 72, 152, 270, 342</p><p>11-limit ETs with a 0.0003-badness below 0.05 are:</p><p>31, 41, 72</p><p>I don&apos;t know how to predict the relationship between epsilon and the error/complexity trade-off.  And I haven&apos;t looked at higher rank temperaments.  But I think it&apos;ll still work there.  Geometry suggests that the badness of a temperament class is related to the badness of the ETs that belong to it.</p><p>I believe the function is a positive definite quadratic form (for 0 &lt; epsilon &lt; 1) and as such a valid lattice norm.  So the problem of finding good equal temperaments maps to that of finding short vectors in a lattice.  Unfortunately, this isn&apos;t the kind of norm that works with LLL reduction.  But it does anchor us pretty much in real mathematics.</p><p>Higher rank temperaments are small areas, volumes, etc, in the lattice.  Maybe it&apos;s possible to represent each as a vector in a lattice as well.</p><p>I don&apos;t plan to look into this more in the near future, but it shows promise.  If anybody wants a project you could maybe take it up.</p><p>                  Graham</p></div><h3><a id=16956 href="#16956">ðŸ”—</a>Carl Lumma &#x3C;carl@lumma.org&#x3E;</h3><span>2/8/2008 8:54:25 AM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Graham wrote...<br/>&gt;In each case it looks like there&apos;s a sensible trade-off<br/>&gt;between complexity and error.  I can&apos;t prove that there<br/>&gt;aren&apos;t any better ETs with a stupidly large number of notes,<br/>&gt;but it&apos;s looking that way.<br/>&gt;<br/>&gt;For another example, the complete set of 11-limit ETs with a<br/>&gt;0.001-badness below 0.07 is:<br/>&gt;<br/>&gt;12, 15, 22, 27, 31, 41, 46<br/>&gt;<br/>&gt;11-limit ETs with a 0.0001-badness below 0.04 are:<br/>&gt;<br/>&gt;31, 72, 152, 270, 342<br/>&gt;<br/>&gt;11-limit ETs with a 0.0003-badness below 0.05 are:<br/>&gt;<br/>&gt;31, 41, 72<br/>&gt;<br/>&gt;I don&apos;t know how to predict the relationship between epsilon<br/>&gt;and the error/complexity trade-off.</p><p>Have you identified the epsilon that yields logflat badness<br/>(in the sense of there being just barely an infinite number of<br/>improving ETs)?</p><p>-Carl</p></div><h3><a id=16958 href="#16958">ðŸ”—</a>Graham Breed &#x3C;gbreed@gmail.com&#x3E;</h3><span>2/8/2008 9:33:52 PM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Carl Lumma wrote:</p><p>&gt; Have you identified the epsilon that yields logflat badness<br/>&gt; (in the sense of there being just barely an infinite number of<br/>&gt; improving ETs)?</p><p>It&apos;s not possible to get logflat badness in the strict sense.  With epsilon=0 (that&apos;s standard error*complexity badness) it looks like a linear-flat badness.  There&apos;s about the same chance of an ET having the required badness whatever its size.  I assume that any finite epsilon means there is a single best ET.  But I can&apos;t prove any of this.</p><p>                  Graham</p></div>
                <script>
                    let monospace = false
                    $('button').on('click', function () {
                      if (monospace) {
                        $('p').css("font-family", "")
                      } else {
                        $('p').css("font-family", "monospace")
                      }
                      monospace = !monospace
                    })
                </script>
            