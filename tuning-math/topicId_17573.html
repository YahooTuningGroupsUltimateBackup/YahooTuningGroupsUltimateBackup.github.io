<a href="/tuning-math">back to list</a><h1>Re: [tuning-math] Re: Approximate GCD's. Are these almost periodic  functions?</h1><h3><a id=17573 href="#17573">ðŸ”—</a>Carl Lumma &#x3C;carl@lumma.org&#x3E;</h3><span>4/29/2010 1:06:31 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Hi Mike,</p><p>I assume you&apos;ve run this by Paul?  What does he think?  -Carl</p><p>At 12:26 AM 4/29/2010, you wrote:<br/>&gt;Rick is on a crusade to get the word &quot;virtual pitch&quot; changed because<br/>&gt;it&apos;s a actually a &quot;real&quot; pitch because pseudoperiodicities are real. I<br/>&gt;think the overall goal now is to find a precise mathematical way to<br/>&gt;get from a complex interval like 501/400 to 5/4, or even from 81/64 to<br/>&gt;5/4.<br/>&gt;<br/>&gt;Here&apos;s a possible solution: convolve the waveform with a sawtooth<br/>&gt;wave, or some form of impulse train with a rolloff. Make it be<br/>&gt;exponentially damped. We&apos;ll call this filtering function c(wt)<br/>&gt;(pretend the w is an authoritative-sounding greek omega sign). Its<br/>&gt;frequency spectrum should look like a feedback comb filter with some<br/>&gt;kind of rolloff, and of a Q that you will basically be picking with<br/>&gt;however much damping you choose.<br/>&gt;<br/>&gt;Convolve the waveform with all of these for all w, and then get the<br/>&gt;total energy for each resulting waveform, and then plot the resulting<br/>&gt;energy(w). If you pick your rolloff and damping properly, you&apos;ll note<br/>&gt;that this will basically give you what you&apos;re looking for: 81/64 will<br/>&gt;generate a huge spike two octaves below the 64 as if it were really<br/>&gt;5/4. You will also see some other huge spikes, and this resulting<br/>&gt;curve basically shows you all of the &quot;possible fundamentals&quot; that the<br/>&gt;brain could pick for any given chord, as well as the probability that<br/>&gt;it will pick each one. (Normalize it so that the sum is 1 and you have<br/>&gt;a brand new type of harmonic entropy to work with, and for chords to<br/>&gt;boot. Voila!)<br/>&gt;<br/>&gt;The damping refers to the tendency of the periodicity mechanism to<br/>&gt;stop tracking the same frequency forever and instead resonate at close<br/>&gt;pseudo-periodicities (which you are noticing yourself visually), and<br/>&gt;the rolloff refers to the fact that higher harmonics generate much<br/>&gt;weaker fundamentals than lower ones.<br/>&gt;<br/>&gt;In complete layman&apos;s terms: come up with a filterbank of low-passed<br/>&gt;comb filters (an infinitely dense one, in fact), set the incoming<br/>&gt;waveform into all of them and see what sticks. I think this is an<br/>&gt;excellent model for how the brain does what it does, although I&apos;m<br/>&gt;unsure as to the exact coefficients for the rolloff and the damping.<br/>&gt;I&apos;m pretty sure the damping changes with the situation, analogous to<br/>&gt;how the free &quot;s&quot; parameter can change in Paul&apos;s HE model.<br/>&gt;<br/>&gt;I call it &quot;Harmonic Profiling,&quot; and I&apos;ll have some MATLAB code for you<br/>&gt;all to play around with as soon as I stop going through this<br/>&gt;post-college-graduate financial crisis that I&apos;m going through.<br/>&gt;<br/>&gt;-Mike</p></div><h3><a id=17575 href="#17575">ðŸ”—</a>Mike Battaglia &#x3C;battaglia01@gmail.com&#x3E;</h3><span>4/29/2010 1:34:52 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On Thu, Apr 29, 2010 at 4:06 AM, Carl Lumma &lt;<a href="mailto:carl@lumma.org">carl@lumma.org</a>&gt; wrote:<br/>&gt; Hi Mike,<br/>&gt;<br/>&gt; I assume you&apos;ve run this by Paul? What does he think? -Carl</p><p>I haven&apos;t run it by him yet. The last time I spoke with Paul about<br/>crazy mathematical stuff was when I was trying to come up with a quick<br/>approximation for the classic HE curve so that we could finally see<br/>how triads and tetrads would turn up. After we spoke about it at<br/>length I started to get on this wavelength instead and abandoned the<br/>process. I didn&apos;t want to bother him with my unfinished train of<br/>thought until I had worked all of the math out, since I know he&apos;s busy<br/>these days.</p><p>I&apos;m still sorting some of the details out though, namely how best to<br/>interpret the resulting curve; whether it represents all of the<br/>possible fundamentals produced, or the full set of all of the<br/>simultaneous fundamentals produced. It could be either in different<br/>cases and I haven&apos;t figured out a clear algorithm to differentiate<br/>between the two yet, save just using my ears. I was planning on<br/>sending it Paul&apos;s way once that was figured out.</p><p>-Mike</p></div><h3><a id=17576 href="#17576">ðŸ”—</a>Mike Battaglia &#x3C;battaglia01@gmail.com&#x3E;</h3><span>4/29/2010 2:26:10 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Also, this approach is different when compared to HE in a few<br/>respects. HE is an overall measure of how consonant a chord is. This<br/>is more of a measure of what is &quot;happening&quot; in a chord<br/>psychoacoustically and what it&apos;s made of. It&apos;s also an extension of my<br/>more recent thinking that there really is no singular dimension of<br/>&quot;consonance&quot; but rather different &quot;flavors&quot; of it, especially when<br/>chords are involved. However, if you do want to come up with a single<br/>measure of &quot;consonance&quot; for a chord, you could do it just by using the<br/>resulting profile as the basis for a sort of &quot;continuous entropy&quot;<br/>calculation.</p><p>How will it compare to classic HE if you do that? For dyads, I think<br/>it&apos;ll probably work out to be about the same as dyadic HE. For triads<br/>I think it will be somewhat similar to calculating the triadic HE, and<br/>then the dyadic HE of each of the sub-dyads, somehow weighting them<br/>and then coming up with an overall entropy measure based on that<br/>information. For tetrads you first get the tetradic HE, then the HE of<br/>each of the sub-triads, then the HE of each of the sub-dyads, and so<br/>on.</p><p>-Mike</p></div><h3><a id=17577 href="#17577">ðŸ”—</a>Mike Battaglia &#x3C;battaglia01@gmail.com&#x3E;</h3><span>4/29/2010 2:26:30 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Ideologically there&apos;s one more difference that I also think is<br/>important: HE comes from a psychoacoustics and information theory<br/>paradigm. It involves coming up with a set of possible &quot;matches&quot; for<br/>an interval (via the Farey series calculation), giving each interval a<br/>&quot;domain&quot; (from the mediant with the next lowest interval to the<br/>mediant with the next highest interval), assigning the incoming dyad a<br/>gaussian curve representing the probability that it will be perceived<br/>as any interval along the spectrum, and then coming up with an entropy<br/>curve based on that.</p><p>This model instead comes from a psychoacoustics and signal processing<br/>paradigm. Instead of a Farey series of intervals, it comes up with a<br/>continuous set of harmonic series that any incoming tones could fit<br/>into. Instead of mediant-based weighting, the weighting is done by the<br/>rolloff of the filter - higher harmonics are weighted as contributing<br/>less to the strength of the fundamental than do lower ones. The<br/>assignment of the logarithmically-skewed Gaussian &quot;range&quot; to the<br/>incoming dyad is replaced by the interaction between each harmonic&apos;s<br/>own linear Gaussian &quot;range&quot; and the linear &quot;ranges&quot; of nearby<br/>competing harmonics from different fundamentals. Emerging from this<br/>property of the model is that that higher harmonics have less of a<br/>&quot;tolerance&quot; for mistuning than lower harmonics, and that this<br/>tolerance is also limited by the &quot;span&quot; a harmonic has to other<br/>nearby, stronger harmonics.</p><p>By far the weakest part of this model has been finding a good rolloff.<br/>I think a 1/N^x weighting isn&apos;t going to be the best way to go. I<br/>believe a value of x as 1.5 worked the best, but still not good<br/>enough. I have a hunch, though, that whenever I do figure it out, that<br/>the end result will be very close to the Farey Series +<br/>mediant-weighting + Gaussian probability curve approach. Which might<br/>then possibly illuminate how those things might emerge from more<br/>fundamental tenets of signal processing.</p><p>-Mike</p></div>