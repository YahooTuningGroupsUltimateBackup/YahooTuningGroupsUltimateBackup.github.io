<a href="/tuning-math">back to list</a><h1>CAT tuning</h1><h3>genewardsmith &#x3C;genewardsmith@sbcglobal.net&#x3E;</h3><span>4/29/2010 6:13:12 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Suppose we have a val v for an n edo. Dividing by successive log2(prime) for the successive primes, we get a vector in some vector space which Graham had a name for which I have forgotten. These have coefficients which are all approximately n; call this thing V. We can apply our favorite measure of central tendency to these values clustered around n, and get a value m. Call the vector [m m m ... m] as M, where the dimension is the same as of V. M has the same measure of central tendency m as V, and hence V-M has an average of 0. If we now take a vector N = [n n n ... n], it has an average value of n. Hence V-M+N has an average of n. If we multiply through the successive values by log2(prime), and then scalar multiply by 1200/n, we get a tuning map valued in cents.</p><p>I propose calling this family of tunings &quot;Center Additively Translated&quot;, or CAT tunings. What, you are probably asking, is the point of a CAT tuning? This emerges when we take wedge products. The wedge products of M, N, and N-M with each other vanish, and hence the wedge products of CAT tuned mappings are the same as those from the original Vs. What are these wedge products? If we multiply through by the corresponding pair of log2(prime) for each entry, we get the wedgie (up to sign). This weighted wedgie is something I&apos;ve mentioned in connection with complexity measurement.</p><p>Of course, since the wedge product is bilinear, what you get by stretching and shrinking is also in proportion, but it isn&apos;t invariant with respect to the choice of mappings to wedge together. Whether this has any real significance I will leave for subsequent considerations to decide.</p></div><h3>Carl Lumma &#x3C;carl@lumma.org&#x3E;</h3><span>4/29/2010 7:37:30 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Gene wrote:</p><p>&gt;Suppose we have a val v for an n edo. Dividing by successive<br/>&gt;log2(prime) for the successive primes, we get a vector in some vector<br/>&gt;space which Graham had a name for which I have forgotten. These have<br/>&gt;coefficients which are all approximately n; call this thing V. We can<br/>&gt;apply our favorite measure of central tendency to these values<br/>&gt;clustered around n, and get a value m. Call the vector [m m m ... m]<br/>&gt;as M, where the dimension is the same as of V. M has the same measure<br/>&gt;of central tendency m as V, and hence V-M has an average of 0. If we<br/>&gt;now take a vector N = [n n n ... n], it has an average value of n.<br/>&gt;Hence V-M+N has an average of n. If we multiply through the successive<br/>&gt;values by log2(prime), and then scalar multiply by 1200/n, we get a<br/>&gt;tuning map valued in cents.<br/>&gt;I propose calling this family of tunings &quot;Center Additively<br/>&gt;Translated&quot;, or CAT tunings. What, you are probably asking, is the<br/>&gt;point of a CAT tuning? This emerges when we take wedge products. The<br/>&gt;wedge products of M, N, and N-M with each other vanish, and hence the<br/>&gt;wedge products of CAT tuned mappings are the same as those from the<br/>&gt;original Vs. What are these wedge products? If we multiply through by<br/>&gt;the corresponding pair of log2(prime) for each entry, we get the<br/>&gt;wedgie (up to sign). This weighted wedgie is something I&apos;ve mentioned<br/>&gt;in connection with complexity measurement.</p><p>Ok, so TOP and TOP-RMS are both CAT.</p><p>&gt;Of course, since the wedge product is bilinear, what you get by<br/>&gt;stretching and shrinking is also in proportion, but it isn&apos;t invariant<br/>&gt;with respect to the choice of mappings to wedge together.</p><p>Hm.</p><p>-Carl</p></div><h3>genewardsmith &#x3C;genewardsmith@sbcglobal.net&#x3E;</h3><span>4/29/2010 10:11:04 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Carl Lumma &lt;carl@...&gt; wrote:</p><p>&gt; Ok, so TOP and TOP-RMS are both CAT.</p><p>I get that TOP for 5-limit 12-et has a tuning map</p><p>[1197.6740698521903352, 1896.3172772659680307,<br/>2794.5728296551107820]</p><p>whereas 5-limit midrange CAT tuning is</p><p>1197.6695528043651638, 1896.3063285850080046,<br/>2794.5888691828040084]</p><p>Obviously this huge difference, amounting to more than 0.016 cents in the case of the map from 5, makes then two tunings distinct.</p></div><h3>Graham Breed &#x3C;gbreed@gmail.com&#x3E;</h3><span>4/30/2010 10:18:51 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On 30 April 2010 03:13, genewardsmith &lt;<a href="mailto:genewardsmith@sbcglobal.net">genewardsmith@sbcglobal.net</a>&gt; wrote:<br/>&gt; Suppose we have a val v for an n edo. Dividing by<br/>&gt; successive log2(prime) for the successive primes,<br/>&gt; we get a vector in some vector space which Graham<br/>&gt; had a name for which I have forgotten. These have<br/>&gt; coefficients which are all approximately n; call this<br/>&gt; thing V. We can apply our favorite measure of central<br/>&gt; tendency to these values clustered around n, and get<br/>&gt; a value m. Call the vector [m m m ... m] as M, where<br/>&gt; the dimension is the same as of V. M has the same<br/>&gt; measure of central tendency m as V, and hence V-M<br/>&gt; has an average of 0. If we now take a vector N =<br/>&gt; [n n n ... n], it has an average value of n. Hence<br/>&gt; V-M+N has an average of n. If we multiply through the<br/>&gt; successive values by log2(prime), and then scalar<br/>&gt; multiply by 1200/n, we get a tuning map valued in cents.</p><p>I called it tuning space, because each point specifies the tuning of<br/>the prime intervals.  It isn&apos;t a temperament space because not all<br/>points map to a system of lower rank.  And it isn&apos;t a val space<br/>because the vals (as I understand them) are only the lattice points.</p><p>Right, so, what&apos;s a &quot;measure of central tendency&quot;?  Ah, &quot;These<br/>measures indicate the middle or center of a distribution.&quot;</p><p><a href="http://writing.colostate.edu/guides/research/glossary">http://writing.colostate.edu/guides/research/glossary</a></p><p>Or synonym of &quot;average&quot; according to Wikipedia.  So the RMS and<br/>mean-abs are measures of central tendency, and so is the (max+min)/2<br/>used in the TOP-max formulae.</p><p>So, V - M = 0.  Where did M come from again?</p><p>Perhaps this is a generalization of something I called zero mean<br/>deviation, anyway.  Or something more devious that I got to come out<br/>as DZMS.</p><p>&gt; I propose calling this family of tunings &quot;Center Additively<br/>&gt; Translated&quot;, or CAT tunings. What, you are probably asking,<br/>&gt; is the point of a CAT tuning? This emerges when we take<br/>&gt; wedge products. The wedge products of M, N, and N-M with<br/>&gt; each other vanish, and hence the wedge products of CAT<br/>&gt; tuned mappings are the same as those from the original Vs.<br/>&gt; What are these wedge products? If we multiply through by<br/>&gt; the corresponding pair of log2(prime) for each entry, we get<br/>&gt; the wedgie (up to sign). This weighted wedgie is something<br/>&gt; I&apos;ve mentioned in connection with complexity measurement.</p><p>Wedge products, right.</p><p>&gt; Of course, since the wedge product is bilinear, what you get<br/>&gt; by stretching and shrinking is also in proportion, but it isn&apos;t<br/>&gt; invariant with respect to the choice of mappings to wedge<br/>&gt; together. Whether this has any real significance I will leave<br/>&gt; for subsequent considerations to decide.</p><p>I don&apos;t know.  Zero mean deviation made some calculations easier, but<br/>I didn&apos;t think it had any great significance.</p><p>                        Graham</p></div><h3>genewardsmith &#x3C;genewardsmith@sbcglobal.net&#x3E;</h3><span>4/30/2010 11:39:45 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Graham Breed &lt;gbreed@...&gt; wrote:</p><p>&gt; Right, so, what&apos;s a &quot;measure of central tendency&quot;?  Ah, &quot;These<br/>&gt; measures indicate the middle or center of a distribution.&quot;<br/>&gt;<br/>&gt; <a href="http://writing.colostate.edu/guides/research/glossary">http://writing.colostate.edu/guides/research/glossary</a><br/>&gt;<br/>&gt; Or synonym of &quot;average&quot; according to Wikipedia.  So the RMS and<br/>&gt; mean-abs are measures of central tendency, and so is the (max+min)/2<br/>&gt; used in the TOP-max formulae.</p><p>Better known under the names &quot;mean&quot;, &quot;median&quot; and &quot;midrange&quot;.</p><p><a href="http://en.wikipedia.org/wiki/Arithmetic_mean">http://en.wikipedia.org/wiki/Arithmetic_mean</a><br/><a href="http://en.wikipedia.org/wiki/Median">http://en.wikipedia.org/wiki/Median</a><br/><a href="http://en.wikipedia.org/wiki/Mid-range">http://en.wikipedia.org/wiki/Mid-range</a></p></div><h3>Graham Breed &#x3C;gbreed@gmail.com&#x3E;</h3><span>4/30/2010 11:34:00 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On 30 April 2010 09:11, genewardsmith &lt;<a href="mailto:genewardsmith@sbcglobal.net">genewardsmith@sbcglobal.net</a>&gt; wrote:</p><p>&gt; I get that TOP for 5-limit 12-et has a tuning map<br/>&gt;<br/>&gt; [1197.6740698521903352, 1896.3172772659680307,<br/>&gt; 2794.5728296551107820]</p><p>Oh, shrunk not stretched.  That means there&apos;s a bug on my website :(</p><p>&gt; whereas 5-limit midrange CAT tuning is<br/>&gt;<br/>&gt; 1197.6695528043651638, 1896.3063285850080046,<br/>&gt; 2794.5888691828040084]</p><p>The unstretched tuning map is</p><p>[1200.0, 1900.0, 2800.0]</p><p>That&apos;s CAT stretched by a factor of about 1.001942039329696</p><p>The unstretched, weighted tuning map is</p><p>w = [1.0, 0.99897210982147422, 1.0049119688379171]</p><p>[max(w) + min(w)]/2 is the same number as above.  So when you say<br/>&quot;apply our favorite measure of central tendency to these values&quot; you<br/>mean you divide by it.  There we go, I know what you&apos;re talking about<br/>now.</p><p>It looks like it is the zero mean deviation when you use a mean as the<br/>average.  But I can&apos;t find a mention of this in primerr.pdf.  I&apos;ll<br/>check the revision control tonight to see if it used to be there, as I<br/>suspect it was.  The point of it was that the RMS and standard<br/>deviation of the weighted tuning maps end up the same.</p><p>                           Graham</p></div><h3>Graham Breed &#x3C;gbreed@gmail.com&#x3E;</h3><span>4/30/2010 11:44:00 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>I wrote:<br/>&gt; It looks like it is the zero mean deviation when you use a mean as the<br/>&gt; average. &nbsp;But I can&apos;t find a mention of this in primerr.pdf. &nbsp;I&apos;ll<br/>&gt; check the revision control tonight to see if it used to be there, as I<br/>&gt; suspect it was. &nbsp;The point of it was that the RMS and standard<br/>&gt; deviation of the weighted tuning maps end up the same.</p><p>Weighted errors, rather.  The standard deviation of the weighted<br/>tuning map is always an approximation to the optimal error (and you<br/>can generalize this to other measures of dispersion).  The ZMD tuning<br/>has the property that the RMS weighted error is equal to the STD<br/>weighted error, and so approximates the TOP-RMS error.  It would be<br/>useful if the TOP-RMS tuning were difficult to calculate.</p><p>                              Graham</p></div><h3>Carl Lumma &#x3C;carl@lumma.org&#x3E;</h3><span>5/1/2010 12:03:39 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Graham wrote:<br/>&gt;[max(w) + min(w)]/2 is the same number as above.  So when you say<br/>&gt;&quot;apply our favorite measure of central tendency to these values&quot; you<br/>&gt;mean you divide by it.  There we go, I know what you&apos;re talking about<br/>&gt;now.</p><p>See also:  <a href="http://groups.yahoo.com/group/tuning/message/88394">http://groups.yahoo.com/group/tuning/message/88394</a></p><p>-Carl</p></div><h3>Graham Breed &#x3C;gbreed@gmail.com&#x3E;</h3><span>5/1/2010 12:52:43 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On 1 May 2010 11:03, Carl Lumma &lt;<a href="mailto:carl@lumma.org">carl@lumma.org</a>&gt; wrote:<br/>&gt; Graham wrote:<br/>&gt;&gt;[max(w) + min(w)]/2 is the same number as above. &nbsp;So when you say<br/>&gt;&gt;&quot;apply our favorite measure of central tendency to these values&quot; you<br/>&gt;&gt;mean you divide by it. &nbsp;There we go, I know what you&apos;re talking about<br/>&gt;&gt;now.<br/>&gt;<br/>&gt; See also: &nbsp;<a href="http://groups.yahoo.com/group/tuning/message/88394">http://groups.yahoo.com/group/tuning/message/88394</a></p><p>Ah, right, so TOP-max should be this kind of CAT.  Why does Gene get<br/>something different?  Hmm.  I think I got muddled up and was using TOP<br/>instead of CAT before.  So TOP-max really seems to be what I thought<br/>CAT with half-range was.  And I still don&apos;t understand CAT.  It<br/>doesn&apos;t even look like a valid stretch of 12-equal.</p><p>                        Graham</p></div><h3>genewardsmith &#x3C;genewardsmith@sbcglobal.net&#x3E;</h3><span>5/1/2010 1:48:48 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Graham Breed &lt;gbreed@...&gt; wrote:</p><p>&gt; Ah, right, so TOP-max should be this kind of CAT.  Why does Gene get<br/>&gt; something different?  Hmm.  I think I got muddled up and was using TOP<br/>&gt; instead of CAT before.  So TOP-max really seems to be what I thought<br/>&gt; CAT with half-range was.  And I still don&apos;t understand CAT.  It<br/>&gt; doesn&apos;t even look like a valid stretch of 12-equal.</p><p>Well, CAT is basically pointless I expect. But I still want to stretch weighted vals by dividing by the mean or the median.</p></div><h3>Carl Lumma &#x3C;carl@lumma.org&#x3E;</h3><span>5/1/2010 2:51:28 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>At 12:52 AM 5/1/2010, you wrote:</p><p>&gt;&gt; See also:  <a href="http://groups.yahoo.com/group/tuning/message/88394">http://groups.yahoo.com/group/tuning/message/88394</a><br/>&gt;<br/>&gt;Ah, right, so TOP-max should be this kind of CAT.  Why does Gene get<br/>&gt;something different?  Hmm.  I think I got muddled up and was using TOP<br/>&gt;instead of CAT before.  So TOP-max really seems to be what I thought<br/>&gt;CAT with half-range was.  And I still don&apos;t understand CAT.  It<br/>&gt;doesn&apos;t even look like a valid stretch of 12-equal.<br/>&gt;<br/>&gt;                        Graham</p><p>I get</p><p>&lt; 1197.6740698521903 1896.3172772659682 2794.5728296551106 |</p><p>for 5-limit 12-tone TOP-max.  Gene got</p><p>[ 1197.6740698521903352, 1896.3172772659680307, 2794.5728296551107820 ]</p><p>Other than the fact that he&apos;s clearly giving more digits than<br/>his computing system can handle (:P), we agree.  What are you<br/>doing?  This is a really simple calculation.</p><p>-Carl</p></div><h3>genewardsmith &#x3C;genewardsmith@sbcglobal.net&#x3E;</h3><span>5/1/2010 3:19:16 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Carl Lumma &lt;carl@...&gt; wrote:</p><p>&gt; I get<br/>&gt;<br/>&gt; &lt; 1197.6740698521903 1896.3172772659682 2794.5728296551106 |<br/>&gt;<br/>&gt; for 5-limit 12-tone TOP-max.  Gene got<br/>&gt;<br/>&gt; [ 1197.6740698521903352, 1896.3172772659680307, 2794.5728296551107820 ]<br/>&gt;<br/>&gt; Other than the fact that he&apos;s clearly giving more digits than<br/>&gt; his computing system can handle (:P), we agree.  What are you<br/>&gt; doing?  This is a really simple calculation.</p><p>I&apos;m taking the weighted val, dividing it by the midrange, unweighting it and multiplying by 1200. Top-mean and Top-median are the same as Top-midrange, only using the mean or the median instead. I don&apos;t think Rop-median is a very good idea, though. Top-mean I like.</p></div><h3>Carl Lumma &#x3C;carl@lumma.org&#x3E;</h3><span>5/1/2010 7:43:46 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Gene wrote:</p><p>&gt;&gt; I get<br/>&gt;&gt; &lt; 1197.6740698521903 1896.3172772659682 2794.5728296551106 |<br/>&gt;&gt; Gene got<br/>&gt;&gt; [ 1197.6740698521903352, 1896.3172772659680307, 2794.5728296551107820 ]<br/>&gt;&gt;<br/>&gt;&gt; Other than the fact that he&apos;s clearly giving more digits than<br/>&gt;&gt; his computing system can handle (:P), we agree.<br/>&gt;<br/>&gt;I&apos;m taking the weighted val, dividing it by the midrange, unweighting<br/>&gt;it and multiplying by 1200. Top-mean and Top-median are the same as<br/>&gt;Top-midrange, only using the mean or the median instead. I don&apos;t think<br/>&gt;Rop-median is a very good idea, though. Top-mean I like.</p><p>I was kidding about your computing system, though I would be curious<br/>to know whether maple or scheme is handling this better (you gave more<br/>digits but they don&apos;t round to mine).  I thought both are supposed to<br/>have infinite precision.</p><p>Looping back to what I wrote on Tuning, Graham wants to multiply the<br/>weighted val w by mean(w)/mean-sq(w).  That&apos;s like<br/>(a+b+c...)/(a^2+b^2+c^2...) where a b &amp; c are elements of w.  You want<br/>to multiply by n/(a+b+c...).  In your original post you noted that w<br/>consists of numbers near n (the ET) and in fact, the more accurate the<br/>temperament the more this is true.  So it&apos;s clear that for good<br/>temperaments, both your scalar and Graham&apos;s is close to 1/n and the<br/>resulting product is a vector filled with near-ones.  The question is<br/>how the two scalars differ as the temperament gets worse.</p><p>Paul proved that any bag of intervals has max weighted error less<br/>than the TOP damage.  Getting something similar for one of these CAT<br/>variants seems critical if TOP aka TOP-max aka CAT-max is to be<br/>unseated as the de facto standard.  Kalle seemed to agree.</p><p>-Carl</p></div><h3>genewardsmith &#x3C;genewardsmith@sbcglobal.net&#x3E;</h3><span>5/1/2010 8:02:30 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Carl Lumma &lt;carl@...&gt; wrote:</p><p>&gt; I was kidding about your computing system, though I would be curious<br/>&gt; to know whether maple or scheme is handling this better (you gave more<br/>&gt; digits but they don&apos;t round to mine).  I thought both are supposed to<br/>&gt; have infinite precision.</p><p>You can set the precision level on Maple, but you need to tell it to round off to something sensible to get rid of junk digits and I didn&apos;t bother.</p><p>&gt; Paul proved that any bag of intervals has max weighted error less<br/>&gt; than the TOP damage.  Getting something similar for one of these CAT<br/>&gt; variants seems critical if TOP aka TOP-max aka CAT-max is to be<br/>&gt; unseated as the de facto standard.  Kalle seemed to agree.</p><p>Firstly, these aren&apos;t CAT variants. Forget CAT, it isn&apos;t worth pursuing. Secondly, I think we do have something similar for TOP mean, but I haven&apos;t looked at the question really.</p></div><h3>genewardsmith &#x3C;genewardsmith@sbcglobal.net&#x3E;</h3><span>5/1/2010 9:58:23 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, &quot;genewardsmith&quot; &lt;genewardsmith@...&gt; wrote:</p><p>&gt; Firstly, these aren&apos;t CAT variants. Forget CAT, it isn&apos;t worth pursuing. Secondly, I think we do have something similar for TOP mean, but I haven&apos;t looked at the question really.</p><p>I&apos;ve thought about this, and it occurs to me that while you can cook up a height function designed to work with TOP-mean, it should&apos;t really matter since it will be bounded with respect to its ratio with Tenney height anyway. These different metrics are bounded with respect to each other, which is why they define the same topology. So, the error of the TOP-mean tuning, divided by Tenney height, ought to be bounded.</p></div><h3>Graham Breed &#x3C;gbreed@gmail.com&#x3E;</h3><span>5/1/2010 11:31:39 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On 2 May 2010 06:43, Carl Lumma &lt;<a href="mailto:carl@lumma.org">carl@lumma.org</a>&gt; wrote:</p><p>&gt; I was kidding about your computing system, though I would be curious<br/>&gt; to know whether maple or scheme is handling this better (you gave more<br/>&gt; digits but they don&apos;t round to mine). &nbsp;I thought both are supposed to<br/>&gt; have infinite precision.</p><p>You can&apos;t have infinite precision floats.  You may have arbitrary<br/>precision, but you have to set it.  I forgot until now that Python<br/>does come with this as standard in the Decimal type.  So here&apos;s the<br/>TOP-max tuning map for 5-limit 12-equal given a precision of 30<br/>(whatever that means)</p><p>&lt;1197.67406985219033511192385283,<br/>1896.31727726596803059387943365, 2794.57282965511078192782232328]</p><p>I calculated it using the 2/(max(w)+min(w)) method and verified it to<br/>most of these digits using different calculations:</p><p>0.00296417296773805329795313419<br/>0.002964172967738053297953134194<br/>0.00296417296773805329795313419681</p><p>One of those converted to cents/octave:</p><p>3.55700756128566395754376102800</p><p>The TOP-max scale stretch is</p><p>0.998061724876825279259936544028</p><p>TOP-RMS:</p><p>0.998700288812473324599129797606</p><p>TOP-like zero mean deviation (the thing Gene&apos;s talking about):</p><p>0.998706981175809944769329868549</p><p>The TOP-RMS error in cents/octave:</p><p>3.10636124174717351638458621504</p><p>The related standard deviation error:</p><p>3.11039344698373043622764925746</p><p>The related RMS error for the zero mean deviation:</p><p>3.10637164970614308020782531921</p><p>So that isn&apos;t the same as the STD error.  But it is the tuning for<br/>which RMS error and STD error are identical.</p><p>You could do the same calculations with bc, which is a standard Unix<br/>utility that you can probably download for Windows, but I haven&apos;t.</p><p>Note that the standard deviation of the weighted errors is the same as<br/>the standard deviation of the weighted tuning map.  Sometimes you can<br/>get better precision by working with the errors.</p><p>&gt; Looping back to what I wrote on Tuning, Graham wants to multiply the<br/>&gt; weighted val w by mean(w)/mean-sq(w). &nbsp;That&apos;s like<br/>&gt; (a+b+c...)/(a^2+b^2+c^2...) where a b &amp; c are elements of w. &nbsp;You want<br/>&gt; to multiply by n/(a+b+c...). &nbsp;In your original post you noted that w<br/>&gt; consists of numbers near n (the ET) and in fact, the more accurate the<br/>&gt; temperament the more this is true. &nbsp;So it&apos;s clear that for good<br/>&gt; temperaments, both your scalar and Graham&apos;s is close to 1/n and the<br/>&gt; resulting product is a vector filled with near-ones. &nbsp;The question is<br/>&gt; how the two scalars differ as the temperament gets worse.</p><p>Multiplying the real val is more to the point.  I don&apos;t know why Gene<br/>wants to multiply the weighted val and then un-weight it.  Also, w is<br/>the weighted tuning map, not the weighted val.  You can get the<br/>optimal errors straight from the weighted val but not the scale<br/>stretches.</p><p>I&apos;ve noticed on my website, now that it&apos;s fixed, that some of the<br/>TOP-RMS stretches are looking very similar to the TOP-RMS errors.  It<br/>may be this approximation at work.</p><p>                        Graham</p></div><h3>Carl Lumma &#x3C;carl@lumma.org&#x3E;</h3><span>5/1/2010 11:42:21 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Graham wrote:</p><p>&gt;&gt; I was kidding about your computing system, though I would be curious<br/>&gt;&gt; to know whether maple or scheme is handling this better (you gave more<br/>&gt;&gt; digits but they don&apos;t round to mine).  I thought both are supposed to<br/>&gt;&gt; have infinite precision.<br/>&gt;<br/>&gt;[snip] So here&apos;s the TOP-max tuning map for 5-limit 12-equal given a<br/>&gt;precision of 30 (whatever that means)<br/>&gt;<br/>&gt;&lt;1197.67406985219033511192385283,<br/>&gt;1896.31727726596803059387943365, 2794.57282965511078192782232328]</p><p>Drat.  Both Gene and I gave junk digits, but his were better<br/>than mine.</p><p>&gt;You can&apos;t have infinite precision floats.  You may have arbitrary<br/>&gt;precision, but you have to set it.</p><p>I&apos;m pretty sure I could design a system that never gave incorrect<br/>digits.</p><p>-Carl</p></div><h3>genewardsmith &#x3C;genewardsmith@sbcglobal.net&#x3E;</h3><span>5/1/2010 11:51:21 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Carl Lumma &lt;carl@...&gt; wrote:</p><p>&gt; I&apos;m pretty sure I could design a system that never gave incorrect<br/>&gt; digits.</p><p><a href="http://en.wikipedia.org/wiki/Interval_arithmetic">http://en.wikipedia.org/wiki/Interval_arithmetic</a></p></div><h3>genewardsmith &#x3C;genewardsmith@sbcglobal.net&#x3E;</h3><span>5/1/2010 11:53:44 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Graham Breed &lt;gbreed@...&gt; wrote:</p><p>&gt; Multiplying the real val is more to the point.  I don&apos;t know why Gene<br/>&gt; wants to multiply the weighted val and then un-weight it.</p><p>What do you propose as an alternative Euclidean norm on tuning space?</p></div><h3>Graham Breed &#x3C;gbreed@gmail.com&#x3E;</h3><span>5/2/2010 12:13:34 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On 2 May 2010 10:53, genewardsmith &lt;<a href="mailto:genewardsmith@sbcglobal.net">genewardsmith@sbcglobal.net</a>&gt; wrote:</p><p>&gt; What do you propose as an alternative Euclidean norm on tuning space?</p><p>If you&apos;re using that space, you can find the optimal stretch as the<br/>closest approach on the val line to the JI point.  But for general<br/>arithmetic there&apos;s no need to do that.</p><p>I invented a term there: val line.  It&apos;s the line passing through the<br/>origin and the val.  Each point on it is a different tuning mapped by<br/>the val.  I could also call it a temperament line as each point is a<br/>temperament, most of them stupidly inaccurate.</p><p>The geometry is simple: the optimal tuning of any temperament class is<br/>its closest approach to the JI point.  The TOP-RMS error is the<br/>shortest distance from the temperament line/(hyper-)surface.<br/>Alternatively, it&apos;s the angle between the hypersurface and the JI<br/>line.  (All of these definitions will be off by a constant.)</p><p>If you want to fix the octave stretch, projecting onto the unit<br/>sphere, or a hyperspace passing through the JI point orthogonal to the<br/>origin, might work.  The standard deviation error is probably one of<br/>these.  But beyond the rank 2 case I don&apos;t think it makes anything<br/>simpler.  There&apos;s extra work in throwing away one dimension and then<br/>putting it back again.</p><p>For a single norm, you know my parametric badness, which is a linear<br/>transformation of the tuning space.</p><p>The complexity, in case you missed that, is the distance from the<br/>origin to the val.  It generalizes to higher ranks no problem.</p><p>                         Graham</p></div><h3>genewardsmith &#x3C;genewardsmith@sbcglobal.net&#x3E;</h3><span>5/2/2010 7:49:24 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Graham Breed &lt;gbreed@...&gt; wrote:<br/>&gt;<br/>&gt; On 2 May 2010 10:53, genewardsmith &lt;genewardsmith@...&gt; wrote:<br/>&gt;<br/>&gt; &gt; What do you propose as an alternative Euclidean norm on tuning space?<br/>&gt;<br/>&gt; If you&apos;re using that space, you can find the optimal stretch as the<br/>&gt; closest approach on the val line to the JI point.</p><p>I get it, I think--this is where your TOP-rms stretch comes from.</p><p> But for general<br/>&gt; arithmetic there&apos;s no need to do that.</p><p>What&apos;s general arithmetic?</p><p>&gt; I invented a term there: val line.  It&apos;s the line passing through the<br/>&gt; origin and the val.  Each point on it is a different tuning mapped by<br/>&gt; the val.  I could also call it a temperament line as each point is a<br/>&gt; temperament, most of them stupidly inaccurate.</p><p>You could call it a point in projective space and I wouldn&apos;t object.</p><p>&gt; For a single norm, you know my parametric badness, which is a linear<br/>&gt; transformation of the tuning space.</p><p>I know that, do I?</p></div><h3>genewardsmith &#x3C;genewardsmith@sbcglobal.net&#x3E;</h3><span>5/2/2010 12:29:41 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Graham Breed &lt;gbreed@...&gt; wrote:</p><p>&gt; If you want to fix the octave stretch, projecting onto the unit<br/>&gt; sphere, or a hyperspace passing through the JI point orthogonal to the<br/>&gt; origin, might work.  The standard deviation error is probably one of<br/>&gt; these.  But beyond the rank 2 case I don&apos;t think it makes anything<br/>&gt; simpler.  There&apos;s extra work in throwing away one dimension and then<br/>&gt; putting it back again.</p><p>I proposed &quot;Euclidean tuning&quot; for what you seem to want: that fixes the search for a nearest point to the JI point to a flat whose first coordinate has value 1. Is this a good name? Anyway, it doesn&apos;t seem to involve any extra work throwing things away and then putting them back in.</p></div><h3>Graham Breed &#x3C;gbreed@gmail.com&#x3E;</h3><span>5/2/2010 11:00:24 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On 2 May 2010 18:49, genewardsmith &lt;<a href="mailto:genewardsmith@sbcglobal.net">genewardsmith@sbcglobal.net</a>&gt; wrote:</p><p>&gt; What&apos;s general arithmetic?</p><p>I mean if you have to calculate the stretched tuning, there&apos;s no need<br/>to appeal to the geometry.  It&apos;s easier to stretch the unweighted<br/>tuning map then stretch the weighted one and then unweighted.</p><p>&gt;&gt; I invented a term there: val line. &nbsp;It&apos;s the line passing through the<br/>&gt;&gt; origin and the val. &nbsp;Each point on it is a different tuning mapped by<br/>&gt;&gt; the val. &nbsp;I could also call it a temperament line as each point is a<br/>&gt;&gt; temperament, most of them stupidly inaccurate.<br/>&gt;<br/>&gt; You could call it a point in projective space and I wouldn&apos;t object.</p><p>I don&apos;t think that&apos;s a useful approximation.  You need the full space<br/>to calculate complexity.  And there are different kinds of<br/>projections.  One gives simple badness as error*complexity.</p><p>&gt;&gt; For a single norm, you know my parametric badness, which is a linear<br/>&gt;&gt; transformation of the tuning space.<br/>&gt;<br/>&gt; I know that, do I?</p><p>I gave you a link: <a href="http://x31eq.com/badness.pdf">http://x31eq.com/badness.pdf</a></p><p>It&apos;s only in two columns, so zoom in and try to understand equation 3<br/>if you can&apos;t read the whole thing.</p><p>                         Graham</p></div><h3>genewardsmith &#x3C;genewardsmith@sbcglobal.net&#x3E;</h3><span>5/2/2010 11:40:31 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Graham Breed &lt;gbreed@...&gt; wrote:<br/>&gt;<br/>&gt; &gt;&gt; I invented a term there: val line. &Acirc;&nbsp;It&apos;s the line passing through the<br/>&gt; &gt;&gt; origin and the val. &Acirc;&nbsp;Each point on it is a different tuning mapped by<br/>&gt; &gt;&gt; the val. &Acirc;&nbsp;I could also call it a temperament line as each point is a<br/>&gt; &gt;&gt; temperament, most of them stupidly inaccurate.</p><p>&gt; &gt; You could call it a point in projective space and I wouldn&apos;t object.<br/>&gt;<br/>&gt; I don&apos;t think that&apos;s a useful approximation.</p><p>That was a kind of a joke. It&apos;s not an approximation, it&apos;s a definition:</p><p><a href="http://en.wikipedia.org/wiki/Projective_space">http://en.wikipedia.org/wiki/Projective_space</a></p><p>&gt; &gt; I know that, do I?<br/>&gt;<br/>&gt; I gave you a link: <a href="http://x31eq.com/badness.pdf">http://x31eq.com/badness.pdf</a><br/>&gt;<br/>&gt; It&apos;s only in two columns, so zoom in and try to understand equation 3<br/>&gt; if you can&apos;t read the whole thing.</p><p>Thanks. I&apos;ve been amusing myself with &quot;Measures of Composite Intervals&quot; so I should be able to read it.</p></div><h3>Graham Breed &#x3C;gbreed@gmail.com&#x3E;</h3><span>5/2/2010 11:54:31 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On 3 May 2010 10:40, genewardsmith &lt;<a href="mailto:genewardsmith@sbcglobal.net">genewardsmith@sbcglobal.net</a>&gt; wrote:<br/>&gt;<br/>&gt;<br/>&gt; --- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Graham Breed &lt;gbreed@...&gt; wrote:<br/>&gt;&gt;<br/>&gt;&gt; &gt;&gt; I invented a term there: val line. &Acirc;&nbsp;It&apos;s the line passing through the<br/>&gt;&gt; &gt;&gt; origin and the val. &Acirc;&nbsp;Each point on it is a different tuning mapped by<br/>&gt;&gt; &gt;&gt; the val. &Acirc;&nbsp;I could also call it a temperament line as each point is a<br/>&gt;&gt; &gt;&gt; temperament, most of them stupidly inaccurate.<br/>&gt;<br/>&gt;&gt; &gt; You could call it a point in projective space and I wouldn&apos;t object.<br/>&gt;&gt;<br/>&gt;&gt; I don&apos;t think that&apos;s a useful approximation.<br/>&gt;<br/>&gt; That was a kind of a joke. It&apos;s not an approximation, it&apos;s a definition:<br/>&gt;<br/>&gt; <a href="http://en.wikipedia.org/wiki/Projective_space">http://en.wikipedia.org/wiki/Projective_space</a></p><p>It was probably me picking the wrong word.  You really do need the<br/>full space to get complexity.  And there really is a projective space<br/>that gives error*complexity badness.</p><p>&gt; Thanks. I&apos;ve been amusing myself with &quot;Measures of Composite<br/>&gt; Intervals&quot; so I should be able to read it.</p><p>That one does come in a alternative format:</p><p><a href="http://x31eq.com/composite_onecol.pdf">http://x31eq.com/composite_onecol.pdf</a></p><p>You may also notice the same formula in another guise.</p><p>                     Graham</p></div><h3>Graham Breed &#x3C;gbreed@gmail.com&#x3E;</h3><span>5/3/2010 11:43:49 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On 3 May 2010 10:54, Graham Breed &lt;<a href="mailto:gbreed@gmail.com">gbreed@gmail.com</a>&gt; wrote:<br/>&gt; On 3 May 2010 10:40, genewardsmith &lt;<a href="mailto:genewardsmith@sbcglobal.net">genewardsmith@sbcglobal.net</a>&gt; wrote:</p><p>&gt;&gt; That was a kind of a joke. It&apos;s not an approximation, it&apos;s a definition:<br/>&gt;&gt;<br/>&gt;&gt; <a href="http://en.wikipedia.org/wiki/Projective_space">http://en.wikipedia.org/wiki/Projective_space</a><br/>&gt;<br/>&gt; It was probably me picking the wrong word. &nbsp;You really do need the<br/>&gt; full space to get complexity. &nbsp;And there really is a projective space<br/>&gt; that gives error*complexity badness.</p><p>In fact, there is a definition that matches what you were talking<br/>about there.  So badness space is a projection into another Euclidean<br/>space, not a projective space.</p><p>How does projective space make anything simpler?</p><p>                    Graham</p></div><h3>genewardsmith &#x3C;genewardsmith@sbcglobal.net&#x3E;</h3><span>5/4/2010 12:14:59 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Graham Breed &lt;gbreed@...&gt; wrote:</p><p>&gt; How does projective space make anything simpler?</p><p>There are lots of contexts where projective spaoe makes things simpler, but I doubt this is one of them.</p></div><h3>Graham Breed &#x3C;gbreed@gmail.com&#x3E;</h3><span>5/6/2010 7:17:21 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On 02/05/2010, genewardsmith &lt;<a href="mailto:genewardsmith@sbcglobal.net">genewardsmith@sbcglobal.net</a>&gt; wrote:<br/>&gt;<br/>&gt; --- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Graham Breed &lt;gbreed@...&gt; wrote:<br/>&gt;<br/>&gt;&gt; If you want to fix the octave stretch, projecting onto the unit<br/>&gt;&gt; sphere, or a hyperspace passing through the JI point orthogonal to the<br/>&gt;&gt; origin, might work.  The standard deviation error is probably one of<br/>&gt;&gt; these.  But beyond the rank 2 case I don&apos;t think it makes anything<br/>&gt;&gt; simpler.  There&apos;s extra work in throwing away one dimension and then<br/>&gt;&gt; putting it back again.<br/>&gt;<br/>&gt; I proposed &quot;Euclidean tuning&quot; for what you seem to want: that fixes the<br/>&gt; search for a nearest point to the JI point to a flat whose first coordinate<br/>&gt; has value 1. Is this a good name? Anyway, it doesn&apos;t seem to involve any<br/>&gt; extra work throwing things away and then putting them back in.</p><p>What&apos;s &quot;a flat&quot;?  I still don&apos;t understand this. It does seem to<br/>involve extra work in that you&apos;ve fixed the first coordinate of<br/>something to 1.  TOP-RMS still looks like the obvious Euclidean<br/>tuning.</p><p>                   Graham</p></div><h3>genewardsmith &#x3C;genewardsmith@sbcglobal.net&#x3E;</h3><span>5/6/2010 1:10:25 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Graham Breed &lt;gbreed@...&gt; wrote:</p><p>&gt; &gt; I proposed &quot;Euclidean tuning&quot; for what you seem to want: that fixes the<br/>&gt; &gt; search for a nearest point to the JI point to a flat whose first coordinate<br/>&gt; &gt; has value 1. Is this a good name? Anyway, it doesn&apos;t seem to involve any<br/>&gt; &gt; extra work throwing things away and then putting them back in.</p><p>&gt; What&apos;s &quot;a flat&quot;?</p><p><a href="http://en.wikipedia.org/wiki/Flat_%28geometry%29">http://en.wikipedia.org/wiki/Flat_%28geometry%29</a></p><p>I still don&apos;t understand this. It does seem to<br/>&gt; involve extra work in that you&apos;ve fixed the first coordinate of<br/>&gt; something to 1.  TOP-RMS still looks like the obvious Euclidean<br/>&gt; tuning.</p><p>Of course it is, but it doesn&apos;t have pure octaves.</p></div><h3>Carl Lumma &#x3C;carl@lumma.org&#x3E;</h3><span>5/6/2010 1:29:02 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>At 01:10 PM 5/6/2010, you wrote:<br/>&gt;&gt; TOP-RMS still looks like the obvious Euclidean<br/>&gt;&gt; tuning.<br/>&gt;<br/>&gt;Of course it is, but it doesn&apos;t have pure octaves.</p><p>Forgive me for butting in, but are you guys talking about<br/>the error or the complexity?  When I read Euclidean I think<br/>of Euclidean complexity, e.g. vs. taxicab.  When I read RMS<br/>I think of error.  I can imagine reasons for relating the two<br/>but ultimately, if we wanted to satisfy Paul with a taxicab<br/>complexity and, say, George Secor with a sum-abs error,<br/>there&apos;s nothing preventing this...  is there?</p><p>-Carl</p></div><h3>genewardsmith &#x3C;genewardsmith@sbcglobal.net&#x3E;</h3><span>5/6/2010 4:42:01 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Carl Lumma &lt;carl@...&gt; wrote:</p><p>&gt; Forgive me for butting in, but are you guys talking about<br/>&gt; the error or the complexity?</p><p>Given that the dual space to a vector space with Euclidean norm also has Euclidean norm, an interesting question. The Euclidean distance to the JIP from a point in tuning space (ie weighted vals, etc) is an error measure. The Euclidean norm of an &quot;unweighted&quot; monzo, which is in the dual space to the tuning space, is a height or complexity measure.</p><p>There are various reasons for liking Euclidean norms. One I&apos;ve just now been playing with is projecting an interval to the subspace tempering out a list of intervals. I&apos;ve done that before, but if we are now all happy with the RMS/Euclidean Tenney analogue, we can use it, and it seems to work fine.</p></div><h3>Carl Lumma &#x3C;carl@lumma.org&#x3E;</h3><span>5/6/2010 6:42:50 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Gene wrote:</p><p>&gt;&gt; Forgive me for butting in, but are you guys talking about<br/>&gt;&gt; the error or the complexity?<br/>&gt;<br/>&gt;Given that the dual space to a vector space with Euclidean norm also<br/>&gt;has Euclidean norm, an interesting question. The Euclidean distance to<br/>&gt;the JIP from a point in tuning space (ie weighted vals, etc) is an<br/>&gt;error measure. The Euclidean norm of an &quot;unweighted&quot; monzo, which is<br/>&gt;in the dual space to the tuning space, is a height or complexity measure.</p><p>It&apos;s amazing but I completely understand this.</p><p>&gt;There are various reasons for liking Euclidean norms. One I&apos;ve just<br/>&gt;now been playing with is projecting an interval to the subspace<br/>&gt;tempering out a list of intervals. I&apos;ve done that before, but if we<br/>&gt;are now all happy with the RMS/Euclidean Tenney analogue, we can use<br/>&gt;it, and it seems to work fine.</p><p>Lost you here.  If you can link me to a post describing the<br/>technique, I&apos;ll read it.  In particular, not sure how such a<br/>technique would depend on the particular flavor of TOP used.</p><p>I know Euclidean norms are nice because there&apos;s lots of analysis<br/>you can do with the Pythagorean theorem, etc.</p><p>I can&apos;t tell if Graham&apos;s convinced you that TOP-RMS is better<br/>than TOP-ZMD, but if so I&apos;d like to know why.  Of ZMD, you wrote<br/>on tuning that &quot;Normalizing by the mean is associated to the<br/>Euclidean norm and minimizes the sum of squared error&quot; which sounds<br/>like what Graham&apos;s now claiming of TOP-RMS.  Can you explain the<br/>difference if you&apos;ve figured it out?</p><p>Thanks,</p><p>-Carl</p></div><h3>genewardsmith &#x3C;genewardsmith@sbcglobal.net&#x3E;</h3><span>5/7/2010 1:56:55 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Carl Lumma &lt;carl@...&gt; wrote:</p><p>&gt; &gt;There are various reasons for liking Euclidean norms. One I&apos;ve just<br/>&gt; &gt;now been playing with is projecting an interval to the subspace<br/>&gt; &gt;tempering out a list of intervals. I&apos;ve done that before, but if we<br/>&gt; &gt;are now all happy with the RMS/Euclidean Tenney analogue, we can use<br/>&gt; &gt;it, and it seems to work fine.</p><p>&gt; Lost you here.  If you can link me to a post describing the<br/>&gt; technique, I&apos;ll read it.  In particular, not sure how such a<br/>&gt; technique would depend on the particular flavor of TOP used.</p><p>The technique, orthogonal projection, requires an inner product (Euclidean) space:</p><p><a href="http://en.wikipedia.org/wiki/Projection_%28linear_algebra%29">http://en.wikipedia.org/wiki/Projection_%28linear_algebra%29</a></p><p>The article is, I think, harder than it needs to be and you may find my Maple code easier to digest:</p><p>dot := proc(u, v)<br/># generic dotproduct of lists u and v<br/>local i, s;<br/>if not nops(u)=nops(v) then RETURN(&apos;dimensions&apos;) fi;<br/>s := 0;<br/>for i from 1 to nops(u) do<br/>s := s + u[i]*v[i] od;<br/>expand(s) end:</p><p>rmsproj := proc(u, s)<br/># projection of interval u by comma list s<br/>local i, m, q, t, v, z;<br/>m := plim(u);<br/>for i from 1 to nops(s) do<br/>m := max(m, plim(s[i])) od;<br/>v := unweight(vecl(u, m));<br/>for i from 1 to nops(s) do<br/>z := unweight(vecl(s[i],m));<br/>v := v + q[i]*z od;<br/>v := expand(v);<br/>t := {};<br/>for i from 1 to nops(s) do<br/>z := unweight(vecl(s[i],m));<br/>t := t union {dot(z, v)} od;<br/>z := solve(t);<br/>subs(z, v) end:</p><p>&gt; I can&apos;t tell if Graham&apos;s convinced you that TOP-RMS is better<br/>&gt; than TOP-ZMD, but if so I&apos;d like to know why.</p><p>I liked ZMD because it was so easy to compute and I guessed it would be close to what Graham was doing, but now that I know what Graham is doing, I know it is also pretty easy to compute. The justification for using TOP-RMS seems straightforward, but in practical terms there&apos;s not much to choose between.</p><p> Of ZMD, you wrote<br/>&gt; on tuning that &quot;Normalizing by the mean is associated to the<br/>&gt; Euclidean norm and minimizes the sum of squared error&quot; which sounds<br/>&gt; like what Graham&apos;s now claiming of TOP-RMS.  Can you explain the<br/>&gt; difference if you&apos;ve figured it out?</p><p>ZMD forces the average deviation from the JIP to be zero. For TOP-RMS this average is very nearly, but not exactly, equal to zero.</p></div><h3>Graham Breed &#x3C;gbreed@gmail.com&#x3E;</h3><span>5/7/2010 9:56:44 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On 7 May 2010 00:29, Carl Lumma &lt;<a href="mailto:carl@lumma.org">carl@lumma.org</a>&gt; wrote:</p><p>&gt; Forgive me for butting in, but are you guys talking about<br/>&gt; the error or the complexity? &nbsp;When I read Euclidean I think<br/>&gt; of Euclidean complexity, e.g. vs. taxicab. &nbsp;When I read RMS<br/>&gt; I think of error. &nbsp;I can imagine reasons for relating the two<br/>&gt; but ultimately, if we wanted to satisfy Paul with a taxicab<br/>&gt; complexity and, say, George Secor with a sum-abs error,<br/>&gt; there&apos;s nothing preventing this... &nbsp;is there?</p><p>We&apos;re talking about error, but it goes for complexity as well.</p><p>There are advantages to measuring error and complexity in similar<br/>ways.  Like I show in that good old primerr.pdf, with some kind of RMS<br/>complexity, the optimal RMS error is a simple &quot;badness&quot; function<br/>divided by the complexity.  That is, error*complexity badness is<br/>easier to calculate than the error, and gives the same result whether<br/>or not you use the octave-equivalent approximations.  Also, badness<br/>and complexity are both quadratic forms, which means you can mix them<br/>together to get my parametric badness.  That has some nice algebraic<br/>properties which make the searches easier -- hence my website requires<br/>less user input and returns the answers pretty quickly.</p><p>I don&apos;t know how to get this working with taxicab geometry.  I don&apos;t<br/>even know how to get complexity working beyond rank 2 beyond arbitrary<br/>functions of the wedgie that may or may not have some logic I don&apos;t<br/>understand.</p><p>                                 Graham</p></div><h3>Graham Breed &#x3C;gbreed@gmail.com&#x3E;</h3><span>5/7/2010 10:03:58 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On 7 May 2010 12:56, genewardsmith &lt;<a href="mailto:genewardsmith@sbcglobal.net">genewardsmith@sbcglobal.net</a>&gt; wrote:</p><p>&gt; The technique, orthogonal projection, requires an inner product (Euclidean) space:<br/>&gt;<br/>&gt; <a href="http://en.wikipedia.org/wiki/Projection_%28linear_algebra%29">http://en.wikipedia.org/wiki/Projection_%28linear_algebra%29</a></p><p>Oh, orthogonal projections, there you go.  The simple answer, Carl, to<br/>why standard deviations and covariances get used is that they happen<br/>to be the same formula as orthogonal projections.</p><p>The STD error is a projection orthogonal to the JI line.  That&apos;s the<br/>same as measuring the shortest distance from the temperament point to<br/>the JI line, which I think is what Gene said above in the thread.  The<br/>TOP-RMS error is the shortest distance from the JI point to the<br/>temperament line/plane/whatever.  One of the differences between them<br/>is sine vs tangent, which doesn&apos;t matter because the angle&apos;s so small.<br/> The other is that the TOP-RMS tuning will be a different distance<br/>from the origin, corresponding to the stretch.</p><p>If I&apos;d known about orthogonal projections before I worked through the<br/>algebra the hard way I could have saved myself a lot of trouble.</p><p>                            Graham</p></div><h3>Carl Lumma &#x3C;carl@lumma.org&#x3E;</h3><span>5/7/2010 11:15:19 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Gene wrote:<br/>&gt;ZMD forces the average deviation from the JIP to be zero. For TOP-RMS<br/>&gt;this average is very nearly, but not exactly, equal to zero.</p><p>Thank you.  -C.</p></div><h3>Carl Lumma &#x3C;carl@lumma.org&#x3E;</h3><span>5/7/2010 11:16:28 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Graham wrote:</p><p>&gt;I don&apos;t know how to get this working with taxicab geometry.  I don&apos;t<br/>&gt;even know how to get complexity working beyond rank 2 beyond arbitrary<br/>&gt;functions of the wedgie that may or may not have some logic I don&apos;t<br/>&gt;understand.</p><p>Are you referring to Paul&apos;s weighted wedgie complexity?  -Carl</p></div><h3>Graham Breed &#x3C;gbreed@gmail.com&#x3E;</h3><span>5/7/2010 10:16:51 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On 7 May 2010 22:16, Carl Lumma &lt;<a href="mailto:carl@lumma.org">carl@lumma.org</a>&gt; wrote:<br/>&gt; Graham wrote:<br/>&gt;<br/>&gt;&gt;I don&apos;t know how to get this working with taxicab geometry. &nbsp;I don&apos;t<br/>&gt;&gt;even know how to get complexity working beyond rank 2 beyond arbitrary<br/>&gt;&gt;functions of the wedgie that may or may not have some logic I don&apos;t<br/>&gt;&gt;understand.<br/>&gt;<br/>&gt; Are you referring to Paul&apos;s weighted wedgie complexity? &nbsp;-Carl</p><p>There are two different wedgie complexities: max-abs and mean-abs.<br/>For the rank 2 case they give very consistent results (one is about<br/>double the other).  I don&apos;t know what happens after that.  I remember<br/>Gene and I getting different rank 3 orderings which was partly to do<br/>with the choices of complexity.  RMS and minimax will disagree<br/>sometimes.  My guess is that max-abs is the correct way to do it,<br/>mathematically speaking.</p><p>In practical terms, I still like the old odd-limit complexity.  But I<br/>don&apos;t know how to generalize that to higher ranks.  I&apos;ve been<br/>thinking, though, about a single generator orthogonal to the<br/>Pythagorean plane, like the generator of a rank 2 temperament is<br/>orthogonal to the octave.</p><p>                       Graham</p></div><h3>genewardsmith &#x3C;genewardsmith@sbcglobal.net&#x3E;</h3><span>5/7/2010 11:34:53 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Graham Breed &lt;gbreed@...&gt; wrote:</p><p>&gt; There are advantages to measuring error and complexity in similar<br/>&gt; ways.  Like I show in that good old primerr.pdf, with some kind of RMS<br/>&gt; complexity, the optimal RMS error is a simple &quot;badness&quot; function<br/>&gt; divided by the complexity.</p><p>Can you give an abstract characterizations of this without invoking matrices?</p></div><h3>genewardsmith &#x3C;genewardsmith@sbcglobal.net&#x3E;</h3><span>5/7/2010 11:39:57 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Graham Breed &lt;gbreed@...&gt; wrote:</p><p>&gt; The STD error is a projection orthogonal to the JI line.</p><p>Is the JI line the line through the origin and the JI point or some other line? What is this projection a projection of?</p><p>  That&apos;s the<br/>&gt; same as measuring the shortest distance from the temperament point to<br/>&gt; the JI line, which I think is what Gene said above in the thread.</p><p>I thought we wanted the shortest distance from the temperament line to the JI point.</p><p>The<br/>&gt; TOP-RMS error is the shortest distance from the JI point to the<br/>&gt; temperament line/plane/whatever.</p><p>And I guess I was right, so what were you saying above?</p><p> One of the differences between them<br/>&gt; is sine vs tangent, which doesn&apos;t matter because the angle&apos;s so small.</p><p>What are &quot;them&quot;?</p></div><h3>Graham Breed &#x3C;gbreed@gmail.com&#x3E;</h3><span>5/7/2010 11:49:17 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On 8 May 2010 10:39, genewardsmith &lt;<a href="mailto:genewardsmith@sbcglobal.net">genewardsmith@sbcglobal.net</a>&gt; wrote:<br/>&gt;<br/>&gt; --- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Graham Breed &lt;gbreed@...&gt; wrote:<br/>&gt;<br/>&gt;&gt; The STD error is a projection orthogonal to the JI line.<br/>&gt;<br/>&gt; Is the JI line the line through the origin and the JI point<br/>&gt; or some other line? What is this projection a projection of?</p><p>Yes, that&apos;s the JI line.</p><p>It&apos;s a projection of the weighted deviations from JI.  Which entails<br/>an error space instead of tuning space.  So i don&apos;t know how the<br/>geometry works out.</p><p>&gt;<br/>&gt; &nbsp;That&apos;s the<br/>&gt;&gt; same as measuring the shortest distance from the temperament point to<br/>&gt;&gt; the JI line, which I think is what Gene said above in the thread.<br/>&gt;<br/>&gt; I thought we wanted the shortest distance from the<br/>&gt; temperament line to the JI point.</p><p>That&apos;s TOP-RMS error.</p><p>&gt; The<br/>&gt;&gt; TOP-RMS error is the shortest distance from the JI point to the<br/>&gt;&gt; temperament line/plane/whatever.<br/>&gt;<br/>&gt; And I guess I was right, so what were you saying above?</p><p>STD error.</p><p>&gt; &nbsp;One of the differences between them<br/>&gt;&gt; is sine vs tangent, which doesn&apos;t matter because the angle&apos;s so small.<br/>&gt;<br/>&gt; What are &quot;them&quot;?</p><p>TOP-RMS error and STD error.</p><p>                 Graham</p></div><h3>genewardsmith &#x3C;genewardsmith@sbcglobal.net&#x3E;</h3><span>5/8/2010 12:00:39 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Graham Breed &lt;gbreed@...&gt; wrote:<br/>&gt;<br/>&gt; On 8 May 2010 10:39, genewardsmith &lt;genewardsmith@...&gt; wrote:<br/>&gt; &gt;<br/>&gt; &gt; --- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Graham Breed &lt;gbreed@&gt; wrote:<br/>&gt; &gt;<br/>&gt; &gt;&gt; The STD error is a projection orthogonal to the JI line.<br/>&gt; &gt;<br/>&gt; &gt; Is the JI line the line through the origin and the JI point<br/>&gt; &gt; or some other line? What is this projection a projection of?<br/>&gt;<br/>&gt; Yes, that&apos;s the JI line.<br/>&gt;<br/>&gt; It&apos;s a projection of the weighted deviations from JI.  Which entails<br/>&gt; an error space instead of tuning space.  So i don&apos;t know how the<br/>&gt; geometry works out.</p><p>Why isn&apos;t that Tuning Map - JIP, which is in tuning space?</p><p>&gt; STD error.</p><p>I guess you are taking the average of the coordinates of the tuning map and finding the distance from JIP times this average to the tuning map, which is where the JIP line comes in? This would be looking at Tuning Map - average * JIP, still a point in tuning space.</p></div><h3>Graham Breed &#x3C;gbreed@gmail.com&#x3E;</h3><span>5/8/2010 12:23:41 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On 8 May 2010 10:34, genewardsmith &lt;<a href="mailto:genewardsmith@sbcglobal.net">genewardsmith@sbcglobal.net</a>&gt; wrote:<br/>&gt;<br/>&gt;<br/>&gt; --- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Graham Breed &lt;gbreed@...&gt; wrote:<br/>&gt;<br/>&gt;&gt; There are advantages to measuring error and complexity in similar<br/>&gt;&gt; ways. &nbsp;Like I show in that good old primerr.pdf, with some kind of RMS<br/>&gt;&gt; complexity, the optimal RMS error is a simple &quot;badness&quot; function<br/>&gt;&gt; divided by the complexity.<br/>&gt;<br/>&gt; Can you give an abstract characterizations of this without invoking matrices?</p><p>I can invoke exterior algebra: ||Q^V|| / ||Q|| ||V||</p><p>Or I can invoke geometry.  The complexity is the distance from the<br/>origin to the val point in tuning space.  The TOP-RMS error is the<br/>sine of the angle between the JI line and the val line (or JI and val<br/>vectors) in the same space.</p><p>You can construct a right angled triangle to get that angle.  I can&apos;t<br/>draw diagrams here, so you&apos;ll have to imagine it.  Call it ABC.  A is<br/>the val, B is the origin, C is a point on the JI line.  The length AB<br/>is the distance from the origin to the val, hence the complexity.<br/>I&apos;ll call it k.</p><p>Let&apos;s look at another triangle, involving the JI point and the optimal<br/>tuning.  There, the tuning is the nearest point on the val/tuning line<br/>to the JI point.  You can set the geometry so that the JI point is a<br/>distance of 1 from the origin.  The distance from the JI point to the<br/>val line is the error.  Call it e.  For this to be minimized, there<br/>must be a right angle between the val line and this far side of the<br/>triangle.  Call the angle between the JI and val lines, the smallest<br/>angle in both triangles, t.  Trigonometry gives us</p><p>sin(t) = e/1</p><p>e = sin(t)</p><p>Let&apos;s go back to the first triangle.  As the val point is fixed, it&apos;s<br/>the JI line we need the closest approach to, so the right angle is in<br/>a different place.  But the small angle&apos;s the same, so</p><p>sin(t) = AC/AB</p><p>e = AC/k</p><p>AC = ek</p><p>So the side of the triangle opposite the origin has a length equal to<br/>error*complexity badness.</p><p>To find it, you do an orthogonal projection parallel to the JI line<br/>onto a plane normal to the JI line including the origin.  This is what<br/>standard orthogonal projections do.  The length of AC is unchanged,<br/>but point C (which wasn&apos;t interesting) becomes the origin.  So AC, the<br/>simple badness, is the distance from the origin to the val point under<br/>this projection.</p><p>                        Graham</p></div><h3>Carl Lumma &#x3C;carl@lumma.org&#x3E;</h3><span>5/8/2010 2:00:02 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Gene wrote:</p><p>&gt;&gt; The STD error is a projection orthogonal to the JI line.<br/>&gt;<br/>&gt;Is the JI line the line through the origin and the JI point or some<br/>&gt;other line? What is this projection a projection of?<br/>&gt;<br/>&gt;&gt; That&apos;s the<br/>&gt;&gt; same as measuring the shortest distance from the temperament point to<br/>&gt;&gt; the JI line, which I think is what Gene said above in the thread.<br/>&gt;<br/>&gt;I thought we wanted the shortest distance from the temperament line to<br/>&gt;the JI point.<br/>&gt;<br/>&gt;&gt; The<br/>&gt;&gt; TOP-RMS error is the shortest distance from the JI point to the<br/>&gt;&gt; temperament line/plane/whatever.<br/>&gt;<br/>&gt;And I guess I was right, so what were you saying above?</p><p>I have a draft of an almost identical message in my outbox.  -Carl</p></div><h3>Carl Lumma &#x3C;carl@lumma.org&#x3E;</h3><span>5/8/2010 2:01:59 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Graham wrote</p><p>&gt;&gt;  That&apos;s the<br/>&gt;&gt;&gt; same as measuring the shortest distance from the temperament point to<br/>&gt;&gt;&gt; the JI line, which I think is what Gene said above in the thread.<br/>&gt;&gt;<br/>&gt;&gt; I thought we wanted the shortest distance from the<br/>&gt;&gt; temperament line to the JI point.<br/>&gt;<br/>&gt;That&apos;s TOP-RMS error.<br/>&gt;<br/>&gt;&gt;&gt; The<br/>&gt;&gt;&gt; TOP-RMS error is the shortest distance from the JI point to the<br/>&gt;&gt;&gt; temperament line/plane/whatever.<br/>&gt;&gt;<br/>&gt;&gt; And I guess I was right, so what were you saying above?<br/>&gt;<br/>&gt;STD error.</p><p>So these live in different spaces...  -Carl</p></div><h3>genewardsmith &#x3C;genewardsmith@sbcglobal.net&#x3E;</h3><span>5/8/2010 2:04:07 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Graham Breed &lt;gbreed@...&gt; wrote:</p><p>&gt; &gt; Can you give an abstract characterizations of this without invoking matrices?<br/>&gt;<br/>&gt; I can invoke exterior algebra: ||Q^V|| / ||Q|| ||V||</p><p>Cool. You didn&apos;t define Q and V, but I&apos;m guessing Q is the JI point and V is a weighted val. The above can be rewritten<br/>||Q/||Q|| ^ V/||V||)</p><p>a wedge between two unit vectors. Hence, this would be your measure of TOP-RMS error. Right so far?</p><p>&gt; Or I can invoke geometry.  The complexity is the distance from the<br/>&gt; origin to the val point in tuning space.  The TOP-RMS error is the<br/>&gt; sine of the angle between the JI line and the val line (or JI and val<br/>&gt; vectors) in the same space.</p><p>Complexity is ||V|| and error is ||Q^V||/(||Q|| ||V||)? That would make error*complexity ||Q/||Q|| ^ V||, which would be your badness measure?</p></div><h3>Carl Lumma &#x3C;carl@lumma.org&#x3E;</h3><span>5/8/2010 2:09:58 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Graham wrote:</p><p>&gt;The complexity is the distance from the<br/>&gt;origin to the val point in tuning space.</p><p>Do vals live in tuning space?  We had this debate in the past.<br/>Paul argued that vals with noninteger entries were just points<br/>off the val lattice in tuning space, whereas Gene, if I understood,<br/>argued the vals should live in a space with only integer coordinates.</p><p>But taking what you say above at face value -- the complexity<br/>depends upon the tuning?  That doesn&apos;t seem right.</p><p>-Carl</p></div><h3>Graham Breed &#x3C;gbreed@gmail.com&#x3E;</h3><span>5/8/2010 2:14:32 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On 8 May 2010 13:04, genewardsmith &lt;<a href="mailto:genewardsmith@sbcglobal.net">genewardsmith@sbcglobal.net</a>&gt; wrote:<br/>&gt;<br/>&gt;<br/>&gt; --- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Graham Breed &lt;gbreed@...&gt; wrote:<br/>&gt;<br/>&gt;&gt; &gt; Can you give an abstract characterizations of this without invoking matrices?<br/>&gt;&gt;<br/>&gt;&gt; I can invoke exterior algebra: ||Q^V|| / ||Q|| ||V||<br/>&gt;<br/>&gt; Cool. You didn&apos;t define Q and V, but I&apos;m guessing Q is the JI point and V is a weighted val. The above can be rewritten<br/>&gt; ||Q/||Q|| ^ V/||V||)</p><p>No, the other way round.  But it doesn&apos;t really matter, does it?  I<br/>did define them in another message, as well.</p><p>Whatever it is doesn&apos;t have to be a val.  It could be the &quot;wedgie&quot; for<br/>any rank temperament, as a multivector.</p><p>&gt; a wedge between two unit vectors. Hence, this would be your measure of TOP-RMS error. Right so far?</p><p>Yes.</p><p>&gt;&gt; Or I can invoke geometry. &nbsp;The complexity is the distance from the<br/>&gt;&gt; origin to the val point in tuning space. &nbsp;The TOP-RMS error is the<br/>&gt;&gt; sine of the angle between the JI line and the val line (or JI and val<br/>&gt;&gt; vectors) in the same space.<br/>&gt;<br/>&gt; Complexity is ||V|| and error is ||Q^V||/(||Q|| ||V||)? That would make error*complexity ||Q/||Q|| ^ V||, which would be your badness measure?</p><p>Simple badness is ||Q^V||/||whatever we call the JI point|| where the<br/>denominator is a constant for the given prime limit.  Unless you mess<br/>it up by starting with unit vectors.  (A unit JI vector is fine.)</p><p>                    Graham</p></div><h3>genewardsmith &#x3C;genewardsmith@sbcglobal.net&#x3E;</h3><span>5/8/2010 2:26:06 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Carl Lumma &lt;carl@...&gt; wrote:</p><p>&gt; Do vals live in tuning space?  We had this debate in the past.<br/>&gt; Paul argued that vals with noninteger entries were just points<br/>&gt; off the val lattice in tuning space, whereas Gene, if I understood,<br/>&gt; argued the vals should live in a space with only integer coordinates.</p><p>Not exactly. Vals are, to start out with, elements of a finitely generated free abelian group. But embed a finitely generated free abelian group in a real vector space and you get, by definition, a lattice.</p></div><h3>Graham Breed &#x3C;gbreed@gmail.com&#x3E;</h3><span>5/8/2010 4:54:27 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On 8 May 2010 13:09, Carl Lumma &lt;<a href="mailto:carl@lumma.org">carl@lumma.org</a>&gt; wrote:</p><p>&gt; Do vals live in tuning space?  We had this debate in the past.<br/>&gt; Paul argued that vals with noninteger entries were just points<br/>&gt; off the val lattice in tuning space, whereas Gene, if I understood,<br/>&gt; argued the vals should live in a space with only integer coordinates.</p><p>You can say that vals live in a val lattice and tunings exist in<br/>tuning space.  But, still, certain points in tuning space look very<br/>much like vals.</p><p>&gt; But taking what you say above at face value -- the complexity<br/>&gt; depends upon the tuning?  That doesn&apos;t seem right.</p><p>If you define complexity as the number of consonances per octave, it<br/>does depend on the tuning of the octave.</p><p>The val as a point in tuning space isn&apos;t a tuning.  It does define a<br/>set of tunings, which lie on the line in tuning space linking the val<br/>to the origin.  One of those points is the TOP-RMS tuning.</p><p>Say you have 12 note equal temperament.  You can find a false val on<br/>the right line but exactly 12 units from the origin.  You can still<br/>construct a triangle to get the right badness, though.  Divide by the<br/>complexity of the false val and you get the STD error.  Scale down by<br/>12 units and you have a point corresponding to the STD tuning with a<br/>distance to the JI point corresponding to the STD error.  So there is<br/>a relationship between vals, tunings, complexity, and error.</p><p>                                Graham</p></div><h3>Graham Breed &#x3C;gbreed@gmail.com&#x3E;</h3><span>5/8/2010 5:00:08 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On 8 May 2010 13:01, Carl Lumma &lt;<a href="mailto:carl@lumma.org">carl@lumma.org</a>&gt; wrote:<br/>&gt; Graham wrote</p><p>&gt;&gt;That&apos;s TOP-RMS error.</p><p>&gt;&gt;STD error.<br/>&gt;<br/>&gt; So these live in different spaces... &nbsp;-Carl</p><p>It depends on what you mean by &quot;space&quot;.  If it&apos;s a set of a points<br/>with certain algebraic properties and a metric, then they&apos;re different<br/>spaces, because the two metrics are different.  But the sets of points<br/>are the same.</p><p>Error space would be tuning space translated so that the JI point is<br/>at the origin.  I think STD error comes from a projection in error<br/>space but it must be some transformation of tuning space as well.<br/>Simple badness is a distance measured in a projection of tuning space.</p><p>                           Graham</p></div><h3>genewardsmith &#x3C;genewardsmith@sbcglobal.net&#x3E;</h3><span>5/8/2010 1:28:55 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Graham Breed &lt;gbreed@...&gt; wrote:</p><p>&gt; You can say that vals live in a val lattice and tunings exist in<br/>&gt; tuning space.  But, still, certain points in tuning space look very<br/>&gt; much like vals.</p><p>That&apos;s because the lattice is a lattice in tuning space.</p><p>&gt; The val as a point in tuning space isn&apos;t a tuning.  It does define a<br/>&gt; set of tunings, which lie on the line in tuning space linking the val<br/>&gt; to the origin.</p><p>The projective val. I used to think Paul liked those and you didn&apos;t.</p><p>&gt; Say you have 12 note equal temperament.  You can find a false val on<br/>&gt; the right line but exactly 12 units from the origin.</p><p>What&apos;s a false val?</p></div><h3>Carl Lumma &#x3C;carl@lumma.org&#x3E;</h3><span>5/8/2010 2:48:41 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Graham wrote:</p><p>&gt;&gt; But taking what you say above at face value -- the complexity<br/>&gt;&gt; depends upon the tuning?  That doesn&apos;t seem right.<br/>&gt;<br/>&gt;If you define complexity as the number of consonances per octave, it<br/>&gt;does depend on the tuning of the octave.</p><p>What kind of complexity is this??  It sounds more like the inverse<br/>of complexity for a constant number of notes/octave.</p><p>&gt;The val as a point in tuning space isn&apos;t a tuning.  It does define a<br/>&gt;set of tunings, which lie on the line in tuning space linking the val<br/>&gt;to the origin.  One of those points is the TOP-RMS tuning.</p><p>We should say how the axes are scaled.  I can think of</p><p>* weighted log units, JIP is [1 1 1 ...]</p><p>* constant log units, JIP is [1200 1901.955 ...]</p><p>* relative log units, JIP is [12 19.01955 27.86314 ...]<br/>or [31 49.13384 71.97977 ...] ...  Are the JIPs colinear here?<br/>Maybe that&apos;s what you were talking about &quot;JI line&quot;.</p><p>Do you have names for each of these?  The val lattice must be<br/>found in the latter, which looks like a different beast to the<br/>first two.</p><p>If we call them weighted tuning space, tuning space, and val<br/>space, respectively, then I could almost believe a point in<br/>val space is a line in either of the tuning spaces.  If the<br/>JIP really is a JIL in val space.  That would make the spaces<br/>duals or something.</p><p>You convinced me before that with a Euclidean norm on val space,<br/>the distance from the origin to a point is a good complexity<br/>(unweighted though).</p><p>For error we want definitely want weighted tuning space.<br/>I believe rank 1 temperaments are lines in this space, which<br/>fits the idea that vals are lines.  Then we want the point on<br/>the line closest to the JIP and the only choice is: which norm.<br/>You claim TOP-RMS is the answer if we choose a Euclidean norm,<br/>which is believable since the formula for RMS looks a lot<br/>Euclidean distance.</p><p>Rank 2 temperaments would be planes I suppose.</p><p>-Carl</p></div><h3>Graham Breed &#x3C;gbreed@gmail.com&#x3E;</h3><span>5/8/2010 10:41:19 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On 9 May 2010 01:48, Carl Lumma &lt;<a href="mailto:carl@lumma.org">carl@lumma.org</a>&gt; wrote:<br/>&gt; Graham wrote:<br/>&gt;<br/>&gt;&gt;&gt; But taking what you say above at face value -- the complexity<br/>&gt;&gt;&gt; depends upon the tuning? &nbsp;That doesn&apos;t seem right.<br/>&gt;&gt;<br/>&gt;&gt;If you define complexity as the number of consonances per octave, it<br/>&gt;&gt;does depend on the tuning of the octave.<br/>&gt;<br/>&gt; What kind of complexity is this?? &nbsp;It sounds more like the inverse<br/>&gt; of complexity for a constant number of notes/octave.</p><p>Erm, yes.  But however complexity&apos;s defined, it&apos;s the number something<br/>per octave, or some other reference interval.</p><p>&gt;&gt;The val as a point in tuning space isn&apos;t a tuning. &nbsp;It does define a<br/>&gt;&gt;set of tunings, which lie on the line in tuning space linking the val<br/>&gt;&gt;to the origin. &nbsp;One of those points is the TOP-RMS tuning.<br/>&gt;<br/>&gt; We should say how the axes are scaled. &nbsp;I can think of<br/>&gt;<br/>&gt; * weighted log units, JIP is [1 1 1 ...]</p><p>That&apos;s Tenney-weighted tuning space.</p><p>&gt; * constant log units, JIP is [1200 1901.955 ...]</p><p>Equal weighting, which isn&apos;t the same thing.</p><p>&gt; * relative log units, JIP is [12 19.01955 27.86314 ...]<br/>&gt; or [31 49.13384 71.97977 ...] ... &nbsp;Are the JIPs colinear here?<br/>&gt; Maybe that&apos;s what you were talking about &quot;JI line&quot;.</p><p>Yes, the JI line is the line through the JI point.</p><p>&gt; Do you have names for each of these? &nbsp;The val lattice must be<br/>&gt; found in the latter, which looks like a different beast to the<br/>&gt; first two.</p><p>The val lattice is found in the first one, and the metric defines complexity.</p><p>&gt; If we call them weighted tuning space, tuning space, and val<br/>&gt; space, respectively, then I could almost believe a point in<br/>&gt; val space is a line in either of the tuning spaces. &nbsp;If the<br/>&gt; JIP really is a JIL in val space. &nbsp;That would make the spaces<br/>&gt; duals or something.</p><p>Not duals.  The metrics would be different.  In tuning space you<br/>measure pitch differences or errors, and in val space you measure<br/>complexity.  Except the metrics are really the same.</p><p>&gt; You convinced me before that with a Euclidean norm on val space,<br/>&gt; the distance from the origin to a point is a good complexity<br/>&gt; (unweighted though).</p><p>Yes.  But only for lattice points.  It doesn&apos;t make sense to talk<br/>about the complexity of a tuning.</p><p>&gt; For error we want definitely want weighted tuning space.<br/>&gt; I believe rank 1 temperaments are lines in this space, which<br/>&gt; fits the idea that vals are lines. &nbsp;Then we want the point on<br/>&gt; the line closest to the JIP and the only choice is: which norm.<br/>&gt; You claim TOP-RMS is the answer if we choose a Euclidean norm,<br/>&gt; which is believable since the formula for RMS looks a lot<br/>&gt; Euclidean distance.</p><p>Euclidean distance gives root sum squared.  That&apos;s proportional to<br/>RMS.  So they&apos;re essentially the same thing.</p><p>Vals aren&apos;t lines.  Vals are lattice points.  The lines are equal<br/>temperaments or temperament classes.  Each point on the line is a<br/>different tuning of the temperament class.  Of course the nearest<br/>tuning to JI will be the optimal one, according to whatever metric you<br/>use, and and the distance from it to JI will be the optimal error.</p><p>&gt; Rank 2 temperaments would be planes I suppose.</p><p>Yes.</p><p>                      Graham</p></div><h3>Graham Breed &#x3C;gbreed@gmail.com&#x3E;</h3><span>5/8/2010 10:43:29 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On 9 May 2010 00:28, genewardsmith &lt;<a href="mailto:genewardsmith@sbcglobal.net">genewardsmith@sbcglobal.net</a>&gt; wrote:<br/>&gt;<br/>&gt;<br/>&gt; --- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Graham Breed &lt;gbreed@...&gt; wrote:<br/>&gt;<br/>&gt;&gt; You can say that vals live in a val lattice and tunings exist in<br/>&gt;&gt; tuning space. &nbsp;But, still, certain points in tuning space look very<br/>&gt;&gt; much like vals.<br/>&gt;<br/>&gt; That&apos;s because the lattice is a lattice in tuning space.</p><p>Yes, but vals aren&apos;t tunings and the metric you apply to them doesn&apos;t<br/>measure tuning.</p><p>&gt;&gt; The val as a point in tuning space isn&apos;t a tuning. &nbsp;It does define a<br/>&gt;&gt; set of tunings, which lie on the line in tuning space linking the val<br/>&gt;&gt; to the origin.<br/>&gt;<br/>&gt; The projective val. I used to think Paul liked those and you didn&apos;t.</p><p>Whyever would that be?</p><p>&gt;&gt; Say you have 12 note equal temperament. &nbsp;You can find a false val on<br/>&gt;&gt; the right line but exactly 12 units from the origin.<br/>&gt;<br/>&gt; What&apos;s a false val?</p><p>It&apos;s a point close to a val but not on the lattice.</p><p>                     Graham</p></div><h3>Carl Lumma &#x3C;carl@lumma.org&#x3E;</h3><span>5/8/2010 11:11:41 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Graham wrote:</p><p>&gt;&gt;&gt;If you define complexity as the number of consonances per octave, it<br/>&gt;&gt;&gt;does depend on the tuning of the octave.<br/>&gt;&gt;<br/>&gt;&gt; What kind of complexity is this??  It sounds more like the inverse<br/>&gt;&gt; of complexity for a constant number of notes/octave.<br/>&gt;<br/>&gt;Erm, yes.  But however complexity&apos;s defined, it&apos;s the number something<br/>&gt;per octave, or some other reference interval.</p><p>I use rounded notes/octave, which doesn&apos;t really depend on the<br/>octave stretch.</p><p>&gt;&gt;&gt;The val as a point in tuning space isn&apos;t a tuning.  It does define a<br/>&gt;&gt;&gt;set of tunings, which lie on the line in tuning space linking the val<br/>&gt;&gt;&gt;to the origin.  One of those points is the TOP-RMS tuning.<br/>&gt;&gt;<br/>&gt;&gt; We should say how the axes are scaled.  I can think of<br/>&gt;&gt;<br/>&gt;&gt; * weighted log units, JIP is [1 1 1 ...]<br/>&gt;<br/>&gt;That&apos;s Tenney-weighted tuning space.<br/>&gt;<br/>&gt;&gt; * constant log units, JIP is [1200 1901.955 ...]<br/>&gt;<br/>&gt;Equal weighting, which isn&apos;t the same thing.</p><p>OK</p><p>&gt;&gt; * relative log units, JIP is [12 19.01955 27.86314 ...]<br/>&gt;&gt; or [31 49.13384 71.97977 ...] ...  Are the JIPs colinear here?<br/>&gt;&gt; Maybe that&apos;s what you were talking about &quot;JI line&quot;.<br/>&gt;<br/>&gt;Yes, the JI line is the line through the JI point.</p><p>But I gave two JI points, and there are quite a lot of them.<br/>Which one is &quot;the&quot; JI point?</p><p>&gt;&gt; Do you have names for each of these?  The val lattice must be<br/>&gt;&gt; found in the latter, which looks like a different beast to the<br/>&gt;&gt; first two.<br/>&gt;<br/>&gt;The val lattice is found in the first one, and the metric defines<br/>&gt;complexity.</p><p>The val lattice ought to have vals in it.  Things like &lt;31 49 72|<br/>are vals.  Weighted, we get things like &lt;n n n n| which don&apos;t seem<br/>to make much of a lattice.</p><p>&gt;&gt; You convinced me before that with a Euclidean norm on val space,<br/>&gt;&gt; the distance from the origin to a point is a good complexity<br/>&gt;&gt; (unweighted though).<br/>&gt;<br/>&gt;Yes.  But only for lattice points.  It doesn&apos;t make sense to talk<br/>&gt;about the complexity of a tuning.</p><p>OK</p><p>&gt;&gt; For error we want definitely want weighted tuning space.<br/>&gt;&gt; I believe rank 1 temperaments are lines in this space, which<br/>&gt;&gt; fits the idea that vals are lines.  Then we want the point on<br/>&gt;&gt; the line closest to the JIP and the only choice is: which norm.<br/>&gt;&gt; You claim TOP-RMS is the answer if we choose a Euclidean norm,<br/>&gt;&gt; which is believable since the formula for RMS looks a lot<br/>&gt;&gt; Euclidean distance.<br/>&gt;<br/>&gt;Euclidean distance gives root sum squared.  That&apos;s proportional to<br/>&gt;RMS.  So they&apos;re essentially the same thing.<br/>&gt;<br/>&gt;Vals aren&apos;t lines.  Vals are lattice points.  The lines are equal<br/>&gt;temperaments or temperament classes.  Each point on the line is a<br/>&gt;different tuning of the temperament class.  Of course the nearest<br/>&gt;tuning to JI will be the optimal one, according to whatever metric you<br/>&gt;use, and and the distance from it to JI will be the optimal error.</p><p>A val is an ET, or rank 1 temperament class.  So I don&apos;t see how<br/>they are lattice points.</p><p>-Carl</p></div><h3>genewardsmith &#x3C;genewardsmith@sbcglobal.net&#x3E;</h3><span>5/9/2010 12:19:41 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Carl Lumma &lt;carl@...&gt; wrote:</p><p>&gt; The val lattice ought to have vals in it.  Things like &lt;31 49 72|<br/>&gt; are vals.  Weighted, we get things like &lt;n n n n| which don&apos;t seem<br/>&gt; to make much of a lattice.</p><p>It&apos;s a coordinate transformation. If you find &lt;31 30.9155579 31.00871218| in it, unweight and and you have integers. It&apos;s an embedding of the vals into a vector space as a lattice, which is a discrete group spanning the vector space. The definition requires a topology, but people often restrict it to the case of a Euclidean normed vector space. Hence you have the abstract abelian group, dual of the group of p-limit intervals, which is the group of vals, and an embedding map weight:Vals --&gt; R^n, where n is the rank of the val group.</p></div><h3>Carl Lumma &#x3C;carl@lumma.org&#x3E;</h3><span>5/9/2010 12:53:31 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Gene wrote:</p><p>&gt;&gt; The val lattice ought to have vals in it.  Things like &lt;31 49 72|<br/>&gt;&gt; are vals.  Weighted, we get things like &lt;n n n n| which don&apos;t seem<br/>&gt;&gt; to make much of a lattice.<br/>&gt;<br/>&gt;It&apos;s a coordinate transformation. If you find &lt;31 30.9155579<br/>&gt;31.00871218| in it, unweight and and you have integers.</p><p>Are you sure it&apos;s a JI point?  It seems more like a JI line.<br/>Weighted, it&apos;s all points n * &lt;1 1 1 ...| where n is an integer.<br/>Unweighted, it&apos;s n * &lt;1 1.58496 2.32193 ...|.</p><p>-Carl</p></div><h3>genewardsmith &#x3C;genewardsmith@sbcglobal.net&#x3E;</h3><span>5/9/2010 1:49:59 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Carl Lumma &lt;carl@...&gt; wrote:<br/>&gt;<br/>&gt; Gene wrote:<br/>&gt;<br/>&gt; &gt;&gt; The val lattice ought to have vals in it.  Things like &lt;31 49 72|<br/>&gt; &gt;&gt; are vals.  Weighted, we get things like &lt;n n n n| which don&apos;t seem<br/>&gt; &gt;&gt; to make much of a lattice.<br/>&gt; &gt;<br/>&gt; &gt;It&apos;s a coordinate transformation. If you find &lt;31 30.9155579<br/>&gt; &gt;31.00871218| in it, unweight and and you have integers.<br/>&gt;<br/>&gt; Are you sure it&apos;s a JI point?  It seems more like a JI line.</p><p>It&apos;s neither, it&apos;s the lattice point associated to &lt;31 49 72|. Transform coordinates and it becomes &lt;31.0 49.0 72.0|.</p></div><h3>Carl Lumma &#x3C;carl@lumma.org&#x3E;</h3><span>5/9/2010 2:01:51 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Gene wrote:</p><p>&gt;&gt; Are you sure it&apos;s a JI point?  It seems more like a JI line.<br/>&gt;<br/>&gt;It&apos;s neither, it&apos;s the lattice point associated to &lt;31 49 72|.<br/>&gt;Transform coordinates and it becomes &lt;31.0 49.0 72.0|.</p><p>Isn&apos;t &lt;15.0 24.5 36| a valid transformed point for this val?</p><p>-Carl</p></div><h3>genewardsmith &#x3C;genewardsmith@sbcglobal.net&#x3E;</h3><span>5/10/2010 12:32:04 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Carl Lumma &lt;carl@...&gt; wrote:<br/>&gt;<br/>&gt; Gene wrote:<br/>&gt;<br/>&gt; &gt;&gt; Are you sure it&apos;s a JI point?  It seems more like a JI line.<br/>&gt; &gt;<br/>&gt; &gt;It&apos;s neither, it&apos;s the lattice point associated to &lt;31 49 72|.<br/>&gt; &gt;Transform coordinates and it becomes &lt;31.0 49.0 72.0|.<br/>&gt;<br/>&gt; Isn&apos;t &lt;15.0 24.5 36| a valid transformed point for this val?</p><p>You&apos;d need to define your coordinate transformation to be able to answer that, but it doesn&apos;t look like it makes any sense. Did you mean<br/>&lt;15.5 24.5 36|?</p></div><h3>Carl Lumma &#x3C;carl@lumma.org&#x3E;</h3><span>5/10/2010 12:39:34 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Gene wrote:</p><p>&gt;&gt; &gt;&gt; Are you sure it&apos;s a JI point?  It seems more like a JI line.<br/>&gt;&gt; &gt;<br/>&gt;&gt; &gt;It&apos;s neither, it&apos;s the lattice point associated to &lt;31 49 72|.<br/>&gt;&gt; &gt;Transform coordinates and it becomes &lt;31.0 49.0 72.0|.<br/>&gt;&gt;<br/>&gt;&gt; Isn&apos;t &lt;15.0 24.5 36| a valid transformed point for this val?<br/>&gt;<br/>&gt;You&apos;d need to define your coordinate transformation to be able to<br/>&gt;answer that, but it doesn&apos;t look like it makes any sense. Did you mean<br/>&gt;&lt;15.5 24.5 36|?</p><p>Sorry, yes.  -C.</p></div><h3>genewardsmith &#x3C;genewardsmith@sbcglobal.net&#x3E;</h3><span>5/10/2010 2:46:50 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Carl Lumma &lt;carl@...&gt; wrote:</p><p>&gt; &gt;&lt;15.5 24.5 36|?<br/>&gt;<br/>&gt; Sorry, yes.  -C.</p><p>So now you have a coordinate transformation, but no apparent point to it.</p></div><h3>Carl Lumma &#x3C;carl@lumma.org&#x3E;</h3><span>5/10/2010 10:39:24 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>At 02:46 AM 5/10/2010, you wrote:</p><p>&gt;&gt; &gt;&lt;15.5 24.5 36|?<br/>&gt;&gt;<br/>&gt;&gt; Sorry, yes.  -C.<br/>&gt;<br/>&gt;So now you have a coordinate transformation, but no apparent point to it.</p><p>?  Clearly this is a point in tuning space, not on the val<br/>lattice, but colinear with &lt;31 49 72|.</p><p>-Carl</p></div><h3>genewardsmith &#x3C;genewardsmith@sbcglobal.net&#x3E;</h3><span>5/10/2010 4:20:38 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Carl Lumma &lt;carl@...&gt; wrote:<br/>&gt;<br/>&gt; At 02:46 AM 5/10/2010, you wrote:<br/>&gt;<br/>&gt; &gt;&gt; &gt;&lt;15.5 24.5 36|?<br/>&gt; &gt;&gt;<br/>&gt; &gt;&gt; Sorry, yes.  -C.<br/>&gt; &gt;<br/>&gt; &gt;So now you have a coordinate transformation, but no apparent point to it.<br/>&gt;<br/>&gt; ?  Clearly this is a point in tuning space, not on the val<br/>&gt; lattice, but colinear with &lt;31 49 72|.</p><p>In that case, you aren&apos;t transforming coordinates.</p></div><h3>Carl Lumma &#x3C;carl@lumma.org&#x3E;</h3><span>5/10/2010 4:38:05 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>At 04:20 PM 5/10/2010, you wrote:</p><p>&gt;&gt; &gt;&gt; &gt;&lt;15.5 24.5 36|?<br/>&gt;&gt; &gt;&gt;<br/>&gt;&gt; &gt;&gt; Sorry, yes.  -C.<br/>&gt;&gt; &gt;<br/>&gt;&gt; &gt;So now you have a coordinate transformation, but no apparent point to it.<br/>&gt;&gt;<br/>&gt;&gt; ?  Clearly this is a point in tuning space, not on the val<br/>&gt;&gt; lattice, but colinear with &lt;31 49 72|.<br/>&gt;<br/>&gt;In that case, you aren&apos;t transforming coordinates.</p><p>There are three things I mentioned, raw vals like the above being<br/>one of them.  But it doesn&apos;t matter, let&apos;s talk Tenney space.<br/>&lt;31 31 31| and &lt;5 5 5| are both JIPs, no?</p><p>-Carl</p></div><h3>Graham Breed &#x3C;gbreed@gmail.com&#x3E;</h3><span>5/10/2010 11:31:27 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On 11 May 2010 03:38, Carl Lumma &lt;<a href="mailto:carl@lumma.org">carl@lumma.org</a>&gt; wrote:</p><p>&gt; There are three things I mentioned, raw vals like the above being<br/>&gt; one of them. &nbsp;But it doesn&apos;t matter, let&apos;s talk Tenney space.<br/>&gt; &lt;31 31 31| and &lt;5 5 5| are both JIPs, no?</p><p>The fact that raw vals have to be translated to Tenney space is what<br/>suggests it isn&apos;t really a val space.  You could, though, use integers<br/>to label the points but have rectangular instead of square spacing.<br/>Then measure Euclidean distances.  This amounts to applying a metric<br/>to the lattice instead of transforming the vals to fit the space.  It<br/>would also mean tuning space was labeled by intervals in octaves.  A<br/>different metric would give labels in cents.</p><p>In general, tuning/complexity space, error space and badness space are<br/>different inner product spaces.</p><p>In Tenney space, the JIP is &lt;1 1 1].  Those other things are points on<br/>the JI line.  Considering all points on the JI line equivalent is like<br/>saying you don&apos;t care about the scale stretch.</p><p>I know different threads are hanging.  Are there any questions people<br/>really want answered?</p><p>                        Graham</p></div><h3>genewardsmith &#x3C;genewardsmith@sbcglobal.net&#x3E;</h3><span>5/11/2010 1:42:35 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Carl Lumma &lt;carl@...&gt; wrote:<br/>&gt;<br/>&gt; At 04:20 PM 5/10/2010, you wrote:<br/>&gt;<br/>&gt; &gt;&gt; &gt;&gt; &gt;&lt;15.5 24.5 36|?<br/>&gt; &gt;&gt; &gt;&gt;<br/>&gt; &gt;&gt; &gt;&gt; Sorry, yes.  -C.<br/>&gt; &gt;&gt; &gt;<br/>&gt; &gt;&gt; &gt;So now you have a coordinate transformation, but no apparent point to it.<br/>&gt; &gt;&gt;<br/>&gt; &gt;&gt; ?  Clearly this is a point in tuning space, not on the val<br/>&gt; &gt;&gt; lattice, but colinear with &lt;31 49 72|.<br/>&gt; &gt;<br/>&gt; &gt;In that case, you aren&apos;t transforming coordinates.<br/>&gt;<br/>&gt; There are three things I mentioned, raw vals like the above being<br/>&gt; one of them.  But it doesn&apos;t matter, let&apos;s talk Tenney space.<br/>&gt; &lt;31 31 31| and &lt;5 5 5| are both JIPs, no?</p><p>No, only &lt;1 1 1| is the JIP.</p></div><h3>Carl Lumma &#x3C;carl@lumma.org&#x3E;</h3><span>5/11/2010 2:03:00 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Graham wrote:</p><p>&gt;In Tenney space, the JIP is &lt;1 1 1].  Those other things are points on<br/>&gt;the JI line.  Considering all points on the JI line equivalent is like<br/>&gt;saying you don&apos;t care about the scale stretch.<br/>&gt;<br/>&gt;I know different threads are hanging.  Are there any questions people<br/>&gt;really want answered?</p><p>Just trying to figure out this geometry.  Maybe we should talk about<br/>units.  The units are</p><p>&lt; notes/octave  notes/twelfth  etc |</p><p>So &lt;31 31 31| is the same tuning as &lt;1 1 1| but not the same...<br/>morphism?  icon?</p><p>Fine and good, but I still don&apos;t see why we&apos;re minimizing distance<br/>to the JIP -- we should be using the JI line.  Here&apos;s where maybe we<br/>got it wrong.  A rank 2 temperament isn&apos;t a plane (which I think you<br/>agreed to recently) but rather a line.  Rank 1 temperaments are points.<br/>To find the best rank 1 temperament (val) and its tuning for a given<br/>number of notes/octaves n, we pick from the points that unweight to<br/>all-integers (true vals) the one closest to &lt;n n n|.  Not the one<br/>closest to &lt;1 1 1|.</p><p>For rank 2, rather than starting with just notes/octave, we start<br/>with two complete vals.  Then the tuning of the primes is the point<br/>on their line closest to the JI line.  The two lines can never<br/>intersect of course.</p><p>I don&apos;t know how to tune the generators.  They live in the dual<br/>space of monzos, correct?</p><p>-Carl</p></div><h3>Graham Breed &#x3C;gbreed@gmail.com&#x3E;</h3><span>5/11/2010 9:56:27 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On 12 May 2010 01:03, Carl Lumma &lt;<a href="mailto:carl@lumma.org">carl@lumma.org</a>&gt; wrote:</p><p>&gt; Just trying to figure out this geometry. &nbsp;Maybe we should talk about<br/>&gt; units. &nbsp;The units are<br/>&gt;<br/>&gt; &lt; notes/octave &nbsp;notes/twelfth &nbsp;etc |<br/>&gt;<br/>&gt; So &lt;31 31 31| is the same tuning as &lt;1 1 1| but not the same...<br/>&gt; morphism? &nbsp;icon?</p><p>They&apos;re not the same tuning.  &lt;31 31 31] means the octave is tuned to<br/>2^31:1 and so on.  It sits in a completely different part of the<br/>space.  They&apos;re the same temperament class.</p><p>&gt; Fine and good, but I still don&apos;t see why we&apos;re minimizing distance<br/>&gt; to the JIP -- we should be using the JI line. &nbsp;Here&apos;s where maybe we<br/>&gt; got it wrong. &nbsp;A rank 2 temperament isn&apos;t a plane (which I think you<br/>&gt; agreed to recently) but rather a line. &nbsp;Rank 1 temperaments are points.</p><p>We&apos;re minimizing distance to the JIP because that&apos;s JI.  We can use<br/>the JI line as well, but that entails octave equivalence (or<br/>scale-stretch equivalence).  A rank 2 temperament class is a plane.<br/>It becomes a line in projective space.  A rank 1 temperament class is<br/>a point in projective space.</p><p>&gt; To find the best rank 1 temperament (val) and its tuning for a given<br/>&gt; number of notes/octaves n, we pick from the points that unweight to<br/>&gt; all-integers (true vals) the one closest to &lt;n n n|. &nbsp;Not the one<br/>&gt; closest to &lt;1 1 1|.</p><p>You find the one that projects closest to &lt;1 1 1]</p><p>&gt; For rank 2, rather than starting with just notes/octave, we start<br/>&gt; with two complete vals. &nbsp;Then the tuning of the primes is the point<br/>&gt; on their line closest to the JI line. &nbsp;The two lines can never<br/>&gt; intersect of course.</p><p>The tuning of the prime is the point in the plane closest to the JI<br/>point.  The tuning you&apos;re talking about ignores scale stretch.</p><p>&gt; I don&apos;t know how to tune the generators. &nbsp;They live in the dual<br/>&gt; space of monzos, correct?</p><p>I&apos;m not sure.  They&apos;re probably points in tuning space.</p><p>                          Graham</p></div><h3>Carl Lumma &#x3C;carl@lumma.org&#x3E;</h3><span>5/11/2010 10:22:51 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Graham wrote:</p><p>&gt;&gt; So &lt;31 31 31| is the same tuning as &lt;1 1 1| but not the same...<br/>&gt;&gt; morphism?  icon?<br/>&gt;<br/>&gt;They&apos;re not the same tuning.  &lt;31 31 31] means the octave is tuned to<br/>&gt;2^31:1 and so on.</p><p>It sure as shinola unweights to the same thing as &lt;1 1 1|.  I call<br/>that the same tuning.</p><p>&gt;&gt; To find the best rank 1 temperament (val) and its tuning for a given<br/>&gt;&gt; number of notes/octaves n, we pick from the points that unweight to<br/>&gt;&gt; all-integers (true vals) the one closest to &lt;n n n|.  Not the one<br/>&gt;&gt; closest to &lt;1 1 1|.<br/>&gt;<br/>&gt;You find the one that projects closest to &lt;1 1 1]</p><p>I find the one closest to &lt;n n n|, and it works.  Gene&apos;s code<br/>seems to work the same way.</p><p>&gt;&gt; I don&apos;t know how to tune the generators.  They live in the dual<br/>&gt;&gt; space of monzos, correct?<br/>&gt;<br/>&gt;I&apos;m not sure.  They&apos;re probably points in tuning space.</p><p>Maybe Gene knows.</p><p>-Carl</p></div><h3>Carl Lumma &#x3C;carl@lumma.org&#x3E;</h3><span>5/11/2010 10:26:40 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>I wrote:</p><p>&gt;&gt;&gt; So &lt;31 31 31| is the same tuning as &lt;1 1 1| but not the same...<br/>&gt;&gt;&gt; morphism?  icon?<br/>&gt;&gt;<br/>&gt;&gt;They&apos;re not the same tuning.  &lt;31 31 31] means the octave is tuned to<br/>&gt;&gt;2^31:1 and so on.<br/>&gt;<br/>&gt;It sure as shinola unweights to the same thing as &lt;1 1 1|.  I call<br/>&gt;that the same tuning.</p><p>Different step size of course.  I&apos;ll call that a different icon,<br/>until Gene corrects me.</p><p>-Carl</p></div><h3>Graham Breed &#x3C;gbreed@gmail.com&#x3E;</h3><span>5/11/2010 10:39:43 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On 12 May 2010 09:22, Carl Lumma &lt;<a href="mailto:carl@lumma.org">carl@lumma.org</a>&gt; wrote:<br/>&gt; Graham wrote:<br/>&gt;<br/>&gt;&gt;&gt; So &lt;31 31 31| is the same tuning as &lt;1 1 1| but not the same...<br/>&gt;&gt;&gt; morphism? &nbsp;icon?<br/>&gt;&gt;<br/>&gt;&gt;They&apos;re not the same tuning. &nbsp;&lt;31 31 31] means the octave is tuned to<br/>&gt;&gt;2^31:1 and so on.<br/>&gt;<br/>&gt; It sure as shinola unweights to the same thing as &lt;1 1 1|. &nbsp;I call<br/>&gt; that the same tuning.</p><p>It doesn&apos;t unweight to the same thing.  And it doesn&apos;t matter how many<br/>times you say it does, because it doesn&apos;t.</p><p>&gt;&gt;&gt; To find the best rank 1 temperament (val) and its tuning for a given<br/>&gt;&gt;&gt; number of notes/octaves n, we pick from the points that unweight to<br/>&gt;&gt;&gt; all-integers (true vals) the one closest to &lt;n n n|. &nbsp;Not the one<br/>&gt;&gt;&gt; closest to &lt;1 1 1|.<br/>&gt;&gt;<br/>&gt;&gt;You find the one that projects closest to &lt;1 1 1]<br/>&gt;<br/>&gt; I find the one closest to &lt;n n n|, and it works. &nbsp;Gene&apos;s code<br/>&gt; seems to work the same way.</p><p>It works because the triangles are congruent.  But the JI point is<br/>still &lt;1 1 1].  Gene agrees.  If you&apos;re doing something else you&apos;re in<br/>a different space.</p><p>                     Graham</p></div><h3>genewardsmith &#x3C;genewardsmith@sbcglobal.net&#x3E;</h3><span>5/11/2010 11:02:50 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Carl Lumma &lt;carl@...&gt; wrote:<br/>&gt;<br/>&gt; Graham wrote:<br/>&gt;<br/>&gt; &gt;&gt; So &lt;31 31 31| is the same tuning as &lt;1 1 1| but not the same...<br/>&gt; &gt;&gt; morphism?  icon?<br/>&gt; &gt;<br/>&gt; &gt;They&apos;re not the same tuning.  &lt;31 31 31] means the octave is tuned to<br/>&gt; &gt;2^31:1 and so on.<br/>&gt;<br/>&gt; It sure as shinola unweights to the same thing as &lt;1 1 1|.  I call<br/>&gt; that the same tuning.</p><p>Does not, it unweights to something 31 times JI, or JI to the 31st power.</p><p>&gt; &gt;&gt; To find the best rank 1 temperament (val) and its tuning for a given<br/>&gt; &gt;&gt; number of notes/octaves n, we pick from the points that unweight to<br/>&gt; &gt;&gt; all-integers (true vals) the one closest to &lt;n n n|.  Not the one<br/>&gt; &gt;&gt; closest to &lt;1 1 1|.<br/>&gt; &gt;<br/>&gt; &gt;You find the one that projects closest to &lt;1 1 1]<br/>&gt;<br/>&gt; I find the one closest to &lt;n n n|, and it works.  Gene&apos;s code<br/>&gt; seems to work the same way.</p><p>Since it&apos;s causing confusion I suppose I&apos;d better rewrite the code.</p><p>By the way, I&apos;m adding stuff to the xenharmonic wiki as per your suggestion. I&apos;ve already been tagged for stealing my own articles from your web site.</p><p>&gt; &gt;&gt; I don&apos;t know how to tune the generators.  They live in the dual<br/>&gt; &gt;&gt; space of monzos, correct?<br/>&gt; &gt;<br/>&gt; &gt;I&apos;m not sure.  They&apos;re probably points in tuning space.<br/>&gt;<br/>&gt; Maybe Gene knows.</p><p>Since they are intervals, they clearly don&apos;t live in tuning space.</p></div><h3>Carl Lumma &#x3C;carl@lumma.org&#x3E;</h3><span>5/11/2010 11:54:40 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Gene wrote:</p><p>&gt;&gt; &gt;They&apos;re not the same tuning.  &lt;31 31 31] means the octave is tuned to<br/>&gt;&gt; &gt;2^31:1 and so on.<br/>&gt;&gt;<br/>&gt;&gt; It sure as shinola unweights to the same thing as &lt;1 1 1|.  I call<br/>&gt;&gt; that the same tuning.<br/>&gt;<br/>&gt;Does not, it unweights to something 31 times JI, or JI to the 31st power.</p><p>I asked if the unweighted units are steps/prime.  If they are,<br/>clearly &lt;n n n| is the same tuning for all n.  The step size would<br/>be different.</p><p>&gt;&gt; I find the one closest to &lt;n n n|, and it works.  Gene&apos;s code<br/>&gt;&gt; seems to work the same way.<br/>&gt;<br/>&gt;Since it&apos;s causing confusion I suppose I&apos;d better rewrite the code.</p><p>The whole thing you said before about minimizing some measure of<br/>central tendency from, lo and behold, &lt;n n n|, means you&apos;re<br/>minimizing distance to the JI line, not the JI point.</p><p>&gt;By the way, I&apos;m adding stuff to the xenharmonic wiki as per your<br/>&gt;suggestion. I&apos;ve already been tagged for stealing my own articles from<br/>&gt;your web site.</p><p>Heh.  I guess I&apos;ll pop over there.</p><p>&gt;&gt; &gt;&gt; I don&apos;t know how to tune the generators.  They live in the dual<br/>&gt;&gt; &gt;&gt; space of monzos, correct?<br/>&gt;&gt; &gt;<br/>&gt;&gt; &gt;I&apos;m not sure.  They&apos;re probably points in tuning space.<br/>&gt;&gt;<br/>&gt;&gt; Maybe Gene knows.<br/>&gt;<br/>&gt;Since they are intervals, they clearly don&apos;t live in tuning space.</p><p>Right.  They&apos;re representable by monzos and I recollect that monzos<br/>and vals are duals.  So I have to wedge, take the complement, and<br/>unwedge.  Or something.</p><p>But let me go on about the geometry I&apos;m pretending to understand.<br/>The way I&apos;m looking at it, a rank 2 temperament will be a line<br/>connecting two vals.  If I have a tuning point like</p><p>&lt;11.976740698521905 18.963172772659682 27.94572829655111|</p><p>presumably it sits between the vals, or if not, at least they are<br/>the nearest pair of points on the line with integer coordinates.<br/>Beyond them, other points with integer coords can be found, but<br/>they would lead to torsional maps.  Then I&apos;d find the optimal<br/>tuning by</p><p>1. drawing a ball around each of the line&apos;s defining vals, of<br/>radius .49 along each axis (this has to be done while weighted)</p><p>2. allowing the line to be defined instead by any pair of points,<br/>one from each ball, such that the distance to the JI line is<br/>minimized.  this is the hard part.</p><p>3. then I could find the tuning of each generator by using the<br/>trick for ETs, where you can get the step size right from the val<br/>dividing any prime by its number of steps.</p><p>I tried this before without the geometry picture, and it only<br/>works if there&apos;s at least one prime in the val you&apos;re trying to<br/>tune for which the other val has a zero.  So there must be<br/>something wrong with my assumptions, since each of the vals<br/>defining the line ought to be independent and the ET trick ought<br/>to work.  Hrm.</p><p>-Carl</p></div><h3>Graham Breed &#x3C;gbreed@gmail.com&#x3E;</h3><span>5/12/2010 2:46:12 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Carl:<br/>&gt;&gt; &gt;&gt; I don&apos;t know how to tune the generators. &nbsp;They live in the dual<br/>&gt;&gt; &gt;&gt; space of monzos, correct?</p><p>Gene:<br/>&gt; Since they are intervals, they clearly don&apos;t live in tuning space.</p><p>Each generator corresponds to a val, which represents it in tuning<br/>space.  You can also define a line of tunings of that val, the same as<br/>for an equal temperament (the special case of only one generator).  So<br/>it may be possible but it&apos;s not clear to me how.</p><p>                         Graham</p></div><h3>genewardsmith &#x3C;genewardsmith@sbcglobal.net&#x3E;</h3><span>5/12/2010 7:44:52 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning-math@yahoogroups.com">tuning-math@yahoogroups.com</a>, Graham Breed &lt;gbreed@...&gt; wrote:<br/>&gt;<br/>&gt; Carl:<br/>&gt; &gt;&gt; &gt;&gt; I don&apos;t know how to tune the generators. &Acirc;&nbsp;They live in the dual<br/>&gt; &gt;&gt; &gt;&gt; space of monzos, correct?<br/>&gt;<br/>&gt; Gene:<br/>&gt; &gt; Since they are intervals, they clearly don&apos;t live in tuning space.<br/>&gt;<br/>&gt; Each generator corresponds to a val, which represents it in tuning<br/>&gt; space.</p><p>There are different things you can call a generator. First, there are rational numbers, as we might say 2 and 3/2 are generators for meantone temperament. Then there are the real numbers obtained by applying a vector in tuning space to these first generators. Corresponding to each generator is a val telling how many of that generator to take when generating the retuned version of any specific p-limit rational number. If you apply it to the rational number which was retuned to get the generator, it should tell you to take one of that generator, and none of any of the others, which is the correspondence. You can also cook up a vector in interval space corresponding to a generator, by applying the tuning map to each prime in succession and weighting the coordinates if you are using an unweighted tuning map.</p></div>