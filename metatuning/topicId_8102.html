<a href="/metatuning">back to list</a><h1>Re: [metatuning] Digest Number 1022</h1><h3>Robert Walker &#x3C;robertwalker@...&#x3E;</h3><span>7/9/2004 9:35:15 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Hi Carl,</p><p>&gt; It may also be worth pointing out here that<br/>&gt; finding an algorithm that produces a given<br/>&gt; desired output can be a very hard problem. So<br/>&gt; hard, in fact, that I think it *extremely*<br/>&gt; unlikely any pure expert system will ever<br/>&gt; pass a Turing test.</p><p>Oh I agree, from what I&apos;ve seen nothing in the field<br/>of computing is anywhere near achieving this,<br/>of being able to behave like a human, except<br/>in specially set up situations where<br/>rules are imposed that make it easy for<br/>the computer to &quot;bluff&quot; its way as a<br/>purported human.</p><p>Though, Penrose&apos;s argument doesn&apos;t actually<br/>show it to be impossible to get good mimics<br/>of human understanding that might<br/>deceive a human for a long time.<br/>But it does give a test that could<br/>be used - if you have a program and have<br/>access to its programming, you will<br/>be able to construct a Godel sentence<br/>for it. Give it as long as it needs<br/>to try and see if it is true, and<br/>same with a human, where of course<br/>the human has to be a mathematician<br/>I suppose.</p><p>To even out the field,<br/>give the human access to whatever<br/>they need in the way of tools to analyse<br/>the statement - can do the same with<br/>teh comptuer program but it won&apos;t do ti<br/>any good to have them, because the<br/>problem is that it won&apos;t understand<br/>it at the meta level.</p><p>So in that sense he shows that<br/>no program can ever pass the<br/>turing argument in full generality.<br/>But whether it could pass it<br/>in a more limited sense I suppose<br/>is another question. Whether<br/>maybe we may have to deal with<br/>robots that have a notion of pseudo<br/>truth that almost but not quite<br/>corresponds to human truth is interesting.<br/>I wonder if anyone has explored that<br/>in novels.</p><p>Of course Asimov&apos;s robots<br/>were &quot;positronic robots&quot; and<br/>with a bit of leniency one could<br/>udnerstand them as relying on non<br/>computable phenomena. Maybe<br/>now they would be called<br/>&quot;gravitonic robots&quot; and use<br/>Penrose&apos;s gravitational collapse<br/>of the wave fnction. But who<br/>knows, perhaps that is just fun<br/>SF and will never be practical.</p><p>&gt; But why should the intoxicated view be<br/>&gt; &quot;distorted&quot;, while the sober view is<br/>&gt; raised to the level of defining reality?</p><p>Because the distorted view distorts<br/>ones interactions with others,<br/>so that you no longer have a clear<br/>shared reality in which to communicate.</p><p>&gt; &gt; Even in Maths actually I feel that<br/>&gt; &gt; it is sometimes insightful to study the history<br/>&gt; &gt; of the subject, not to understand the<br/>&gt; &gt; proofs, but to understand the context<br/>&gt; &gt; for the proof and what gave rise to it,<br/>&gt; &gt; and to give it more interest and life<br/>&gt; by seeing it in its original setting.</p><p>&gt; I actually study it to understand the proofs. :)</p><p>Yes, indeed. Later the proofs get streamlined<br/>so much and explanatory material removed<br/>from them, makes sense. I think it is a good<br/>way to learn maths in fact, we are presented<br/>with these ideas to learn that took humans<br/>centuries to assimilate and we learn them<br/>in a few years. Maybe one misses something<br/>there and it could be a help to go back<br/>through it again a bit more slowly.</p><p>&gt; Once again, humans are irrelevant. Any proof<br/>&gt; a human can write could be written by Hilbert&apos;s<br/>&gt; automated proof-checker.</p><p>But humans wrote the proof checker. Every time<br/>you make a new axiom system you could<br/>do a proof checker for the axiom system.<br/>But until you codify your ideas into an<br/>axiom system you have no proof checker.</p><p>Historically and experientially, the<br/>truth comes first, then you write an<br/>axiom system to try and incorporate<br/>it as much as possible in  a system of<br/>rules for a particular field, say<br/>geometry, numbers or whatever.</p><p>Eventually people made these grand theories<br/>like ZFC and you can have a proof checker for that<br/>if you can persuade the mathematicians to<br/>put their results into that form. But<br/>that isnt&apos; a complete theory and you<br/>will never have such by Godel again.</p><p>If humans really are irrelevant,then<br/>you need some way for the proof checker<br/>to spontaneously assemble without the<br/>work of human engineers or programmers.<br/>Then who is it who says that it is true<br/>anyway.</p><p>Not to say human have to mean humans as in<br/>bipedal mammals who are closely related<br/>genetically to chimpanzees. I&apos;m sure<br/>any concious being will be able to share<br/>the same notions of truth if they<br/>have a developed enough understanding<br/>of the worldto be able to formulate the<br/>concept. I think it is instinctive in<br/>fact, so even if you can&apos;t express it<br/>well conceptually, you have it within you,<br/>like the character who discovered he had been<br/>speaking prose all his life :-).</p><p>Even chimpanzees are capable of lying<br/>I remember reading, in their actions,<br/>which I think means they have some kind<br/>of rudimentary probably not very well<br/>formed notion of truth, you have to know<br/>what truth is in order to be able to lie<br/>don&apos;t you. Probably other creatures<br/>also too have some kind of rudimentary<br/>understanding that certain things<br/>are true and others aren&apos;t, to guide<br/>their actions. E.g. a dog knows<br/>that there is meat in a room for instance<br/>by smelling or whatever, coudl be said<br/>to ahve some kind of notion of truth.<br/>Of course it can&apos;t understand Godel&apos;s<br/>theorem but it has the potential there,<br/>just isn&apos;t bright enough to follow the<br/>proof.</p><p>But a programmed computer I think<br/>can&apos;t even have that spark that could<br/>be developed into a fully fledged<br/>notion of truth - because of<br/>Penrose&apos;s argument. I used to think<br/>that it was possible and that it might<br/>be possible to be born as an aware<br/>programmed computer. But I can&apos;t<br/>see how it could be now. Could<br/>mistakenly think you are a computer<br/>possibly but you wouldn&apos;t actually<br/>be and if aware, would depart from your programming<br/>sort of when no-one is looking or something.</p><p>If somehow mysteriously awareness<br/>capable of understanding truth could<br/>inhabit a computer, then it could<br/>only do so as a result of<br/>hardware glitches etc somehow<br/>patterned to let it survive<br/>(maybe by gravitationally induced<br/>quantum coherence again :-))<br/>.<br/>Probably a story of some kind<br/>could be written there.</p><p>Robert</p></div><h3>Carl Lumma &#x3C;clumma@...&#x3E;</h3><span>7/9/2004 11:38:23 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>&gt; Though, Penrose&apos;s argument doesn&apos;t actually<br/>&gt; show it to be impossible to get good mimics<br/>&gt; of human understanding that might<br/>&gt; deceive a human for a long time.<br/>&gt; But it does give a test that could<br/>&gt; be used - if you have a program and have<br/>&gt; access to its programming, you will<br/>&gt; be able to construct a Godel sentence<br/>&gt; for it. Give it as long as it needs<br/>&gt; to try and see if it is true, and<br/>&gt; same with a human, where of course<br/>&gt; the human has to be a mathematician<br/>&gt; I suppose.</p><p>Really!?  I&apos;d love to know how to give that<br/>test!</p><p>&gt; So in that sense he shows that<br/>&gt; no program can ever pass the<br/>&gt; turing argument in full generality.</p><p>Does that cover self-extensible programs?</p><p>&gt; &gt; But why should the intoxicated view be<br/>&gt; &gt; &quot;distorted&quot;, while the sober view is<br/>&gt; &gt; raised to the level of defining reality?<br/>&gt;<br/>&gt; Because the distorted view distorts<br/>&gt; ones interactions with others,<br/>&gt; so that you no longer have a clear<br/>&gt; shared reality in which to communicate.</p><p>Oh, I dunno...</p><p>&gt; If humans really are irrelevant,then<br/>&gt; you need some way for the proof checker<br/>&gt; to spontaneously assemble without the<br/>&gt; work of human engineers or programmers.<br/>&gt; Then who is it who says that it is true<br/>&gt; anyway.</p><p>There is work into minimal proofcheckers,<br/>I think....</p><p>-Carl</p></div>