<a href="/old-tuning-list">back to list</a><h1>Posts from Brian McLaren</h1><h3><a id=2036 href="#2036">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>9/23/1995 8:36:56 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>I will be uploading one of a new set of messages from<br>Brian McLaren per day for the next few weeks. At his request, I will <br>not title them in the Subject line. (My own posts will have titles<br>so they can be distinguished from his, though I imagine content and <br>tone will be sufficient indications of authorship. )<br>	Also, I do not have time at the present to edit or reformat<br>them. So, read'em at your own risk. :-).<br>	 As Brian does not have a telephone or email, any comments or<br>questions that need a quick answer should be sent to him by US mail, <br>though I do send him the accumulated Tuning Digests on a disk about <br>once a month. His US mail address is the following:<br> <br>	Brian McLaren  <br>	2462 S.E. Micah Place<br>	Corvallis, OR 97333-1966-17 <br>	USA <br> <br>(Note the non-standard ZIP code. OR is the state of Oregon.)<br> <br>--John<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Sat, 23 Sep 1995 17:40 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id IAA02819; Sat, 23 Sep 1995 08:39:53 -0700<br>Date: Sat, 23 Sep 1995 08:39:53 -0700<br>Message-Id:  <9509230839.aa04145@cyber.cyber.net><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2038 href="#2038">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>9/24/1995 9:55:13 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Tuning & Psychoacoustics - Post 1 of 25<br>---<br>The rules of Western harmony, to paraphrase<br>Voltaire, are a lie commonly agreed upon.<br>Ultimately, the music we choose to make <br>is limited (or liberated) by our understanding <br>of what our ears hear, and how. <br>Over the course of more than a year various<br>forum subscribers  have treated us to<br>a Mount Everest of misinformation about<br>what the ear hears, how the brain interprets it,<br>and how sounds change during the complex and<br>surprising process we call listening.<br>These fairy tales and "just so" stories about hearing<br>and the ear are common currency.  They are<br>the misinformation about the ear/brain system<br>that "everyone knows."   And, like giant<br>alligators in the sewers and detectives<br>photographing an image of a murderer in a <br>corpse's pupils, these  tall tales  never seem <br>to go away.<br>This post is the first of a series which <br>will examine the evidence about what<br>the ear actually hears and how.  These posts<br>will discuss some of the *facts* of the <br>ear/brain system, as opposed to the <br>fantasies and  canards that<br>"everyone knows are true."<br>---<br>First, it's important to understand that<br>some subscribers will react violently to this<br>series of posts.  <br>Many composers, musicians and<br>performers will angrily attempt to refute the<br>facts listed here. These violent reactions <br>will arise partly out of surprise, partly from<br>an unwillingness to relinquish long-held <br>beliefs, and partly because the facts of the <br>ear/brain system are not yet widely known <br>outside the realm of psychoacoustics and <br>psychophysics.  In fact, the majority of<br>today's composers and music theorists <br>exist in a blissful state of ignorance<br>about the ear/brain system--a state similar<br>to that which characterized clerics in the days<br>when Galileo first pointed his telescope<br>at the moon.  Back then, "everyone knew"<br>that the stars were fixed in Aristotle's<br>crystal spheres; "everyone knew" that the<br>moon and sun belonged to a celestial<br>sphere unchanging and perfect; "everyone<br>knew" that the planets rotated around the<br>earth, and that no satellites circled (say)<br>Jupiter or Saturn; "everyone knew" that<br>Aristotle was the beginning and the end<br>of all knowledge, and "everyone knew"<br>that there remained only the tiniest <br>crumbs of knowledge yet to be gleaned <br>about a universe which was perfectly<br>ordered, perfectly simple, and--<br>by and large--perfectly understood.<br>---<br>When Galileo turned his lens to the <br>moon and discovered that it had<br>mountains, and when he observed<br>satellites around Jupiter, and when<br>he saw new stars in the sky, <br>he was called, alternately, "ignorant,"<br>"a charlatan," "an imposter,"  "well-<br>meaning but ignorant of Aristotle's<br>teachings," "too stupid to properly<br>interperet what he saw through<br>his telescope," and so on.<br>Many of the best-educated men and<br>women of Galileo's time refused<br>to look through his telescope at the<br>sky, because they *knew* that <br>his claims could not possibly be<br>true.<br>It's sadly easy to deduce that all of<br>the above antics will be duplicated<br>in the course of this or that subscriber's<br>reaction to this series of posts.<br>---<br>This sounds shocking.  It is.  In saying<br>this, I assert that most musicians and<br>composers today are ignorant of how<br>the ear hears and how the brain interprets<br>sound.  More: I assert that they are not<br>only ignorant, but actively and perversely<br>misinformed.  Lastly, I assert that much<br>of this misinformation hampers the<br>progress of music and interferes with<br>our ability even to conceive new<br>universes of harmony and melody.  <br>What we cannot perceive, we cannot<br>explore; and when we cannot explore,<br>we stagnate.  <br>Much of the myth and fantasy which fills<br>musicians' heads is promulgated by<br>so-called "modern" academia using<br>so-called "modern" music theory<br>textbooks (the content of which actually<br>hails from the 17th, 18th and 19th<br>centuries).<br>The next post will present some of<br>the surprising  characteristics of the ear/<br>brain system, and some recommendations<br>for references.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Mon, 25 Sep 1995 01:56 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id QAA13589; Sun, 24 Sep 1995 16:56:38 -0700<br>Date: Sun, 24 Sep 1995 16:56:38 -0700<br>Message-Id: <950924235355_71670.2576_HHB53-1@CompuServe.COM><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2046 href="#2046">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>9/25/1995 8:19:24 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Tuning & psychoacoustics - post 2 of 25<br>---<br>Many and strange are the myths which<br>afflict so-called "modern" music theory,<br>particularly when it comes to the operation<br>of the human ear.<br>Most of these tall tales have been handed<br>down to present-day musicians from the 19th<br>century, although some of the myths date <br>from much earlier--as early as the number<br>mysticism of Pythagoras, the Babylonians,<br>the Egyptians, and of Hindu astrology.<br>Shockingly, typical "modern" music theory<br>texts cite Helmholtz, Rameau and Mersenne<br>as the sole authorities on acoustics and <br>psychoacoustics--or they cite other <br>"modern" music theory texts which cite<br>only these musty & antique sources.  <br>This is comparable to a "modern" science<br>text citing Lagrange, Hamilton and<br>Newton as authorities on the nature of<br>subatomic physics.   A physics professor<br>who wrote such a book would be laughed <br>out the profession--but for some reason<br>this practice is acceptable in music.<br>Together, this antique trove of musical<br>old wives' tales and acoustic "just-so stories" <br>constitutes a body of misinformation<br>which has been handed down through <br>textbooks which thoughtlessly draw on<br>older textbooks, until the chain of<br>errors reaches back through 3 centuries<br>or more.<br>Partch has illuminated a few links in this<br>monumental chain of fabulation and<br>compounded error, but the amount of<br>misinformation is far larger than<br>even he could ever have suspected.<br>---<br>Every statement presented in this series <br>of posts as fact will be supported<br>as far as possible by references from <br>the scientific literature.  When subscribers<br>to this forum violently attack these<br>posts--as no doubt they will--the interested reader <br>is  advised not to rely on *my* bare assertions<br>*or* the unsupported claims of those <br>who say "it's [a lie/ignorant/wrong, etc]"<br>Rather, the interested reader is<br>advised to go to the original reference<br>sources. Read them. Search out the audio<br>tapes & CDs specified below. Listen to them. <br>And finally: perform your<br>own experiments with Csound or a<br>synthesizer, using your own ears and<br>a computer.<br>This last point is *crucial.*<br>You will need to perform true double-<br>blind tests on your own hearing to<br>obtain valid conclusions.  If you concoct<br>a set of test tones and listen to them<br>*knowing* what they are, your ears<br>will lie to you and you will literally<br>not be able to hear the test tones<br>and acoustic examples objectively.<br>Only by using a true double-blind<br>procedure can you reliably ascertain<br>what your ears *actually* hear, as opposed<br>to what you *think* you're hearing.<br>This is why the most common<br>objection to the facts of modern<br>psychoacoustics--"I don't hear it that <br>way!"--is utterly meaningless.  Without<br>A-B-X double-blind tests, none of you<br>can tell what intervals you prefer (nor <br>can I) because the knowledge of what you<br>*think* you're listening to and what<br>you *expect* to hear  contaminates<br>and alters what you hear.  <br>---<br>This point is so important that it is<br>worth an example: <br>"The extent to which observers can persist<br>in the same error of observation was shown<br>to me by the following experiment. High-fidelity<br>fans complained about the nonlinear distortion<br>in a certain sound-transmission system. To test<br>the maximal distortion these listeners would<br>tolerate, an induction coil was made with an iron<br>core that was highly overloaded and produced<br>nonlinear hysteresis distortion.  A second coil<br>containing no iron was combined with the first<br>in such a way that only the pure distortion remained.<br>Musicians were delighed with this system, which<br>made tenors' voices sound metallic and heightened <br>the dynamics of the orchestra.  Their adjustments of<br>the system to optimal sound had about 70% pure iron<br>distortion." [von Bekesy, G., "Hearing Theories and <br>Complex Sounds," Journ. Acoust. Soc. Am, 35(4), <br>April 1963, pg. 589]<br>Without an objective reference and<br>an independent means of measurement,<br>*we do not know what we hear.*<br>Over the course of this series of posts,<br>it will become clear that the ear sometimes<br>adds to, sometimes subtracts from, and<br>always changes the information that<br>enters  our auditory system as <br>sound waves.  <br>For example: <br>[1] Highly trained symphony orchestra<br>musicians reglarly perform intervals as <br>small as 683 cents and as wide as 725 cents,<br>yet hear them  as "perfect fifths;"<br>["Some Aspects of Perception - I," Shackford,<br>Journ. Mus. Theory, Vol. 5, 1961, pp. 13-26]<br>[2] So-called "perfect" intervals, including<br>the octave and 3/2, can sound dissonant<br>or consonant depending on the range in<br>which they sound, even if they use<br>harmonic-series timbres; ["The Science<br>of Musical Sound," Sundberg, 1992, pg. 73]<br>[3] Pitches transposed up an octave can<br>be heard by musically trained listeners<br>as dropping slightly in pitch; ["The Science<br>Of Musical Sounds," Pierce, 1992, pg.  214]<br>[4] Tones of specific pitch can be heard<br>by musically trained listeners when in<br>fact no tones are physically present; and<br>tones can disappear and become inaudible<br>to the ear/brain system even though <br>they're presented to the ear at high<br>amplitude; ["Psychoacoustics: Facts and<br>Models," Zwicker & Fastl, 1993, pp. 91-135;<br>"The Perception of Musical Tones," Rasch<br>and Plomp, pp. 1-21, in "The Psychology<br>of Music," ed. Diana Deutsch, 1982; "The<br>Science of Musical Sounds," Sundberg,<br>pp. 48-86.]<br>[5] The ear/brain system can generate<br>audible illusions which convince the<br>listener that s/he is hearing paradoxical <br>and impossible sounds--sounds which<br>simultaneously speed up and slow down,<br>for instance, or sounds which simultaneously<br>rise and fall in pitch; or sounds which<br>rise endlessly in pitch, or fall endlessly<br>in pitch; ["The Science of Musical Sounds,"<br>Pierce, pg. 215; "Structural Representations<br>of Musical Pitch," Shepard, in "The <br>Psychology of Music," Ed. Diana Deutsch,<br>1982, pp. 334-373.]<br>[6] There is a universal human craving for<br>stretched intervals, which leads highly<br>trained musicians to perform so-called<br>"perfect" intervals consistently wider<br>than the ratios by which "everyone knows" <br>these intervals are defined; ["The Science<br>of Musical Sound," Sundberg, pp. 104-105,<br>"Introduction to The Physics and <br>Psychophyics of Music," Roederer, pg. 155]<br>[7] The ear/brain system detects pitch<br>in a complex way still not fully understood, <br>with the result that the pitch of a complex<br>sounds is perceived to change with<br>the loudness of the sound, the amount<br>and onset of noise masking the sound,<br>the type other harmonic sound played<br>simultaneously, the degree of harmonicity<br>of the partials in the sound, the length<br>of the sound being played, the spectral<br>centroid of the sound, and the suddeness<br>of onset of the sound; ["Experiments<br>On Tone Sensation," Plomp, pp. 127-129;<br>"Introduction to the Physics and <br>Psychophyics of Music," Roederer, pg.<br>135; "Perception of Timbral Analogies,"<br>Wessel & Ehresman, Rapports IRCAM 1978,<br>pp. 1-29, Pickles, James O., "An Introduction<br>to the Physiology of Hearing," Academic Press,<br>1988, pp. 270 ff., etc.]<br>[8] Many of the inner workings of the<br>ear/brain system are still unknown, and<br>each of the conflicting theories of how<br>the ear/brain system hears is supported<br>by some psychoacoustic evidence, but<br>contradicted by the rest.<br>["Experiments On Tones Sensation," Plomp,<br>pp. 49-52; "The Science of Musical<br>Sound," Sundberg, pp. 100, 186; "The Science<br>of Musical Sounds," Pierce, pp. 101, 113-114;<br>"Rapports IRCAM - Musical Acoustics,"<br>Risset, 1978, pg. 8; "Introduction To the<br>Physics and Psychophysics of Music,"<br>Roederer, 1973, pp. 130-133]<br>---<br>All of which points to the conclusion that<br> the ear/brain system is *complex.*<br>There is no simple explanation for how we<br>hear.  The ear/brain system generates<br>false information, destroys some of<br>what comes into our ears, and transforms<br>all of it, either subtly or grossly.<br>Yet the single common thread that will run<br>through all the so-called "rebuttals" and<br>attacks on this series of posts will be:<br>THE EAR IS SIMPLE. "Helmholtz explained it<br>all," one person will yelp, while others will<br>screech "Terhardt explained it all," or "Backus'<br>book tells you everything you need to know!"<br>The interested reader is advised, again,<br>not to believe me *or* to believe those who<br>attempt to rebut me.  Rather, the interested<br>reader is advised to *study the psychoacoustic<br>literature,* excerpts of which and references<br>from which will be listed extensively in every<br>post.<br>Only by doing this can the objective reader<br>get a real sense of the extraordinary complexity<br>of human hearing, and the self-evident <br>falsity of claims that "the ear is simple"<br>and "Helmholtz explained it all in 1863,"<br>and "my 1939-vintage references don't say that."<br>Do not lend your credence thoughtlessly to<br>*any* statement without *testing for yourself*<br>the evidence (or lack thereof) for that<br>statement. Wisdom does not arise from<br>credulity, but from doubt.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Mon, 25 Sep 1995 17:21 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id IAA21245; Mon, 25 Sep 1995 08:21:28 -0700<br>Date: Mon, 25 Sep 1995 08:21:28 -0700<br>Message-Id: <Pine.3.89.9509251025.A18905-0100000@styx.ios.com><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2054 href="#2054">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>9/26/1995 10:34:05 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Tuning & psychoacoustics - Post 3 of 25<br>---<br>The psychoacoustic literature overwhelmingly points to the conclusion that, <br>first and foremost, the ear/brain system is *complex.*<br>There is no one simple explanation for how we hear.  The ear/brain system <br>generates false information, throws away some of the sound waves <br>physically received by the ear, and transforms the rest, either subtly or <br>grossly, in the process first of encoding the physical rarefactions and <br>compressions of air into neural impulses, and subsequently processing the <br>neural information in higher brain centers.<br>While the physical process by which the organ of Corti responds to incoming <br>sound waves and the impulses produced in the auditory nerve are known facts,  the arguments among various investigators arise from the *interpretations* of these facts. Some psychoacoustic <br>researchers claim a primary role for the physical acoustic transduction of <br> others claim that the operation of higher brain functions on the encoded nerve impulses is most important (the theory of tuning as a  learned response). <br>Because of the extraordinary variation in reliability and competence among <br>the various authors of psychoacoustic texts over the last century, and <br>because of the rapid progress in the field (which has rendered many earlier <br>texts obsolete), the interested reader is advised *not* to unquestioningly <br>believe *any* references dated earlier than 1970.<br>Rather, the reader is advised to *study as much of the <br>psychoacoustic literature as possible*, excerpts of which and references to <br>which are listen extensively in this article.<br>Only in this way can the objective reader get a real sense of the <br>extraordinary complexity of human hearing, and the provable falsity of <br>claims that "the ear is simple," "Helmholtz explained it all," or "so-and-so's <br>book on musical acoustics written in the 1950s tells us everything we need <br>to know about human hearing."<br>Reading is not enough.  Since the subject is what we hear and how, the <br>reader must also listen and make up hi/r own mind.<br>After perusing this post, the reader is strongly advised to listen to the <br>following tapes/CDs and study the following references: <br>[1] "Auditory Perception: An Audio Training Course," by F. Alton Everest. This <br>is the best single audio-tape set of examples of classic experiments  <br>demonstrating the complexity of the hearing process. At $159 this 104-page <br>manual and 4 audio cassette set isn't cheap. However, if you read the manual <br>and listen to the tapes, you'll quickly learn the basics of how we *actually* <br>hear (as opposed to how most musical theory textbooks and all too many <br>outdated acoustics and psychology texts *claim* we hear).<br>[2] "The Science of Musical Sound," by John R. Pierce, 2nd edition, 1992, with <br>accompanying audio cassette, covers the simplest elements of <br>psychoacoustics.<br>The cassette is useful for elementary phenomena--binaural beats, <br>"streaming," the critical band, consonance of simple vs. complex tones, etc., <br>but it cannot subsitute for Everest's far more complete set of <br>demonstrations.<br>[3] Houstma, Rossing and Wagenaars, 1987, "Auditory Demonstrations," <br>Philips 1126-061. An 80-track CD compendium of psychoacoustic <br>demonstrations of many psychoacoustic phenomena.<br>[4] Mathews, ed., "Sound Examples: Current Directions In Computer Music," <br>MIT Press, 1989.  A disc with a wider range of synthesized psychoacoustic <br>examples than the original cassette companion [2] above. <br>[5]  "Introduction To the Physics and Psychophysics of Music," 2nd ed. 1973 <br>and 3rd ed. 1995 by Juan Roederer contains one of the best general <br>discussions of the psychoacoustic literature up to that time (1973).  <br>Roederer covers a wide range of surprising characteristics of the ear/brain <br>system which are entirely ignored by less complete, and sometimes <br>completely misinformed or out-of-date texts published around the same <br>period.  <br>[6] "The Science of Music Sounds" by Johan Sundberg (1992) is one of the <br>best general references on modern psychoacoustics to date. It contains more <br>up-to-date citations than any text other than Zwicker and Fastl, and it <br>quotes a wider ranger range of sources than any other text but Sundberg <br>(1992) and Deutsch (1982).<br>[7] "The Psychology of Music," ed. Diana Deutsch, 1982, contains an excellent <br>cross-section of definitive summaries of various psychoacoustic phenomena <br>by the leaders in the field.<br>[8] "Psychoacoustics: Facts and Models," by Zwicker and Fastly, 1993, is the <br>best in-depth discussion of experimental psychoacoustics. It does not <br>discuss the various theoretical models of the ear/brain system and does not <br>cover streaming, nor does it consider the musical implications of <br>psychoacoustics.  Within its limits, however, it's the best reference on the <br>experimental side of the field for the specialist.<br>[9] "Audition" by Pierre Buser and Michael Imbert (translated by R.H. Kay), <br>1995, is the most detailed book on the physical structure of the ear/brain <br>system to date.  It also offers the most complete picture to date of the <br>neural structure of the ear/brain pathway, along with a micrometric<br>discussion of the various kinds of neurons which repond to<br>different frequencies, amplitudes, frequency differences, etc. passed along <br>the auditory nerve.  This book also does not discuss large-scale theoretical <br>models of the ear/brain system, nor does it concern itself with such high-<br>level phenomena as categorical perception or auditory illusions; but on the <br>level of the physical neural structure of the ear/brain pathway it is <br>unmatched.<br>Lastly, readers should *avoid* the statements about psychoacoustics <br>contained in many of the following well-meaning but outdated or simply <br>erroneous texts:<br>"The Acoustical Foundations of Music" by Backus, 1969, contains accurate <br>information on acoustics and the physics of some musical instruments.  <br>Unfortunately, almost all of Backus' statements about psychoacoustics had <br>been proven incomplete or incorrect by the time of publication of his book <br>(1969).<br>For example:<br>"The sense of pitch (related to vibration frequency) is thus partly <br>determined by the place along the basilar membrane where the vibration <br>amplitude is largest. There must be other factors also, since for sounds <br>close together in frequency, especially at low frequencies, the difference in <br>motion of the basilar membrane does not appear great enough to account for <br>the pitch discrimination of a good musician." [Backus, 1969, pg. 81]<br>This statement is correct but incomplete: the periodicity theory of hearing <br>can explain pitch discrimination at low fundamental frequencies but Backus <br>never mentions it. In fact the word "periodicity" does not appear in the index <br>of his book.<br>Again:<br>"Complex tones may also be built up out of harmonics but with the <br>fundamental omitted. The ear generally hears such tones as having the <br>fundamental frequency, even though there is no actual vibration of that <br>frequency present in the sound.  This missing fundamental effect is <br>explained on the basis of difference tones, since any two adjacent <br>harmonics will have a difference tones of the fundamental frequency." <br>[Backus, 1969, pg. 106]<br>This explanation dates from Helmholtz's time (1860s) and is known to be <br>incorrect. "One of the experimental results in Chapter 3 was that the <br>detectability threshold for combination tones is significantly lower for <br>small than for large frequency differences between the primary tones.  From <br>this, the conclusion was drawn that the ear's distortion cannot be <br>represented by a frequnecy-independent nonlinear characteristic." [Plomp, <br>1966, pg. 121]<br>"Helmholtz's belief that summation tones and difference tones are the most <br>prominent aural combination tones has become very widespread. However, <br>recent psychophysical and physiological experiments have revealed that this <br>belief is unjustified (Zwicker, 1955; Holdstein, 1970). Evidence for aural <br>summation tones has never been found, and difference tones arise only for <br>stimuli of relatively high intensity." [Houtsma, Adrian, "What Determines <br>Musical Pitch?" Journal of Music Theory, Vol. 17, No. 1, 1973, pp. 139-158] <br>Clearly Backus is misinformed and is passing that misinformation along to <br>his readers.<br>Other inaccuraies abound in Backus' text.<br>Jean-Claude Risset and Max Mathews, two of the most important pioneers in <br>analyzing real-world musical timbres, found in 1969 that instrument sounds <br>synthesized using fixed harmonic overtones sounded lifeless and artificial. <br>"Attempts of synthesis show how grossly inadequate it is to describe the <br>tone quality by a simple frequency spectrum."  [Pierce, J.R. , Mathews, M.  <br>and Risset J-C., "Further Experiments on the Use of the Computer in <br>Connection with Music," Grasvener Blaetter, no. 27/28, pg. 93, 1965] <br>In 1963--when Backus was still writing his text--Max Mathews pointed out: <br>"Our experience has shown how little we now know about relation of the <br>quality of sound to various features of waveform." [Mathews, M., "The Digital <br>Computer As a Musical Instrument," Science, Vol., 142, November, 1963, pg. <br>554]<br>Risset describes the state of ignorance which prevailed in the field of <br>musical acoustics through 1969 (the year in which Backus' text was <br>published): "Despite the considerable skill and ingenuity of scientists such <br>as Hermann Helmholtz or Dayton C. Miller, early analyses of musical-<br>instrument tones have not given satisfactory results. (...)  For a long time <br>physicists have performed analyses of musical-instrument tones, to find <br>out the physical correlates of their tone quality.  Many results of such <br>analyses have been published. (...) Computer sound synthesis makes it <br>possible to synthesize virtually any sound from a physical description of <br>that sound.<br>"This technique provides a way to check sound analyses: a successful <br>analysis should yield a physical description of the sound from which one <br>could synthesizer a sound that, to a listener, is nearly indistinguishable <br>from the original.<br>"We have tried to use the results of analyses of musical-instrument tones <br>that are to be found in musical-acoustic treatises as input data for <br>computer sound synthesis.  In most cases we have obtained sounds that bear <br>very little resemblance to the actual tones produced by the instrument <br>chosen; in almost all cases the available descriptions of musical-<br>instrument tones fail the fool-proof synthesis test.  Hence the descriptions <br>must be considered inadequate." [Risset, J.C. and Mathews, Max, "Analysis of <br>Musical-Instrument Tones," Physics Today, Volo. 22, No. 2, February 1969, <br>pp. 23-24.]<br>By Backus' own admission, his text was based on a series of lectures <br>developed over 10 years--which means that his psychoacoustic references <br>date from the 1930s, 1940s and 1950s during a critical period of upheaval <br>in psychoacoustics caused by the application of computers to music. <br>Backus does not mention computer analysis of sound: "The mechanical <br>method of analyzing sounds was cumbersome, slow and inaccurate; much <br>better equipment is available now for this kind of work.  This equipment is <br>electronically operated and therefore much faster; an oscillogram can be <br>obtained in one cycle of sound and analysis of the sound wave can be made in <br>one second or less." [Backus, 1969, pg. 101]<br>As Risset points out, the use the oscillograms prevents researchers from <br>following the evolution of a sound's spectrum throughout a long time period.  <br>Thus Backus' techniques are by definition inadequate and out of date.<br>None of Backus' references hint at the then-unpublished results of <br>Guttman, Shepard, Risset and Mathews, which changed the entire field of psychoacoustics.<br>Thus Backus' book is full of errors and misconceptions about the ear/brain system and should be ignored. <br>"Genesis of a Music" by Harry Partch, (1947, 2nd ed. 1974) contains much <br>valuable information about just intonation, acoustic instrument-building <br>and the fundamentals of musical acoustics.  Alas, virtually all of Partch's <br>statements about consonance, dissonance, human hearing and the ear/brain <br>system are claptrap.  He cites no psychoacoustic literature dated later than <br>1945: Partch was simply unfamiliar with modern experimental evidence <br>about the ear/brain system.<br>"Musical Engineering," by Harry F. Olson is an excellent introduction to the <br>physics of sound production in musical  instruments.  The statements about <br>musical timbre, the ear/brain system and consonance/dissonance embodied <br>the best knowledge up to that time (1957).  Unfortunately, most of what <br>Olson says about musical timbre, consonance,  hearing, etc., was disproven <br>by the experiments of Wessel, Risset, Ward, and many others in the 1960s <br>and early 70s.<br>""[On] my arrival in the States in 1964...I elected to focus on timbre.  The <br>palette  of computer sound, potentially boundless, was in fact quite <br>restricted, and one did not know how to generate certain sounds. In <br>particular, brassy sounds resisted synthesis efforts. I had to convince <br>myself that the recipes of respected acoustics treatises (like H. F. Olson's) <br>did not work.  As one may judge, from tones synthesized from such recipes, <br>they did not." [Risset, Jean-Claude, "Computer Music Experiments 1964...", <br>Computer Music Journal, Vol. 9, No. 1, Spring 1985, pg. 11]<br>"Fundamentals of Musical Acoustics," by Arthur Benade (1976) contains <br>reliable details on acoustics, but some of  Benade's information on sound <br>production in various instruments has now been proven incorrect--<br>particularly, Benade's theory of "regimes of oscillation" for brass <br>instruments. <br>Benade's text, like Backus, does not contain the word "periodicity" in its <br>index. And many of Benade's statements on psychoacoustics contradict the <br>results of modern research,  although to his credit Benade himself admits <br>this: "The foregoing remarks disagree somewhat with the conclusions drawn <br>by the authors of the following thoughtfully written papers:<br>J.E. F. Sundberg & J. Lindqvist, "Musical Octaves and Pitch," JASA, Vol. 54, <br>1973, pp. 922-929," and so on.   <br>Benade's references on psychoacoustics show strange gaps and a peculiar <br>selectivity.  Ohm, Stumpf, Seebeck, Schouten, Plomp, von Bekesy, Sundberg, <br>Ward and Burns are not cited in the biolography at the end of the chapter <br>"The Acoutical phenomena governing the musical relationships of pitch," <br>while Pierce, Mathews, Shepard, Risset, Sundberg, Ward and Burns are not cited in the chapter "Successive Tones: Reverberation, Melodic Relationships, and Musical Scales." <br>Instead an article by Steven and Volkman dating from 1940 is cited, <br>along with Helmholtz--whose work dates from the 1860s--and "The <br>Collected papers of Wallace Sabine," another 19th-century figure. <br>For a researcher in the 1970s to write a text whose primary psychoacoustic <br>citations hail from the 1860s-1880s is peculiar, to say the least. Like Hall, <br>Benade is a physical acoustician whose bibliography and reference lists <br>betrays a scanty knowledge of modern psychoacoustics, and an unsavory <br>penchant for discarding results with which his simplistic mathematical <br>models disagree.<br>Rossing, "The Physics of Music," 1993, is a comprehensive discussion of the <br>physical basis of acoustic instrument timbre, but it contains very little <br>information about psychoacoustics.  To be fair, that was not Rossing's focus.  <br>Still, the text contains nary a mention of Wessel's streaming phenomenon, <br>no reference to Ward, Corso, Pikler, Sundberg and Terhardt's findings  on the <br>universal preference for stretched octaves, fifths and thirds; no information <br>on how pitch perception is affected by masking, context, tone length, etc.; <br>no distinction twixt physical and perceptual pitch or physical and <br>perceptual loudness, etc.<br>Other texts may prove popular.  Before believing any reference on <br>psychoacoustics, be sure to check its date. Many pre-1970 acoustics text <br>either lack important psychoacoustic data, are outdated, or contain a wealth <br>of outright misinformation parrotted from Rameau, Mersenne and Helmholtz.<br>Check the bibliographies of these suspect texts--notice how few post-1945 <br>papers are cited, and how often the authors take issue with well-known and <br>accepted results from the 60s, 70s, 80s and 90s verified independently by <br>many reserachers in psychoacoustics on 4 continents.  Lastly, simply <br>compare what you hear on F. Alton Everest's tapes and the Houtsma, Rossing <br>and Wagenaars disc and the Mathews "Sound Examples: Current Directions in <br>Computer Music" disc with claims made by the author in question.<br>--mclaren <br> <br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Tue, 26 Sep 1995 21:23 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id MAA17646; Tue, 26 Sep 1995 12:22:26 -0700<br>Date: Tue, 26 Sep 1995 12:22:26 -0700<br>Message-Id: <199509261918.AA04185@net4you.co.at><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2061 href="#2061">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>9/27/1995 8:13:43 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Psychoacoustics - post 4 of 25<br>---<br>The ear itself is the gateway to new kinds<br>of harmony and new forms of music.  The<br>more we learn about the subtleties of the<br>ear/brain system, the wider the range of<br>xenharmonic musics we can make.<br>---<br>MYTH: EVERYONE KNOWS HOW THE EAR PERCEIVES<br>  PITCH. HELMHOLTZ EXPLAINED IT IN 1863.<br>FACT: Since 1841 there have been 3 competing theories<br>of how the ear operates. <br>Some evidence supports, while other evidence <br>contradicts, each hypothesis about <br>how the ear perceives sound.<br>---<br>Ohm (1843) is the founder of modern hearing<br>theory.  "Ohm introduced the view that the<br>analyzing power of the hearing organ may be <br>compared to the way in which periodic <br>functions can be analyzed mathematically<br>by applying Fourier's theorem (Ohm 1843).<br>Helmholtz fully recognized the significance<br>of this hypothesis and based his theory on<br>it..." ["Experiments On Tone Perception,"<br>Plomp, R., 1967, pg. 102]<br>In effect both Ohm and Helmholtz viewed<br>the ear as a frequency analyzer. Ohm's First<br>Law states that the ear detects a pitch<br>only if there is significant acoustic<br>energy at the fundamental frequency of<br>that pitch, which (as we all know) consists<br>of a set of sine wave harmonics added<br>together.<br>---<br>Everyone knows this, and it's wrong.<br>Ohm's hypothesis was dealt a series of<br>blows by experimental evidence.<br>Researchers using crude light microscopes<br>from the 17th through the early 19th centuries<br>examined the cochlea and found what appeared<br>to be rods.  This naturally suggested a set of<br>tuned resonators--an idea which Helmholtz<br>picked up in the 1840s and elaborated into<br>the first (resonance) version of his theory of <br>hearing.<br>"The principle of resonance, based on early work<br>of Galileo, was proposed as a way for low and high<br>tones to have different effects on the ear. For example,<br>in 1683 du Verney, in his `Traite de l'organe de<br>l'ourie,' suggested that a ribbon-like structure<br>along the length of the cochlea vibrates in different<br>places to different frequencies through resonance<br>by noting that the width of the ribbon changed from<br>one end of the cochlea to the other. (..) In 1851 Corti<br>described a number of the finer structures inside the <br>cochlea, the most prominent of which he called teeth,<br>while others called them rods.  The inverted V is <br>now called the "arch of Corti," but his vantage point<br>was from above, so that the arches appeared as extended<br>rods...  He described the rods as delicate, free, and flexible,<br>and he supposed that their movements stimulated acoustic<br>nerve fibers which, at the time, were believed to end <br>in the vicinity of the rods." [Gulick, W. Lawrence, <br>George A. Geschneider and Robert D. Frisina, "Hearing:<br>Physiological Acoustics, neural coding and Psychoacoustics,"<br>Oxford University Press, 1989, pg. 59]<br>The mistaken picture of the arches of Corti as resonating rods<br>was the one used by Helmholtz to support his earliest<br>"resonance" theory of hearing.<br>However, successive improvement in the resolution of<br>available light microscopes--due largely to the work<br>of the mathematician Abel--dealt a serious blow to<br>Helmholtz's 1863 "Tonemfindungen," in which he stated<br>in detail a theory of hearing he had presented in a lecture in<br>Bonn during the winter of 1857.<br>"In his public lecture in 1857, Helmholtz proposed that<br>sounds reaching the cochlea would set certain of the rods<br>of Corti in motion by sympathetic vibration.  He envisaged <br>the rods as a set of tuned resonators, so that only those with<br>a natural frequency equal to that of the stimulus would vibrate<br>and thus stimulate only those acoustic fibers that served them."<br>[Gulick, W. Lawrence,  George A. Geschneider and Robert D. <br>Frisina, "Hearing: Physiological Acoustics, neural coding and Psychoacoustics," Oxford University Press, 1989, pg. 60]<br>The subsequent microscopic "...discoveries of Deiters in <br>1860 made it clear that the rods of Corti were unsuitable as <br>resonators because they were arches rather than independent <br>rods. So, in `Empfindungen,' Helmholtz revised his theory by<br>shifting the resonators to the transverse fibers of the basilar<br>membrane, a membrane "stretched" across the cochlear tube."<br>[Gulick, W. Lawrence,  George A. Geschneider and Robert D. <br>Frisina, "Hearing: Physiological Acoustics, neural coding and Psychoacoustics," Oxford University Press, 1989, pg. 61]<br>In keeping with the ancient principle of likeness, according<br>to which features of the nervous system symbolzed the external<br>world, Helmholtz adopted the doctrine of "specific nerve energies," <br>which stated that each nerve responded to a unique stimulus<br>and only to that stimulus.  This doctrine was proposed by Helmholtz's<br>teacher Johannes Mueller in 1838 in Mueller's `Handbuch der <br>Physiologie,' but it was first stated by Herophilus and Eristratus <br>in 490 B.C. and subsequently expounded by Aristotle in 344 B.C.<br>"By extending Mueller's doctrine, Helmholtz claimed that each <br>acoustic nerve fiber had its own `quality,' so that, when activated, <br>it always led to the perception of a particular pitch. (..) Accordingly,<br>frequency was coded by the place of stimulation along the longitudinal<br>axis of the cochlea." [Gulick, W. Lawrence,  George A. Geschneider and <br>Robert D. Frisina, "Hearing: Physiological Acoustics, neural coding and Psychoacoustics," Oxford University Press, 1989, pg. 61]<br>This did not solve the problems with Helmholtz's theory of<br>hearing.  Instead, more and more dififculties began to appear<br>after its publication in 1863:<br>"First, the transverse fibers of the basilar membrane are <br>neither under tension nor independent. Therefore, they are<br>ill-suited to serve the function ascribed to them in theory.<br>(..) Second, even if the transverse fibers were under tension<br>and independent suspended, the variation in fiber length and<br>mass is so restrictive as to limit resonance to a frequency<br>range that is only a small fraction of the total to which we<br>respond. (..)<br>"Third, there is a serious difficulty with the principle of <br>resonance as a means to account for frequency discrimination.<br>(..) Fourth, since no resonance is wholly specific, Helmholtz's<br>theory also was criticized because a tone of a given frequency<br>would produce resonance not only in the tuned resonator but also<br>in those that are slightly mistuned.  Accordingly, one tone would<br>signal a number of places, and therefore, a number of pitches.<br>In 1900 Gray offered his hypothesis of maximum stimulation to<br>counter this objection. He proposed that the exactly tuned<br>resonator would also show maximum resonance, and it was this<br>trasnverse fiber that singaled the place for that tone. However,<br>he claimed that with intense stimulation many resonators would<br>be responding at the practical maxima, and since the precision of<br>the place would thereby be lost, he predicted that differential<br>pitch sensitivity would worsen as a function of increasing<br>intensity.  Psychophysical data show the opposite to be true.<br>(..) Fifth, Helmholtz assumed that changes in stimulus intensity<br>produced changes in stimulus magnitude.  However, by 1914, the<br>work of Adrian on the all-or-none property of neural action seemed <br>emphatically to deny this requirement of the Helmholtz theory.<br>As the current century began, the resonance-place theory of hearing <br>was in some trouble."  [Gulick, W. Lawrence,  George A. Geschneider and <br>Robert D. Frisina, "Hearing: Physiological Acoustics, neural coding and Psychoacoustics," Oxford University Press, 1989, pg. 63]<br>Other strong doubts about the Helmholtz or "place" theory of hearing <br>arose as a result of Seebeck's experiments in 1843.<br>"He constructed a siren from a forced air system, in front of which<br>he placed a rotating disk with small holes separated by specific <br>distances so as to produceshort sound pulses separated by<br>precisely specified time intervals. (..) The pitch of this periodic<br>pulse was the same as that of a 500-Hz tone.  This is not surprising,<br>since the pulse train delivered 500 pulses/sec. A more surprising<br>result occurred when pulses alternated between two slightly<br>different values. Although the timing between pulses<br>had been changed only slightly...the perceived pitch dropped<br>dramatically from that of a 500-Hz tone to that of a 250-Hz tone<br>despite the fac that most of the energy in this slightly<br>modified stimulus was still at 500 hz.  The physical property<br>that was clearly altered by ths light change in pulse timing was the<br>period. (..) This change in pitch was attributed to the change in<br>the period of repeating sound pressure wave and eventually became<br>known as periodicity pitch." [Gulick, W. Lawrence, George A.<br>Geschneider and Robert D. Frisina, "Hearing: Physiological Acoustics,<br>Neural Coding, and Psychoacoustics," Oxford University Press, <br>1989, pg. 257]<br>As Gulick et alii point out, "Seebeck's work was important because it<br>led investigators to consider the timing of neural impulses as a <br>possible neural code for pitch perception. The place and neural synchrony<br>[periodicity] theories represent two very different views on how the<br>nervous system codes pitch.  For the place theorist it is the frequency<br>spectrum of the stimulus that is important, whereas for the neural<br>synchrony theorist it is some aspect of the time waveform, such as <br>the period, that is important. (..) The controversy between proponents<br>of two viewpoint gained momentum in the 1940s with the work of<br> Schouten." [Gulick, et al., 1989, pg. 258]<br>Pierce describes hearing Schouten's effect first-hand: "He had constructed<br>a sort of optical siren (Figure 6-4) by means of which he could produce sounds with various waveforms.  Using this, he produced sounds with harmonically related partials... Then, by proper  adjustments, he <br>could cancel out the fundamental frequency... I could hear<br>this fundamental frequency come and go, but the pitch of the sound <br>did not change at all.  In some way, my ear inferred the proper pitch <br>from the harmonics..." ["The Science of Musical Sound," Pierce,<br>2nd ed., 1992, pg. 92;  also see Ohm, G.S., "Ueber die Definition des <br>Tones, nebst daran geknuepfer Theorie der Sirene und aehnlicher <br>tonbildener Vorrichtungen," Ann. Phys. Chem, Vol. 59, ppg. 513-565,<br>also see  Schouten, "The Perception of subjective tones," Proceedings <br>of the Koninklijke Nederlandse Akademie van Wetenschappen, 1938, <br>vol. 41, pp.  1083-1093.]<br>While most of the details of Helmholtz's theory of hearing are now<br>known to be inaccurate, parts of the underlying idea  were adopted <br>in the "place" theory of hearing.  According to this theory, just intonation<br>is the ideal musical tuning and the 4:5:6 chord which stands at the<br>center of traditional Western harmony is a necessary outcome of<br>the physical structure of the human auditory system.<br>As will be seen, however, all of the objections to Helmholtz's<br>theory remain troublesome even to modern-day place theories. <br> The modern place theory cannot explain the simultaneously fine <br>frequency discrimination  of the ear and its broad range of frequency response; the modern place theory cannot explain the missing fundamental;<br>nor can it  explain how the relatively wide travelling waves on the<br>basilar membrane give rise to delicate pitch judgments.  The<br>modern place theory cannot explain how the ear can detect<br>the pitch of tones whose fundamental lies below  rougly 150 Hz.  <br>The modern place theory cannot explain how only 3000 hair cells<br>account for the measured jnd of the average subject; the modern<br>place theory cannot explain why louder sounds are more<br>accurately judged in frequency when the opposite is predicted<br>from conventional frequency; and the modern place theory cannot<br>explain categorical perception, the encoding of pitch and<br>amplitude in the auditory nerve, the universal human preference<br>for stretched intervals and beat rates between 4 and 6 Hz, and<br>so on.<br>Thus there is substantial reason to doubt that either small integer<br>ratios or 4:5:6 chords consitute either a privileged or even a<br>necessary outcome of the human ear/brain system. <br>On the other hand, some aspects of the auditory system are<br>convincingly explained by the modern place theory.  The cocktail<br>party effect, the ability to perceive the pitch of tones with<br>a high-pitched fundamental. "Furthermore, support for the view<br>that perception ohte pitch of them issing fundamental is not due <br>to the excitation of low freuqency-sensitive neurons responding<br>to low freuqnecy distortion products of a complex tone comes<br>from observatiosn that a low frequency masking noise presented <br>with the high freuqnecy complex tone does not eliminate the<br>perception of the missing fundamental." [Gulick, et al., 1989, pg. 259] <br>The next post will examine in greater detail the place theory<br>of hearing, and the psychoacoustic evidence for and against it,<br>along with the implications for tuning and music.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Wed, 27 Sep 1995 19:26 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id KAA06522; Wed, 27 Sep 1995 10:26:35 -0700<br>Date: Wed, 27 Sep 1995 10:26:35 -0700<br>Message-Id: <199509271725.KAA19263@osiris.ac.hmc.edu><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2073 href="#2073">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>9/28/1995 10:31:12 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Tuning & Psychoacoustics - post 5 of 25<br>--<br>As mentioned in the previous post,<br>the elements of the modern place<br>theory of hearing are found in Helmholtz's<br>19th-century model of the ear.  Thus it's<br>worth taking some time to examine<br>the implications of that model:<br>"Helmholtz's hearing theory can be<br>considered as an elaboration of three<br>hypotheses. In general terms, the first<br>one is:<br>"Hypothesis I. The analysis of sound is<br>accomplished in the inner ear by means<br>of a large number of resonators tuned<br>to different frequencies from low to <br>high." ["Experiments On Tone Perception,"<br>Plomp, pg. 102, 1966]<br>Helmholtz originally ascribed the<br>"resonator" function to the arches<br>of Corti but (as mentioned in the <br>last post) when he put his ideas down<br>in his book he changed his mind<br>and proposed that the transverse <br>fibres of the basilar membrane act<br>as resonators. His arguments were:<br>[1] In the cochlea of birds, no arches<br>of Corti are found (Hasse, 1867); [2] <br>the width of the basilar membrane<br>varies from about 0.04 mm at its <br>base up to 0.5 mm at the helicotrema<br>(Hansen, 1863); [3] the membrane is<br>much more tightly stretched transversely<br>than longitudinally.<br>"On the basis of these measurements,<br>Helmholtz estimated the selectivity<br>of the resonators, amounting to about<br>4% of the resonance frequency, with<br>bandwidth proportional to logarithmic<br>frequency.<br>"Hypothesis II. A particular tone-pitch<br>corresponds to each of the numerous<br>nerve fibers in such a way that pitch<br>decreases gradually from the basal to<br>the apical end of the organ of Corti."<br>["Experiments On Tone Perception," <br>Plomp, R., pg. 103, 1966]<br>While Helmholtz's hypotheses explained<br>some aspects of human hearing, it<br>did not explain others.   In particular,<br>these hypotheses did not explain how <br>combination tones or beats<br>of mistuned consonances occur.<br>Thus Helmholtz proposed a third<br>hypothesis:<br>"Hypothesis III. The sound transmission<br>of the ear is characterized by nonlinear<br>distortion." ["Experiments On Tone<br>Perception," Plomp, R., pg. 103, 1966]<br>By means of these 3 hypotheses <br>Helmholtz was able to explain much<br>of the experimental data available<br>to him in 1863.  <br>Other aspects of human hearing remained<br>unexplained.  As Plomp points out, "The<br>Achilles' heel of his conception was<br>why periodic sound waves are always<br>characterized by a pitch corresponding<br>to the fundamental. ...  Even so, Helmholtz's<br>theory became widely accepted soon<br>after its publication under the names<br>of resonance theory and place theory."<br>[Plomp, R., 1966, pg. 104]<br>There were other problems with<br>Helmholtz's theory.  Whether in modern<br>form as the "place" theory or in terms<br>of Helmholtz's original conception, the<br>pitch sensitivity of the human ear is<br>significantly greater than the predictions<br>made on the basis of the place theory.<br>Moreover, if the ear is primarily  a Fourier <br>analyzer, why did it respond to the irregularly-<br>spaced holes of Seebeck's siren (Seebeck,<br>1846) with a sensation of definite<br>pitch not present in any of  the<br>Fourier components of the waveform<br>generated when the siren rotated?  <br>Stumpf, one of the proponents of a<br>competing theory of hearing, pointed<br>out these flaws in the original<br>place theory:<br>"The view that fibres of 0.5 mm length <br>should be tuned to low frequencies did <br>not sound very credible and we may<br>suppose that many agreed with Stumpf's<br>statement: `It remains wonderful,<br>however, that so small particles can<br>resonate even on the lowest tones<br>that we produce by strings of enormous<br>size and by which we can bring into<br>resonance only strings of the same<br>size.'" [Plomp, 1966, pg. 107; see also<br>Stumpf, C., "Tonpsychologie," Vol. 2,<br>Verlag S. Hirzel, Leipzig, 1890, pg. 92]<br>Plomp points out: "Some investigators<br>tried to save the resonance hypothesis<br>by supposing that the resonators<br>must be sought in other structures of<br>the cochlea: the hair cells (Baer, 1872;<br>Hermann, 1894; Myers, 1904; Specht,<br>1926) or the tectorial membrane (Kishi,<br>1907; Shambaugh, 1907, 1909, 1911; <br>Leiri, 1932). Others, however, rejected<br>the resonance hypothesis entirely, <br>proposing new hearing theories in which<br>the frequency-analyzing power of the<br>hearing organ was approached in quite<br>a different way (Meyer, 1896, 1898,<br>1899, 1907; Ewald, 1899, 1903,<br>Wrightson, 1918, and many others)."<br>[Plomp, 1966, pp. 107-108]<br>Because of the failure of Helmholtz's<br>original hypothesis to explain many <br>auditory phenomena, many researchers<br>cast about during the period from the<br>1840s to the 1860s for another model<br>of human hearing.  Many researchers<br>seized upon Seebeck's 1843 proposal<br>as the answer.<br>Namely, that "Tones give rise to<br>synchronous nerve impulses whose<br>rate determines pitch.  Wundt tried<br>to evade the difficulty that according<br>to this hypothesis Bernstein's findings<br>would suggest a pitch limit at about<br>1600 cps. He explained that not the<br>total duration of the nerve impulses<br>but the much shorter duration of their<br>peaks might determine the highest<br>pitch audible..." [Plomp, 1966, pg. 105]<br>In favor of this competing hypothesis,<br>called the periodicity theory of hearing, <br>two pieces of early evidence were advanced<br>by Seebeck, Wundt, Stumpf and others:<br>"1. Binaural beats. Dove (1839) had<br>pointed for the first time to the fact<br>that stimulating the ears separately <br>with tones of slightly different frequencies<br>gives rise to slow "binaural beats." Usually,<br>they were explained as resulting from<br>bone conduction between the ears (Seebeck,<br>1846; Mach, 1875; Stumpf, 1890, p. 458;<br>Schaefer, 1891). Thompson, who discovered<br>the beats independently, found that they do<br>not change over into a difference tone when<br>the frequency difference is increased (1877,<br>1878, 1881). Therefore, he suggested that<br>binaural beats are caused by interference in<br>a higher centre of the auditory pathway."<br>[Plomp, 1966, pg. 105]<br>This latter was the first suggestion that the brain was<br>directly involved in the processing of musical<br>sounds. Previous theories, like Helmholtz's, <br>assumed that the ear did all the processing<br>required and that the auditory nerve simply<br>acted as a conduit through which the preprocessed<br>nerve impulses travelled.   Wundt's and Stumpf's<br>observations made it clear, however, that the<br>brain was *part* of the auditory system which<br>determined pitch, spectral content, etc.--perhaps<br>*the* crucial part (as subsequent late-20th-century<br>"pattern transformation" hypotheses of hearing have<br>stressed).<br>The second piece of evidence supporting<br>the Seebeck/Stumpf/Wundt periodicty theory was:<br>"2. Direct stimulation of the auditory nerve.<br>The sensational conclusion that the cochlea<br>is not essential for obtaining an auditory<br>sensation was drawn independently by<br>Fano and Massini (1891) and by Ewald (1892).<br>They based their opinion on the positive<br>reactions on sound by pigeons with removed<br>hearing organs. The conclusion was severely<br>crticized by Matte (1894), Bernstein (1895),<br>Strehl (1895), and Kuttner (1896), and<br>defended by Ewald (1895) and Wundt (1895)"<br>[Plomp, 1966, pg. 106]<br>Plomp points out that although this second<br>competing hearing theory could explain<br>interruption tones and beats of mistuned<br>consonances much better than Helmholtz's<br>theory did, its influence was small, perhaps<br>because Wundt did not work the theory out<br>in nearly as much detail as did Helmholtz<br>in the 2nd edition of "On The Sensation of Tone." <br>The whole later development of physiological<br>acoustics can be regarded as an elaboration<br>of these two competing and contradictory<br>hypotheses, along with Fetis' 1843 learned-<br>response theory of hearing. Like Seebeck's<br>and Stumpf's periodcity theory--which was<br>largely ignored until Schouten in 1935 performed<br>a convincing series of experiments which clearly<br>demonstrated the inadequacy of the place theory<br>of hearing--Fetis' 1843 theory of learned response<br>was likewise ignored for many years.  Starting in<br>the 1950s,  Ward, Burns, Corso, Licklider, and others<br>performed a series of experiments which cast profound<br>doubt on many aspects of both the periodicity and<br>place theory and strongly supported Fetis' 1843 <br>hypothesis. <br>Recently, the auditory artifacts produced by <br>cochlear implants have provided strong evidence against<br>the periodicity theory:  "If we believe the <br>extreme position that at low frequencies information is<br>carried purely by the temporal pattern of nerve impulses,<br>then periodic electrical stimulation should produce<br>faithful auditory sensations and good discrimination<br>of frequencies. The results of electrical stimulation have <br>on the whole been disappointing for such a prediction.<br>In only a few cases to electrical stimuli seem to produce<br>clear tonal sensations. A typical report is that tones<br>sound like "comb and paper" (e.g., Fourcin et al., 1979).<br>[Pickles, James. O., "An Introduction to the Physiology<br>of Hearing," Academic Press, 2nd ed., 1988, pg. 316]<br>On the other hand, the place theory also conflicts with<br>experiment: "In a quasi-linear spectral analyzer such<br>as the cochlea the physical limits of frequency resolution<br>are limited by the duration of the stimulus, as a result<br>of spectral splatter: stimulus duration x spectral line<br>width = 1.  (..) Temporal theories are not so limited...<br>(..) On the hypothesis that place and not temporal cues are<br>used, we can calculate a lower limit for the frequency<br>difference limen as a function of the length of the<br>stimulus.  Moore (1973) showed that below 5 khz frequency<br>discrimination for short stimulus was up to an order of<br>magnitude better than expected on a place basis. " <br>Pickles, James. O., "An Introduction to the Physiology<br>of Hearing," Academic Press, 2nd ed., 1988, pg. 273]<br>As a result, "At the moment pattern hypotheses are<br>dominant..." Pickles, James. O., "An Introduction to the Physiology<br>of Hearing," Academic Press, 2nd ed., 1988, pg. 273]<br>The phenomenon of forward and backward masking<br>also directly contradicts the place theory.  In forward<br>masking, a masking tone precedes the test tone by a<br>small time period--in backward masking, the masking<br>tone occurs *after* the test tone.  If Fourier analysis<br>is occurring mechanically in the ear, it's difficult to<br>explain how a second tone appearing *after* the test<br>tone can interfere with the Fourier analysis.  And in<br>any case, the fact that masking occurs is a fundamental<br>problem for Fourier models of hearing. <br>"Masking is an example of limitations of the<br>auditory system's ability to analyze individual frequency<br>composnents in a complex sound. If the ear were a perfect <br>frequency analyzer, then one sound would never mask<br>the detecability of another sound.  Instead, simultaneously<br>presented sounds would be independently processed, and the<br>perpcetion of one would not affect the perception of others.<br>Masking demnstrates that this ideal state does not exist.<br>Whenever masking occurs, frequency analysis fails.  When<br>the presence of a sound of a particular frequency makes it<br>difficult or impossible to hear another sound of a different<br>frequency, the ear has failed to analyze and detect the<br>individual frequency components of the complex sound<br>created by simultaneous presentation of the two sounds."<br>[Gulick, W. Lawrence and George A. Geschneider and<br>Robert D. Frisina, "Hearing: Physiological Acoustics, Neural<br>Coding, and Psychoacoustics," Oxford University Press,<br>1988, pg. 300] <br>As a result of these pervasive problems with both the<br>place and periodicity theories of hearing,<br> Fetis' model of the ear/brain system<br>as a feedback path controlled primarily by software (viz.,<br>learned response) has now gained great currency. <br>in part because of the inadequacy of current evidence<br>In part this is also probably due to increasing use of computers <br>and  software in the congitive sciences and their consequent<br>popularity as a conceptual model for neural systems.<br>(As will be seen in a future post, a researcher's tools <br>exert a potent influence on the mental models he forms.)<br>If accurate, the "pattern transformation" model of hearing<br>implies that many different tuning systems and musical<br>syntaxes are appropriate.  According to this theory of hearing,<br>no particular complex of overtones has a privleged status<br>in the ear, and no specific musical tuning is implied as<br>superior on the basis of the structure of the ear.<br>Because of the importance of this question for tuning and<br>music, the next post will examine detailed evidence<br>for and against the periodicity and place models of <br>pitch perception.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Fri, 29 Sep 1995 07:12 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id WAA06397; Thu, 28 Sep 1995 22:12:35 -0700<br>Date: Thu, 28 Sep 1995 22:12:35 -0700<br>Message-Id: <Pine.SOL.3.91.950929001046.2688C-100000@library><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2079 href="#2079">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>9/29/1995 9:24:03 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Tuning & Psychoacoustics - Post 6 of 25<br>---<br>MYTH: THE OPERATION OF THE EAR CAN BE<br>EXPLAINED AS THAT OF A FOURIER ANALYZER,<br>WITH SOME SLIGHT MODIFICATIONS.<br>FACT:  Today there are 3 competing models which<br>explain how the ear/brain system operates, and <br>some experimental data supports each hypothesis<br>and contradicts the others.  Each theory has enjoyed<br>proponents for more than 100 years, primarily<br>because many aspects of the ear's behaviour cannot <br>be explained by means of Fourier analysis.<br>---<br>During the late 19th and early 20th<br>century, rapid advances in technology allowed<br>scientists to subject both the place theory<br>and the periodicity theory of hearing<br>to ever-more-sophisticated tests.<br>"On the basis of these different methods,<br>the fact is now well established that the<br>stimulated region of the basilar membrane<br>shifts for decreasing frequency from the<br>basal to the apical end." [Plomp, 1966,<br>pg. 108; see also Cioco, 1934; Crow et al,<br>1934, Oda, 1938; Stevens et al., 1935;<br>Walzl and Bordley, 1942; Schuknecht,<br>1960; Kemp, 1935, 1936, Smith, 1947,<br>Smith and Wever, 1949; Davis et al.<br>1953; Culler, 1935, Culler et al. 1937,<br>1943; and particularly von Bekesy,<br>1944, 1955, 1957.]  von Bekesy<br>constructed a large and simplified<br>physical replica of the cochlea which used<br>the tactile sense of the arm to <br>stimulate the organ of Corti and the <br>auditory pathway.  He proved that<br>even in the case of a very broad<br>maximum of the pattern of vibration,<br>only a small section was felt<br>subjectively to vibrate. This lent<br>strong suport to the view that<br>the place of maximal stimulation<br>along  the basilar membrane <br>corresponds to pitch.  (That is,<br>to Helmholtz's theory, with a good<br>deal of updating; Helmholtz's idea<br>of "resonators" had to be abandoned,<br>and many of the details of his theory<br>modified, to explain experimental<br>results, as we've seen.)<br>While von Bekesy's experiments <br>provided strong confirmation for<br>some of the place theory's prediction,<br>they contradicted other aspects <br>of the place theory.   There<br>remained unresolved, for instance,<br>the question of how to account<br>for the ear's extraordinary<br>sensitivity to tuning differences<br>of individual partials and of<br>the fundamental frequency of<br>the sound wave itself.  WIth only<br>3000 hair cells each spaced 9 microns apart,<br>this was difficult to explain. Known pitch<br>discrimination would demand sensitivity to<br>stimulation on the basilar membrane measured<br>in fractions of a micron,  even though the measured<br>width of the travelling wave on the basilar membrane<br>is many times that width. (This objection<br>was originally raised to Helmholtz's <br>now-obsolete hypotheses of the<br>1860s, and it still bedevils advocates<br>of the modern place theory.) Moreover,<br>if pitch sensitivity were due solely to the hairs<br> lining the basilar membrane, and not to neural<br>processing, there would have to be far more<br>hairs than the known 3000 inner hair cells <br>(electron microscopy has shown that<br>the remaining 12,000 outer hair cells serve <br>an ancillary function, rather than a direct <br>freqency-detection role.  This is also supported<br>by data from the action potentials of the<br>two classes of stereocilia as obtained by<br>microelectrodes.) "The two types of coupling can<br>therefore be associated with the different<br>roles of the two types of hair cell in cochlear<br>function, inner hair cells detecting the movement<br>of the [basilar] membrane, and the outer hair cells<br>helping to generate it." [Pickles, James O., "An<br>Introduction to the Physiology of Hearing," Academic<br>Press, 1988, 2nd ed., pp. 158-159] <br>It is also difficult to explain pitch perception of<br>sounds with low but missing fundamentals: <br>"Suppose high harmonics generate the low pitch.<br>They wil be relatively closely spaced and will not<br>be resolved by the auditory stytem. Recognition of<br>the psectral pattern will not therefore be possible,<br>but hte harmonics wil eb able to interact in the<br>nervous system to produce periodically varying<br>activity.  Temporal theories are therefore supported."<br>[Pickles, James O., "An Introduction to the Physiology<br>of Hearing," Academic Press, 1988, pg. 273]<br>However, Pickles points out that "This is again an<br>area which is controversial, and over the years<br>opinions have swayed in favour of one hypothesis<br>or the other." (I.e., periodicity or place theory.)<br>Both theories suffer from the limits imposed <br>mathematically by their proposed mechanisms<br>of action, which are in each case  different<br>from those observewd: "The lower limit for the place <br>principle is believed to be about 150 Hz becuase <br>the excitation pattern on the basilar membrane does <br>not change with frequencies lower than this limit.<br>Some investigators think that the temporal principle<br>codes ptich for the very low frequencies and supplements<br>the place principle over the midrange frequencies. The<br>upper frequency limit of the applicability of the temporal<br>principle is uncertain. Some investigators put this limit<br>as low as 300 to 400 hz, and others put it as high as<br>4000 to 5000 Hz." [Gulick, W. Lawrence,<br>George A. Geschneider and Robert D. Frisina, "Hearing:<br>Phsyiological Acoustics, Neural Coding, and<br>Psychoacoustics," Oxford University Press,<br>1989, pg. 261]<br>Equally troubling for advocates of the place<br>theory is the fact when sine tones are used,<br>the ear displays a completely different consonance/<br>dissonance curve than that produced by complex<br>tones--instead of a series of peaks and troughs, a<br>smooth shifted-bell-curve-like response is seen <br>for sine tones.  The Ohm/Helmholtz Fourier theory <br>of hearing fails to explain this result.<br>Moreover, von Bekesy found that<br>contrary to Helmholtz's presumption,<br>"it appeared that combination tones<br>are not due to nonlinear vibration of <br>[the timpanic] membrane. Furthermore<br>he discovered that the introduction<br>of a negative or positive static<br>pressure into the external meatus<br>changed the loudness of difference<br>tones. This would imply that these tones<br>are produced in the middle ear." [Plomp,<br>1966, pg. 111]<br>"However Wever et al, 1941, conducted<br>experiments which contradicted von<br>Bekesy's findings just mentioned. ...<br>Further investigations...suggested that<br>the main source of combination tones<br>must be sought in the sensory <br>processes, where the microphonic<br>potential is evoked, and not in the<br>mechanical part of the inner ear (Wever<br>and Lawrence, 1954)" [ Plomp, 1966, <br>pg. 111] <br>In addition, the experiments of von Bekesy,<br>who did more than any other researcher to<br>put the place theory of hearing on a modern<br>scientific basis, were also open to considerable<br>doubt. " Von Bekesy's observations<br>have been questioned on two grounds. Visual<br>observations mean that the vibration amplitude<br>had to tbe at least of the order of the wavelength<br>of light, and the high intensities (130 dB SPL) <br>necesssary make extrapolation to a more <br>physiological range unjustified. Secondly, his<br>measurements were performed on cadavers. It is<br>now known that not only does the experimental<br>animal have to be alive, but the cochlea has to be<br>in extremely good phisological condition, to<br>show a satisfactory mechanical response."<br>[Pickles, James O., "An Introduction to the <br>Physiology of Hearing," Academic Press, 1988,<br>end ed., pg. 40]<br>In short, investigations began<br>to suggest that many important <br>auditory phenomena could only be<br>explained by the software, not the<br>hardware, of the ear/brain system--<br>that is, by the brain itself. "[For] the<br>phenomenon...once called "periodicity<br>pitch" [there are] alternative explanations...<br>known as "pattern" theories.  They suppose that<br>the auditory system, by recognizing that the tones<br>sounded are the upper harmonics of a low tones, <br>supplies the missing fundamental that would have<br>generated them. This is again an area which is<br>controversial, and over the years opinions have swayed<br>in favor of one hypothesis or the other." [Pickles, James<br>O., "An Introduction to the Physiology of Hearing," <br>Academic Press, 1988, 2nd. ed., 1988, pg. 273]<br>Clearly by the 1980s much of the  support for the<br>place  theory of hearing had crumbled.  In 1984 Pierce<br>writes: "Helmholtz accomplished a great deal despite the <br>limitations of the technology available to him.<br>Yet he reached false conclusions. He believed the perception <br>of musical pitch depends on the presence of the fundamental <br>frequency. This is not true for low keys on the piano keyboard,<br> or for orchestra chimes, or for bells. HIs other false conclusion<br>was that the relative phases of sinusoidal components do not <br>affect the timbre of  a sound." ["The Science of Musical Sound,"<br>Pierce, J.R. , 1992, pg. 185; see also "Tone Segregation by Phase: <br>On the Phase  Sensitivity of the single ear," Kubovy and<br>Jordan, JASA, Vol. 66, No. 1, 1979, pp.  100-106]<br>Still, the place hypothesis accounts very convincingly for <br>at least a few  characteristics of the ear/brain <br>system: it explains how the ear can resolve complex sounds into<br>separate pitches, explains the function and structure of some<br>of the mechanical components of the inner ear, it explains <br>elegantly the near-logarithmic nature of pitch, and it explains why<br>very close tones are heard as being identical in pitch.<br>On the other hand, the place theory does *not* explain why stretched <br>intervals significantly larger than those predicted<br>by the small whole number ratios (or numerological, essentially<br>Kabalistic) theory of  consonance are universally preferred to <br>so-called "pure" intervals (which in psychoacoustic tests<br>are consistently heard as "flat" or "too narrow").  Nor does the modern <br>place theory explain combination tones, (as mentioned above), or <br>the fact that two inharmonic-series tones matched to an inharmonic-<br>series scale sound strongly consonant (Risset, 1978, 1984, 1985; <br>Sethares, 1992; Geary, 1980; Pierce, 1966; Carlos, 1987; Plomp and<br>Levelt, 1965, Kameoka and Kuriyagawa, 1969); nor does the <br>place theory explain (or predict)  modern auditory illusions--<br>Shephard's tones,  Risset's tone containing ten 1180-cent<br>intervals which when transposed UP an octave DROPS <br>in audible pitch by a perceived 20 cents, etc.<br>All of these phenomena *can* be explained by the periodicity <br>theory of hearing as emergent  properties of an autocorrelation<br>system.<br>However, the periodicity theory itself has a number of problems.<br>It does not explain the universal human preference for stretched<br>octaves, fifths and thirds, a preference found in the earliest<br>experiments performed on measured intervals and in all <br>double-blind psychoacoustic tests performed for 150 years <br>since;  the periodicity theory of hearing cannot account for the <br>fact that pitches very close together create a "chorus" effect <br>instead of massive dissonance. By contrast, the broad region<br>of general stimulation of the basilar membrane around the<br>much narrow region of maximal stimulation--one of the hallmarks<br>of the place theory--explains this effect simply and clearly.<br>The phenomenon of combination tones is poorly explained by *both*<br>competing hypotheses. As Plomp points out, "This problem applies<br>both to place pitch and periodicity pitch. If pitch is based on the place<br>of maximal vibration, it is essential for hearing a combination tone that<br>the corresonding place of the basilar membrane is stimulated. Then the<br>question may be asked of how this can be accomplished by sensory<br>processes of hair cells at a distant place of the cochlea. The ascertainment<br>of Six (1956) that cochlear microphonics correponding to combinationg tones have their maximum at the same place as the primary tones, contradicts this possibility.<br>If, on the other hand, pitch is based on the periodicity of nerve impulses, <br>the problem arises how impulses that  are synchronous with the frequency of combination tones can be initiated when the waveform of cochlear<br>michrophonics is flattened (the common form of distortion)" [Plomp, 1966, pg. 121]<br>Summing up, James Pickles points out that "Frequency difference limens<br>are very much smaller than cirtical bands. Two mechanisms are possible.<br>For instance, the subject may detect shifts in the place of excitation<br>in the cochlea. This is called the "place theory." Or he may used temporal<br>information.  We know that the firing int he auditory nerve is phase-locked<br>to the stimulus waveform up to about 5 khz. In this theory, called the<br>"temporal" [or "periodicity] theory, the subject discriminates the<br> two tones by using the tme interval between the neural firings. It is not<br>clear which of the two mechanisms is used.  Indeed the controversy has been<br>active for more than 100 years, and the fact that it is not yet settled shows<br>that we still do not have adequate evidence.  Auditory physiolgoists divide<br>into three groups, namely those that think only temporal information is used, those that think only place information is used, and an eclectic<br>group, who suppose that temporal information is used at low frequencies,<br>and only place information at high." [Pickles, James O., "An Introduction<br>To the Physiology of Hearing," Academic Press, 2nd ed., 1988, pg. 271]<br>The implications for musical tuning are mixed.  Because no clear evidence<br>has emerged in favor of any of the three major theories of hearing, <br>no single tuning can be considered to "privileged" or uniquely suited<br>to the human ear.  On the other hand, because of the mixed results<br>from pscyhoacoustic experiments, the data examined so far would<br>tend to support the use of any of the major categories of musical<br>tuning: namely, just intonation, equal temperament, or non-just non-<br>equal-tempered scales.<br>The next post will discuss several modern experiments which provide<br>evidence for the third "pattern recognition" hypothesis of hearing,<br> and the implications of all 3 of these hypothetical auditory mechanisms <br>for music & tuning.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Fri, 29 Sep 1995 19:07 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id KAA23266; Fri, 29 Sep 1995 10:07:19 -0700<br>Date: Fri, 29 Sep 1995 10:07:19 -0700<br>Message-Id:  <9509291007.aa21406@cyber.cyber.net><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2083 href="#2083">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>9/30/1995 9:09:50 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Tuning & Psychoacoustics - post 7 of 25<br>---<br>We've seen that three competing theories<br>of pitch perception have tried to explain<br>the ear-brain system since the middle<br>of the 1840s.  No one model accounts<br>for all the ear's behaviour, and some evidence<br>contradicts each hypothesis.<br>"Protagonists of both place and time theories<br>point out how small the detectable limits are<br>when translated into the terms of the other theory.<br>Temporal [i.e., periodicity] theorists point out that a frequency<br>discrimination limen of 3 Hz at 1 Khz corresponds<br>to a shift in the pattern of excitation on the basilar<br>membrane of 18 microns, or the width of 2 hair cells.<br>Place theorists point out the that the same limen<br>corresponds to a time discrimination of 3 microseconds,<br>as against some 1000 microseconds for the width of a<br>nerve action potential, and a variability of some hundreds<br>in its intiation.  (..) There are several lines of evidence<br>for and against these two theories, none of which is<br>conclusive." [Pickles, James O., "An Introduction to<br>the Physiology of Hearing," Academic Press, 2nd.<br>ed., 1988, pp. 271-272.]<br>At this point it's instructive to step back<br>and recall that all cultures are conceptually<br>limited by their experience.  The Cargo Cult<br>of the South Seas Islands during WW II arose<br>because the islanders fitted B-17s into<br>their experience as godlike birds from<br>a supernatural realm.<br>In the same way,  the most sophisticated<br>means of frequency analysis available to<br>Helmholtz was a set of tuned glass resonators.<br>By putting his ear to these globes, he could hear<br>a particular resonant frequency amplified out<br>of a complex harmonic timbre.  So it was<br>natural for Helmholz to model the ear/brain<br>system as a set of millions of tuned<br>resonators.<br>As technology advanced during the late 19th<br>and early 20th century,  high-precision machine<br>tools became available.  So it was natural for<br>von Bekesy & others to model the ear/brain system as<br>a precision machine for performing mechanical<br>Fourier transforms of complex harmonic sounds.<br>[For more details on these hypotheses, see:<br>Helmholtz, "On the Senations of Tone," 1863;<br>Plomp, R. "The ear as a frequency analyzer," JASA,<br>1964, vol. 36, pp. 1628-1636;  Boomsliter & Creel,<br>"The Long Pattern Hypothesis of Pitch and Harmony,"<br>Journ. Mus. Theory, Vol. 5, 1961, p. 1-12; von<br>Bekesy, G. "Concerning the Fundamental Component<br>of Periodic Pulse Patterns and Modulated Vibrations<br>Observed on the Cohlaer Model with nerve Supply,<br>JASA, Vol. 33, 1961, ppg. 888-896; von Bekesy,<br>"Three Experiments Concerned with Pitch<br>Perception," JASA, Vol. 35, pp. 602-606, 1963;<br>von Bekesy, G. "Hearing Theories and Complex<br>Sounds," JASA, Vol. 35, pp. 588-601, 1963;<br>Licklider, J.C. R. : "Periodicity Pitch and Related<br>Auditory Process Models," Intern. Audiol. Vol. 1,<br>pp. 11-36, 1962.]<br> Then  in the 1940s and 1950s computers became<br>available, and with them software.<br>So it became natural for modern researchers to<br>model the ear/brain system as a combination<br>of hardware and software, with software<br>performing the crucial functions of pitch<br>detection, perception of consonance, dissonance,<br>etc.  Thus we now see papers like: Goldstein, J.R.<br> "An optimum  processor theory for the central formation of the<br>pitch of complex tones," JASA, 1973, Vol. 54, pp.<br>1496-1616; Wightman, F. I. "The pattern-<br>transformation model of pitch," JASA, 1973,<br>vol. 54, pp. 407-416.<br>So what do we have?<br>Quite possibly, a series of cargo cults.<br> The ear/brain system is viewed<br>by each era in terms of the most convenient<br>available paradigms, regardless of whether<br>those paradigms are actually appropriate.<br>In an interview with Curtis Roads, Max Mathews<br>summarized all 3 theories of hearing with<br>typical elegance and pith: "In a book first published<br>in 1863, Helmholtz proposed that dissonance<br>arises from unpleasant beats between partials<br>whose drequencies are too close together. [4] The<br>octave is the most consonant of intervals because<br>all of the partials of the upper coincide in frequency<br>with partials of the lower tone. (...) Rameau had<br>another view of harmony. [6] He observed that<br>in a major triad all frequencies present are integer<br>multiples of a basse fundamentale or fundamental<br>bass which, in the root position of the chord (C, E, G)<br>lies two octaves below the root of the chord. (...)<br>But, one might hold that musical harmony is merely<br>a matter of brainwashing; that we accept combinations<br>of tones that we have been taught are correct, and<br>reject those that we have been taught are incorrect.<br>We have some experimental evidence that bears on<br>this." [Mathews, M. and Pierce, J.R. "Harmony and<br>Non-Harmonic Partials," Rapports IRCAM, 1980, pp. 3<br>-5]<br>The above passage describes clearly the 3<br>different competing hypotheses of hearing<br>still competing even today: namely,  [1] that<br>the ear is a frequency-domain Fourier analyzer;<br>[2] that the ear is a time-domain autocorrelator;<br>[3] that the ear/brain system uses a learned<br>neural net system of pitch/interval recognition<br>and consonance/dissonance classificiation.<br>The contradictory results of experiments on<br>pitch sensation lead to the conclusion that<br>some aspects of all of these 3 models of human<br>hearing bear some relation to the ear/brain<br>system's actual operation.  However, because<br>some of the experimental results are contradicted<br>by each of these 3 models of hearings,  it<br>is inescapably clear that under various<br>circumstances one or more of these ear/brain<br>hearing systems becomes dominant, and in<br>some cases (particularly in the case of<br>auditory illusions) all 3 of the ear/brain<br>systems can clash and yield conflicting<br>results.<br>These  3 separate hypothetical mechanisms<br>for processing  both vertical and horizontal<br>(sequential) pitch are: [1] a frequency-based or<br>Fourier analysis system; [2] a time-based or<br>autocorrelative system; [3] ear/brain "wetware"<br>that includes a strong learned component,<br>and which is capable of actively filtering<br>out auditory information, creating illusory<br>auditory information, and transforming some<br>or all of the information conveyed from the<br>basilar membrane and the hair cells  to the auditory<br>nerve, and from there into the Sylvian fissure,<br>the superior medial olive and the geniculate<br>nucleus--all areas in the brain responsible<br>for dealing with aspects of auditory perception.<br>This last point is important, because it is now<br>known that musicians and non-musicians use<br>different brain centers when hearing the same<br>music.  Musicians show glucose metabolism<br>primarily in the left brain when listening to<br>music, while non-musicians show glucose<br>metabolism both brain hemispheres.<br>These PET scan results offer strong<br>confirmation of the third model of hearing--<br>what Mathews and Pierce call the "brainwashing"<br>hypothesis, the model of hearing as molded by<br>learned response (first put forward by Fetis and<br>Alexander J. Ellis in the middle of the 19th century).<br>While the Fourier analysis model of the ear/brain and<br>the autocorrelative (or periodicity pitch) model<br>have been extensively documented, what<br>about experiments documenting the "wetware"<br>component of the ear/brain system?<br>Auditory illusions provide strong evidence<br>for this hypothesis of the ear/brain<br>system: Shepard, R. N., "Circularity in<br>judgments of relative pitch," JASA, 1964,<br>vol. 36, pp. 2346-2353; McAdams, S.<br>and Bregman, A. "Hearing Musical Streams,"<br>Computer Music Journal, 1979, Vol. 3,<br>pp. 26-44; Locke, S. and Kellar, L., "Categorical<br>percpetion in a non-linguistic mode," Cortex,<br>Vol. 9, 1973, pp. 355-369; Cohen, A. "Inferred<br>sets of pitches in melodic perception,"<br>In R. Shepard, Cognitive structure of musical<br>pitch," symposium presented at the meeting<br>of the Western Psychological Association, San<br>Francisco, CA, April 1978; Burns, E. M. and<br>Word, W. I., "Categorical perception--phenoneon<br>or eiphenomenon: Evidence from experiments<br>int ehperception of melodic musical intervals,"<br>JASA, 1978, vol. 63, pp. 456-468; Blcehner,<br>M.J. "Musical Skill and categorical perception<br>of harmonic mode," Status Report on Speech<br>Perception, SR-51/52. New Maven, Connecticut,<br>Haskins Laboratories, 1977, pp. 139-174;<br>Balzano, G. J., "Musical versus psychoacoustical<br>variables and their influence on the perception<br>of musical intervals," Bulletin of the Council<br>for Research in Music Education, 1981; Bachem,<br>A. "Tone Height and tone Chroma as two different<br>pitch qualities," Acta psychogica, 1950, vol.<br>7, pp. 80-88; Moreno, E., "Expanded Tunings in<br>Contemporary Music: Theoretical Innovations and<br>Practical Applications," Vol. 30, Studies in the<br>History and Interpretation of Music, The Edwin<br>Meller Press, Lewiston: 1992; Moreno, E. "The<br>Existence of Unexplored Dimensions of Pitch:<br>Expanded Chroma," Proc. ICMA, 1992, pp. 404-405;<br>Pierce, J.R. "Attaining Consonance in Arbitrary<br>Scales," JASA, 1966, pg. 249;  Butler, J. W. and<br>Daston, P. G., "Music Consonance as Musical<br>Preference: A Cross-Cultural Sutdy," Journ. of Gen.<br>Spcyh.., 1968, vol. 79, pp. 129-142; Hutchinson,<br>W. and Knopoff, L., "The Acoustic Component of<br>Western Consonance," Interface, Vol. 7, 1978,,<br>pp. 1-29; Watkins, A. J., "Perceptual Aspects of<br>synthesized approximations to Melody," JASA,<br>Vol. 78 No. 4, 1985, pp. 1177-1186; Pikler, A. G.,<br>Mels and Musical Intervals," Journ. Mus. Theory,<br>Vol. 10, 1966, pp. 288-298; Risset, J-C., "Musical<br>Acoustics,"  Rapports IRCAM 1978, pp. 7-8.<br>Why are these 3 models of ear/brain function<br>important to musicians in the real world?<br>They're of crucial concern to microtonalists because<br>if the place theory is right, then just intonation is<br>the ideal tuning.  If the periodicity theory is the<br>correct description of how the ear hears, then<br>many tunings are acceptable provided that the<br>interval between the fundamental and the first<br>partial, and twix each subsequent pair of partials,<br>is larger than the critical band at that frequency.<br>As Pickles points out, the periodicity theory does<br>*not* offer support for conventional Western<br>musical practice: "It might be thought that the<br>pleasant consonance of simple musical intervals<br>depends on the simple relations between their periods,<br>resulting in synchronous nerve firing.  However,<br>once it is realized that most musical notes are<br>rich in overtones, and that consonance might depend<br>on a lack of beats between the harmonics, the<br>argument cannot be used to support the importance<br>of time information." [Pickles, James O., "An Introduction<br>To the Physiology of Hearing," Academic Press, 2nd ed.,<br>1988, pg. 274]<br>On the other hand, if Fetis/Ward/Burns' "pattern<br>recognition" hypothesis of the ear as a pliable active<br>feedback system molded by learned response is the true<br>picture of human hearing, then *any* type of tuning is<br>acceptable.  After a while, the listeners will<br>become acculturated and learn to accept *any*<br>arbitrary interval as "consonant" or "dissonant."<br>And what if elements of all three models are<br>at work in the ear/brain system?<br>In that case, the implications for musical tuning<br>are more complex--a situation which will be<br>considered in the next post.<br>--mclaren<br>&<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Sun, 1 Oct 1995 02:44 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id RAA20743; Sat, 30 Sep 1995 17:43:51 -0700<br>Date: Sat, 30 Sep 1995 17:43:51 -0700<br>Message-Id: <9510010034.AA17220@us2rmc.zko.dec.com><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2085 href="#2085">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/1/1995 9:31:39 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Tuning & Psychoacoustics - post 8 of 25<br>---<br>As xenharmonists, it's of some interest to us<br>exactly how the ear/brain system works.  If the<br>human ear favors one tuning system over another,<br>we want to know about it. <br>Alas, the evidence is far from clear, and there are<br>problems with all three hypotheses of ear/brain<br>function.<br>Concerning the place and periodicity hypotheses<br>of hearing, "On current evidence, it is not possible<br>to decide betwene the temporal and place theories<br>of frequency distribution. (..) In any case the best<br>support for the eclectic [pattern recognition] view<br>is the rather negative one that the evidence in favour<br>of either of the other two theories is not conclusive,<br>and this may be a function of the quality of evidence<br>available, rather than of the actual operation of the<br>auditory system." [Pickles, James O., "An<br>Introduction to the Physiology of Hearing," Academic<br>Press,  2nd ed., 1988, pg. 277]<br>Risset summarizes the evidence for and problems<br>with all 3 proposed ear/brain mechanisms in<br>his 1978 IRCAM report: "Numerological theories of<br>consonance suffer difficulties. Because of the<br>ear's tolerance, intervals corresponding to 3:2 (a<br>simple ratio) and 300,001/200,000 (a complex <br>ratio) are not discriminated. Also psychophysiological<br>evidence indicates that numerical ratios should not<br>be taken for granted. The subjective octave corresponds<br>to a frequency ratio a little larger than 2, and is<br>reliably different for different individuals (Ward,<br>1954; Sundberg and Lindqvist, 1973); this effect<br>is increased by sleep-deprivation (Elfner, 1964).<br>There are also physical theories of consonance. <br>Helmholtz (1877) links the degree of dissonance<br>to the audibility of beats between the the partials<br>of the tones.  This theory is hardly tenable, <br>because the pattern of beats, for a given interval,<br>depends very much on the placement of the<br>interval within the audible frequency range. Recent<br>observations (Plomp, 1966) suggest an improved<br>physical explanation of consonance: listeners find<br>that the dissonance of a pair of pure tones is maximum<br>when the tones are about a quarter of a critical<br>bandwidth apart; the tones are judged consonant<br>when they are more than one critical bandwidth<br>apart. Based on this premise, Pierce (1966, also<br>in von Foerster and Beuachamp, 1969, pp. 129-132)<br>has used tones made up on non-harmonic partials, <br>so taht the ratios of fundamnetal leading to<br>consonance are not the conventional ones:<br>Kameoka et al. (1969). have developed an <br>involved method to calculate the magnitude<br>of disonance...<br>"Whereas the explanation put forth by Plomp<br>can be useful to evalutate the "smoothnesss"<br>or "roughness" of a combination of tones, it<br>is certainly insufficient to account for<br>musical consonance. In a laboratory study,<br>Van de Geer et al., (1962) found that intervals <br>judged the most consonant<br>by laymen do not correspondent to the ones<br>usually term consonant. This result is<br>elaborated by recent work by Fuda and Wessel (1977).<br>The term consonance seems ambiguous, since it <br>refers at the same time ot an elemental level,<br>where "smoothness" and "roughness" are<br>revaluated, and to a higher esthetic level,<br>where consonance can be functional in a given<br>style. The two levels are related in a culture-<br>bound fashion. In music, one does not judge only<br>the consonance of isolated tones: as Cazden (1945)<br>states, "context is the determining factor. (...) the<br>resoution of intervals does not have a natural<br>basis; it is a common response acquired by all<br>individuals within a culture area (cf. also Lundin,<br>1947)." Musical consonance is relative to a musical<br>style ( Guernesey, 1928); ninth chords, dissonant<br>in Mozart's music, are treated as consonant by<br>Debussy (Chailley, 1951; Cazden, 1962, 1968, 1972).<br>The cultural and contextual aspects of musical<br>consonance are so important that, despite nativists'<br>claims to the contrary, purely mathematical and/or<br>physical explanations can only be part of the story.<br>cf. Costere, 1962)." [Risset, J-C., "Musical Acoustics,"<br>Rapports IRCAM, 1978 pp. 7-8]<br>In short, all 3 hypotheses of hearing explain different<br>aspects of the  ear/brain system.  Depending on the<br>acoustic stimulus, different systems appear to  operate<br>to process sound. This is most powerfully evidenced by Sethares,<br>W., "Local Consonance and the Interaction between<br>Timbre and Tuning," JASA, vol. 94 No. 3, 1993, pp. 1218-1219,<br>Slaymaker, J., "Inharmonic Tones," JASA         1970, and <br> Roads, C. "An Interview with Max Mathews," Computer Music<br>Journal, 1980.  <br>In the latter, Mathews points out: <br>"Our initial experiments were aimed at finding <br>out what properties of normal harmonic music<br>carried over to music that was made with<br>stretched overtones. We found some things<br>carried over and some things did not. The<br>sense of "key" carried over better than we<br>expected.<br>ROADS: So you can actually detect "keys" in<br>sequences of completely inharmonic sounds.<br>MATHEWS: That's right. You play two samples<br>and a person can reliably say whether they're<br>in the same or a different key.<br>Other properties do not carry over. The sense<br>of finality in a traditional cadence does<br>not carry over. A person who hears a cadence<br>with unstretched tones says, "That sounds<br>very final to me." When he hears the same<br>cadence played with stretched tones, he'll<br>say "That doesn't sound especially final." But<br>we have been able to make other inharmonic<br>materials which do convey a sense of cadence.<br>(...)<br>ROADS: If we can detect "keys" and some form<br>of finality within a cadence or progressions<br>within inharmonic tones, then some of the <br>theories of harmony in the past must not have<br>been as cogent as some of their proponents<br>have thought them to be.<br>MATHEWS: Our results are contradictory. We<br>loked at two theories. One was the Rameau<br>theory of the fundamental bass, and the other<br>was the Helmholtz and Plomp theory of the<br>consonance and dissonance of overtones. The<br>destruction of the cadence would support<br>the Rameau theory and the persistence of<br>the sense of key would support the Helmholtz<br>and Plomp theory. So we have one result which<br>supports one theory and one which supports the <br>other, with the overall conclusion that the world <br>a more complicated place than we had perhaps<br>hoped it was. We will have to dig deeper<br>before we can say which is causing<br>the various perceptions we find meaningful<br>to music" [Roads. C, "An Interview With Max<br>Mathews, Comp. Mus. Journ., Vol 4 No. 4, 1980,<br>pp. 21-22]<br>MYTH: PITCH PERCEPTION IS SIMPLE, AND<br>CONSONANCE, DISSONANCE AND HARMONY<br>CAN BE EXPLAINED BY EITHER RAMEAU'S<br>OR HELMHOLTZ'S MODELS<br>FACT: Musical phenomena are a complex<br>interaction of at least 3 ear/brain mechanisms<br>for recognizing and assigned pitch, and<br>each ear/brain system can conflict with<br>the other 2, leading to paradoxical results,<br>auditory illusions and a great deal of learned<br>behaviour on the part of the listener as to<br>what "consonance," "dissonance," and even what<br>"pitch" is.<br>This latter will prompt the usual screams<br>of protest from those into whose brainpans<br>little information about modern psychoacoustics<br>has dripped; thus it is important to<br>make clear that even something as purportedly<br>"elementary" and "innate" as the pitch sense<br>displays extremely complex behaviour. <br>The next post will examine the meaning(s)<br>of the term "pitch," the psychophysical<br>factors which influence its perception, and<br>the implications for tuning & music.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Sun, 1 Oct 1995 20:53 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id LAA27839; Sun, 1 Oct 1995 11:52:54 -0700<br>Date: Sun, 1 Oct 1995 11:52:54 -0700<br>Message-Id: <199510011852.AA24025@net4you.co.at><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2090 href="#2090">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/2/1995 9:12:35 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Tuning & Psychoacoustics - Post 9 of 25<br>---<br>"A theory should as simple as possible--<br>but not simpler." -- Albert Einstein<br>---<br>MYTH: PITCH IS THE LOGARITHMIC FREQUENCY<br>HEIGHT OF A MUSICAL TONE, AND ITS<br>PERCEPTION IS AUTOMATIC AND INNATE.<br>Fact: There are 3 kinds of pitch: physical,<br>mel and perceptual pitch.  The 3 differ<br>significantly. Perceptual pitch is never<br>identical to the log of the frequency of<br>the fundamental of the perceived tone,<br>and mel pitch differs radically from both.<br>The perception of all 3 kinds of pitch is<br>strongly influenced by both context and<br>learned experience.<br>---<br>The perceived pitch of sine tones depends<br>on their duration and their loudness. "A<br>150-Hz tone increasing from 45 to 90 dB<br>drops in pitch to an extent corresponding<br>to a 12% frequency shift. This is close<br>to 2 semitones in the diatonic scale. The<br>sensitivity to this effect varies considerably<br>between individuals. (...) A funny consequence<br>of this is that a soft sine tone at 300 Hz<br>may sound as a pure octave of a loud sine<br>tone at 168 Hz. The mathematically pure<br>octave, however, has the frequency of 150<br>Hz. The tone that sounds as a pure octave<br>is 12% too high. This means that mathematically<br>it is a minor seventh! This is a good argument<br>for avoiding confusion of perceptual and physical<br>entities." ["The Science of Musical Sounds,"<br>Sundberg, 1992, pg. 46]<br>Pierce explains that "By asking naive subjects<br>to relate frequency changes of sine waves to<br> a halving of pitch, psychologists found a mel<br>scale of pitch (for sine waves). In the mel scale<br>there is no simple relation between frequency<br>and pitch; nothing like the octave shows up. (...)<br>The sounds of orchestral bells are not periodic,<br>and these sounds do not have all the properties<br>of periodic musical sounds. One can play tunes<br>with bells, and the pitches that are assigned<br>to bells can be explained largely in terms<br>of the frequencies of prominent almost-<br>harmonic partials.<br>"Clucking sounds and shushing sounds (bands<br>of noise) have  brightness, but no<br>periodicity. Oddly, *we can play a <br>recognizable tune with these sounds,<br>even though they cannot be heard as <br>combining into chords or harmony.* <br>Apparently, in the absence of a clear pitch,<br>brightness can suggest pitch.' ["The Science<br>of Musical Sound," Pierce, J.R. 1992, <br>pg. 37]<br>"Systematical series of experiments have been<br>carried out in which listeners have been <br>asked to adjust the frequency of a variable<br>tone so that it sounds "twice as high"<br>or "half as high" as a reference tone. (...)<br>The mel scale is constructed such that<br>a halving of the number of mels corresponds<br>to a halving of the pitch perceived. As<br>shown in the figure, a tone with the pitch<br>of 1,000 mel sounds twice as high as<br>another tone with the pitch of 500 mel.<br>Examination of the figure tells us this<br>corresponds to a frequency shift from<br>approximately 1,000 to 380 Hz." ["The<br>Scinece of Musical Sounds," Sundberg,<br>1992, pg. 47]<br>The mel scale of pitch measures what<br>is also sometimes called "ratio pitch."<br>This is drastically different from the<br>ordinary scale of perceptual musical<br>pitch, since the mel scale applies only<br>to sine tones.  <br>However, the plot thickens as soon as<br>we realize that *many musical timbres<br>can be modelled as sums of sine waves.*<br>Thus the conceptual basis for <br>conventional harmonic-series models<br>of consonance, as well as for the <br>purported acoustic superiority of<br>small whole-number ratios,<br>comes into doubt as soon as we<br>begin to examine the psychoacoustic<br>evidence in detail.  If perceptual<br>pitch is always different from <br>physical logarithmic pitch, how <br>can either equal-tempered or<br>just intonation tunings offer a<br>valid model for musical harmony<br>and musical melody?<br>To make matters even more complex,<br>"In certain cases the amplitude <br>dependence of the pitch of complex<br>tones is the opposite of that shown<br>in Figure 3.4. If the loudness of a <br>complex tone of about 100 Hz <br>fundamental frequency is increased,<br>its pitch may rise rather than drop."<br>["The Science of Musical Sounds,"<br>Sundberg, 1992, Pg. 46]<br>"The pitch of pure tones depends not <br>only on frequency, but also on other<br>parameters such as sound pressure<br>level. (...) Pitch shifts of pure<br>tones can also occur if additional<br>sounds that produce partial masking<br>are presented.  Pitch shifts produced<br>by a broad-band noise masker are<br>shown in Fig 5.4, and are given as<br>a function of both frequency and<br>critical-band rate of the pure tones,<br>the level of which is 50 dB. (...)<br>The results display in Fig 5.5 show pitch<br>shifts up to 8% at low frequencies<br>near 300 Hz, and a pitch shift<br>of only 1% at higher frequencies<br>between 1 and 4 kHz, due to the octave<br>ratio of partial-masking tone<br>and test tone." ["Psychoacoustics: <br>Facts and Models," Zwicker<br>and Fastl, 1993, pp. 105-107]<br>The pitch of pure tones is also<br>dependent on their duration. <br>Doughty and Garner (1948) found<br>that pitch is unchanging for tones of <br>25 msec and longer, but that<br>12-msec and 6-msec tones have<br>a lower pitch. [See Doughty, J. M and<br>Garner, W.R. "Pitch Characteristics<br>of short tones. II: Pitch as a function<br>of tonal duration," J. Exp. Psychol.,<br>Vol. 38, pp. 478-494, 1948]<br>Corso summed up the situation when<br>he concluded that "the pitch of musical<br>sounds is not directly proportional to<br>the logarithm of the frequency and is<br>probably complexly conditioned." [Corso,<br>J.F., "Scale Position and Performed Musical<br>Octaves," Journal of Psychology, Vol. 37,<br>1954]<br>In short, most of what musicians<br>"know" about pitch is untrue,<br>at least as far as pure sine tones<br>are concerned.   This casts strong<br>doubt on tuning theories which ascribe<br>to various pitch relationships "special"<br>characteristics--in particular, the<br>data adduced in this post casts strong<br>doubt on both just and equal-tempered<br>tuning systems, and would tend instead<br>to favor non-just non-equal-tempered<br>tunings.<br>What about complex tones made<br>up of many sinusoidal components<br>and the influence of learning and<br>context?  What are the implications<br>for tuning and for music?<br>That's the topic of the next post.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Mon, 2 Oct 1995 19:10 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id KAA17686; Mon, 2 Oct 1995 10:10:07 -0700<br>Date: Mon, 2 Oct 1995 10:10:07 -0700<br>Message-Id: <Pine.A32.3.91.951002110443.55513A-100000@tiger.cudenver.edu><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2095 href="#2095">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/3/1995 8:22:15 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Tuning & psychoacoustics - post 10 of 25<br>---<br>So far we have seen the complexity of the ear's response to pitch; not a <br>quantity linearly proportional to the logarithm of frequency, pitch appears <br>to be influenced by many aspects of timbre--amplitude, masking tones, <br>overtone harmonicity, and range of the note played.  <br>The ear's perception of complex sounds is equally complicated.<br>"Both von Helmholtz and Wundt based the development of harmony and <br>melody on the coinciding harmonics for consonant intervals." [Plomp, R. and <br>Levelt, W.J.M., "Tonal Consonance and Critical Bandwidth," Journ. Acoust. <br>Soc. Am., Vol. 6, No.1, April 1965, pg. 549]<br>Simple experiments, conducted in the 1960s, showed this not to be the case.<br>"On the basis of more recent and more sophisticated experiments (Plomp and <br>Levelt, 1965) on consonance judgment involving pairs of pure tones and <br>inharmonic complex tones, it became apparent that the beats between <br>harmonics may not be the major detemrining factor in the perception of <br>consonance. Two pure tones an octave or less apart were presented to a <br>number of musically naive (untrained) subjects who were supposed to give a <br>qualification as to the "consonance" or "pleasantness" of the superposition. <br>A *continuous pattern* was obtained, that did not reveal preferences for <br>any partuclar musical interval. Whenever pure tones are less than about a <br>minor third apart, they were judged "dissonant" (except for the unison); <br>intervals equal orlarger than minor third were judged as more or less <br>consonant, irrespective of the actual frequency ratios.  The shape of the <br>curve really depends on the absolute frequency of the fixed tone." [Roederer, <br>J., "The Physics and Psychophysics of Music," 1973, Pg. 142] <br>Plomp and Levelt called this interval, somewhat smaller than a minor third, <br>"the critical bandwidth."  It changes size slightly at lower frequencies.  <br>"...maximal tonal dissonance is produced by intervals subtending 25% of the <br>critical bandwidth, and maximal tonal consonance is reached for interval <br>width of 100% of the critical bandwidth." [Plomp, R. and Levelt, W.J.M., <br>"Tonal Consonance and Critical Bandwidth," Journ. Acoust. Soc. Am., Vol. 6, <br>No.1, April 1965, pg. 549]<br>"An interesting consequence of the significance of the critical bandwidth is <br>that the degree of dissonance of a dyad depends on many factors other than <br>the frequency ratio.  If the tones have many strong overtones, the <br>consonance quality is reduced.  A consonant dyad becomes increasingly <br>dissoannt when it is transposed downward on the frequency scale, just as <br>for sine tones. For example, a major third sounds reasonably consonant <br>around A4, but if played close to C2 it sounds quite dissonant on most <br>instruments.  The relation between consonance and frequency ratios is also <br>entirely dependent on whether the tones have harmonic spectra.<br>"Consonance is apparently a highly conditioned phenomenon. It is stimulating <br>to realize that the dissonance/consonance concept in music theory would <br>have been entire different if our musical instruments had not provided us <br>with harmonic spectra!" [Sundberg, J., "The Science of Musical Sounds,"1992, <br>pg. 85]<br>This finding lends support to all three tunings (just, equal tempered, non-<br>just non-equal) provided that the partials of the musical notes are changed <br>so as to fit the tuning.<br>As mentioned above, Plomp's and Levelt's findings (extended and refined by <br>Kameoka and Kuriyagawa's formula for calculating the consonance of <br>complex tones) also casts doubt on many conventional "rules" of harmony <br>and melody--even if just intervals and perfectly harmonic overtones are <br>used: "As an application of the consonance theory, effects of harmonic <br>structure on the consonance characterisc are discussed. (...) <br>(...) It became clear that the fifth was not always a consonant interval.  A <br>chord of two tones that consists of only odd harmonics, for example, shows <br>muchworse cosnonance at the fifth (2:3) than at the major sixth (3:5) or <br>some other frequency ratios.  This was proved true  by psychological <br>experiments carried out in another institute (sensory Inspection Committe <br>in the Japan Union of Scientists and Engineers) with a different method of <br>scaling. Thus, the fact warns against making a mistake in applying the <br>conventional theory of harmony to synthetic musical tones that can take <br>variety in the harmonic structure." [Kameoka, A., and Kurigawa, M., <br>"Consonance Theory Part II: Consonance of Complex Tones and Its <br>Calculation Method," Journ. Aoucst. Soc. Am., Vol. 45, No. 6, 1969, pg. 1460]<br>Because consonance and dissonance depend not on the harmonicity of two <br>complex tones, but on the coincidence (or lack thereof) of their component <br>partials within the critical bandwidth for that frequency range, "...these <br>examples refer to a vast domain opened up by digital synthesis, namely that <br>of inharmonic tones.  Most sustained instrumental tones are equasi-<br>periodic, and their frequency components are harmonically related, which <br>stresses certain intervals like the octave and the fifth.  With the freedom of <br>constructing tones from arbtirary frequency components, one can break the <br>relationship between consonance-dissonance aspects and fixed, privileged <br>intervals (Pierce 1966). In his piece Stria (1977), Chowning has thus been <br>able to make rich textures permeate each other without dissonance or <br>roughness, by controlling the frequencies constituting these textures. This <br>is also a case where spectra not only play a coloristic role (see Roads 1985) <br>but actually peform a quasi-harmonic function." [Risset, J.C., "Digital <br>Techniques and Sound Structure in Music," in "The Music Machine," ed. Curtis <br>Roads, 1985, pg. 122]<br>"By using a digital computer, musical tones with an arbitrary distribution of <br>partials can be generated.  Experience shows that, in accord with Plomp's <br>and Levelt's experiments with pairs of sinusoidal tones, when no two <br>successive partials are too close toegher such tones are consonant rather <br>than dissonant, even though the partials are harmonics of the fundamental.  <br>For such tones, the conditions for consnance of two tones will not in general <br>be the traditional ratios of the frequencies of the fundamentals. (...)  It <br>appears that, by providing music with tones that have accurately specified <br>but nonharmonic partial structures, the digital computer can release music <br>from the tyranny of 12 tones without throwing consonance overbarod." <br>[Pierce, J.R., Journ. Acoust. Soc. Am., Vol. 6, No. 12, 1966, pg. 249]<br>"I suggest that the nonharmonic domain of frequency relationships may in <br>some way contain a necessary system of hierarchical structural functions."  <br>[Dashow, J.,  "Spectra As Chords," Computer Music Journal, 1980]" <br>"The hypothesis has been made that perceived  effects similar to the <br>consonance and dissonance experienced with harmonic tones  should exist <br>for inharmonic tones. Clearly, it cannot be claimed that the perceptions are <br>exactly the same, since inharmonic and harmonic tones themselves sound <br>different to the ear. However, the experiments do establish a similarity <br>between the consonance dissonance phenomenon in harmonic and inharmonic <br>sounds." [Geary, J.M., "Consonance and Dissonance of Pairs of Inharmonic <br>Tones,"  J.Acoust. Soc. Am, 67 (5), May 1980]<br>"The chords sounded smooth and nondissonant but strange and somewhat <br>eerie. The effect was so different from the tempered scale that there was <br>no tendency to judge in-tuneness or out-of-tuneness. It seemed like a peek <br>into a new and unfamiliar  musical world, in which none of the old rules <br>applied, and the new ones, if any, were yet undiscovered." [Slaymaker, F. H, <br>"Chords From Tones Having Stretched Partials," J. Acoust. Soc. Am., Vol. 47, pp. 1469-1471, 1970]<br>"We have to compose real music of many kinds within all and any of our new <br>tuning schemes, if this work is to have any lasting value at all, or be taken <br>seriously by the music community..."[Carlos, W., "Tuning: At the Crossroads," <br>Computer Music Journal, 1987] <br>In short, "Experiments with inharmonic partials (Slaymaker, 1970; Pierce, <br>1966) have shown that consonance or dissonace is indeed dependent on the <br>coincidence of partials and not necessarily on the simple frequency ratio <br>between the fundamnetal frequencies..." [Rasch, R.A. and Plomp, R., "The <br>Perception of Musical Tones," in "The Psychology of Music," ed. Diana <br>Deutsch, 1982, pg. 21]. Thus all three tuning systems appear equally viable <br>on the basis of the evidence considered in this post, given a digital or acoustic instrument whose partials are matched to the  tuning system <br>in question.<br>The next post will discuss the important phenomenon of categorical<br>perception, and its implications for tuning and music.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Tue, 3 Oct 1995 19:30 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id KAA04880; Tue, 3 Oct 1995 10:30:18 -0700<br>Date: Tue, 3 Oct 1995 10:30:18 -0700<br>Message-Id: <m0t0B81-000FwjC@frollo.fa.disney.com><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2097 href="#2097">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/4/1995 10:18:47 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Tuning & Psychoacoustics - Post 11 of 25<br>---<br>MYTH: "I KNOW WHAT MY EARS HEAR AND<br>I KNOW WHAT A 'PURE' OCTAVE, A 'PURE'<br>FIFTH, AND A 'PURE' THIRD IS."<br>FACT: Because of the phenomenon of<br>categorical perception, none of us know<br>we actually hear--as opposed to what<br>our ear/brain system brainwashes us<br>into *believing* we hear.  The only way to<br>actually *determine* what you're<br>hearing (rather than what you *think*<br>you're hearing) is to use double-blind<br>psychoacoustic tests.<br>Until 1969, such tests were seldom<br>used.  Computers were unheard-of;<br>and prior to computer-generated<br>psychoacoustic test tones, the only<br>available readily controllable test<br>tones were those generated by analog<br>circuits whose frequency drifted <br>by significant amounts as the temperature<br>of the sound-generating circuit changed.<br>As a result, ignorance of the<br>ear/brain system's behaviour was<br>near-absolute prior to Max Mathews'<br>creation of the acoustic compiler in 1959.<br>As a result of Mathews' innovation, many<br>surprising properties were discovered in<br>the ear/brain system.<br>One of the most surprising of these properties<br>is known as "categorical perception."<br>---<br>The phenomenon of categorical perception<br>is familiar to linguists.  <br>Everyone pronounces phonemes,<br>vowels, and consonants slightly differently--<br>and in different regional dialects the <br>sound of a word may be entirely<br>transformed.  In New England, "pahk my cah,"<br>in the MidWest, "park my car," down south,<br>"purk m' cuhr."  The ear/brain system <br>has a learned mechanism for dealing with<br>these differences--different sounds are<br>heard as the same semantic unit.  This<br>ear/brain system of learned categorization<br>is known as categorical perception, and it<br>operates so efficiently that people in a given<br>region of the country cannot even "hear" their<br>own accent.  As far as they can tell, they're<br>speaking "standard English"--everyone else is<br>slurring or pinching or warping their words "with<br> some strange kind of accent."<br>Categorical perception has been proven to <br>operate in the perception of musical sounds, <br>and it gives rise to many of the same distortions<br> of the auditory system.<br>In the paper "Categorical Perception--Phenomenon<br>or Epiphenomenon: Evidence from experiments in<br>the perception of melodic musical intervals,"<br>by E. M. Burns and W. D. Ward [JASA, vol. 63, No. 2, <br>1978, pp. 456-468], the authors point out:<br>"An experiment on the perception of melodic<br>intervals by musically untrained observers<br>showed no evidence for the existence of<br>"natural" categories for musical intervals."<br>The authors also found that for trained<br>musicians "musical intervals are also<br>rather unique in that musicians are able to<br>perfectly identify more than 30 categories<br>of musical intervals..."  These results<br>strongly contradict both the standard 12-tone<br>dogma that only the intervals of the 12-TET<br>scale are recognizable or musically <br>significant; and the standard "natural<br>interval" dogma which holds that some<br>musical intervals are [fill in your own<br>preferred propaganda] "natural," "pure," <br>"preferred," "rational," etc.  <br>Among other interesting conclusions, Ward<br>and Burns found that "The average difference<br>limen (based on the 75% correct<br>points from the psychometric functions)<br>for three subjects at the physical octave<br>was 16 cents. The DL's at other ratios in the<br>civicinity of the octave were not <br>significantly different. A DL of 16 cents is in<br>good agreement with the DL estimated from the <br>from the standard deviation of repeated<br>adjustments of sequential octaves (about 10<br>cents) in the same frequency region found by<br>Ward (1954). (...) As in Moran and Pratt's<br>experiment, large differences were found for<br>DL's at different ratios, but the range of <br>DL's (14-25 cents) was in good agreement<br>with their results." [Burns, E. M. and Ward,<br>W.D.,  JASA, 63(2), Feb. 1978, pg. 456]<br>This preference for stretched as<br>opposed to purportedly "natural" intervals<br>is not a new discovery.  As will be seen<br>in the post after this one, the preference<br>for stretched vertical intervals--and for <br>significantly *wider* melodic than<br>vertical intervals--was discovered by<br>the very first researchers who <br>investigated the operation of the<br>ear/brain system.<br>What are the implications of these particular<br>psychoacoustic data for tuning and music?<br>First, these data explain clearly and convincingly<br>why there are so many different tunings systems<br>and timbres used in the various musics of cultures<br>throughout the world.  Because of the influence of<br>categorical perception and the implied importance<br>of learned response on the ear/brain system, any<br>system of pitches can be learned as "preferred"<br>by the ear.  Thus a Mongolian Buddhist using the r-gynd-stad<br>tuning can with equal justification claim that the pitches<br>of his musical system enjoy a privileged status in the<br>ear/brain sytem as can Javanese gamelan performer.<br>According to the psychoacoustic results adduced above,<br>both musicians are correct--because the cultures in<br>which their pitch preferences were formed characterize<br>those particular pitches as "special."  And because of the<br>known effects of learned response and categorical perception,<br>a wide variety of pitches can equally be perceived as<br>"special" or "uniquely privileged."<br>These psychoacoustic data would also tend to support current<br>Western musical practices, at least to the extent that the Western<br>12-tone tuning system is acculturated into Wesern musicians<br>and composers, and to which Western performers and audiences<br>perceive departures from those pitches as falling within the <br>range of variability which (as Moran and Pratt point out) characterize <br>all pitches.<br>Categorical perception strongly favors all three classes of tuning--<br>just intonation, equal temperament and non-just non-equal tunings--<br>since once the pitches are learned and perceived as "special" or<br>"privileged" both audience and performers strongly tend to<br>perceive departures from those pitches as "ornamental," if<br>indeed the departures are heard as different pitches at all. If<br>these psychoacoustic results are accurate, all tuning systems<br>are self-reinforcing feedback systems, with "errors" heard as<br>slight variations of base pitches (as in the case of Jaipongan,<br>where slendro or pelog are used as base scales for ornamental<br>extra-scalar variations, or as in the various sruti of East Indian<br>practice, where the remaining 22 pitches are used as ornamental<br>extra-modal variational pitches, or as in the vocal inflexions  of <br>Sinead O'Conner, Louis Armstrong or Ella Fitzgerlad, all of whom consistently range microtonally outside the 12-tone equal tempered <br>scale in which their song purports to reside).<br>The next post will consider the effects of possible interactions<br>between the various ear/brain processes discussed to date,<br>and the evidence for such interactions, along with the implications<br>for tuning and music.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Thu, 5 Oct 1995 21:58 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id MAA22353; Thu, 5 Oct 1995 12:58:04 -0700<br>Date: Thu, 5 Oct 1995 12:58:04 -0700<br>Message-Id:  <9510051256.aa03198@cyber.cyber.net><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2098 href="#2098">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/5/1995 12:58:04 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Tuning & psychoacoustics - post 12 of 25<br>---<br>The psychoacoustic evidence for the periodicity and Fourier-analysis-based <br>models of hearing has now been examined. <br>But what about interaction between these two ear/brain systems?<br>Evidence for this comes from David Wessel's examination of a psychoacoustic effect known as "streaming" in the mid-70s: <br>"Consider a melodic line of eleven tones where the even-numbered tones and <br>the odd-numbered tones are separated in register. As shown...at a rate of 5 <br>or 6 tones per second, a listener would hear the sequence as a coherent <br>succession.  At a faster tempo--10 to 12 tones per second--the high tones <br>group together to form a separate stream from the low tones. At an <br>odge, C., Jerse, T. "Computer Music: Synthesis, Composition and Performance," 1985, pg. 47]<br>Time is a crucial factor in pitch perception, implying further feedback <br>between the periodicity and Fourier-analysis systems of pitch detection: <br>"The data...show that the just-noticeable relative frequency difference <br>increases with decreasing test-tone duration. (...) At long durations (around <br>500 ms) a critical-band rate difference of 0.01 Bark represents the just-<br>noticeable difference for pitch.  At a duration  of 10 ms, the JNDF amounts <br>on average to 0.2 Bark.  For a decrease of the test-tone duration by a factor <br>of 10 ms, the magnitude of the JNDF, expressed in critical-band rate, <br>increases by a factor of 10.  Thus pitch differences which are easily <br>detected at logn durations are no longer distinguishable at short durations.  <br>This effect is well known to musicians: inaccuracies in intonation, easily <br>detected in sustained tones, almost disappear if the tones are considerably <br>shortened in duration, for example by playing `spiccato.'" [Zwicker, W. and H. <br>Fastl, Psychoacoustics: Facts and Models, 1990, pg. 116]<br>Other results make it clear that the perception of pitch is dependent on the <br>temporal order of tones:<br>"When presented witha group of spectral components, a listener may or may <br>not fuse them into the percept of a single sound.  One of the determining <br>factors is the "onset asynchrony" of the spectrum which refers to the <br>difference in entrance times among the components. (...)  Rudolf Rasch has <br>noticed a related phenomenon with regard to the synchronization of tones in <br>chords in polyphonic music.  He has found that the amount of asynchrony in <br>starting times of chord tones actually improves our ability to perceive the <br>individual tones while we continue to perceive the chord as a whole. <br>Rasch has shown that the effect obtains best when the attacks of the tones <br>are spread out over a time span of 30 to 50 msec." [Dodge, C., and Jerse., T. <br>"Computer Music:  Synthesis, Composition and Performance," 1985, pg. 59]<br>Because of this unexpected interdependence of time with freqeuncy <br>perception, it seems likely that all 3 of the ear's mechanisms for processing <br>sound interact to some degree. There is further evidence for this interaction <br>between all 3 ear/brain systems in the form of auditory paradoxes:<br>"Paradoxical effects can be obtained thanks to the precision and flexibility <br>inherent in computer synthesis.  Shepard produced a sequence of 12 tones in <br>chromatic succession which seem to rise indefinitely in pitch when they are <br>repeated.  I extended this  paradox and generated, e.g., ever-ascending or <br>descending glissandi, and sounds going down the scale and at the same time <br>getting shriller. These paradoxes are not merely "truquages"--artificial <br>curiosities: they reflect the structure of our pitch judgments.  Pitch appears <br>to comprise a focalized aspect, related to pitch class, and a distributed <br>ascpect, related with spectrum, hence with timbre--and the paradoxes are <br>obtained by controlling independently the physical counterpart of these<br>attributes, which are normally correlated. I have even manufactrured a <br>sound which does down in pitch for most listeners when its frequencies are <br>doubled--i.e., when one doubles the speed of the tape recorder on which it is <br>played; this shows how misleading mere intuition can be in predicting the <br>effect of simple transformations on unusual sounds." [Risset, J.C., "The <br>development of Digital Techniques: A Turning Point for Electronic Music?"  <br>Rapports IRCAM No. 9, 1978, pg. 7]<br>These effects make clear the importance of context and the subtlety of <br>interaction among the ear's various methods of sound processing. <br>This would tend to militate against tuning theories which stress absolutes <br>like beats or the convenience of easy modulation, and would support instead <br>the use of non-just non-equal-tempered tunings whose context-driven <br>character mirrors  this aspect of the ear/brain system.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Fri, 6 Oct 1995 07:40 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id WAA01139; Thu, 5 Oct 1995 22:40:25 -0700<br>Date: Thu, 5 Oct 1995 22:40:25 -0700<br>Message-Id: <951006053855_71670.2576_HHB33-5@CompuServe.COM><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2101 href="#2101">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/6/1995 11:06:52 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Tuning & psychoacoustics - post 13 of 25<br>---<br>One of the oldest of old wives' tales about the ear/brain<br>system is the fairy tale that the ear/brain system responds<br>with in some special (viz., magical) way to intervals described <br>by small whole numbers.  Sometimes the supersitition is overt, <br>betraying clearly its occult origins in Cabbalism, gematria,<br>Hindu astrology and Babylonian extispicy--as in  Zarlino's choice of <br>the senario (small whole numbers less than 6) as the<br>basis for tuning because of the  Medieval system of number<br>mysticism, according to which 6 was "a perfect number" because<br>its prime factors add up to the number itself.<br>Or as in the case of Johannes Avianius' view of the 4:5:6 triad <br>as "Unitrisona omnis Harmoniae," a mystical "three in one" <br>musical trinity deriving its supernatural potency from <br> the Christian Father, Son and Holy Ghost.<br>In other cases the superstitition is gussied up with references<br>to Fourier analysis--the mathematics of which (as has been seen)<br>do not explain many properties of the ear/brain system.<br>Contrary to this long-running musical myth,  psychoacoustic<br>evidence shows that listeners hear stretched intervals as<br>"pure" and intervals with the small whole number ratios<br> predicted by numerological theories of consonance as "too<br>flat" and "impure."  <br>The evidence is extensive:<br>In his 1976 thesis for the Dept. of Speech Communciation and Music <br>Acoustics at the Royal Institute of Technology at Stockholm, K. Agren found <br>the average size of the major second to be 199 cents; the major third 402 <br>cents; the purportedly "perfect" fifth 704 cents; and the octave 1204 cents.  <br>The standard deviation for all subjects was 14 cents for the M2nd, 9 cents <br>for M3rd, P5 10 cents, and octave 10 cents.  In accord with all other <br>experiments on perception of musical intervals, Agren found that subjects <br>uniformly preferred *stretched* intervals on average 5-8 cents wider than <br>their purportedly "natural"  counterparts.<br>This preference for stretched as opposed to purportedly "natural" intervals <br>is not a new discovery.  The preference for stretched vertical intervals--<br>and for significantly *wider* melodic than vertical intervals--was <br>discovered by the very first researchers who investigated the operation of <br>the ear/brain system.<br>C. J. Delezenne, in "Memoires sur les valeurs numeriques des  notes de la <br>gamme," Recueil des travaux de la Societe des  Sciences de Lille,  1826-<br>1827,  was the first researcher to  identify the preference for thirds wider <br>than the purportedly  "natural" 5:4. Delezenne's data also showed a <br>preference for stretched octaves:  "In fact, it is a daily experience that in <br>climbing to the  octave from the tonic, the musical ear demands  the octave  <br>so strongly that in order to get away from the leading tone,  and to arrive <br>more  quickly at the octave, the latter is raised  involuntarily."  Pg. 24, <br>Ibid.)  Delezenne used an adjustable  monochord and gave his values in <br>fractions of a Pythagorean  comma rather than in cents.  <br>His results are especially striking  because when starting the experiment he <br>explicitly rejected the Pythagorean system, but was eventually forced to <br>admit the now-universally-recognized preference for stretched intervals <br>wider than the so-called "natural" intervals.  <br>In 1869 Cornu and Mercadier built a phonautograph, an early method of <br>recording waveforms.  Mssrs. C. & M.  directed the  sound waves with a <br>parabolic dish toward a membrane, which in turn engraved the waveform on <br>a smoked drum of camphorated cellulose by means of a needle.  <br>Simultaneously an electric chronometer marked the drum the drum at <br>intervals of 1 second.  By measuring the wavelength, Cornu and Mercadier <br>could precisely determine pitch--as opposed to the usual wild guess about <br>what pitch was actually played, or heard (the "wild guess" method is still <br>used by many contemporary music theorists).  Many musicians assert on the <br>basis of nothing other than some undefined extrasensory perception that <br>they "can tell a Pythagorean third when they hear it," etc.  <br>As these experiments unmistakably prove, this is not so. <br>Again, to make the point clear, categorical perception leads us to recognize <br>as "perfect" or "natural" intervals which differ greatly from small-whole-<br>number ratios; moreover, there is at work a universal human craving for <br>stretched intervals.)<br>The amount of evidence for human preference for stretched octaves is so <br>voluminous that no digressions can be afforded.  The subject will be dealt <br>with later in this series. Thus, to return to the early  scientific record: <br>Cornu & Mercadier found that the mean intonation for a vertical dyad  <br>yielded the ratio  1.251, close to but sharper than the 5/4;   however, a <br>consecutive-tone test yielded 1.2666 as the mean value.  <br>Notice that this shows a marked preference not only for stretched vertical <br>intervals, but for even more widely stretched melodic intervals.  <br>The Pythagorean third is 1.256, so the experiment showed that in the <br>successive intonation of 2 tones, the subjects preferred a sharped <br>Pythagorean third.  Cornu and Mercadier interpreted their results to mean <br>that musicians customarily use 2 different thirds for vertical and <br>successive intervals, and that they also prefer intervals somewhat sharper <br>than would be expected by contemporary models of human hearing. [Cornu & <br>Mercadier, "Sur les intervalles musicaux," Comptes Rendus de l'Academie  <br>Royale des Sciences, 1869a, pp. 301-308.]<br>The evidence for a preference for wider-than-"rational" intervals doesn't <br>end in 1869, however.  It scarcely begins there:<br>In 1876 Preyer found that what he called the "index of sensitivity" for the <br>major thirds was 158; this corresponds to 11 cents.  So intervals as large <br>as 397 cents were still identified as major thirds.  This is midway between <br>the 5/4  and the 81/64 (12 cents short of the 407-cent Pythagorean major <br>third). [Preyer, W. T., "Ueber die Grezen der Tonwahremung," Jena, 1876]<br>In 1897-8 Carl Stumpf studied both the minor third and the major third in 3 <br>forms: ascending, descending and simultaneous intervals. His results showed <br>a marked asymmetry in the  spread of sharp vs. flat errors. For the minor <br>third, the listeners  were more inclined to accept considerable flatting than <br>slight  sharping.  Stumpf stated that the "point of subjective purity" shifted <br>toward flat minor thirds. Analysis of data from his second experiment with <br>major thirds showed exactly the opposite tendency. In this case, the point of <br>subjective purity shifted to sharp thirds.  [Stumpf, C. and H. F. Meyer, <br>"Massbestimmungen ueber die Reinheit consonanter Intervale," in Beitraege <br>zur Akustik und Musikwissenschaft, Vol. 2, 1898]<br>Moran and Pratt's investigations in 1926 found an average error of 18 cents <br>for the intervals of the 12-TET scale. "There is a range of about half an <br>equal semitone midway between each musical interval, within which an <br>interval should be recognized by D as neither of the familiar intervals, next <br>above or below it."  This meant that major thirds sharped by as much as 25 <br>cents were still recognized by their subjects as  pure thirds. [Moran, H. and <br>C. C. Pratt, "Variability of Judgements on Musical Intervals," Journal of <br>Experimental Psychology, Vol. 9, 1926]<br>Comprehensive statistics showing a preference for melodic Ptyhagorean <br>thirds  were first compiled by P.C. Greene in 1937. [Green, P.C. "Violin <br>Performance with Reference to Tempered, natural and Pythagorean <br>Intonation," Iowa Studies Music 4, pp. 232-251, 1937]<br>Bolt was the first to use pure sine waves and electronic instrumentation. In <br>1947 he observed mistuned major thirds and found  the same results--<br>although his main interest was in spectral cues for identifying mistuned <br>intervals.  [Bolt, R.H., "Masked Differential Pitch Sensitivity of the Ear  for <br>Musical Intervals, " JASA, vol. 19, 1947]<br>In 1948 Nickerson observed the same melodic preference for widely <br>stretched (viz., near-Pythagorean) thirds. [Nickerson, J.F., "A Comparison of <br>Performance of the  Same Melody in Solo and in Ensemble with Reference to <br>Equi-Tempered, Just, and Pythagorean Intonation," Ph.D. thesis, Univ. Minn., <br>1948]<br>Ward studied the octave sense along with preferred values  for thirds and <br>fifths starting in 1954.  <br>Ward's 1970 chapter in "Music Perception" lends further  support to the <br>preference for wider-than-5:4 thirds, both vertically and melodically. <br>Additional papers which amass evidence for this universal human preference <br>include: Ward, W.D., "Music Perception," In  "Foundations of Modern  Auditory <br>Theory," Ed. J. V. Tobias, 1970 see also Ward, W.D. "Subjective Musical <br>Pitch," JASA, Vol. 25, 1954.]  Corso and Pikler & Harris reproduced these <br>results in the late 50s-early 60s. [Corso, J.F. "Scale Position and Performed <br>Musical Octaves," J. Pysch., Vol. 37, 1954; Pikler, A. G.  & J.D. Harris, <br>"Measurement of the Musical Interval Sense," JASA, Vol. 33, pg. 862, 1961.]  <br>Pikler's article "History of Experiments on the Musical Interval Sense," <br>Journal of Music Theory, 1966, pp. 55-95,  summarizes these results at <br>length.<br>During the late 60s and throughout the 70s Johan Sundberg used computer <br>analysis of recordings of live performances to determine performers' <br>intonational preference.  His difficult-to-obtain report STL-QOSR- 2-3, <br>Speech Transm. Lab., Stockholm 1970, "Statistical computer measurement <br>of the tone-scale in played music," by Fransoon, F., Sundberg, J.  and <br>Tjernlund P. is summarized in Sundberg's 1992 text as confirming <br>Delezenne's, Voos', Corso's, Ward's, Lichte's,  Pikler & Harris', et al.'s <br>results; Sundberg, J. "The  Science of Musical Sounds," 1992, pg. 105. <br>Roederer's 1973 text quotes Ward's confirming data for Pythagorean thirds.  <br>Roederer ascribes the preference to Terhardt's hypothesis of universally <br>stretched intervals rather than Pythagorean intonation as such.  <br>In 1975 Terhardt and Zick published a paper showing that  for tone <br>sequences emphasizing melody over accompaniment, subjects preferred all <br>intervals stretched. [Terhardt, E. & Zick, M. "Evaluation of the Tempered Tone <br>Scale in Normal, Stretched and Contracted Intonation," Acustica, Vol. 32, <br>1975, pp. 268-274.]<br>The most recent paper supporting the stretched-third preference appears to <br>be Voos, "Quality Ratings of Tempered 5ths and Major 3rds," Music <br>Perception, Vol. 3 No. 3, 1986.]<br>By this point it should be clear that the evidence for musicians  preferring <br>intervals *wider* than the 81:64  as a "major third" goes back at least 125 <br>years.   <br>What about the octave?<br>This subject is so enormous and so important that the purported "perfect" <br>octave of 2:1 will be dealt with separately in the next two posts.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Fri, 6 Oct 1995 22:52 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id NAA12599; Fri, 6 Oct 1995 13:52:09 -0700<br>Date: Fri, 6 Oct 1995 13:52:09 -0700<br>Message-Id: <009977C6B6BABBDC.42AF@ezh.nl><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2104 href="#2104">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/7/1995 7:42:06 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Tuning & psychoacoustics - post 14 of 25<br>---<br>"In the case of the octave, the craving for stretching has been noticed for <br>both dyads and melodic intervals. The amount of stretching preferred <br>depends on the mid frequency of the interval, among other things. The <br>average for synthetic, vibrato-free octave tones has been found to be about <br>15 cents.  Thus, subjects found a just octave too flat but an octave of 1215 <br>cents just." [Sundberg, J. "The Science of Musical Sounds," 1992, pg. 104]<br>MYTH: "The interval is just or not at all." [Harrison, "Lou Harrison's Music <br>Primer," 1971, pg. 48]<br>FACT: "For centuries, musical folklore has held that the simplest ratios are <br>the best  ratios, in musical intonation.  Thus the interval betwen two <br>frequencies having a ratio of 3:2 is the "perfect" fifth; 4:3 gives a "perfect" <br>fourth, etc. (...) These philosophical and a priori views of temperament, <br>however, are hardly supported by empirical evidence." [Ward, W.D. and <br>Martin, W.D., "Psychophysical Comparison of Just Tuning and Equal <br>Temperament in Sequences of Individual Tones," JASA, Vol. 33, No. 50, 1961, <br>pg. 586]<br>MYTH: "This 2 to 1 relationship is a constant one...the fact is that nature <br>does not offer one tone and its doubling (200 to 400) as a given quality of <br>relationship, and the same quality of relationship in two tones which are <br>not a ratio of doubling (200 to 600, for example)" [Harry Partch, "Genesis of <br>a Music,"  2nd. Ed., 1974, pg. 77.]<br>FACT: "If a frequency of 8 kHz is chosen for f1, subjects produce for the <br>sensation of `half pitch' not at a frequency of 4 kHz, but a frequency of about <br>1300 Hz." [E. Zwicker and H. Fastl, "Psychoacoustics: Facts and Models," <br>1993, pg. 103.] <br>MYTH: "If, through some terrestrial disaster, our [equal-tempered] musical <br>system were completely lost, it would sooner or later be inevitably <br>redicsovered, just as it exists today, after having passed through <br>transformations identical or similar those those it has undergone." [Ducup <br>de Saint-Paul, quoted in Matthys Vermeulen, "Hic et Nunc, Jacobe," Djawa, <br>Vol. 12, 1932, pp. 146-149]<br>FACT: "It is quite remarkable that musicians seem to prefer too wide or <br>"stretched" intervals." [Johan Sundberg, "The Science of Musical Sounds," <br>1992, pg. 103.]<br>MYTH: "Notice that these frequency clumps are arranged in a harmonic series <br>based on a fundamental frequency half that of tone M, and also that any lack <br>of accuracy in setting an exact 3/2 frequency ratio will be called to our <br>attention... " [Benade, A. H., Fundamentals of Musical Acoustics, 1975, pg. <br>272]<br>FACT: "The experimental results very convincingly show that, on the <br>average, singers and string players perform the upper notes of the major <br>third and the major sixth with sharp intonation (Ward 1970)...The same <br>experiments revealed that also fifths and fourths and even the almighty <br>octave were played or sung sharp, on the average! (A reciprocal effect <br>exists. Pure octaves are consistently judged by musicians to sound flat!) <br>Rather than revealing a preference for a given scale (the Pythagorean), these <br>experiments point ot the existence of a previously unexpected *universal <br>tendency to play or sing sharp all musical intervals.* (italics in original <br>text)" [Juan Roederer, "Introduction to The Physics and Psychophysics of <br>Music," 1973, pg. 155.]<br>MYTH: "Consequently, these statements can be conclusively made; the ear <br>consciously or unconsciously classifies intervals according to their <br>comparative consonance or comparative dissonance; this faculty in turn <br>stems directly form the comparative smallnesss or comparative largeness <br>of the numbers of the vibrational ratio..." [Harry Partch, "Genesis of a Music,"  <br>2nd. Ed., 1974, pg. 87.]<br>FACT: "Therefore it must be concluded that even just or pythagorean <br>intonation cannot be considered as ideal.  Rather, optimum intonation of a <br>diatonic scale probably depends on the structure of the actual sound in the <br>same manner as has been previously discussed with respect to tempered <br>scales." [E. Terhard and S. Zick, "Evaluation of the Tempered Tone Scale In <br>Normal, Stretched, and Contracted Intonation," Acustica, Vol. 32, 1975, pg. <br>273.]<br>MYTH:"The reason that the ratio does not change is simply and wholly because  physiogically the ear does not change excpet over a period of thousands and  millions of years." [Partch, Genesis of a Music, 2nd ed.,<br> 1974, pg. 97]<br>FACT: "The degree of consonance depends on the quality or  spectrum of the <br>component tones, i.e., the relative intensity of dissonant vs. consonant upper <br>harmonics." [Juan Roederer, "The Physics and Psychoacoustics of Music," pg. <br>143.]<br>MYTH: "Long experience in tuning reeds on the Chromelodeon convinces me <br>that it is preferable to ignore partials as a source of musical materials.  <br>The ear is not impressed by partials as such.  The faculty--the prime <br>faculty--of the ear is the perception of small-number intervals, 2/1, 3/2, <br>4/3, etc., etc., and the ear cares not a whit whether these intervals are in or <br>out of the overtone series." [Harry Partch, "Genesis of a Music,"  2nd. Ed., <br>1974, pg. 87.]<br>FACT: "In 1987 IPO issued a wonderful disc by Houtsma, Rossing and <br>Wagenaars...illustrating the effects of a moderate stretching...of scale <br>frequencies and/or partial spacings. Part of a Bach chorale is played with <br>synthesized tones. When neither scale nor partial frequencies are stretched, <br>we hear the intended harmonic effect.  When the scale is unstretched but the <br>partial frequencies are stretched, the music sounds awful. Clearly, intervals <br>in the ratio of small whole numbers are in themselves insufficient to give <br>Western harmonic effects." [John R. Pierce, "The Science of Musical Sound," <br>2nd Ed., pp. 91-92.]<br>MYTH: "In the previous section of this chapter, I made a definition: we would <br>henceforth reserve the word  *tone* to refer to sounds having harmonic <br>partials. For emphasis, I will often refer to such sounds as musical    <br>tones...to underline the fact that harmonically related complexes of partials <br>have a very    special    perceptual    status    that happens also to make <br>them useful in music." [Benade, A.H., Fundamentals of Musical Acoustics, <br>1975, pg. 264]<br>FACT: "Clearly the timbre of an instrument strongly affects what tuning and <br>scale sound best on that instrument." [Wendy Carlos, "Tuning: At the <br>Crossroads," Computer Music Journal, 1987.]<br>"Most instruments in our music culture produce harmonic spectra,  as <br>mentioned.  However, in the contemporary computer-aided electroacoustic <br>music studios, is not a necessary constraint any longer.  One would then ask <br>if this does not open up quite new possibilities also with respect to <br>harmony.  If one decides to use one particular kind of inharmonic sepctra for <br>all tones, it should be possible to tailor a new scale and a new harmony to <br>this inharmonicity." - Johan Sundberg, "The Science of Musical Sounds," pg. <br>100.<br>"By using a digital computer, musical tones with an arbitrary distribution of <br>partials can be generated.  Experience shows that, in accord with Plomp's <br>and Levelt's experiments with pairs of sinusoidal tones, when no two <br>successive partials are too close together such tones are consonant rather <br>than dissonant, even though the partials are not harmonics of the <br>fundamental.  For such tones, the conditions for consonance of two tones <br>will not in general be the traditional ratios of the frequencies of the <br>fundamentals...  [The 8-TET scale] is, of course, only one example of many <br>possible scales made up of tones whose upper partials are not harmonics of <br>the fundamental and having unconventional intervals, which nonetheless can <br>exhibit consonance and dissonance comparable to that obtained with <br>conventional musical intstruments (which have harmonic partials) and the <br>diatonic scale.  It appears that, by providing music with tones that have <br>accurately specific but nonharmonic partial structures, the digital comptuer <br>can release music from the constraint of 12 tones without throwing <br>consonance overboard."  [John R. Pierce, "Attaining Consonance in Arbitrary <br>Scales," Journal of the Acoustical Society of America, 1966, p. 249.]<br>"The physical correlate of an interval is not a ratio, anymore than the <br>physical correlate of a pitch is a frequency.  Intervals and pitches both have <br>thresholds, ranges of variability," [Moran, H. and C. C. Pratt, "Variability of <br>Judgments on Musical Intervals," Journal of Experimental Psychology, Vol. 9, <br>1926] <br>Evidence for this conclusion is so voluminous and so detailed that it <br>cannot be contained in a single series of 22 posts. However, the next post <br>scratches the surface of this body of evidence, and hints at the enormous<br> extent of the experimental data showing a universal human preference for <br>stretched octaves, fifths, thirds, etc.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Sun, 8 Oct 1995 03:26 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id SAA22621; Sat, 7 Oct 1995 18:25:50 -0700<br>Date: Sat, 7 Oct 1995 18:25:50 -0700<br>Message-Id: <951008012346_71670.2576_HHB23-1@CompuServe.COM><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2107 href="#2107">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/8/1995 8:12:29 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Tuning & psychoacoustics - post 15 of 25<br>---<br>MYTH:"In any given range of pitch the comparative consonance of an interval <br>is determined by the relative frequency of the wave  period in the sounding <br>of the interval." [Harry Partch, "Genesis of a Music,"  2nd. Ed., pg. 151.]<br>FACT: "Systematic measurements show that people tend to find that an <br>interval traditionally classified as "consonant" sounds  progressively <br>dissonant the farther down in the bass it is  played...In the very low bass, <br>even the octave sounds dissonant!" [Johan Sundberg, "The Science of Musical <br>Sounds," pg. 73.] <br>"Even the *order* in which two instruments define a musical interval is <br>relevant.  For instance, if a clarinet and a violin sound a major third, with <br>the clarinet playing the lower note, the first dissonant pair of harmonics <br>will be the 7th harmonicof  the clarinet with the 6th harmonic of the violin <br>(because only  odd harmonics of the clarinet are present).  This interval <br>sounds smooth.  If, on the other hand, the clarinet is playing the upper tone, <br>the 3rd harmonic of the latter will collide with the 4th harmonic of the <br>violin tone, and the interval will sound  `harsh.'" [Roederer, J., "Introduction <br>to The Physics and  Psychophysics of Music," 1973, pg. 143.]<br>In his 3-part article, "Some Aspects of Perception," Shackford reveals how <br>widely so-called "perfect" intervals can deviate when performed by trained <br>symphony-caliber performers from major orchestras--yet these intervals <br>are still heard as "perfect." Because Shackford's measurements offer such <br>remarkable proof of the ear/brain's categorical perception mechanism at <br>work, the article deserves an extended quote:<br>"Mean Values (MV) and quartile deviations (QD) of interval sizes measured in <br>a string trio [composed of members of the New York Philharmonic] as <br>compared with just, equally tempered and Pythagorean tunings (J,ET and P):<br>--------------------------------------<br>          Dyads           <br>Interval  	MV (cents)  QD (cents)<br>Major 2nd    204              197-211<br>minor 3rd    305              287-318<br>Major 3rd    410              402-418<br>Fifth        	707              699-714<br>---------------------------------------<br>          Melodic           <br>Interval  	MV (cents)  QD (cents)<br>Minor 2nd     93               86-101<br>Major 2nd     204             199-209<br>Fourth           501             408-510<br>Fifth             701             692-708<br>---------------------------------------<br>[Shackford, "Some Aspects of Perceptions," Journ. Mus. Theory, Vol. 6, 1961]<br>"Fifths and twelfths are shown in Examples 17 and 18; and then a statistical <br>analysis of the sizes of these intervals in performance is represented in <br>Example 19. The spread of 50 cents, a quarter tone, between the largest and <br>smallest fifths played is surprisingly large for the interval that is supposed <br>to be the most sensitive to inaccuracies of intonation." [Shackford, C. "Some <br>Aspects of Perception - I," Journ. Mus. Theory, Vol. 6, 1961, pg. 185]<br>"Thirds and tenths are shown in Example 20 and are then analyzed in <br>Example 21. Major thirds and tenths have about the same spread [50 cents] <br>but the median and mean is larger for thirds. (...)  As with fifths, long-held <br>thirds and tenths show a narrower spread than those used in passing. Though <br>sizes approaching the "natural" value of 386 cents were used, the <br>Pythagorean interval of 408 cents appears to be the most representative of <br>actual practice." [Shackford, C., "Some Aspects of Perception - I," Journ. Mus. <br>Theory, Vol. 6, 1961, pg. 189]<br>"For barbershop quartets, a Major 3rd of 403 cents was preferred, while a <br>fourth of 493 cents and a fifths of 705 cents was preferred." [Sundberg, J. <br>"The Science of Musical Sounds," 1992, pg. 100]<br>"It is quite remarkable that musicians seem to prefer too wide or 'stretched' <br>invervals in many cases. Above we have seen several examples of interval <br>stretching: the barbershop singers' fifth and just minor seventh; string trio <br>players' melodic  major and minor thirds and fifths; music listeners <br>preferred sizes of fifth and octave; and a professional musician's settings <br>of melodic intervals that contain  ascending fifths. In the case of octaves, <br>the craving for stretching has been noticed for both dyads and melodic <br>intervals. The amount of stretching preferred depends on the mid frequency <br>of the interval, among other things. The average for synthetic, vibrato-free <br>octave tones has been found to be about 15 cents. Thus, subjects found a <br>just octave too flat but an octave of 1215 cents just. (...) A German <br>acoustician, Ernst Terhardt, developed an interesting theory that proposes <br>an explanation for why  we are so eager to stretch octaves. He departed <br>from the fact that the pitch of a sine tone is changed if another sine tone <br>starts to sound simuntaneously. The net result is that both tones push the <br>pitch of the other tone away from its own pitch to increase the distance <br>between the two. In this way, the pitch interval between the first partials <br>in a harmonic stpectrum becomes a bit stretched. (...) Terhardt believes that <br>this stretched octave follows us from cradle to casketand that is is this <br>octave that musicians model when they play." [Sundberg, J. "The Science of <br>Musical Sounds," 1992, pp. 103-105]<br>Additional papers which adduce evidence for the universal preference for <br>stretched octaves include Terhardt, E., "Pitch, Consonance and harmony," <br>JASA, Vol. 55, 1970, pg. 410. He didn't cite Terhardt, E., "On the perception <br>of periodic sound fluctuations (roughness)." Acustica, Voll. 30, 1974, pg. <br>201. Nor does he cite Terhardt, E. and Zick, M., "Evaluation of the Tempered <br>Tone Scale in Normal, Stretched and Contracted Intonation," Acustica, Vol. <br>32, 1975, pp. 269-276, in which Terhardt points out: "Therefore it must be <br>concluded that even just or Pythagorean intoantion cannot be considered as <br>ideal. Rather, optimum intonation of a diatonic scale probably depends on <br>the structure of the actual sound in the same manner as has been previously <br>discussed with respect to tempered pianos." [Terhardt, E. and Zick, M., op <br>cit.]<br>Terhardt goes on to conclude: "It is remarkable, however, that stretched <br>intonation is distinctly preferred to contracted intonation. Probably, the <br>pitch interval established by the simultaneous complex tones fits better <br>with the mentally stored octave interval in stretched intonation than in <br>contracted intonation.  This is well in line with the psychoacoustic <br>phenomenon of octave enlargement." [Terhardt, E. and Zick, M. , op cit.]<br>Various musicians who find these results inconvenient have claimed that <br>the preference for stretched intervals occurs not because Western <br>musicians "prefer" non-just sharp intervals, but because they learn to play <br>them; a wealth of evidence disproves this claim.  <br>In "Octave adjustment by non-western musicians," Edward M. Burns <br>states "The results were essentially the same as found with Western<br> musicians, that is, small intrasubject variability, large intersubject<br> variability, and a small but statistically signficant frequency-dependent<br> "stretch" of the physical octave when adjusting the subjective octave. <br>(...) As suggested by Terhardt, they do seem to rule out the explanation <br>that this stretched is learned from the "stretched" tuning of the piano <br>to which Western musicians are universally exposed. This stretched <br>tuning of the piano is due to certain physical characteristics of the <br>piano strings and is not found in most instruments to which the Indian<br> musicians are exposed." [Burns. E. M, op cit., Session M: Musical acoustics,<br> 88th meeting of the  Acoustical Society of America; in JASA, vol. 56,<br> Supplement, pg. S 26]<br>In the same session, Burns' paper "In Search of the Shruti," cites evidence <br>from Indian musicians confirming "earlier experiments [which] indicate <br>that the phenomenon of "categorical perception" is present in the <br>perception  of musical intervals." [Burns, op cit, in JASA, Vol. 56, Supplement, pg. S 26]<br>This explains why various just intonation fans hear the perceptually <br>non-octave 2:1 ratio as being a "pure" octave while listeners not indoctrinated by constant exposure to just intonation accurately<br>perceive the distorted 2:1 ratio  as smaller than the perceptual octave.<br>  Exactly the same effect is at work among Javanese musicians who <br>hear many different gamelan as being tuned to "pelog" even though "the majority of large Balinese gamelan are tuned with five pitches to the octave, having some intervals larger than others, in a general pattern <br>that has come to be called pelog: but no two gamelan have exactly the <br>same pattern of intervallic structure.  This is not for want of skill.  <br>It is because the tuning pattern has been composed." [Erickson, Robert,  "Timbre and the Tuning of the Balinese Gamelan," Soundings, pg. 98, 1984]<br>Categorical perception also explains why equal tempered intervals are <br>accepted with such equanimity by listeners; a wide variety of different <br>intervals are perceived as "thirds" and "fifths" and "fourths" and "sixths" <br>in an actual musical peformance setting:  a psychological mechanism is <br>at work whereby listeners unconsiously process the sounds they hear <br>and fit unfamiliar intervals into familiar categories.  Listeners <br>literally *hear what they expect to hear*--regardless of what is <br>*actually played.* <br>More evidence for this phenomenon comes from "Categorical Perception--<br>Phenomenon or epiphenomenon: Evidence from experiments in the perception <br>of melodic musical intervals," Burns, E. M. and Ward, W.D., JASA vol. 63, No. <br>2, Feb. 1978, pg. 456.<br>"In marked contrast to the extreme accuracy of musical-interval judgments <br>in the experimental situations cited above is the large variability found in <br>measurements of intonation in musical performance.  The results of several <br>studies on intonation in performance of western classical music have been <br>summarized by Ward (1970). They show large variations in the tuning of <br>individual intervals (ranges of almost a semitone) in a given performance.  <br>Similar variability has been found in measurements of intonation in <br>nonclassical western music (Stauffer, 1954; Fransson, Sundberg and <br>Tjernland, 1970; Owens, 1974) and in nonwestern music (Jhairazbhoy and <br>Stone, 1963; Callow and Shepherd, 1972; Spector, 1966).  Of course this <br>large variability is not in itself surprising since variability in production of <br>tones is involved. The important point, however, is that in the above-cited <br>studies, all listeners, including the performing musicians, agreed that the <br>compositions were performed correctly and the large variability in <br>intontion was not detected. <br>"This apparent inability to detect large variations in interval size in certain <br>situations suggests that a phenomenon associated with the perception of <br>speech tokens, "categorical perception," may be involved." [Burns, E., and <br>Ward, W.D., "Categorical Perception--Phenomenon or epiphenomenon: <br>Evidence from experiments in the perception of melodic musical intervals," <br>JASA vol. 63, No. 2, Feb. 1978, pg. 456.]<br>Again, in "Categorical Perception of Musical Intervals," Burns and Ward point <br>out "A body of evidence indicates that certain speech units are perceived in <br>in a special mode called `categorical perception,' the characteristics of <br>which are (1) the existence of well-defined identification functions and (2) <br>the ability to predict precisely the discrimination functions from the <br>identification functions, based on the  assumption that the subjects can <br>discriminate two stimuli better than they can differentially identify them.  <br>(...) A study of the perception of musical intervals by experienced musicians <br>was performed using the procedures associated with categorical perception <br>experiments;...the results show that the musicians exhibit categorical <br>perception, some to a degree approaching that shown in the perception of <br>stop consonants." [Burns, E. and Ward W., "Categorical Preception of Musical <br>Intervals," JASA, Vol. 55, No. 2, Feb. 1974]<br>The powerful evidence for categorical perception in listeners and <br>performers alike lends equal support to just, equal-tempered and non-just <br>non-equal-tempered  tunings.  Because listeners unwittingly brainwash <br>themselves to hear the intervals they expect regardless of what intervals <br>are actually performed,  all three tunings should prove equally acceptable to <br>listeners.<br>Of course there is more evidence for a difference between the stretched<br>intervals heard as "pure" and the perceptually-distorted intervals<br>characterized by small whole numbers, and universally heard as<br>"too narrow" and "flat."  The next post will examine some more<br>of this enormous body of evidence.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Sun, 8 Oct 1995 20:46 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id LAA28440; Sun, 8 Oct 1995 11:45:50 -0700<br>Date: Sun, 8 Oct 1995 11:45:50 -0700<br>Message-Id: <951008184423_71670.2576_HHB28-1@CompuServe.COM><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2111 href="#2111">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/9/1995 7:52:48 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Tuning & psychoacoustics - post 16 of 25<br>---<br>The evidence for a universal human preference for stretched intervals is<br>so overwhelming that it appears throughout the length and breadth<br>o`e psychoacoustic literature, both with Western and non-Western<br>musicians:<br>"Dowland has reported that measurements of Western and non-Western fixed <br>pitch instruments suppprt Ward's conclusion that the perceptual octave is <br>some 15 cents larger than the  physical or mathematical octave.  Western <br>musical practice supports these conlusions (play sharp in higher octave). <br>Balinese gamelan tunings take advantage of this apparently widespready <br>characteristic of pitch perception to create a multi-octave beating ocmplex <br>in their fixed pitch instruments."  [Erickson, Robert, "Timbre and the Tuning <br>of the Balinese Gamelan," Soundings, pg. 100, 1984]<br>Particularly revealing is "The 1215-Cent Octave: Convergence of Western and Non-Western  Data on Pitch Scaling,"  W. J. Dowling, Abstract QQ5, 84th meeting of the Acoustical Society of America, Friday, December 1, 1972, p. 101 of program.<br>Yet more evidence for a universal preference for stretched octaves comes<br>from Sundberg, who found that the octave was as a rule played <br>significantly sharp by performing musicians, and was also preferred sharp <br>of the 2:1 in adjustment tests:<br>"Evidently the octave intervals in such stretched scales will exceed a 2:1 <br>frequency ratio slightly. Thus, it is necessary to distinguish between the <br>*physical octave * (PO) which is defined as a 2:1 frequency ratio, and the <br>*subjective (musical) octave * (MO) that is perceived as pure.  (...) As a rule, <br>the perceptual octave corresponds to a fundamental frequency ratio <br>exceeding 2:1." [Sundberg, J. and Lindqvist, J., "Musical Octaves and Pitch," <br>JASA, 54(4), 1973, pp. 973-929]<br>Among the many implausible arguments which attempt to explain away this <br>mountain of experimental evidence for a preference for an octave interval <br>larger than the purportedly "pure" 2:1, most prevalent is the claim that <br>these "laboratory experiments do not represent real musical practice."  <br>If this objection is correct, why does computer analysis of the frequencies <br>of pitches played during actual performances which show a uniform stretch <br>of the octave also show the same results as the laboratory psychoacoustic <br>experiments?  And why do psychoacoustic measurements and experiments <br>stretching back over 150 years uniformly produce the same results?<br>"This disparity between the physical and subjective octaves is not a new <br>discovery.  Stumpf and Meyer, using the method of constant stimuli, had 18 <br>subjects judge pairs of successive tones as greater than, less than, or equal <br>to an octave.  They lower tone was 300 cps and the upper tone was varied <br>around 600 cps.  They found that 602 cps (the higher upper tone used) <br>received 52 percent "less," 43 precent "equal," and 5 percent "greater" <br>responses from the group, indicating that the mean subjective octave of 300 <br>cps was somewhere above 602 cps (the present Fig. 4 gives about 605 cps). <br>Later von Maltzew, in an investigation on the identification of intervals in <br>the upper frequency range, found that a physical octave was more often <br>called a major seventh or below than a minor ninth or above. See C. Stumpf <br>and M. Meyer, Beit. Akust. Musikw., Vol. 2 ppg. 84-167, 1898. C. v. Malzew, Z. <br>Psychol. Vol. 64, pp. 16-257, 1913. [Ward., W.D., "Subjective Musical Pitch," <br>Journ. Acoust. Soc. Am. , Vol. 26, No. 3, May 1954, pg. 374]<br>"The average standard deviation of repeated adjustments of sequential or <br>simultaneous octaves composed of sinusoids is on the order of 10 cents <br>(Ward, 1953, 1954; Terhardt, 1969; Sundberg & Lindquist, 1973).  A range of <br>average deviations from 4 to 22 cents for adjustments of the other <br>intervals of the chromatic scale (simultaneous presentation) has been <br>reported by Moran and Pratt (1926). Rakowski (1976) reports variability--in <br>interquartile ranges--of 20 to 40 cents for both ascending and descending <br>melodic versions of the 12  chromatic intervals. Other general trends <br>evident from the results of adjustment experiments are...a tendency to <br>'compress' smaller intervals (adjust narrower than equal-tempered <br>intervals) and "stretch" wider intervals (adjust wider)."  [Burns, E. M., and <br>Ward, W.D., "Intervals, Scales and Tuning," in The Psychology of Music, ed. <br>Diana Deutsch, 1982, pg. 250.]<br>"A number of measurements have been made of the intonation of musicians <br>playing variable-tuning instruments under actual performance conditions <br>(e.g., Greene, 1937; Nickerson, 1948; Mason, 1960; Shackford, 1961, 1962, a, <br>b). The results of these measurements have been summarized by Ward <br>(1970). They show a fairly large variability for the tuning of a given <br>interval in a given performance--ranged of up to 78 cents, interquartile <br>values of up to 38 cents. The mean values of interval tunings, in general, <br>show no consistent tendency to either just intonation or Pythagorean <br>intonation in either melodic or harmonic situations.  The general tenedency  <br>seems to be to contract the semitone and slightly expand all other intervals <br>relative to equal temperament.  There is also some evidence of context-<br>dependent effecst (e.g., to play F# sharper than Gb (Shackford, 1962 a,b)]. <br>Those results mirror, to a certain extent, the results of the adjustment and <br>identification experiments using isolated intervals (discussed in Sections <br>III A and III B) which showed a tendency to compress the scale for small <br>intervals and stretch the scale for large intervals, in both ascending and <br>descending modes of  presentation. <br>"The above measurements were obtained for Western classical music, but <br>the same general tendencies are evident in intonation form a military band <br>(Stauffer, 1954),  Swedish folk musicians (Fransson, Sundberg & Tjernland, <br>1970), and jazz daxophonists (Owes, 1974). Measurements of intonation <br>inperformance for Indian (Hindustani) classical music (jairazbhoy & Stone, <br>1963; Callow and Shepard, 1972) show similar variability." [Burns, E. M., and <br>Ward, W.D., "Intervals, Scales and Tuning," in The Psychology of Music, ed., <br>Diana Deutsch, 1982, pg. 258.]<br>"Even the ubiquitous 5th itself is played, on the average, sharper than the <br>702 cents predicted; indeed, in Shackford's study, it is played sharpest in a <br>harmonic context, where the minimization-of-beat forces would be <br>expected to be the most active." (...) Thus evidence indicates strongly that in <br>musical performances the target pitch for frequencies actually produced in <br>response to a given notation is one that is just a shade sharper than that <br>called for by Et.  In the 500 and 1000 Hz regions, even the subjective octave <br>(sacrosanct 2:1 in all theoretical systems) is about 1210 cents for pure <br>tones (Ward, 1954). In his studies, Shackford (1962 a,b) measured harmonic <br>10th, 11th and 12th and found that they were sharped to about the same <br>extent as 3rd, 4tha nd 5th.<br>"Boomsliter and Creel (1963) too have provided striking confirmation of this <br>theory. (...) ...it is clear from the sample dat they present aththe preferred <br>scale almost always is composed of tones consistently higher in frequency <br>than those of ET. For example, in three classical numbers (the Marseillaise, <br>a Bartok dance, and Mozart's Serenta Notturna), all notes above "do" are <br>preferred 4 to 23 cents sharp." [Ward, W.D., "Musical Perception," in <br>"Foundations of Modern Auditory Theory," ed. J.V. Tobias, Vol. 1,  pp. 420-<br>421]<br>cent 2:1.<br>The next post will examine data bearing on the third theory of hearing--<br>a model of the ear so far not dealt with as extensively as the other two.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Tue, 10 Oct 1995 02:20 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id RAA12768; Mon, 9 Oct 1995 17:20:34 -0700<br>Date: Mon, 9 Oct 1995 17:20:34 -0700<br>Message-Id: <951010001440_71670.2576_HHB24-3@CompuServe.COM><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2122 href="#2122">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/11/1995 2:29:05 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Tuning & psychoacoustics - post 17 of 25<br>---<br>While Ohm's/Helmholtz's view of the ear as Fourier  analyzer has staggered<br>under the blows of psychoacoustic research, so has the<br>Seebeck/Stumpf/Schouten model of the ear as a neural periodicity pitch<br>detector.<br>True, 50 years of research has unearthed many results which cannot be<br>explained by the frequency-domain model or "place theory" of hearing... But the<br>periodicity model of hearing has *also  *shown many shortcomings.<br>In particular, both models of the ear/brain system fail to explain or predict<br>the important phenomenon of categorical perception.  Neither model of hearing ex<br>plains the existence or pitch of the Zwicker Tone, or Risset's and<br>Shepherd's auditory paradoxes (sounds which when transposed upward by an<br>octave, drop in perceived pitch; sounds which appear to rise or fall<br>indefinitely in pitch yet whose fundamental frequency never changes;<br>sounds which are heard as speeding up/slowing down constantly yet whose<br>rate never changes).<br>Moreover, if the structure of the human ear is responsible for the music we<br>make and the tunings we use and the harmonies we prefer, how is it possible<br>to explain the fact that different cultures make entirely different kinds of<br>music?<br>If the ear is either a Fourier analyzer or a time-based autocorrelator which<br>responds most powerfully to either small-integer ratios played on<br>instruments with integer harmonics (the Fourier analysis model of hearing)<br>or fixed pitches played on instruments whose partials are matched to the<br>tuning--for example, the Railsback stretch of the grand piano matched to<br>the stretch of the partials of the piano strings--(this is the autocorrelation<br>model of hearing in which tuning & timbral partials, even if stretched, will<br>autocorrelate so as to yield uniform time-domain periodicities and thus a<br>sense of definite pitch with fundamental)...<br>If either of these models of hearing is accurate, why do the Javanese play<br>inharmonic instruments using stretched octaves and non-just non-equal-<br>tempered tunings?<br>Are other cultures deranged?  Are their ears physically different from ours?<br>Musicologists of the 19th century dismissed the Javanese, the Balinese, and<br>other non-western music with references to "the degree of aural<br>development among races as well as individuals."<br>The variability in Javanese and Balinese tunings was dismissed by De Lange<br>and Snelleman in 1992 with the memorable phrase: "for those whose ears<br>are insufficiently developed, the perfect fourth is not divided into two<br>whole tones and a semitone, but rather as the sixth, eventh and eighth<br>harmonic partials." [DeLange, Daniel and Snellman, J.F, "La Musique et les<br>instruments de musique dans les Indes Orientales neerlandaises," in<br>Lavignac, "Encylopedie de la musique et dictionnaire du COnservatoire:<br>Histoire de la musique, premiere partie (Paris, 1922," Vol. 5, pg. 3148.]<br>Such racism has become less fashionable over the last three quarters of a<br>century, but much of the debate over psychoacoustics and tuning takes place<br>in a cultural vacuum: only western music is considered, and psychoacoustic<br>arguments for or against this or that tuning are often made only in the<br>context of western equal temperament or just intonation tuning systems.<br>However, such enthocentrism is slowly changing.<br>"One of the revelations of modern psychoacoustic and etnomusicological<br>reserach has been the extraordinary complexity of intonation as used by<br>Western and non-Western musicians." [Perlman, Marc, "American Gamelan in<br>the Garden of Eden: Intonation in a Cross-Cultural Encounter," Musical<br>Quarterly, 1995, pg. 532]<br>"There are...a number of musical cultures that apparently employ<br>approximately equally tempered 5- and 7-interval scales (i.e., 240 and 171<br>cent step-sizes, respectively) in which the fourths and fifths are<br>significantly mistuned form their natural values.  Seven-interval scales are<br>usually associated with Southeast Asian cultures (Malm, 1967). For<br>example, Morton (1974) reports measurements (with a Stroboconn) of the<br>tuning of a Thai xylophone that "varied only + or - 5 cents" from an equally<br>tempered 7-interval tuning. (In ethnomusicological studies measurement<br>variability, if reported at all, is generally reported without definition.)<br>Haddon reported (1952) another example of a xylophone tuned in 171-cent<br>steps from the Chopi tribe in Uganda.  The 240-cent step-size, 5-interval<br>scales are typically associated with the "gamelan" (tuned gongs and<br>xylophone-type instruments) orchestras of Java and Bali (e., Kunst, 1949).<br>However, mreasurements of gamelan tuning byHood (1966) and McPhee (1966)  show e<br>xtremely large variations, so much so that McPhee states: "Deviations  in what i<br>s considered the same scale are so large that<br>one might with  reason state that there are as many scales as there<br>are gamelans." Another example of a 5-interval, 24--cent step tuning<br> (measured by a  stroboconn,  "variations" of 15 cents) was reported by<br> Wachsmann (1950) for a Ugandan harp.  Other examples of equally tempered scales<br> are often reported for pre-instrumental cultures...<br>For example, Boiles (1969) reports measurements (with a Stroboconn,<br>"+ or - 5 cents accuracy") of a South American Indian scale with equal<br>intervals of 175 cents, which results in a progressive octave stretch.<br>Ellis (1963), in extensive measurements in Australian<br>aboriginal pre-instrumental cultures, reports pitch distirbutions that<br>apparently follow arithmetic scales (i.e., equal separation in Hz).<br>Thus there seems to be a propensity for scales that do not utilize perfect<br>consonances and that are in many cases highly variable, in cultures that<br>either are pre-instrumental or whose main instruments are of the xylophone<br>type. Instruments of this type produce tones who partials are largely<br>inharmonic (see Rossing, 1976) and whose pitches are often ambiguous (see<br>de Boer, 1976)." [Burns, E. M. and Ward, W. D., "Intervals, Scales and Tuning,"<br>in The Psychology of Music, 1982, ed. Diana Deutsch, pg. 258]<br>These empirical data would seem to indicate that  of the three tunings (equal te<br>mpered,  just intonation, and non-just non-equal-tempered)<br>non-just non-equal-tempered and equal temperament are most widely<br>used by other cultures.  This is a conclusion directly opposite to that<br>implied by the idea of small whole numbers as uniquely preferred by<br>the ear/brain system.<br>The next post will examine in detail the third theory of hearing, first<br>proposed by Fetis in 1843, and in later life espoused by Helhmoltz: namely,<br>the view that the ear prefers a set of intervals determined by learning<br>and culture.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Thu, 12 Oct 1995 03:16 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id SAA00081; Wed, 11 Oct 1995 18:15:55 -0700<br>Date: Wed, 11 Oct 1995 18:15:55 -0700<br>Message-Id: <951012011313_71670.2576_HHB40-2@CompuServe.COM><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2124 href="#2124">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/12/1995 6:33:22 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Tuning & psychoacoustics - post 18 of 25<br>---<br>So far little has been said about the third theory of hearing, first proposed <br>by Fetis in 1841 and supported by Helmholtz and Ellis, as well as by vast amounts of psychoacoustic data from Ward, Dixon, Terhardt, et alii. <br>Fetis ascribed musical intervals and msuical conventions to "education" <br>rather than to "nature," mathematics, or the structure of the ear.<br>Although few of the proponents of equal temperament or just intonation who <br>quote him will admit it, Helmholtz echoed this sentiment when he wrote <br>that the Western musical system "does not rest solely upon inalterable <br>natural laws, but is also, at least partly, the result of esthetical principles, <br>which have already changed, and will still further change, with the <br>progressive development of humanity." [Helmholtz, Hermann, "On the <br>Sensation of Tone," 2nd. Dover ed., 1863, pg. 235]<br>As  previously noted, after exhaustive study of the musics of many cultures, <br>Alexander James Ellis concluded that "the Musical Scale is not one, not <br>`natural,' nor even founded necessarily on the laws of the constitution of <br>musical sound, so beautifully worked out by  Helmholtz, but very diverse, <br>very artificial, and very capricious." [Ellis, A. J., "On the Musical Scales Of <br>Various Nations," Journal of the Royal Society of the Arts, Vol. 3, 1885, pg. <br>536]<br>"The evidence presented thus far implies that musical-interval categories <br>are learned rather than are the direct result of characteristics of the <br>auditory system. This evidence includes: (1) the variability found in <br>measured scales and intonation, even when possible contextual effects are <br>taken into account; (2) the intrasubject variability, large intersubject <br>variability, and consistent deviations from small-integer-ratio categories <br>found in category-scaling and adjustment expeirments; (3) the absence of <br>small-integer-ratio ssingularities in frequency-ratio-JND functions and <br>absence of small-integer- ratio confusions in absolute-identification <br>experiments; and (4) the relative inability ofmusically untrained subjects to <br>perform musical interval identification or discrimination exeriments. <br>[Burns, E.M., and Ward, W.D, "Intervals, Scales, and Tuning," in The Psychology <br>of Music, ed. Diana Deutsch, 1982, pg. 261]<br>Moreover "since stimulus uncertainty in `real world' perception is, in <br>general, high, it might be expected that categorical preception of musical <br>pitchwould be the normal situation. This conclusion is supported by the <br>results of the various investigations of intonation in performance. Second, <br>the lack of evidence for the existence of natural categories for musical <br>intervals implies that individuals in a given culture learn the scales of their <br>culture from experience, not because of any innate propensity of the <br>auditory system for specific intervals." [Burns, E. M., and Ward., W.D., <br>"Categorical Perception," Journ. Acoust. Soc. Am., Vol. 63, No. 2, February <br>1978, pg. 466.]<br>"To the casual glance, the range and variability figures of Table III may <br>suggest that the performers were not very proficient, which is not at all <br>true.  Even when tuning an instrument to the *same* pitch as a standard, <br>the typical musician will show a standard deviation, in repeated settings, of <br>about 10 cents (Corso, 1954)." [Ward, W.D., "Musical Perception," in <br>"Foundations of Modern Auditory Theory," ed. J.V. Tobias, 1970, Vol. 1, pg. <br>418]<br>Again, these psychoacoustic results provide equal support for all three <br>major systems of tuning: equal-tempered, just intonation, and non-just non-<br>equal-tempered, inasmuch as the evidence strongly suggests that once the ear learns to accept any given set of musical intervals they are quickly<br>learned and categorized as "pure," "preferred," "natural," etc.<br>--mclaren<br> <br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Thu, 12 Oct 1995 15:58 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id GAA08250; Thu, 12 Oct 1995 06:58:00 -0700<br>Date: Thu, 12 Oct 1995 06:58:00 -0700<br>Message-Id: <00997C43D9CD945A.4CBC@ezh.nl><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2133 href="#2133">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/13/1995 8:00:23 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Tuning & psychoacoustics - post 19 of 25<br>---<br>We return to the parable of the three blind men and the elephant. Because of <br>the powerful prejudicial effect of mathematical and  physical models on <br>our perceptions and preconceptions, it's vital to understand some of the <br>drawbacks of those mathematical models--in particular, the Fourier <br>transform, far and away the most popular analysis technique for dealing <br>with sounds.  <br>As it turns out, the complexity of the ear's behavior is mirrored by the <br>complexities and limitations which beset the Fourier transform. <br>"The measurement of sound spectra is complicated by the fact that the <br>spectra of almost all sounds change both rapidly and drastically as time <br>goes by.  This situation is worsened by the fact that the accuracy with <br>which we can measure a spectrum inherently decreases as we attempt to <br>measure it over smaller and smaller intervals of time.<br>"The spectral content of any instant during the temporal evolution of a <br>waveform does not even exist; for example, we could scarcely tell anything <br>at all about the frequency comopnents of a digital signal by examining a <br>single sample!  We can measure what happens to the spectrum only on the <br>average over a short interval of a sound--perhaps a millisecond or so.  The <br>longer the interval, the more accurate our measurement of the average <br>spectral content during that interval, but the less we know of the variations <br>that occurred during that  interval.  Thus the problem of spectral <br>measurement may be see to be one of finding the best compromise between <br>the opposing goals.  Just how much accuracy is needed is still an open <br>question in the realm of musical psychoacoustics: in some cases  our ears <br>seem to be more toleraant of approximations than in others.  The historical <br>model of spectra as measured by Hermann Helmholtz (see References) is <br>clearly inadequate for believable resynthesis..." [Moore, F. R., "An <br>Introduction tothe Mathematics of Digital Signal Processing," Part II, <br>Computer Music Journal, Vol. 2, No. 2, pg. 43] <br>Claims of "perfect  reconstruction of the input signal" are often made for <br>Fourier transform analysis.   These claims are true only insofar as the <br>continuous Fourier transform is involved, a mathematical operation demanding  infinite amounts of data and infinite numbers of frequency<br> components. <br>Claims of "perfect reconstruction of the input signal" are *untrue* for the  discrete short-time Fourier transform applied to real-world signals.<br>"The test of any analysis/synthesis system is how little it distorts the <br>signal.  The phase vocoder, or short-term Fourier system, as it is also <br>called, is capable of zero distortion. (...) Consequently, what comes out of <br>each channel is a pure sinusoid.  We can measure its frequency, phase, and <br>amplitude. Thus, we can recreate the signal exactly by producing a new <br>sunsoid of that frequency, phase, and amplitude.<br>"In the electronic music literature this is called additive synthesis.  <br>Needless to say, when the assumption is violated, and the input signal is <br>something like white noise, the output of each channel is not a sinusoid and <br>cannot be represented with only phase, frequency, and magnitude data. You <br>must use a different representation. But for harmonic sounds in which the <br>pitch and amplitude are not changing, categorizing the signal by these three <br>numbers yields a system which is an identity."[Moorer, J.A., "A Conversation <br>with James A. Moorer," Roads, C. in "The Music Machine," 1989, pg. 14]<br>In the real world all sounds contain noise.  And not just one kind<br>of noise: many different kinds of noise are present. There is <br>always some white noise, and always some 1/f noise represented by jitter <br>in the fundamental frequency, there is always a stochastic component in the <br>individual harmonic envelopes, and there is always some band-limited noise, <br>as for instance from the scrape of a violin bow or the background breath-<br>noise in a flute. Thus the claim of "perfect reconstruction of the input <br>signal" is untrue for real-world Fourier analysis applied to real-world <br>sounds.   The exact amount of distortion introduced and the precise <br>amount of data lost by doing a real-world short-time Fourier analysis of a <br>real-world sound varies with the sound. <br>In some cases, the distortion and data loss is negligible, while in other <br>cases the short-time Fourier analysis renders the sound unrecognizable.<br>So why do many people continue to act as though the Fourier perspective<br>is the only valid one for dealing with acoustics?<br>Because engineering courses are saturated with the Fourier perspective, it <br>is often assumed that frequency/time duality (or in optics, <br>contrast/periodicity) is the only possible way of looking at any physical <br>phenomenon--particularly acoustics.  <br>This is often true, but by no means always.<br>In fact multiple methods of sound analysis have long been suggested: in <br>1947 Denis Gabor suggested an alternative to the Fourier method of analysis <br>of sounds in his paper "Acoustical Quanta and the theory of hearing." [Gabor, <br>D, "Nature," Vol. 159, 1947, pg. 303.]<br>Both Morlet and Daubechies wavelets have offered new paradigms for <br>analyzing sounds: see Kronland-Martinet et alii, "Grossman, A. and Kronalnd-<br>Martinet, R., "Time-and-scale representation obtained through continuous <br>wavelet transforms," 1988, Signal Processing IV: theories and Applications, <br>Amsterdam: Elsevier Science Publishers. <br>The Fourier transform viewpoint is a linear parametric method of analysis.  <br>Thus it is strictly limited by the assumptions inherent in parametrized <br>analysis, and by the assumption that input functions will obey the <br>superposition principle.<br>Other non-linear non-parametric models for signal processing exist. See <br>Maragos, P., "Slope Transforms: Theory and Application to Nonlinear Signal <br>Processing," IEEE Trans.Sig. Proc., Vol. 43, No. 4, April 1995, pp. 864-877.<br>Each of these mathematical analysis methods has its own unique drawbacks: <br>"Even though the Morlet wavelet analysis seems to compact information in a <br>way that is well suited to the characteristics of hearing, it does not work <br>as easily as the use of Gabor grains for altering independently frequency and <br>speed.  Hence the value of this or that method is contingent on the music <br>purpose. Indeed to realize various types of intimate sonic modification, one <br>may have to go out of the general framework and resort to more specific <br>methods." [Risset, J.C., "Timbre Analysis by Synthesis," in "The Music <br>Machine," 1992, pg. 37]<br>Frequency-based mathematical models of analysis are not the only kind <br>possible: time-based autocorrelation methods of pitch detection have long <br>been implemented in computers. Both the Average-Mangitude Difference Function (a time-based autocorrelation) and the zero-crossing detection function (another time-based period-detection method) are typically used<br>to extract a fundamental frequency track from a digitized  waveform prior to employing a Fourier transform to dissect the sound into sinusoids. <br>Thus, ironically, the best-known frequency-domain algorithm for analyzing <br>musical sounds is crucially dependent on a *prior    time-domain    <br>autocorrelation    algorithm * when we want to apply it in the real <br>world. Given this incestuous connection between frequency- and time-<br>domain methods of analysis in the real world, it is not clear why one <br>viewpoint (the Fourier transform) ought to dominate the discourse of signal <br>processing.<br>The progressive discovery of the many limitations of the Fourier transform <br>as a tool for analyzing real-world sounds has led to a search for alternative <br>methods of analysis: Jean-Claude Risset, the pioneer of analysis-by-<br>synthesis in 1965 on mainframe computers at Bell Labs, states: "From these <br>studies I draw two conclusions: first, there does not seem to be any general <br>and optimal paradigm to either analyze or synthesize any type of sound.  One <br>has to scrutinize the structure of the sound--quasiperiodic, sum of <br>inharmonic components, noisy, quickly or slowly evolving--and also <br>investigate to find out which features of sound are relevant to the ear." <br>[Risset, Jean-Claude, "Timbre Analysis by Synthesis," in "The Psychology of <br>Music," ed. Diana Deutsch, 1982, pg. 18]<br>Because the Fourier mindset dominates and shapes so much<br>of the discourse of Western music, it's important to point<br>out *all* of its limitations and inaccuracies.  Thus the<br>next post will continue the discussion of the many conditions<br>under which the Fourier viewpoint is inappropriate for<br>real music in the real world.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Fri, 13 Oct 1995 17:07 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id IAA05441; Fri, 13 Oct 1995 08:07:19 -0700<br>Date: Fri, 13 Oct 1995 08:07:19 -0700<br>Message-Id: <Pine.SOL.3.91.951013095946.18776B-100000@library><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2140 href="#2140">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/14/1995 7:39:20 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Tuning & psychoacoustics - post 20 of 25<br>---<br>As is now evident, the Fourier transform is at best poorly suited<br>to the analysis of real-world sounds.<br>Noise, inharmonic partials and radical phase changes insure that<br>many real-world instrument tones are poorly modelled as a<br>sum of pure sinusoids near-constant in magnitude and phase.<br>This is complicated by the fact that "...much of the characteristic sound of <br>an instrument is in its transient regions, such as the attack portion of its <br>tone." [Moorer, J. A., "Signal Processing Aspects of Computer Music - A <br>Survey," Computer Music Journal, Vol. 2, No. 2, pg. 7]<br>To date, the aperiodic and chaotic attack portions of instrumental notes <br>have consistently resisted analysis, as have the residual stochastic <br>portions of the sound which cannot be analyzed successfully by current <br>techniques: a variety of work-arounds are  generally used to "smooth-over" <br>the radical phase and magnitude discontinuities generated by Fourier <br>analysis of the attack transients, or to parametrize the chaotic-attractor <br>"residual" and mimic it with some kind of bandlimited noise generator added <br>to the resynthesized signal.<br>"Each...spectrogram tells how amplitude and phase vary as a function of <br>frequency.  This process of analysis and resynthesis has been called a phase <br>vocoder.  Serra made use of the process to his ends, taking successive <br>spectra at intervals of around 10 milliseconds.<br>"Such successive spectra do not in themselves give a deep insight into <br>musical sounds.  Serra's innovation was to use successive spectra in <br>dividing the signal into two parts--and deterministic, or predictable part, <br>and a stochastic, or unpredictable, noisy part.  The deterministic part Serra <br>took to be clear peaks which in several successive spectra change just a <br>little in apmlitude and phase.  This part of the spectrum Serra resynthesized <br>by generating the individual sinusoidal compoennts whose amplitudes, <br>frequencies, and phases changed with time in the fashion indicated by the <br>successive spectra. (...) [Serra] replaced this [non-deterministic] part of the <br>spectrum with a noise that had roughly the  same overall spectrum as his <br>stonachastic part but that didn't match it in waveform.<br>"Serra tested this division of the signal into a deterministic and stochastic <br>part...by listening separately to the deterministic and stochastic parts, and <br>then adding them and listening to their sum. A piano sound reconstructed <br>from the deterministic spectra alone didn't sound like a piano.  With the <br>stochastic or noise portions added, it sounded just like a piano.  The same <br>was true of a guitar, a flute, a drum, even the human voice." [Pierce, J.R., <br>"The Science of Musical Sound," 2nd ed., 1992, pg. 106] <br>Moreover, Fourier techniques work even to a rough  approximation only with <br>a small class of harmonic-series instruments (Western brass instruments, <br>double reeds and strings, the harp). <br>"Most percussion instruments (drums, bells) are inharmonic. This means that <br>to describe them with sinusoids aften requires a large number of such. <br>There are some synthesis techniques for creating what often turn out to be <br>quite convincing drum-like or gong-like sounds, but to date there are few <br>analysis techniques that can be used with inharmonic sounds."  [Moorer, J. A., <br>"Signal Processing Aspects of Computer Music - A  Survey," Computer Music <br>Journal, Vol. 2, No. 2, pg. 7]<br>Bearing in mind that this puts all of Javanese and Bainese and Thai and most <br>African and South American music off-limits to Fourier analysis (because <br>these cultures  use mainly inharmonc instruments), the value of <br>Fourier analysis becomes questionable in the context of world music.<br>The net result is that conventional FFT  analysis *sometimes* tells us <br>*something* about what is going on in *portions* of *a few notes* played  by *a few instruments.*  <br>However, the Fourier transform is far from the universal mathematical <br>Swiss Army Knife it has been touted as being.<br>For example, suppose we try to increase frequency resolution by taking an <br>FFT of tens of thousands of points--we have only 2 ways of doing this.  [1] <br>Add tens of thousand of zeroes padded at the end of each wavecycle, which <br>merely refines the accuracy with each bin's frequency is specified but does <br>not tell us anything about what's going on between the frequency bins <br>(where most of the interesting and complex behavior of real-world <br>intstruments takes place); or [2] we can extend our FFT over multiple <br>wavecycles, which does give us some information about what's going on <br>between frequency bins because the fundamental of the wavecycle is apt to <br>change over the couse of several period--but this dodge lumps all the <br>spectral changes in 2, 3, or more wavecycles into a single analysis frame <br>and thus "smears out" the spectral changes of the sound in time. <br>If this sounds like "Catch-22," guess what? <br>It is. <br>Heisenberg's Uncertainty Principle is actually an outgrowth of the basic <br>characteristic of wave motion:  to wit, you can accurately measure <br>*either*  the frequency *or *  the period of a changing waveform, but you <br>cannot measure *both * precisely at the *same    time. * And when you <br>increase the precision with which you measure the wavetrain's period, you <br>consequently decrease the precision with you measure the wavetrain's <br>frequency.<br>This has profoundly important consequences for the FFT.<br>[1] Increasing your time resolution (that is, making the FFT snapshots closer <br>together in time) deceases your frequency resolution (because you must <br>therefore take smaller FFTs over those smaller time-lengths). <br>[2] Increasing your frequency resolution (that is, taking the FFT snapshot <br>over a bunch of different spectrally-evolving wavecycles) decreases your <br>time resolution (because all the spectral changes in each frequency line are <br>lumped into a single frequency and averaged over the number of wavecycles <br>you're looking at).<br>[3] Increasing the number of phase points, to give you a more precise <br>measurement of the exact amount by which partial is detuned from the <br>others, also increases the number of frequency bins--and to do this you <br>must extend the FFT over a longer time-period, which in turn means you're <br>lumping your phase changes together and averaging them out, which entirely <br>defeats your purpose.<br>[4] Decreasing the number of frequency points, to narrow down the time <br>window over which you take the FFT "snapshot," also decreases the number <br>of phase points--which divides the fundamental frequency in a smaller <br>number of divisions and defeats your purpose by making the measured <br>frequency changes coarser in the time domain.<br>Because the discrete Fourier transform is cyclic and imposes an infinite <br>periodicity (both supersonic and subsonic) on your spectrum, you must use a <br>limited fixed sampling rate and band-limit your input samples to avoid <br>aliasing (that is, to avoid the lowest supersonic and the highest subsonic <br>frequency bins from bleeding into your audible frequency bins and <br>contaminating them with inharmonic-sounding spurious garbage). <br>But once you fix your samling rate, you've thrown out all information <br>between samples. This means that there's no way to  reconstruct the detail <br>in the waveform "between" the samples because it's gone.  You've dumped it <br>out.  You've thrown out the baby with the bathwater.  The price you pay for <br>perfect reconstruction of a signal is that the signal that spews out of your <br>mathematical analysis algorithm is sometimes quite different from the real <br>analog signal that came in.<br>"Sometimes" because if there's very little noise and the partials are almost <br>perfectly harmonic,  you get good results with the Fourier transform even in <br>its discrete version.<br>Alas, most sounds are *not*  noise-free and perfectly harmonic.<br>"If you have a hammer, everything in the world looks like a nail."  This is <br>nowhere more true than of the Fourier transform.<br>Many writers have begun articles on tuning or acoustics with statements <br>along the lines of: "Musical sounds are made up of sinusoidal frequency  and <br>phase components..."  <br>No!<br>Wrong!<br>Completely false!<br>Classic error.<br>These people have mistaken the *map*  for the *territory.*<br>They have confused the *mathematical  model * of the  physical <br>phenomenon with the *physical phenomenon * itself.<br>*Sounds * are displacements of air molecules.   <br>*Sinusoids * are ideal mathematical entities infinite in temporal extent <br>and perfectly periodic.    <br>Sometimes one or another mathematical model works well in analyzing <br>acoustical phenomena; other times they all work well, sometimes *none * <br>yield useful results. <br>Different mathematical techniques and different conceptual models are <br>required for different acoustical phenomena, as Risset points out.<br>There is no "one size fits all."  Yet this this is exactly what the Fourier <br>tykes would have us believe.<br>The universe exhibits what the mathematicians call "the inexhaustibility of <br>the real."  Goedel proved this in 1930: the universe is ultimately more <br>complex than any statements we can make about it mathematically.<br>Or, to put in another way, there are an infinite number of true but <br>unprovable propositions.<br>Clearly proponentsn of this or that tuning system who write circularly-<br>reasoned arguments a la "that's the beauty of mathematics--it has an <br>inescapable logic" haven't collided with the real world in the form of a <br>sound that turns to junk when you Fourier analyze it.  <br>For example, breathy vocal sounds. Or flute multiphonics, or a cymbal clash, <br>or gamelan bar note.<br>It's worth remembering Fourier never came up with his transform to solve <br>the problem of frequency analysis. He used it as a clever dodge to solve the <br>problem of heat comduction in a  metal bar.  <br>It worked well on that problem, but it has since been greatly extended--in <br>some cases, overextended.<br>The wavelet transform, a probably superior mathematical method for <br>analyzing acoustic phenomena, dates from only 1987.<br>Since then we've had very few useful & powerful transforms.  <br>Mathematical progress has been slow.  The Walsh Transform is no big help--<br>it is acoustically "brittle" and is too few Walsh components are used in a <br>reconstructing a sound, the output is intolerably buzzy and distorted-<br>sounding.  Bart Kosko's fuzzy Kalman filter promises some insight into <br>acoustic transformations but the amount of  ground gained has been <br>small...and the rate of progress slow.<br>In the end, the real world is very *very*  VERY complex.  <br>Our linear parametric mathematical models models apply with accuracy only <br>to an tiny class of physical phenomena.  <br>It has become increasingly (distressingly!) clear over the last few years <br>that sounds are not "infinite harmonic wavetrains containing perfectly <br>harmonic overtones with a few stochastic ergodic noise components mixed <br>in."<br>Rather, real computer analysis of actual instrument timbres shows with <br>brutal clarity that real-world sounds run the entire gamut from chaotic <br>strange attractors to pure noise to semi-noise/semi-pitched to strongly <br>pitched narrowband noise to mostly harmonic sounds with a rock-steady <br>fundamental.<br>No one mathematical analysis technique is adequate to model all these <br>ranges of behavior.  And when you realize that something as simple as the <br>flute can exhibit the entire range (overblown multiphonics, semi-pitch <br>"breathy" whispery notes, flutter-tongued notes, strongly pitched notes in <br>the lower registers with a steady fundamental) you start to realize  that <br>the FFT is useful for only a very limited class of musical sounds. Thus it is <br>hardly surprising that the to-date largely FFT-obsessed model of the ear as <br>frequency analyzer has had extremely limited success in explaining real-<br>world musical preferences, the effects of real-world intervals on listeners, <br>and the real-world propensity of composers, performers and audiences to <br>prefer intervals not well defined by the integer eingenvalue vocabulary  of <br>the Fourier transform.<br>--mclaren<br> <br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Sat, 14 Oct 1995 17:30 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id IAA19603; Sat, 14 Oct 1995 08:30:29 -0700<br>Date: Sat, 14 Oct 1995 08:30:29 -0700<br>Message-Id:  <9510140829.aa01987@cyber.cyber.net><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2144 href="#2144">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/15/1995 7:59:42 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Tuning and psychoacoustics - post 21 of 25<br>---<br>Throughout this series of posts, we have seen that the ear/brain system is not simple.<br> Tones," in "The Psychology of Music," ed. Diana Deutsch, 1982, pg. 21]<br>But the behavior of the ear/brain system is also different from that predicted by Seebeck, Stumpf and Schouten: <br>e away the fundamental 440 cps and the second harmonic 880 cps? <br>l. 1, No.1, 1955, pg. 55 (English edition, 1957)]<br>This is the simplest and most compelling example of the contradictory behavior of the ear/brain system.<br>s. (...) The fundamental neural message is given by the rate and the distribution in time with which individual impulses are fired along the axon." [Roederer, Juan, "The Physics and Psychophysics of Music," 1973, pg. 45]<br>des the information on repetition rate or periodicity pitch (see below)."  [Roederer, Juan, "The Physics and Psychophysics of Music," 1973, pg. 45]<br>main and the Seebeck/Stumpf time-domain model of the ear, and instead supports the Fetis/Burns/Ward model of the ear as an adaptive system molded by learned responses.<br>Thus in one simple experiment we have compelling evidence both for and against all 3 major theories of hearing.<br>Other compelling evidence for the "contextual" behaviour of the ear/brain system abounds. <br> influencing is effected by the following vowel (regressive dissimilation) as well as by the preceding." [Werner Meyer-Eppler, "Statistic and Psychologic Problems of Sound,"  Die Reihe, Vol. 1, No.1, 1955, pg. 55 (English edition, 1957)]<br>and Synthesis," in "The Psychology of Music," ed. Diana Deutsch, 1982, pg. 36]<br> 429.]<br> 1, pg. 429.]<br>greater than 2 milliseconds." [Pierce, J.R., "The Science of Musical Sound," 2nd ed., 1992, pg. 149]<br>"On the hypothesis that critical band filters can be identified with<br>auditory nerve filters, the model of Zwicker and Scharf was tested by<br>Pickles (1983). (...) The results agreed with the psychophysical darta, in<br>that the summed activity increased with stimulus bandwidth, for wider<br>timulus bandwidths. (Fig. 9.13 B).  However, there was no clear sign<br>of a flat portion in the function at narrow bandwidths. The reason for<br>this is not known..." [Pickles, James O., "An Introduction to the Physiology<br>of Hearing," Academic Press, 2nd ed., 1988, pg. 283]<br>. <br>he listener is based on learned experience..." [Roderer, Juan, "The Physics and Psychophysics of Music," 1973, pg. 134] <br>But by far the most striking gaps in current knowledge of the ear/brain system involve the  question of how the human auditory performs 3-dimensional sound localization. <br>TF, or the location of a specific sound using that mathematically-modelled HRTF.<br><br>Human Subjects," J. Audio Eng. Soc., 43(5), 1995 May, pp. 300-321; also<br>see Appleton, J., "Machine Songs III: Music In the Service of Science--<br>Science in the Service of Music," Computer Music Journal, 16(3), 1992,<br>pp. 17-21]<br>Clearly, there remain many unexplained aspects in the behavior of the ear/brain system.<br>The next post examines the mass of evidence gleaned from<br>the many psychoacoustics results confirmed and supported<br>by a wealth of modern.  Although the modern psychoacoustic<br>data is complex, it does support some conclusions.  These will<br>be given in the next post, after which the various biases and<br>prejudices of the psychoacoustic researchers themselves will<br>be examined...with an eye to determining how much or how little<br>their prejudices affected the conclusions each major researcher<br>drew from hi/r research.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Sun, 15 Oct 1995 19:43 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id KAA28157; Sun, 15 Oct 1995 10:42:44 -0700<br>Date: Sun, 15 Oct 1995 10:42:44 -0700<br>Message-Id: <951015174059_71670.2576_HHB28-1@CompuServe.COM><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2151 href="#2151">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/16/1995 8:42:42 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Tuning and psychoacoustics - post 21 of 25<br>---<br>Throughout this series of posts, we have seen that the ear/brain system <br>is not simple.<br>As is now clear, the behavior of the auditory system when presented <br>with complex tones is different than that predicted by Ohm/Helmholtz: <br>"Helmholtz's working hypothesis has  been put aside by later <br>investigators, both those who worked in music and those who worked <br>in psychoacoustics.  Several reasons for this can be given.  First, <br>before the introduction of electroacoustic means of tone production <br>and control in the 1920s, it was not possible to carry out the <br>necessary psychoacuostical experiemnts, while Helmholtz's observations <br>proved insufficient in many ways. Second, it turned out that musical <br>theory has its own rules apart formm the perceptual relevance of the<br> characteristics of the sounds it makes." [Rasch, R. A., and Plomp, R.,<br> "The Perception of Musical Tones," in "The Psychology of Music," ed. <br>Diana Deutsch, 1982, pg. 21]<br>But the behavior of the ear/brain system is also different from that <br>predicted by Seebeck, Stumpf and Schouten: <br>"It sounds obvious if we say that we hear a note a' if the fundamental <br>of the frequency is 440 c.p.s. But what happens if we remove this <br>fundamental by electrical means, leaving on ly the harmonics with <br>frequencies of 880, 1320, 1760 cps, etc?  Or if we take away the <br>fundamental 440 cps and the second harmonic 880 cps? <br>We learn from experiments that the perceived pitch level remains the <br>same: a'.  One may take away many of the lower harmonics without <br>altering this.  If this `mutilated' note is interrupted for only an <br>interval of a second, the sensation is completely altered. Instead of <br>the `residual tone' on a' we now hear another pitch which lies <br>approximately in the region of the strongest remaining harmonics and <br>is called `formant pitch.'" [Werner Meyer-Eppler, "Statistic and <br>Psychologic Problems of Sound," Die Reihe, Vol. 1, No.1, 1955, pg. 55 <br>(English edition, 1957)]<br>This is the simplest and most compelling example of the contradictory <br>behavior of the ear/brain system.<br>The ability of the ear to extract an unambiguous fundamental frequency <br>from a complex tone argues strongly in favor of the Ohm/Helmholtz <br>hypothesis of the ear as a Fourier analyzer; but the ability of the <br>ear to still hear a "residual" fundamental even after the fundamental <br>and lower harmonics have been removed electronically cannot be <br>explained by the ear-as-Fourier-analyzer model of hearing. Instead, <br>"beats of mistuned consonances and periodicity pitch can be perceived <br>even if each component tone is fed dichotically to a different ear.  <br>In such a case, of course, the complete vibration pattern never <br>arises--what must arise is a superposition or interaction of the <br>neural signals from both cochleas after they have been combined at <br>the medullar or midbrain levels. (...) The fundamental neural message <br>is given by the rate and the distribution in time with which <br>individual impulses are fired along the axon." [Roederer, Juan,<br>"The Physics and Psychophysics of Music," 1973, pg. 45]<br>Thus the ability to hear such residual pitch argues against the<br> Ohm/Helmholtz Fourier analyzer model of hearing, and for the <br>Seebeck/Stumpf model of the ear as time-domain autocorrelator in <br>which "the actual time distribution of [auditory nerve] impulses <br>codes the information on repetition rate or periodicity pitch (see <br>below)."  [Roederer, Juan, "The Physics and Psychophysics of <br>Music," 1973, pg. 45]<br>However, the fact that after a brief interruption the ear hears <br>exactly the same tone from which fundamental and lower harmonics <br>have been electronically removed as having an entirely different <br>pitch argues strongly against BOTH the Ohm/Seebeck frequency-domain <br>and the Seebeck/Stumpf time-domain model of the ear, and instead <br>supports the Fetis/Burns/Ward model of the ear as an adaptive <br>system molded by learned responses.<br>Thus in one simple experiment we have compelling evidence both <br>for and against all 3 major theories of hearing.<br>Other compelling evidence for the "contextual" behaviour of the <br>ear/brain system abounds. <br>"...it is to be emphasized that sound elements which are juxtaposed <br>in time can have the effect that identical physical vibration <br>procedures give rise to totally different sensations.  The phenomenon <br>has been particularly observed in the case of synthetic explosive <br>sounds such as `p',`t', `k' which may be perceived in a totally <br>different manner, depending on the vowels which are juxtaposed <br>to them (3).  To explain this one cannot attribute it to masking <br>which has already been known for a long time becuase the <br>influencing is effected by the following vowel (regressive <br>dissimilation) as well as by the preceding." [Werner Meyer-Eppler, "<br>Statistic and Psychologic Problems of Sound,"  Die Reihe, Vol. 1, <br>No.1, 1955, pg. 55 (English edition, 1957)]<br>Further evidence of complex phenomena possibly produced by <br>interaction between the ear's frequency-domain and its <br>time-domain processing functions was brought forward by <br>Strong and Clark. "...in order to evaluate the  relative significance <br>of spectral and temporal envelopes, [they] resorted to an <br>interesting process: they exchanged the spectral and temporal <br>envelopes among the wind instruments and asked listeners to <br>attempt to identify these hybrid tones.  The results indicated <br>that the spectral envelope was dominant if it existed in a unique <br>way (as in the oboe, clarinet, bassoon, tube and trumpet); otherwise <br>(as in the flute, trombone, and French horn), the temporal envelope <br>was at least as important." [Risset, Jean-Claude, "Exploration of <br>Timbre by Analysis and Synthesis," in "The Psychology of Music," <br>ed. Diana Deutsch, 1982, pg. 36]<br>Some results are simply inexlicable by any of the above models: <br>"Doughty and Garner (1948)...concluded that pitch was unchanging <br>for tones of 25 msec and longer, but that 12-msec and 6-msec <br>tones have a lower pitch.  However, Boomsliter et al., (1964) <br>emphasize that the transition from "click" to "tone" depends on <br>the intensity. Swigart (1964) has reported a perhaps related <br>phenomneon for repeated short bursts of tone.  If one presents <br>successive 8-msec bursts of 1000-Hz tone with 1-msec pauses  <br>between (i.e., if one cuts out every ninth cycle), the pitch is <br>significantly lower than that of a continuous 1000-Hz tone.  <br>Just why, however, is still unclear." [Ward, W.D., "Musical <br>Perception," in "Foundations of Modern Auditory Theory," ed. J.V. <br>Tobias, Vol. 1, pg. 429.]<br>"An aspect of pitch perception that is still regarded as <br>somewhat mysterious despite a goodly amount of experimentation <br>is "aboslute" (or "perfect") pitch." [Ward, W.D., "Musical Perception," <br>in "Foundations of Modern Auditory Theory," ed. J.V. Tobias, Vol. 1, <br>pg. 429.]<br>"In 1973 David M. Green published some interesting results on <br>temporal acuity. He measured the ear's ability to discriminate <br>between two signals that have different waveforms but the same <br>energy spectrum.  An example of such signals is any short waveform <br>and the same waveform reversed in time, such as those in figure <br>10-5.  Here Part A is a sound of decreasing frequency, Part B is a <br>sound of increasing frequency. Green found that the ear can tell the <br>difference between two such waveforms if their duration is greater <br>than 2 milliseconds." [Pierce, J.R., "The Science of Musical Sound," <br>2nd ed., 1992, pg. 149]<br>"On the hypothesis that critical band filters can be identified with<br>auditory nerve filters, the model of Zwicker and Scharf was tested by<br>Pickles (1983). (...) The results agreed with the psychophysical data, in<br>that the summed activity increased with stimulus bandwidth, for wider<br>timulus bandwidths. (Fig. 9.13 B).  However, there was no clear sign<br>of a flat portion in the function at narrow bandwidths. The reason for<br>this is not known..." [Pickles, James O., "An Introduction to the <br>Physiology of Hearing," Academic Press, 2nd ed., 1988, pg. 283]<br>No model of the ear/brain system convincingly explains any of <br>the above results, or for that matter one of the best-known <br>quirks in musical perception: perfect pitch. Musical aesthics is <br>yet another abyss which has swallowed many a psychoacoustic <br>researcher. <br>"Why some vibration patterns appear more "beautiful" than others <br>is not known.  A great deal of research (good and bad) has been <br>attempted, for instance, to find out what physical characteristics <br>make a Stradivarius violin a great instrument.  Many of these <br>characteristics are dynamic in character, and most of them seem <br>more related to the major or minor facility with which the player <br>can control the wanted tone "color" (timbre), than to a "passive" <br>effect on a listener.  To a large extent the impression on the listener <br>is based on learned experience..." [Roderer, Juan, "The Physics and <br>Psychophysics of Music," 1973, pg. 134] <br>But by far the most striking gaps in current knowledge of the <br>ear/brain system involve the  question of how the human auditory <br>performs 3-dimensional sound localization. <br>A Head-Related Transfer Function can be measured empircially for <br>each individual by means of microphones placed in the ear canals  <br>and an extremely high-speed computing engine, but to date no one <br>has offered a general mathemtical model which predicts the HRTF, <br>or the location of a specific sound using that mathematically-<br>modelled  HRTF.<br>The best example of this complete gap in our psychoacoustic <br>knowledge is the inadequacy of current stereo speakers.  Even a <br>6-year-old child easily detects the difference between a recording <br>reproduced from digital media on high-quality stereo speakers, and <br>a live performance: but to date no one has succeeded in <br>formulating a mathematical model of hearing which details the <br>difference in hard numbers. [See Moeller, H. K., Soerenson, M. F.,<br> Hammershoei, D., and Jensen, C. B, "Head Related Transfer Functions <br>of Human Subjects," J. Audio Eng. Soc., 43(5), 1995 May, pp. <br>300-321; also see Appleton, J., "Machine Songs III: Music In the <br>Service of Science-- Science in the Service of Music," Computer <br>Music Journal, 16(3), 1992,pp. 17-21]<br>Clearly, there remain many unexplained aspects in the behavior of <br>the ear/brain system.<br>The next post examines the mass of evidence gleaned from<br>the many psychoacoustics results confirmed and supported<br>by a wealth of modern.  Although the modern psychoacoustic<br>data is complex, it does support some conclusions.  These will<br>be given in the next post, after which the various biases and<br>prejudices of the psychoacoustic researchers themselves will<br>be examined...with an eye to determining how much or how little<br>their prejudices affected the conclusions each major researcher<br>drew from hi/r research.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Tue, 17 Oct 1995 01:35 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id QAA13399; Mon, 16 Oct 1995 16:34:38 -0700<br>Date: Mon, 16 Oct 1995 16:34:38 -0700<br>Message-Id: <199510162332.AA046446328@athena.ptp.hp.com><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2156 href="#2156">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/17/1995 8:40:51 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Tuning & psychoacoustics - post 22 of 25<br> <br>---<br>In the course of this series of posts much experimental evidence has been <br>reviewed.  Forum subscribers open-minded enough to have read the original <br>references now understand the degree of contradiction and complexity <br>which attends the human auditory system.<br>As we've seen, the evidence offered by psychoacoustic research is not <br>simple and straightforward.  Some results conflict,  and others support <br>none of the three accepted models of human hearing.<br>There is, however, a preponderance of evidence to support a number of basic <br>conclusions about the ear/brain system:<br>The fact that different aspects of the ear/brain's sound processing function <br>are evoked by different experiments opens up the likelihood that at least 3 <br>different ear/brain systems operate to process sound.  Wever (1964) was <br>the first to suggest that more than one mechanism exists to process sound; <br>von Bekesy strongly implies this conclusion in his 1966 paper. Plomp (1967) <br>strongly disagrees, but gives no basis for his objection. Pickles (1989) <br>points out that "the best support for [this] view is the rather negative<br>one that the evidence in favour of either of the other two [place and<br>periodicity] theories is not conclusive, and this may be a function of<br>the quality of the evidence available, rather than of the acutal operation<br>of the auditory system." [Pickles, James O., "An Introduction to the<br>Phsyiology of Hearing," Academic Press, 2nd ed., 1988, pg. 277]<br>The leading candidates for different mechanisms for detecting pitch and <br>processing sounds, they are: [1] the Fourier analyzer action of the <br>basilar membrane; [2] the  encoding of pitch and spectral content by <br>repetition rate of neurons firing  along the auditory nerve; [3] the <br>combination of received neural impulses in medullar and higher brain <br>areas and the consequent active feedback pathway between the Sylvian <br>fissure, the superior medial nucleus, and the different classes of neurons <br>in the primary, secondary and third- and fourth-order nerve fibers of <br>the auditory nerve.<br>What does this imply?<br>First, the role of learning and the possible conflict twixt periodicity and <br>Fourier analysis makes it clear that "the pitch of musical sounds is not <br>directly proportional to the logarithm of the frequency and is probably <br>complexly conditioned."  [Corso, J.F. "Scale Position and Performed Musical <br>Octaves," Journal of Psychology, Vol. 37, 1954] This renders suspect tuning <br>theories which ascribe absolute and invariant qualities to this or that <br>scale  degree or interval.  Instead, pitch and  intervallic quality appear <br>to be  storngly influenced by musical context, as well as by the overtone <br>content of the intervals.<br>This conclusion would tend to support all three tunings equally, depending <br>on musical context, and learning: just intonation, equal temperament, and <br>non-just non-equal-tempered tunings are all equally supported by the <br>brain's learned sound processing capacities.<br>With instruments using strictly harmonic spectra, this conclusion weakly <br>supports the use of just intonation tuning--weakly, because of the <br>important role of learned response in the ear/brain system.   For <br>instruments which do not use strictly harmonis spsectra, non-just non-<br>equal-tempered systems are weakly supported: this conclusion does not <br>support use of equal temperament except insofar as education and <br>acculturation can sufficiently indoctrinate listeners into accepting that <br>tuning.<br>Second, from Plomp and Levelt's and Kameoka and Kuriyagawa's work it is <br>clear that the roughness or sharpness of musical intervals is largely <br>determined by proximity of individual overtones with the critical band for <br>that frequency range.<br>It is also clear from Mathews', Pierce's, Geary's, Sethares' and Dashow's <br>work that timbres can be matched to tunings using digital technology so as <br>to precisely control the degree of audible roughness or smoothness within <br>the intervals of the scale.<br>However, it is less clear from the psychoacoustic evidence that audible <br>roughness and sharpness of musical intervals equates with "consonance" and <br>"dissonance," much less with the more sophisticated quality of <br>"concordance" and  "discordance" put forward by Easley Blackwood.<br>Much of the music-theory literature on consonance and dissonance merely <br>redefines those terms to favor the author's chosen list of references. By <br>redefining consonance as "beats," just intonation emerges as the preferred <br>tuning; by redefining consonance as "roughness," the periodicity theory is <br>favored with the proviso that the partials of the overtones be warped to fit <br>the tuning (so that all the partials share sub- and super-multiples of the <br>same periodicity); and if consonance is redefined as "learned preference," or <br>"experimental results of interval preference," non-just non-equal-tempered <br>tuning emerges as the "best" tuning based on the empirical evidence of <br>preference for stretched non-just non-equal-tempered intervals.<br>A good example of this process can be found in the following quote from <br>Plomp:<br>"In conclusion, Helmholtz's theory, stating that the degree of dissonance is <br>determined by the roughness of rapid beats, is confirmed. It appears that <br>maximal and minimal roughness are related to critical bandwidth..." [Plomp, <br>"Experiments on the Tone Sensation," 1967, pg. 58] By discussing only <br>harmonic tones and by defining dissonance as "the roughness of rapid beats," <br>just intonation emerges as the de facto winner.<br>A different set of assumptions produces an entirely different conclusion.  <br>For example, Risset's composition Inharmonique is based on inharmonic <br>tones which also exhibit a lack of "roughness of rapid beats."  Thus Risset's <br>harmonic practices would appear to be equally acceptable according to <br>Plomp's definitions, yet Risset's composition does not employ small-integer <br>ratios--but the compositions still exhibits marked examples of dissonance <br>and consonance.<br>Moreover, musical intervals are often not heard as isolated units: "there is <br>considerable evidence that melodies are perceived as *gestalts * or <br>patterns, rather than as a seuccession of individual intervals, and that <br>interval magnitude is only a small factor in the total percept." [Burns., <br>E.M.,  and Ward, W.D., "Intervals, Scales and Tuning," in "The Psychology <br>of Music," ed. Diana Deutsch, 1982, pg. 264] <br>As Plomp points out, "A clear relationship exists between these data, <br>justifying the conclusion that consonance is closely related to the absence <br>of (rapid) beats, as in Helmholtz's theory.  The critical-bandwidth curve <br>fits the data rather well." [Plomp, "Experiments In the Tone Sensation," <br>1967, pg. 58]<br>Thus, while the psychoacoustic evidence on "roughness" and "smoothness" of <br>musical intervals is clear, the musical imlications are less <br>striaghtforward.  As von Bekesy points out, "...linearity can be assumed of <br>the mechanical part of the [auditory] stimulation; but from a physiological <br>point of view, the question of linearity in the nervous system is still  <br>open to speculation." [von Bekesy, G., "Hearing Theories and Complex <br>Sounds," Journ. Acoust. Soc. Am., Vol. 35, No. 4, 1963, pg. 588]<br>Although "beats" are castigated by one group of theorists and used as the <br>justification for one set of tuning theories, strong evidence exists that a <br>beat rate of 6 to 7 Hz adds to the perceived musicality of a performance.  <br>This is true of both non-Western and Western music:  "Even a cursory <br>acquaintance with the sound of a Balinese gamelan uncovers some puzzling <br>aspects of musical timbre.  The beating complex that is the result of all <br>the beats produced in the gamelan, and especially dependent upon the beats <br>of paired metallophones, resembles in its effect the quality of a string, <br>woodwind or brass section in a Western orchestra.  (...) It appears that <br>some type of pulsation at rates between 6 and 7 times per second -- and <br>slightly irregular -- is musically desirable, both in Bali and in the West, <br>that the effects of beats and the effects of vibrato are similar so far as <br>the quality of richness is concerned, and that the unfiication of hte <br>sound (section sound) can be accomlished with either technique." [Erickson, <br>R., "Timbre and the Tuning of the Balinese Gamelan," Soundings, 1984, <br>pg. 100]<br>In fact the argument for this or that tuning according to beat rate  is not <br>supported by the psychoacoustic data, except insofar as the data strongly <br>support a universal preference for low-level beats in the 6-7 Hz region.<br>The ability of the ear to extract individual components from complex <br>sounds, however, argues strongly in favor of just intonation.<br>JI tunings are the only tunings which accord with the ear's Fourier <br>analysis mechanism.<br>It is, however, clear that Fourier analysis is only one method used by the <br>ear to process sounds, and in many situations it is the least important <br>system. Both Plomp & Levelt's and Kameoka and Kuriyagawa's findings strongly <br>support all three general kinds of tunings, provided that the overtones of <br>the individual partials of the notes are matched to the scale as suggested <br>by Sethares, Risset, Pierce and McLaren.<br>We've seen from Shepard's and Risset's auditory illusions and from Wessel's <br>streaming phenomenon that all 3 ear/brain systems of pitch processing <br>interact; sometimes they conflict.  This provides opportunities for <br>composition using digital media, and tends to support non-just non-equal-<br>tempered tunings (albeit weakly).<br>At first glance, the surprising and universal human preference for stretched <br>intervals, including a stretched octave of between 1210 and 1215 cents on <br>average, strongly favors non-just non-equal-tempered scales. <br>However Terhardt has brought forth convincing evidence that much of this <br>effect is due to learning: and in that case, since any musical tuning can be <br>learned, all three tunings are supported by this body of evidence to the <br>degree that acculturation is involved.<br>The wide variability of interval size in live concerts by expert performers <br>tends to support this concludion; however Terhardt's findings in comparing <br>stretched, compressed and equal-tempered tunings found a differential <br>preference for all three types of tunings--depending on context.<br>This evidence gives superiority to either equal-tempered, stretched or <br>compressed tunings, depending on whether harmony or melody predominates.<br>The body of psychoacoustic evidence as a whole clearly shows a difference <br>between the size of preferred melodic and harmonic intervals called by the <br>same name; this also provides strong evidence for categorical perception of <br>musical intervals, which in turn tends to vitiate the superiority of any <br>given tuning.  If, once learned, an interval can be recogtnized even though <br>significantly altered in size, then many different tunings should prove <br>equally musical and effective provided that Rothenberg's properiety criteria <br>are observed.<br>The experiments also show a clear dichotomy between the preferred size of <br>vertical intervals and sequential intervals. Both preferred interval sizes <br>as measured in adjustment tests are significantly larger than small-integer <br>ratios predicted by conventional Western theory, but the sequential <br>intervals heard as "true thirds," "true fifths," "true octaves," etc. are <br>even wider than the already winder-than-just vertical intervals.  This body <br>of data strongly supports the use of non-just non-equal-tempered tunings, <br>inasmuch as the psychoacoustic data support neither a preference for <br>tempered nor just intervals. <br>Lastly, the limitations on the applicability of the Fourier transform do <br>not argue against just intoantion or for any other tuning, since the FFT is <br>entirely appropriate for strictly harmonic sounds; however an awareness of <br>the limitations of the FFT as a tool for explaining and analyzing musical <br>sounds serves as a warning against generalizing the results of this or that <br>psychoacoustic experiment beyond its proper range.  <br>Thus the data is mixed and, as promised, there exists considerable <br>psychoacoustic evidence to support each major type of tuning, as well as a <br>significant body of findings which tend to *refute * the arguments for each <br>particular tuning.<br>To date, the psychoacoustic data amassed by various researchers has been <br>considered as though it were a perfect array of unbiased results.  However, <br>all the major psychoacoustic researchers have exhibited strong biases <br>toward this or that particular tuning philosophy.  In some cases this <br>muiscal bias  had little effect on the conclusions they chose to draw from <br>their data; in other cases, these researchers deliberately buried or <br>ignored results which did not conform to their tuning prejudices.  <br>The next post will examine in detail the biases of each major reseracher,<br>and the degree to which it warped his conclusions.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Tue, 17 Oct 1995 18:17 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id JAA08685; Tue, 17 Oct 1995 09:16:38 -0700<br>Date: Tue, 17 Oct 1995 09:16:38 -0700<br>Message-Id: <Pine.SOL.3.91.951017110431.9413A-100000@library><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2161 href="#2161">ðŸ”—</a>JOHNSON@SKSOID.dseg.ti.com</h3><span>10/18/1995 5:55:00 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>Greetings!<br><br>I've read with great interest the topics of this list for some time...<br><br>Recently there was mention made of Chinese bells and I remember an excellent<br>article in the April 1987 issue of Scientific American which describes an <br>instrument made of 65 bronze bells recovered by archaeologists in 1978 that<br>dates back to the fifth century B.C.<br><br>An unusual (and rather charming) discovery about these old chime bells is that<br>they were constructed such that each will produce two separate pitches<br>depending upon where they are struck (The interval is always a minor or major <br>third.).  To quote the article, "The design of the bells requires a <br>theoretical grasp of physics and engineering formerly thought to have evolved <br>only in the late 18th century."<br><br><br>Thoughts??? Observations???<br><br>regards,<br><br>dj<br><br>dana-johnson@ti.com<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Wed, 18 Oct 1995 17:09 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id IAA09635; Wed, 18 Oct 1995 08:09:28 -0700<br>Date: Wed, 18 Oct 1995 08:09:28 -0700<br>Message-Id:  <9510180805.aa17347@cyber.cyber.net><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2162 href="#2162">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/18/1995 8:09:28 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Tuning & psychoacoustics - post 23 of 25<br>---<br>Psychoacoustics is an empirical science. Mathematical theories abound, <br>but they are attempts to explain experimental evidence. There are no valid "a priori" theories of hearing.<br>Psychoacoustics uses choice and adjustment methods, along with <br>computer analysis of live performances.  The first methods  involve laboratory  setting, while the second generally does not. <br>Overall results from both settings tend to agree. <br>Psychoacoustic researchers are prone to bias.  The goal of scientific <br>investigation is not to reduce or eliminate the prejudice of the <br>investigator, but to reduce or eliminate its effect on the measured <br>results. All of the psychoacoustic researchers cited so far have tuning <br>preferences. <br>Some of these researchers warp the presentation of results to favor a given <br>tuning system, while others do not.<br>Ohm (1843), Helmholtz (1863) and Pikler (1898) strongly favored  just <br>intonation tunings and the ear-as-Fourier-analyzer model. To explain away <br>the empirical evidence that 19th-century composers and performers <br>universally used equal tempered tunings, Helmholtz claimed that modern <br>performers were incompetent and that "true" (i.e., just) intonation was a <br>lost art, requiring superlative skill. To refute the empirical evidence that <br>most people who listened to music seemed to like equal-tempered intervals, <br>Helmholtz claimed that modern listeners had been brainwashed by equal <br>temperament.<br>In order to determine a listener's "true"  preference among musical <br>intervals, he contended, one needs must find an ear uncomtaminated by <br>debased modern equal-tempered music.  Since ears accustomed to pure just <br>intonation and unsullied by equal temperament were not to be found in 19th <br>century Europe, Helmholtz's hypothesis ran afoul of the first demand on any <br>scientific hypothesis: namely, that it be testable. <br>However, in the second edition of his book "On the Sensations of Tone," <br>Helmholtz modified his original position and wrote that music "does not <br>rest solely upon inalterable natural laws, but is also, at least partly, the <br>result  of esthetical principles, which have already changed, and will still <br>further change, with the progressive development of humanity." [Helmholtz, <br>Hermann, "On the Sensation of Tone," 2nd. Dover ed., 1863, pg. 235]<br>Helmholtz is thus a contradictory figure, on the one hand explaining away <br>empirical evidence with various pieces of circular reasoning, and on the <br>other hand openly suggesting that the third, or learned, model for hearing <br>had a strong influence on the auditory system.<br>Pikler and Ohm proved less open-minded, and they consistently bury results <br>which conflict with just intonation as the "best" tuning. <br>Seebeck (1843), Stumpf (1896) Schouten (1938), Boomsliter & Creel (1965), <br>Plomp (1967) and Roederer (1973) are strongly biased toward the <br>periodicity model of the ear.   Of these, Seebeck, Schouten and Stumpf do not <br>attempt to explain all pitch processing or auditory phenomena on the basis <br>of the periodicity theory: they simply give their results and omit mention of <br>data which would tend to contradict their conclusions. <br>Plomp's approach deserves special mention.  He argues tenaciously and at <br>length against von Bekesy's place theory near the end of his magnum opus, <br>Experiments In the Tone Sensation (1967).  After describing a model of the <br>ear's pitch and spectral-analysis functions as a set of 1/3-octave bandpass <br>filters, Plomp goes on to state: "This model of the ear's frequency-analyzing <br>mechanism must be considered as a simplified representation, since the ear <br>does not containa  limited number of fixed filters but is a continuous <br>system of overlapping filters. Nevertheless, Figure 60 elegantly accounts <br>for both the discrimination of the lower harmonics and the preservation of <br>periodicity.  The way in which these waveforms give rise in the ear to <br>periodic nerve impulses, however, is still rather unknown." [Plomp, <br>"Experiments In the Tone Sensation," pg. 128, 1967]<br>Plomp mentions experiments by de Boer (1956), Schouten (1962), Ritsma <br>and Engel (1964) and Licklider (1956, 1959, 1962)--all staunch advocates <br>of the periodicity theory.  Significantly, Plomp does not mention any of the <br>experiments which tend to contradict the periodicity theory of hearing--in <br>particular, Flanagan and Guttman's 1959 experiments and the removal of the <br>fundamental from the Seebeck click series.  These experiments *are <br>*described by von Bekesy.<br>By neglecting to cite the full range of experimental results, Plomp creates a <br>false impression that all psychoacoustic data support the periodoicity <br>theory.  Moreover, he neglects to mention that the Fourier-analysis (or <br>place) theory of hearing could equally well account for the fact that pitch is <br>primarily determined by the lower harmonics of a sound, and that even when <br>those lower harmonics are masked by noise the ear still detects a definite <br>pitch.  "Apart from the question of how a model spanning only two octaves <br>can throw any light on the perception of a complex tone, we may ask how <br>this observation can explain why the pitch of a complex tone is not altered <br>when the lower harmonics are masked completely by noise... In that case, <br>thecontribution fo the place corresonding to the fundamental is eliminated." <br>[Plomp, "Experiments In the Tone Sensation," 1967, pg. 130]<br>Oddly, Plomp neglects to mention the obvious place-theory explanation of <br>this effect. This phenomenon is well known from the perception of definite <br>pitch ascribed to bells: the ear operates as a Fourier analyzer and fits the <br>partials of the bell into the higher members of a harmonic series, then <br>assigns the bell a perceived pitch given by the assumed fundamental.  If the <br>ear's Fourier analysis can assign a nonexistant fundamental to a bell, why <br>not to a strictly harnonic sound whose lower harmonics are masked by <br>noise?<br>Houtsma summarizes this explanation concisely: "De Boer (1956) reported <br>pitch matches in which inharmonic complex tones comprising five or seven <br>partials with uniform frequency spacing were aurally matched to periodic <br>complex tones with a fundamental that differed systematically from the <br>spectral spacing of the inharmonic sound. Schouten, Ritsma and Cardozo <br>(1962) produced similar data for AM complexes (three partials)...and <br>smoorenburg (1970) found essentially the same results using complexes <br>consisting of only two tones. [Houstma, A.J.M., and Goldstein, J.L., "The <br>Central Origin of the Pitch of Complex Tones: Evidence from Musical Interval <br>Recognition," Journ. Acoust. Soc. Am., Vol 51, No. 2, 1971, pg. 525]<br>Moreover, Plomp glosses over the most serious objection to the periodicity <br>theory--namely, that because of the duration imposed on the impulses from <br>nerve fibers in the inner ear, pitches above 1600 Hz should not be <br>perceptible. "The physiological process which sets an upper limit to the <br>frequency of impulses in each fiber is the refractory period. For a brief <br>interval of approximately 1 msec after each impulse the nerve-fiber is not <br>excitable and cannot transmit another impulse." [Boring, E. G. and A. Forbes, <br>Hearing: Its Psychology and Physiology, 1983, 2nd ed., pg. 401]  Plomp's <br>response to these objections is worth noting:  <br>"The hypothesis that hte pitch of a tone is based on the period of the sound <br>waves may be criticized ont eh ground that this periodicity is preserved up <br>to 3000-4000 cps, whereas we are able to distinguish tones up to about <br>16000 cps. This discrepancy is one of the most serious arguments against <br>periodicity pitch. It is obviated by Wever's assumption (Chapter 7) that the <br>ear is provided with two ptich-detecting mechanisms: one, based on <br>periodicity, for low frequency and one, based on place of maximal <br>stimulation along the basilar membrane, for high frequencies.  This <br>conception is not very attractive, however." [Plomp, "Experiments In the <br>Tone Sensation, 1967, pg. 130]<br>This is a remarkable statement. Plomp saves the periodicity model of pitch <br>by dragging in another model of ear/brain function, then criticizing his own <br>conclusion!<br>Plomp never explains why the idea of multiple auditory pitch detection <br>mechansisms is "not very attractive."  Moreover, his arguments for the <br>periodicity theory lose much of their power because he's forced to appeal to <br>the very theory he's arguing against (the place theory) in order to save the <br>periodicity theory for notes with high fundamentals.<br>In several cases where both the periodicty and place theories offer equal <br>explanatory power, Plomp consistently comes down on the side of the <br>periodicity theory.  Consider the following example:<br>"Upon presenting tone intervals with the same freuqnecy ratios to the ear, <br>for instance the mistuned interval 200 + 601 cps, the same phenomena were <br>observed as with (von Bekesy's) model. This corresondence was considered <br>by von Bekesy as an affirmation that in both cases the same mehcanism is <br>involved.  In his opinion, it seems clear that the periodicity of the nerve <br>impulses does not play an important part in the production of beats.<br>Although this reasoning appears rather attractive, I prefer an alternative <br>explanation of the beats which is based on the assumption that pitch is <br>related to the periodicity of nerve impulses." [Plomp, "Experiments In the <br>Tone Sensation," 1967, pg. 125]<br>Perhaps even the most diligent researchers become confused when <br>attempting to explain away their own biases.  At least Plomp admits his <br>prejudice: "In the writer's opinion, this explanation of pitch perception in <br>terms of periodicity is more satifactory than those based on the palce <br>principle. If the pitch of complex tones is derived from periodicity, it is <br>difficult to see why this should not be the case for simple tones, too." <br>[Plomp, "Experiments In the Tone Sensation," 1967, pg. 129]  <br>Aside from the fact that many of his objections to the place theory are <br>easily answered, and that he neglects to point out some of the most serious <br>problems with the periodicity theory, Plomp is reasonably straightforward <br>about his leanings toward the periodicity theory.<br>Boomsliter & Creel, in "The Long Pattern Hypothesis in Music," Journ. Mus. <br>Theory, 1965, are not so forthcoming.<br>They are strongly prejudiced toward just intonation, and their article does <br>not cite results which tend to contradict either periodicity or JI tunings <br>(viz., combination tones, the universal preference for stretched intervals, <br>etc.) and they explicitly attempt to derive all of the ear's functions from the <br>periodicity theory.  For example, there's no mention of the body of <br>psychoacoustic evidence for a universal preference for stretched intervals, <br>and Boomsliter and Creel explain away their own data showing a general <br>preference for just intervals on their "search organ" singificantly larger <br>than those predicted by the just intonation theory of small whole numbers. <br>The same is true of Roederer in his book's section on the physical makeup of <br>the ear/brain system: there is a great deal of discussion of neurons and <br>neural firing pattern, none at all on the processing of medullar and higher <br>brain areas nor any detailed discussion of von Bekesy's experiments, the <br>physical action of the organ of Corti, etc.  However to his credit Roederer <br>does cite extensively the results of Ward, Corso, Terhardt, Sundberg and <br>Lindqvist for the unviersal preference of stretched invtervals.  <br>Thus Roederer, like Helmholtz, is a contradictory figure--deliberately <br>overemphaszing some of the evidence, while remaining open-minded about <br>other contradictory results. Fetis (1943), Ellis (1885) Corso (1954), Ward <br>(1970),  Burns (1970), Hood (1975) and Erickson (1983) are all strongly <br>biased toward the ear-as-controlled-by-learned-preference model of <br>hearing.  Terhardt and Ward/Burns tend to bury evidence which does not <br>favor their view by dumping a superflux of additional results on top of the <br>relevant data; this has the same effect as squirelling the relevant data <br>away in a bibliograhy at the back of the article, but it achieves the same end <br>by opposite means. Fetis, Hood, Ellis, tend to stress the  multiplicity of <br>results and musical cultures, rather than concentrating on empirical data <br>from specific experiments.<br>Von Bekesy demonstrates a bias toward the place theory but his bias does <br>not appear to affect his willingness to bring forward contradictory results. <br>In particular, he cites both the periodicity and place theories as worthy of <br>additional investigation in his 1966 article "Hearing Theories and Complex <br>Sounds," Journal of the Acoustic Society of America. <br>Terhardt & Zick, Kameoka & Kuriyaga, Pierce, Mathews, Green, Wessel, <br>Risset  and Sundberg do not exhibit a bias toward any specific theory of <br>hearing.  These authors all cite competing hypotheses and suggest lines of <br>further experimental inquiry into all 3 ear/brain models.<br>Throughout this article the intent has been to present psychoacoustics data <br>as clearly as possible.<br>In many cases this meant extracting experimental results from layers of <br>refutation or from citations buried in bibliographies because this or that <br>psychoacoustician preferred not to bring the inconventient result out into <br>the body of the text, where it might raise embarassing questions.<br>In other cases, viz., Risset or von Bekesy or Pierce, extensive direct quotes <br>of secondary sources were used because these sources offered the most <br>detailed survey of the evidence.<br>Thus the casual reader must be wary of Roederer, Helmholtz, Plomp and <br>other sources widely cited because of the covert (sometimes overt) bias <br>toward this or that tuning or theory or hearing.<br>As mentioned at the outset, acousticians have fared far worse than <br>psychoacoustics researchers in this regard.  <br>Backus (1969), like von Bekesy, is biased toward just intonation--but unlike <br>von Bekesy he neglects to mention any of the psychoacoustic experiments <br>which cast doubt on either just intonation as the ideal tuning system or the <br>place theory as the sole explanation of hearing.  In the chapter ""Intervals, <br>Scales, Tuning, and Temperament," Backus lavishes 3 pages on just <br>intonation and 2 pages on Pythagorean intonation but only 1 page on equal <br>temperament. No tunings are mentioned  other than Pythagorean, meantone, <br>just intonation and equal temperament: there is, for example, no reference <br>to pelog, slendro, the Indian srutis, or any other non-European tuning..<br>Moreover, Backus buries or is not aware of many psychoucstic data which <br>contradict his view of the ear as simple Fourier analyzer.  In part (as <br>mentioned earlier) this is because Backus had the bad luck to publish his <br>book "The Science of Musical Acoustics" just before computers introduced <br>an immense unpheaval into acoustic and auditory research. In part the <br>problem appears to be overt prejudice against acoustic results which do not <br>favor just intonation.  As mentioned earlier, texts by Rossing and Hall <br>supersede the acoustics in Backus and the psychoacoustics  (where Backus <br>refers to them at all) are incorrect as well as out of date. Thus Backus' <br>entire text should be ignored.<br>Benade (1975) cannot excuse his lapses on the basis of bad timing. In the <br>period 1970-1974 much of the data cited throughout this series of posts <br>was already well known; Benade chooses not only to ignore it, but actually <br>to argue with a number of independently-confirmed results, particularly the <br>universal preference for stretched musical intervals and the accumulated <br>evidence for the periodicity theory.   <br>For example: "Experiments by Paul Boomsliter and Warren Creel give us very <br>important information on what a musician actually does about tuning.  My <br>discussion in this capter is strongly influenced by these data, although I do <br>not completely accept their published interpretatiojn.  Paul C. Boomsliter <br>and Warren Creel, "The Long Pattern Hypothesis in harmony and hearing," J. <br>Mus. Theory, Vol. 5, No. 2, 1961, pp. 2-30, and Paul C. Boomsliter and Warren <br>Creel, "Extended Reference: AN Unrecognized Dynamic in Melody," J. Mus. <br>Theory, vol. 7, No. 2, 1963: pp. 2-22. " [Benade, A., "Fundamentals of Musical <br>Acoustics, 1975, pg. 303]<br>In short, Benade agrees with Boomsliter and Creel's claim for "small-<br>integer-ratio" detectors in the ear, but rejects the evidence they provide for <br>the periodicity theory of hearing.   Benade's commentary is notable because <br>[1] it is hidden away in a  footnote and [2] it ignores the fact that a wealth <br>of additional evidence supports the periodicity theory of hearing--evidence <br>which cannot be easily explained by the place theory, which Benade <br>espouses.<br>Again: "Everywhere in our experiments we have found indications that our <br>nervous system processes complex sounds coming to it by seeking out <br>whetever subsets of almost harmonically related components it can find." <br>[Benade, A., "Fundamentals of Musical Acoustics," 1975, pg. 68]<br>This statement is as deceptive as it is true.  The accuracy of Benade's claim <br>depends on experiments he chooses to perform: and by failing to perform <br>auditory experiments which would cast doubt on the place theory of hearing, <br>Benade creates the impression that no such doubt exists.  As has been seen <br>throughout this article, there is ample evidence both to support and <br>contradict the place theory of hearing (and to support and contradict the <br>other two models of hearing as well). By omitting mention of any of this <br>additional evidence, Benade creates a profoundly misleading impression in <br>the unwary reader.  The implication of Benade's statement is that all <br>psychoacoustic experiments support the place theory of hearing--entirely <br>untrue, as we have seen.<br>Again: "The situation with tones having harmonic partials is much more <br>straightforward.  We have already learned that pitch-matchings between <br>usccessive and superposed tones are in agreement the tones consist of a <br>few strong partials." [Benade, A., "Fundamentals of Musical Acoustics," <br>1975, pg. 302]<br>The psychoacoustic data do not support this claim.  On the contrary: every <br>psychoacoustic experiment since the 1830s shows a distinct and <br>measurable difference betwen intervals heard as "perfect" when played <br>successively and when played simultaneously, with a strong tendency for <br>successive tones to be played wider than simultaneous tones, and a <br>consistent tendency for both categories of tones to be played wider than <br>small-integer ratios.  Clearly in this case Benade is unware of (or has <br>chosen to ignore) 150 years of  psychouacoustic data.<br>For these reasons Benade's text is unreliable insofar as it bears on <br>psychoacoustics.  Some of Benade's acoustic results remain valid, others <br>have been disproven--particularly Benade's discussion of oscillation <br>patterns in woodwinds and his theory of regimes of oscillation for brass <br>instruments.  On balance the entire text should be ignored in favor of more <br>detailed and far more accurate treatments by Rossing, Fletcher, Askill and <br>Lord Rayleigh.<br>Rossing and Fletcher's "The Physics of Musical Instruments," and Askill's <br>"The Physics of Musical Sound" remain excellent surveys of the state of the <br>art in musical acoustics.  As mentioned, however, little information on <br>psychoacoustics can be gleaned from these texts because psychoacoustics is <br>not their concern.  These texts do not cite appreciable amounts of <br>psychoacoustic data and should not be quoted to support this or that tuning <br>or theory of hearing.<br>"Musical Acoustics: An Introduction," by Donald Hall, 1980, contains an <br>accurate precis of acoustics of piano strings, metallohpohnes and <br>woodwinds, as well as good survey of brass instruments, et alii. Hall is <br>strongly biased toward just intonation and he buries or calls into question <br>psychoacoustic data which do not accord with his prejudices. The acoustic <br>portion of Hall's text is impeccable and worth reading, while the section of <br>the book which bears on tuning systems and psychocoustics is incomplete, <br>outdated, full of errors of omission, and should be ignored.<br>The single best overall survey of psychoacoustic experiments peformed up <br>to the 1960s is Plomp's 1966 text "Experiments In the Tone Sensation." It <br>contains an exhaustive bibliography unmatched anywhere else, and <br>constantly uses extensive direct quotes from the original sources.  Plomp <br>exhibits a constant and strong bias toward the periodicity theory; however, <br>he readily admits his prejudice.<br>He is also conscientious in pointing out behaviours of the human ear which <br>are not well explained.<br>Georg von Bekesy is biased toward the place theory; not surprising, <br>inasmuch as his work put the place (Fourier) theory of hearing on a firm <br>foundation. He cites both the periodicity and place theories as deserving <br>further study, however,  and (like Plomp) also cites results which <br>contradict all three  models of the ear/brain system.  <br>"Experiments in Hearing," New York: Robert E. Krieger, 1960 and republished <br>in 1980, is the single best source of references for the place theory of <br>hearing. <br>Harvey Fletcher's "Speech and Hearing in Communication," 1953, is dated but <br>unlike Backus and Benade it is not rendered worthless by overt bias.  Better <br>texts now exist (Sundberg, Rossing, Pierce, Terhardt & Zick) but the results <br>Fletcher cites tend to be accurate.<br>Diana Deutsch's 1982 "The Psychology of Music"  summarizes key  <br>psychoacoustic results by many of reserachers who made the original <br>findings.   Most of the  contributors are biased toward one or another tuning <br>and the reader must take care to separate experimental results from the <br>conclusions drawn by the various authors.  As has been seen, the conclusions <br>of various researchers are on occasion mere opinions, unsupported by the <br>facts.  The data cited in Deutsch's compilation are extensive and accurate, <br>although the bibliogpraphies for each section prove distinctly selective.<br>"Psychological Acoustics," edited by E.D. Herbert, is a collection of the <br>original papers in psychocoustics from the 1870s to the 1970s. This is the <br>only text which amasses all the original results in the original authors' own <br>words.  Much of the material is now dated, however, and therefore provides <br>an incomplete picture of the ear/brain system.<br>"Auditory Scene Analysis," by Albert S. Bregman, 1990, is a disappointment. <br>It is vague on crucial points and does not cite enough psychoacoustic <br>references.  While Bregman does not exhibit major biases toward any <br>specific tuning system, he appears to gloss over many difficult areas of <br>psychoacoustics; viz., the contradictory evidence for various theories of <br>hearing, unexplained ear/brain phenomena, the role of musical illusions in <br>the auditory path, etc. <br>On the whole Bregman's text is useful as a quick overview but should not be <br>cited as a primary source.<br>The next and last post of this series will discuss the higher-level <br>ineraction of tuning, timbre and structural tonality as considered by<br>Rothenberg, Keislar, Douthett and as examined in the work of Pierce, Risset, Sethares, Carlos, et al.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Wed, 18 Oct 1995 18:02 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id JAA13167; Wed, 18 Oct 1995 09:01:51 -0700<br>Date: Wed, 18 Oct 1995 09:01:51 -0700<br>Message-Id: <Pine.A32.3.91.951011123529.42758B-100000@freenet2.freenet.ufl.edu><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2168 href="#2168">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/19/1995 9:37:24 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Tuning & psychoacoustics - post 24 of 25<br>---<br>Juan Roederer is one of the more influential psychoacoustic researchers.  <br>Like many others in the field, he is biased toward a particular model of<br>the ear.Roederer is strongly biased toward the periodicity theory of hearing.<br>In "Introduction to Physics and Psychophysics of Music," the section on the<br> physical makeup of the ear/brain system shows this bias clearly.<br>In this section there is a great deal of discussion of neurons and <br>neural firing pattern, none at all on the processing of medullar and higher <br>brain areas nor any detailed discussion of von Bekesy's experiments, the <br>physical action of the organ of Corti, etc.  However to his credit Roederer <br>does cite extensively the results of Ward, Corso, Terhardt, Sundberg and <br>Lindqvist for the universal preference of stretched invtervals.  <br>Thus Roederer, like Helmholtz, is a contradictory figure--deliberately <br>overemphaszing some of the evidence, while remaining open-minded about <br>other contradictory results. Fetis (1943), Ellis (1885) Corso (1954), Ward <br>(1970),  Burns (1970), Hood (1975) and Erickson (1983) are all strongly <br>biased toward the ear-as-controlled-by-learned-preference model of <br>hearing.  Terhardt and Ward/Burns tend to bury evidence which does not <br>favor their view by dumping a superflux of additional results on top of the <br>relevant data; this has the same effect as squirelling the relevant data <br>away in a bibliograhy at the back of the article, but it achieves the same <br>end by opposite means. Fetis, Hood, Ellis, tend to stress the  multiplicity of <br>results and musical cultures, rather than concentrating on empirical data <br>from specific experiments.<br>Von Bekesy demonstrates a bias toward the place theory but his bias does <br>not appear to affect his willingness to bring forward contradictory results. <br>In particular, he cites both the periodicity and place theories as worthy of <br>additional investigation in his 1966 article "Hearing Theories and Complex <br>Sounds," Journal of the Acoustic Society of America. <br>Terhardt & Zick, Kameoka & Kuriyaga, Pierce, Mathews, Green, Wessel, <br>Risset  and Sundberg do not exhibit a bias toward any specific theory of <br>hearing.  These authors all cite competing hypotheses and suggest lines of <br>further experimental inquiry into all 3 ear/brain models.<br>Throughout this article the intent has been to present psychoacoustics <br>data as clearly as possible.<br>In many cases this meant extracting experimental results from layers of <br>refutation or from citations buried in bibliographies because this or that <br>psychoacoustician preferred not to bring the inconventient result out into <br>the body of the text, where it might raise embarassing questions.<br>In other cases, viz., Risset or von Bekesy or Pierce, extensive direct quotes <br>of secondary sources were used because these sources offered the most <br>detailed survey of the evidence.<br>Thus the casual reader must be wary of Roederer, Helmholtz, Plomp and <br>other sources widely cited because of the covert (sometimes overt) bias <br>toward this or that tuning or theory or hearing.<br>As mentioned at the outset, acousticians have fared far worse than <br>psychoacoustics researchers in this regard.  <br>Backus (1969), like von Bekesy, is biased toward just intonation--but <br>unlike von Bekesy he neglects to mention any of the psychoacoustic experiments<br> which cast doubt on either just intonation as the ideal tuning<br>system or the place theory as the sole explanation of hearing.  In the <br>chapter ""Intervals, Scales, Tuning, and Temperament," Backus lavishes 3 <br>pages on just intonation and 2 pages on Pythagorean intonation but only 1 <br>page on equal temperament. No tunings are mentioned  other than<br>Pythagorean, meantone, just intonation and equal temperament: there is, <br>for example, no reference to pelog, slendro, the Indian srutis, or any other <br>non-European tuning..<br>Moreover, Backus buries or is not aware of many psychoucstic data which <br>contradict his view of the ear as simple Fourier analyzer.  In part (as <br>mentioned earlier) this is because Backus had the bad luck to publish his <br>book "The Science of Musical Acoustics" just before computers introduced <br>an immense unpheaval into acoustic and auditory research. In part the <br>problem appears to be overt prejudice against acoustic results which do <br>not favor just intonation.  As mentioned earlier, texts by Rossing and Hall <br>supersede the acoustics in Backus and the psychoacoustics  (where Backus <br>refers to them at all) are incorrect as well as out of date. Thus Backus' <br>entire text should be ignored.<br>Benade (1975) cannot excuse his lapses on the basis of bad timing. In the <br>period 1970-1974 much of the data cited throughout this series of posts <br>was already well known; Benade chooses not only to ignore it, but actually <br>to argue with a number of independently-confirmed results, particularly the <br>universal preference for stretched musical intervals and the accumulated <br>evidence for the periodicity theory.   <br>For example: "Experiments by Paul Boomsliter and Warren Creel give us very <br>important information on what a musician actually does about tuning.  My <br>discussion in this capter is strongly influenced by these data, although I do <br>not completely accept their published interpretatiojn.  Paul C. Boomsliter <br>and Warren Creel, "The Long Pattern Hypothesis in harmony and hearing," J. <br>Mus. Theory, Vol. 5, No. 2, 1961, pp. 2-30, and Paul C. Boomsliter and Warren <br>Creel, "Extended Reference: An Unrecognized Dynamic in Melody," J. Mus. <br>Theory, vol. 7, No. 2, 1963: pp. 2-22. " [Benade, A., "Fundamentals of Musical <br>Acoustics, 1975, pg. 303]<br>In short, Benade agrees with Boomsliter and Creel's claim for "small-<br>integer-ratio" detectors in the ear, but rejects the evidence they provide <br>for the periodicity theory of hearing.   Benade's commentary is notable <br>because [1] it is hidden away in a  footnote and [2] it ignores the fact that <br>a wealth of additional evidence supports the periodicity theory of hearing--<br>evidence which cannot be easily explained by the place theory, which Benade <br>espouses.<br>Again: "Everywhere in our experiments we have found indications that our <br>nervous system processes complex sounds coming to it by seeking out <br>whetever subsets of almost harmonically related components it can find." <br>[Benade, A., "Fundamentals of Musical Acoustics," 1975, pg. 68]<br>This statement is as deceptive as it is true.  The accuracy of Benade's claim <br>depends on experiments he chooses to perform: and by failing to perform <br>auditory experiments which would cast doubt on the place theory of hearing, <br>Benade creates the impression that no such doubt exists.  As has been seen <br>throughout this article, there is ample evidence both to support and <br>contradict the place theory of hearing (and to support and contradict the <br>other two models of hearing as well). By omitting mention of any of this <br>additional evidence, Benade creates a profoundly misleading impression in <br>the unwary reader.  The implication of Benade's statement is that all <br>psychoacoustic experiments support the place theory of hearing--entirely <br>untrue, as we have seen.<br>Again: "The situation with tones having harmonic partials is much more <br>straightforward.  We have already learned that pitch-matchings between <br>usccessive and superposed tones are in agreement the tones consist of a <br>few strong partials." [Benade, A., "Fundamentals of Musical Acoustics," <br>1975, pg. 302]<br>The psychoacoustic data do not support this claim.  On the contrary: every <br>psychoacoustic experiment since the 1830s shows a distinct and <br>measurable difference betwen intervals heard as "perfect" when played <br>successively and when played simultaneously, with a strong tendency for <br>successive tones to be played wider than simultaneous tones, and a <br>consistent tendency for both categories of tones to be played wider than <br>small-integer ratios.  Clearly in this case Benade is unware of (or has <br>chosen to ignore) 150 years of  psychouacoustic data.<br>For these reasons Benade's text is unreliable insofar as it bears on <br>psychoacoustics.  Some of Benade's acoustic results remain valid, others <br>have been disproven--particularly Benade's discussion of oscillation <br>patterns in woodwinds and his theory of regimes of oscillation for brass <br>instruments.  On balance the entire text should be ignored in favor of more <br>detailed and far more accurate treatments by Rossing, Fletcher, Askill and <br>Lord Rayleigh.<br>Rossing and Fletcher's "The Physics of Musical Instruments," and Askill's <br>"The Physics of Musical Sound" remain excellent surveys of the state of the <br>art in musical acoustics.  As mentioned, however, little information on <br>psychoacoustics can be gleaned from these texts because psychoacoustics <br>is not their concern.  These texts do not cite appreciable amounts of <br>psychoacoustic data and should not be quoted to support this or that tuning <br>or theory of hearing.<br>"Musical Acoustics: An Introduction," by Donald Hall, 1980, contains an <br>accurate precis of acoustics of piano strings, metallohpohnes and <br>woodwinds, as well as good survey of brass instruments, et alii. Hall is <br>strongly biased toward just intonation and he buries or calls into question <br>psychoacoustic data which do not accord with his prejudices. The acoustic <br>portion of Hall's text is impeccable and worth reading, while the section of <br>the book which bears on tuning systems and psychoacoustics is incomplete, <br>outdated, full of errors of omission, and should be ignored.<br>The single best overall survey of psychoacoustic experiments peformed up <br>to the 1960s is Plomp's 1966 text "Experiments In the Tone Sensation." It <br>contains an exhaustive bibliography unmatched anywhere else, and <br>constantly uses extensive direct quotes from the original sources.  Plomp <br>exhibits a constant and strong bias toward the periodicity theory; however, <br>he readily admits his prejudice.<br>He is also conscientious in pointing out behaviours of the human ear which <br>are not well explained.<br>Georg von Bekesy is biased toward the place theory; not surprising, <br>inasmuch as his work put the place (Fourier) theory of hearing on a firm <br>foundation. He cites both the periodicity and place theories as deserving <br>further study, however,  and (like Plomp) also cites results which <br>contradict all three  models of the ear/brain system.  <br>"Experiments in Hearing," New York: Robert E. Krieger, 1960 and republished <br>in 1980, is the single best source of references for the place theory of <br>hearing. <br>Harvey Fletcher's "Speech and Hearing in Communication," 1953, is dated <br>but unlike Backus and Benade it is not rendered worthless by overt bias.<br>Better texts now exist (Sundberg, Rossing, Pierce, Terhardt & Zick) but the<br> results Fletcher cites tend to be accurate.<br>Diana Deutsch's 1982 "The Psychology of Music"  summarizes key  <br>psychoacoustic results by many of reserachers who made the original <br>findings.   Most of the  contributors are biased toward one or another tuning <br>and the reader must take care to separate experimental results from the <br>conclusions drawn by the various authors.  As has been seen, the <br>conclusions of various researchers are on occasion mere opinions, <br>unsupported by the facts.  The data cited in Deutsch's compilation are <br>extensive and accurate, although the bibliogpraphies for each section prove <br>distinctly selective.<br>"Psychological Acoustics," edited by E.D. Herbert, is a collection of the <br>original papers in psychocoustics from the 1870s to the 1970s. This is the <br>only text which amasses all the original results in the original authors' <br>own words.  Much of the material is now dated, however, and therefore <br>provides an incomplete picture of the ear/brain system.<br>"Auditory Scene Analysis," by Albert S. Bregman, 1990, is a disappointment. <br>It is vague on crucial points and does not cite enough psychoacoustic <br>references.  While Bregman does not exhibit major biases toward any <br>specific tuning system, he appears to gloss over many difficult areas of <br>psychoacoustics; viz., the contradictory evidence for various theories of <br>hearing, unexplained ear/brain phenomena, the role of musical illusions in <br>the auditory path, etc. <br>On the whole Bregman's text is useful as a quick overview but should not be <br>cited as a primary source.<br>The next and last post of this series will discuss the higher-level <br>ineraction of tuning, timbre and structural tonality as considered by<br>Rothenberg, Keislar, Douthett and as examined in the work of Pierce, <br>Risset, Sethares, Carlos, et al.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Thu, 19 Oct 1995 19:38 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id KAA07308; Thu, 19 Oct 1995 10:37:43 -0700<br>Date: Thu, 19 Oct 1995 10:37:43 -0700<br>Message-Id: <009981E2B053B9DF.5D10@ezh.nl><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2175 href="#2175">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/20/1995 7:57:41 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Tuning & psychoacoustics - post 25 of 25<br>---<br>As an empirical science, psychoacoustics is largely concerned with <br>measuring the reactions of the ear/brain system to specific acoustic <br>stimuli. However, human hearing is a hierarchical process made up of many <br>layers of abstraction.  <br>Small acoustic stimuli shade imperceptibly into larger ones, leading <br>inexorably to such large-scale percepts as "key center," "cadence," and<br> "discordance" and "concordance." As Eberhard Zwicker points <br>out, "It is clear that psychoacoustics plays an important role in musical <br>acoustics.  There are many basic aspects of musical sounds that are <br>correlated with the sensations already discussed in psycoacoustics.  <br>Examples may be different pitch qualities of pure tones and complex sounds, <br>perception of duration, loudness and partially-masked loudness, sharpness <br>as a an aspect of timbre, perception of sound impulses as events within the <br>temporal patterns leading to rhythm, roughness, and the equivalence of <br>sensational intervals.  For this reason it can be stated that most of this <br>book's contents are also of interest in musical acoustics. At this point we <br>can concentrate on two aspects that have not been discussed so far: musical <br>consonance and the Gestalt principle." [Zwicker, E. and H. Fastl, <br>Psychoacoustics: Facts and Models, 1990, pg. 312]<br>Zwicker characterizes the hierarchical perception of musical tones by <br>drawing a distinction between sensory consonance (perceived roughness, <br>sharpness, and noisiness of the tone) and harmony, (perceived tonal <br>affinity, tolerability, and root relationship of tones or sequences of tones <br>to a scale).  <br>So doing, he posits that both modes of perception are hierarchically involved<br> in the sensation of musical consonance.<br>Both experience and experiment tell us that the process of listening to <br>music involves levels of neural organization above the purely physical <br>acoustic operation of the inner ear.  While the point of maximal stimulation <br>on the basilar membrane indicates a simple mechanical Fourier analysis of <br>sounds entering the ear, the firing pattern of neural fibers in the auditory <br>nerve encodes pitch and spectral information in the nerve system in a <br>complex way.<br>The path between primary auditory nerve and cerebral cortex is not a simple <br>one.  Many feedback loops control the processing of auditory information, <br>and there are many opportunities for higher brain centers to alter the raw <br>input travelling up the auditory nerve--and vice versa.<br>The anatomy of the pathway between the auditiory nerve and   the cerebral <br>cortex is complex: the cells of the primary neurons (that is, those in the <br>auditory nerve) are located within the modiolus of the cochlea; these <br>primary nurons terminate in the cochlear nucleus, a mass of gray matter <br>located in the dorsal and lateral portion of the medulla oblongata. Here the <br>physical nerve connection breaks. From this point there is a synpatic <br>connection (mediated by neurotransmitters) to the neurons of the inferior <br>colliculus.  After another synpatic gap in the neural pathway, the third-<br>order neurons converge on the medial geniculate body, the final relay station<br> on the auditory path to the cerebral cortex. It's worth nothing that the <br>medial geniculate body not only collates fibers from the audtiory nerve, but <br>also from other sensory systems and from the cerebral cortex as well. Thus <br>the geniculate body serves not as a passive relay station so much as an <br>active filtering and integrating locus.<br>>From the geniculate body, the fourth-order auditory neurons connect with <br>the cerebral conrtex by way of a thin sheet of radiating nerve fibers.  These <br>radiations include corticofugal fibers running from the cortex back to the <br>medial geniculate body.<br>Thus the auditory neural pathway contains a complex feedback loop, <br>controlled by several sets of higher brain loci, running between the auditory <br>nerve and the cerebral cortex.  <br>Most of the fourth-order neurons enter a small region ofthe posterial half <br>of the horizontal wall of the Sylvian fissure, which acts as a focal zone for <br>the entire auditory cortex. The complexity of the auditory region of the <br>Sylvian fissure is daunting: each cochlear fiber makes connections with <br>thousands of other neurons grouped in at least thirteen regions, and <br>populated by many different types of neurons. To make the process even <br>more complex, not all of these neurons respond identically. Some produce <br>strong signals when presented with tones in a <br>particular frequency range but do not respond to tones in other frequency <br>ranges. A small fraction of neurons emit strong signals when two different <br>frequencies are sounded together, but these same neurons produce little or <br>no response when either frequency sounds alone. Some neurons are most <br>strongly stimulated by sounds at specific amplitudes: sounds outside this <br>narrow amplitude window cause no resopnse from suchneurons. For yet other<br> auditory nerve fibers, the higher the sound's amplitude, the stronger the <br>response, until a satuation point is reached. Some neurons respond best toe <br>amplitude-moedulated tones, others to frequency-modulated tones. Some <br>neurons respond with paritcular vehemence to sounds coming from a <br>particular region of space, and some neurons respond best to sounds that <br>are moving in space.<br>Because these cortical loci consist of neural pathways, they are formed by <br>learned response and can be changed.  Thus, the impact of culture and <br>experience on musical perception is at least as great as the physical <br>sensory correlates of musical tone--if not greater.<br>"I once attended...a concert in Bangkok that was totally mystifying. I could <br>see that the audience was utterly enraptured, swooning at moments of <br>apparently overwhelming emotional beauty that made no impression on me <br>whatsoever; not only that, I couldn't distinguish them from any other <br>moments in the piece." [Eno, Brian, "Resonant Complexity," Whole Earth <br>Review, May 1995, pg. 42]<br>This points to a important caveat.  While the results adduced so far provide <br>evidence for this or that musical tuning system ont he basis of sensory <br>consonance, psychoacoustics cannot describe or validate the higher levels <br>of musical organization implicit in a tuning system.<br>Thus the internal structure of a tuning is different from the sensory <br>consonance produced by intervals within that tuning.  For example: Risset's, <br>Pierce's and Sethares' timbral mapping procedure, following the <br>implications of research by Plomp and Levelt and Kameoka and Kuriyagawa, <br>allow a composer to control the level of *sensory consonance * in a given <br>tuning, but mapping the component partials of a sound into a given <br>maximally consonant set for a specific scale does *not * change the <br>inherent tonality of the scale, its Rothenberg propriety, the Barlow <br>harmonicity or the Wilson efficiency of the scale.<br>In short, by changing timbre, note duration, and compositional style one can <br>change the surface affect of music produced in a given tuning: but the <br>deeper structural elements of the tuning remain invariant. <br>Ivor Darreg described one of the deeper structural invariants in a given <br>tuning as its "mood:" "In my opinion, the striking and characteristic moods <br>of many tuning-systems will become the most powerful and compelling <br>reason for exploring beyond 12-tone equal temperament. It is necessary to <br>have more than one non-twelve-tone system before these moods can be <br>heard and their significance appreciated." [Darreg, Ivor, "Xenharmonic <br>Bulletin No. 5, 1975, pg. 1]<br>David Rothenberg proposed that the Rothenberg propriety of a scale <br>explains some aspects of the scale's deep structure; Clouth and Douthett <br>duplicated some of this work in their article "On Well-Formed Scales."  <br>John Chalmers has speculated that Rothenberg propriety explains the sense <br>of tension in such tunings as Ptolemy's intense diatonic.<br>In addition to the "mood" or overall "sound" of a given tuning, Darreg and <br>McLaren (1991) pointed out that each tuning exhibits some degree of <br>inherent bias toward melody or harmony.  The Pythagorean intonation and <br>13-tone equal temperament, for example, are both strongly biased toward <br>melody, while 31-tone equal temperament and 13-limit just intonation are <br>strongly biased toward harmony.<br>Douglas Keislar made this same point in his 1992 doctoral thesis.  In it, <br>Keislar describes research which demonstrates that altering the surface <br>characteristics of the music--timbre, tempo, spatialization--does not <br>change the deeper structural characteristics of the tuning. Thus, while <br>mapped overtones will make a comopsition in 13-tone equal temperament <br>sound more acoustically smooth, it does not change the essentially atonal <br>character of the 13-tone scale, nor does it materially affect the scale <br>"mood." Similarly, changing the timbres of a composition in Ptolemy's <br>intense diatonic tuning will alter the degree of sensory roughness or <br>smoothness; adding reverberation will mask to greater or lesser degree <br>some of the overall "sound" of the composition.  But the sense of aesthetic <br>tension created by scale intervals which are, in Rothenberg's usage, <br>improper, will remain unchanged.<br>Thus the implications for tuning suggested by psychoacoustic research <br>must be viewed as separate from larger musical and perceptual questions. <br>Because current psychoacoustic experiments focus on questions of sensory <br>perception, there remains a dichotomy between what Easley Blackwood has <br>called "concordance and discordance" and sensory consonance and <br>dissonance. In fact sensory consonance is a misnomer: the effects are more <br>accurately described as sensations of auditory roughness or smoothness.<br>Depending on the tuning or the composition, intervals which are perceived <br>as rough may prove concordant, while intervals which prdouce the auditory <br>sensation of smoothness may strike the listener as discordant--that is, out <br>of place musically.  In Western music, the best example of this phenomenon <br>is the perfect fourth, which sounds acoutically smoother than the major <br>third but which by itself generally constitutes an unstable and  musically <br>discordant interval.<br>In Balinese and Javanese music, the best example is the stretched 1215-<br>cent octave, which sounds acoustically rough but which produces as sense <br>of musical concordance when performed by a gamelan.<br>The most striking example in my own experience was a 1990 concert by <br>the Women's National Chorus of Bulgaria. One of the duets (a folk song <br>from the Thracian plains) ended on a large major just second (9/8).  The <br>Western audience sat without moving forwhat seemed a long time: only <br>when the  singers bowed did the audience realize the duet was over, and <br> applaud.  In  this case the contradiction between learned perceptions of <br>concordance and cadence, and the sensory perception of roughness in the <br>cadential intervals, prevented the audience from correctly perceiving the <br>cadence. <br>It is important not to confuse sensory roughness or smoothness, as <br>measured by psychoacoustical experiments, with higher-level perceptions <br>of musical consonance and dissonance. Many advocates of just intonation <br>have baselessly conflated the two categories, while advocates of Fetis' <br>model (viz., all auditory responses are predominately learned responses) <br>excessively emphasize the abstract levels of hierarchical auditory <br>perception while unjustifiably discounting the purely physical processes at <br>work in the human ear/brain system--in particular the frequency-analysis <br>operations of the basilar membrane and the periodicity-extraction <br>mechanism of the neurons in the auditory nerve. <br>Ultimately, what Zwicker calls Gestalt musical perception is mediated not <br>only by the physics and acoustics of the inner ear, but also by primary, <br>secondary, third-order and fourth-order neurons, a variety of different <br>brain locations, and the operant conditioning imposed by experience, culture <br>and  musical tradition.  The conclusions of this series of posts must be <br>taken in that context, and understood in that larger framework.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Sat, 21 Oct 1995 01:16 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id QAA08509; Fri, 20 Oct 1995 16:16:08 -0700<br>Date: Fri, 20 Oct 1995 16:16:08 -0700<br>Message-Id: <Pine.3.89.9510201934.A16496-0100000@email.ir.miami.edu><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2179 href="#2179">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/21/1995 7:38:10 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: large numbers of tones/oct on<br>   sample-playback MIDI modules<br>---<br>It came to my attention recently that<br>a professor at the University of <br>Mississippi teaches a college course<br>about Elvis' Hawaiian films. <br>This was a relief to me.  It proved that<br>no matter how bizarre and nonsensical<br>the posts of certain folks on this forum,<br>they're actually quite rational compared <br>to the *truly*  looney denizens of the <br>so-called "real world."<br>Speaking of the real world, the yakademics<br>have now returned from sabbatical and are<br>no longer giving "special tutoring" to those<br>special coeds.<br>Since this forum is still largely an academic reserve,<br>it empties out during the summer, leaving only<br>the lone desultory student or two burned out <br>by a McJob at 2 am but not yet ready to lobotomize<br>hi/rself with The Weather Channel.<br>Thus there was little point in my posting anything<br>during the summer months.  <br>Now that the rich white PhDs and the dirt-poor<br>overworked students are both back from summer<br>hiatus, there's an audience capable of hoisting<br>torches & pitchforks and screaming "Somebody get a rope!"<br>In short, an audience fully up to the high standards<br>of academic open-mindedness and insight we've<br>all come to respect so deeply.<br>Various claims to the contrary, it is in fact possible<br>to use sample-playback MIDI modules with only 1 pitch <br>table for either equal-tempered multiple divisions of the <br>octave or high-limit just intonation *without* the dreaded<br>"chipmunking" effect.<br>As you'll recall, "chipmunking" occurs when a sample<br>recorded at one pitch is played back at a drastically<br>different pitch.  At first glance, you'd think this<br>unavoidable when dealing, say, with one of Erv Wilson's<br>70-pitch hebdomekontanies.<br>Chipmunking typically occurs on the Proteus modules<br>the VFX, and all the other xied-wavetable synths.<br>Whence arises chipmunking?   <br>Consider:  starting with some 1/1 pitch--say, A 440 Hz--<br>the pitch table of the MIDI module will contain a progressively <br>lower playback pitch than the frequency at which the sound was <br>originally recorded.<br>Take the following Wilson 70-note [1,17,41,67,97,127,157,191]<br>hebdomekontany (4 out of 8 CPS):<br>Scale degree 1: C + 0.000 cents<br>Scale degree 2: C + 14.9691 cents<br>Scale degree 3: C + 28.5475 cents<br>Scale degree 4: C + 32.3370 cents<br>Scale degree 5: C + 57.9854 cents<br>Scale degree 6: C# + 7.8545 cents<br>Scale degree 7: C# + 33.5029 cents<br>Scale degree 8: C# + 45.3184 cents<br>Scale degree 9: C# + 55.7040 cents<br>Scale degree 10: C# + 70.9667 cents<br>Scale degree 11: C# + 72.2992 cents<br>Scale degree 12: C# + 97.9476 cents<br>Scale degree 13: D + 35.0111 cents<br>Scale degree 14: D + 48.5894 cents<br>Scale degree 15: D + 50.2738 cents<br>Scale degree 16: D + 60.6594 cents<br>Scale degree 17: D + 63.8521 cents<br>Scale degree 18: D + 74.2378 cents<br>Scale degree 19: D + 77.2546 cents<br>Scale degree 20: D + 90.8330 cents<br>Scale degree 21: D# + 53.5448 cents<br>Scale degree 22: D# + 82.0924 cents<br>Scale degree 23: E + 19.5562 cents<br>Scale degree 24: E + 46.5370 cents<br>Scale degree 25: E + 95.0737 cents<br>Scale degree 26: E + 98.8633 cents<br>Scale degree 27: F + 12.4416 cents<br>Scale degree 28: F + 22.0545 cents<br>Scale degree 29: F + 24.5116 cents<br>Scale degree 30: F + 25.8441 cents<br>Scale degree 31: F + 38.0900 cents<br>Scale degree 32: F + 39.4224 cents<br>Scale degree 33: F + 51.4924 cents<br>Scale degree 34: F + 65.0708 cents<br>Scale degree 35: F + 74.3808 cents<br>Scale degree 36: F + 87.9591 cents<br>Scale degree 37: F# + 0.0291 cents<br>Scale degree 38: F# + 1.3616 cents<br>Scale degree 39: F# + 13.6075 cents<br>Scale degree 40: F# + 14.9400 cents<br>Scale degree 41: F# + 17.3970 cents<br>Scale degree 42: F# + 27.0100 cents<br>Scale degree 43: F# + 40.5883 cents<br>Scale degree 44: F# + 44.3779 cents<br>Scale degree 45: F# + 92.9145 cents<br>Scale degree 46: G + 19.8954 cents<br>Scale degree 47: G + 57.3592 cents<br>Scale degree 48: G + 85.9067 cents<br>Scale degree 49: G# + 48.6186 cents<br>Scale degree 50: G# + 62.1970 cents<br>Scale degree 51: G# + 65.2138 cents<br>Scale degree 52: G# + 75.5994 cents<br>Scale degree 53: G# + 78.7921 cents<br>Scale degree 54: G# + 89.1778 cents<br>Scale degree 55: G# + 90.8621 cents<br>Scale degree 56: A + 4.4405 cents<br>Scale degree 57: A + 41.5040 cents<br>Scale degree 58: A + 67.1524 cents<br>Scale degree 59: A + 68.4848 cents<br>Scale degree 60: A + 83.7475 cents<br>Scale degree 61: A + 94.1332 cents<br>Scale degree 62: A# + 5.9487 cents<br>Scale degree 63: A# + 31.5970 cents<br>Scale degree 64: A# + 81.4662 cents<br>Scale degree 65: B + 7.1145 cents<br>Scale degree 66: B + 10.9041 cents<br>Scale degree 67: B + 24.4824 cents<br>Scale degree 68: B + 39.4516 cents<br>Scale degree 69: B + 53.0300 cents<br>Scale degree 70: B + 86.4216 cents<br>(Those of you unfamiliar with a Wilson CPS<br>or the hebdomekontany will want to review<br>topic 2 of Tuning Digest 17 from 17 February<br>1994, also topics 1 and 2 of Tuning Digest<br>30 from 3 March 1994.  The latter, by Paul<br>Rapoport, comprise perhaps the finest into<br>to the subject yet written.)<br>As you can see, entering the above 70-note<br>just array into an EMu proteus synth, <br> starting with 1/1 = 440.0 Hz + 0 cents,<br>produces a progressive transposition of sounded<br>pitch vs. originally-sampled pitch as the<br>scale rises.  By the time we reach pitch 70,<br>the synth is playing a note at 440 Hz + 1186.4 cents<br>which was originally sampled playing at <br>440 Hz + 7000 cents!    In other words note<br>70 of the just array is being played almost 5.5 <br>octaves *lower* than its original pitch.  This<br>produces wildly bizarre sonic artifacts--growls,<br>wah-wah-wah effects, low- or high-pitched<br>background noise, etc., collectively known<br>as "chipmunking."   <br>Is there any way to avoid these weird sonic artifacts<br>when playing either just arrays with a lot of different<br>notes, or small just arrays which modulate extensively,<br>or equal temperaments with lots of notes per octave?<br>Yes, there is.<br>The solution is twofold:<br>[1] Use a SMPTE-locked MIDI interface with a multitrack<br>tape deck *OR* any ordinary MIDI interface with a<br>hard disk recorder; and...<br>[2] Write a program which re-maps the MIDI notes in<br>your composition to different MIDI channels depending<br>on their MIDI note number.<br>Using this combination, you can now lay down just arrays<br>or equal tempered scales up to 127 notes per octave without<br>any significant chipmunking.<br>To see how this works, let's take a concrete example.  First<br>we write a program--perhaps using MAX to re-map the notes<br>in real time, or using the Cal portion of Cakewalk on IBM<br>machines, or even using the MIDI file routines available <br>for $40.00 from Sound Quest to write your own C or BASIC<br>or PASCAL program--that reads in the MIDI notes of our<br>composition.  Note X is remapped as note X on channel 1,<br>note X +1 is remapped as note X on channel 2, note<br>X + 3 is remapped as note X on channel 3, note X + 4 is<br>remapped as note X on channel 4, note X + 5 is remapped as<br>note X on channel 5, and note X + 6 is remapped as note<br>X in channel 6.  Then note X + 7 is remapped as note X+1 on<br>channel 1, note x + 8 is remapped as note X + 1 on channel 2...<br>and so on.  You get the idea. <br>Next, make up 6 different tuning tables for, say, <br>your Proteus II module.  All 6 tuning tables use 12<br>notes per octave out of the hebdomekontany.  Tuning<br>table 1, for instance, would be:<br>Scale degree 1: C + 0.0000 cents<br>Scale degree 2: C# + 7.8545 cents<br>Scale degree 3: C# + 97.9467 cents<br>Scale degree 4: D + 90.8330 cents<br>Scale degree 5: D# + 82.0924 cents<br>Scale degree 6: E + 98.8633 cents<br>Scale degree 7: F# + 0.0291 cents<br>Scale degree 8: F# + 92.9145 cents<br>Scale degree 9: G + 85.9067 cents<br>Scale degree 10: G# + 48.6187 cents<br>Scale degree 11: A + 4.4405 cents<br>Scale degree 12: A# + 5.9487 cents<br>The second tuning table would be:<br>Scale degree 1: C + 14.9691 cents<br>Scale degree 2: C# + 33.5029 cents<br>Scale degree 3: D + 35.0111 cents<br>Scale degree 4: D# + 53.5448 cents<br>Scale degree 5: E + 46.5370 cents<br>Scale degree 6: F + 12.4416 cents<br>Scale degree 7: F# + 1.3616 cents<br>Scale degree 8: G + 19.8954 cents<br>Scale degree 9: G# + 62.1970 cents<br>Scale degree 10: A + 41.5040 cents<br>Scale degree 11: A# 31.5970 cents<br>Scale degree 12: B + 10.9041 cents<br>and so on.<br>Now copy your remapped MIDI file to 5 different<br>files with similar names; then delete<br>all notes on channels 2-6 for file 1,<br>delete all notes on channels 1 & 3-6 for<br>file 2, etc.   If you're dealing with an<br>orchestration using multiple MIDI files<br>you may want to write into a program a<br>routine which automatically deletes all<br>but the 12 transposed notes/oct in each of<br>the channels you need for that MIDI file.<br>Now lock your sequencer via SMPTE to<br>your multitrack tape recorder and lay<br>down channel 1 using pitch table 1.<br>Run the tape recorder back and<br>lay down channel 2 using pitch table 2,<br>and so on until you've laid down all 6<br>channels using all 6 pitch tables.<br>If you don't have an Alesis ADAT or<br>a Tascam DA-88, don't despair--my<br>experience shows that for compositions<br>of less than 15 minutes or so you can<br>lock WITHOUT SMPTE to a hard disk<br>recorder and still maintain perfect sync<br>with prerecorded parts, provided your<br>hard disk recorder has a "trigger playback<br>on MIDI" feature (most do).   Since hard<br>disk recorders boast unmeasurably low<br>wow and flutter, you can actually lock multiple<br>recorded parts in sync *without* using SMPTE<br>sync.  I've done this with 3 different stereo<br>tracks, equivalent to 6 mono tracks, so there's<br>absolutely no reason why you can't do it with as<br>many tracks as your hard disk recorder will allow.<br>Of course the different parts will eventually <br>drift apart if they last long enough...20, 30,<br>40 minutes or so.  But for pieces less than about<br>15 minutes my experience is that the parts<br>remain in perfect sync.  And since hard disk<br>recorders are getting dirt cheap, this is good<br>news for all of us.<br>As you can see, this process is laborious--but it<br>produces excellent sonic results.  The worst<br>chipmunking you'll get with a 70-note hebdomekontany<br>is a note transposed about 85 cents up or down from<br>the pitch it was originally recorded at: this is<br>a stretch or compression or less than 5%, and produces<br>virtually no sonic artifacts.  And 70 notes is an acid<br>test!  Very few just arrays use that many notes!<br>One further refinement you might want to consider<br>is to compose a piece with lots of notes per octave<br>using a "sketch" set of timbres generated by a synth<br>which doesn't suffer from chipmunking--say, a<br>TX81Z or a VL-1.  Once you've got the skeleton of<br>the composition laid down using these approximate<br>timbres, orchestrate the final version with a box<br>like one of the E-Mu Protei or even one of the Korg<br>synths limited to retuning within 12 tones per octave.<br>Then lay down multiple tracks with the final timbres<br>for a full version of the composition. <br>Although it's more trouble than merely entering a simple<br>pitch table and playing all the MIDI notes with a single<br>sequencer track, this method has the advantage of<br>allowing you to make full use of the high-quality samples<br>available in contemporary MIDI boxes.  And as we all<br>know, synthesizer technology lurched to a grinding halt<br>sometime around 1989 and the synthesizer industry<br>decided to commit financial suicide. As a result virtually all<br>modern synths are nothing but sample-playback boxes.<br>Thus the method described here is the only really<br>effective way to deal with modern so-called synths<br>(which aren't really synthesizers any more, they're all<br>just fancy effects boxes with prerecorded sounds burned<br>into ROM) when using large number of tones (just or equal <br>tempered) per octave.<br>JI composers, take special note--by using the above process<br>with one channel for each key into which you want to module,<br>you can modulate to a virtually unlimited number of different<br>just 1/1s by laying down different tracks with SMPTE sync<br>or via hard disk recorder playback-on-MIDI-note sync.  (Number<br>of keys is virtually unlimited because remember--there's no<br>limit to the number of different pitch tables you can load<br>into your synth *sequentially.* Using this method you could<br>modulate into 300 successive 1/1s if you were so inclined!) This<br>completely obviates the purported "difficulty" of modulation<br>when using just intonation, and renders utterly moot all the<br>various "practical" objections to just intonation raised <br>throughout the 19th and early 20th century on the basis of the<br>"impossibility" of modulating between just key centers.<br>Best of all, as hard disk recorders drop in price and hard disks<br>grow bigger and cheaper, you'll have more and more capability<br>on hand as time goes on.  God I love the 90s!<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Sat, 21 Oct 1995 19:32 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id KAA17301; Sat, 21 Oct 1995 10:32:29 -0700<br>Date: Sat, 21 Oct 1995 10:32:29 -0700<br>Message-Id: <199510211731.KAA17136@eartha.mills.edu><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2182 href="#2182">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/22/1995 7:42:36 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: custom MIDI controller<br>---<br>One of the biggest stumbling blocks in<br>the path of the microtonal revolution is<br>the lack of a generalized MIDI keyboard.<br>If MIDI users could buy a keyboard like<br>the one on the Secor generalized <br>Scalatron, microtonality would take<br>an enormous step forward.  Suddenly,<br>it would become simple and easy to perform<br>keyboard music in 31, 19, Partch 43, Wilson<br>41, Secor 17, or Helmholtz 24-note tunings.<br>Well, guess what?<br>Now you can build your own generalized MIDI<br>keyboard--and for less than $275!<br>PAVO, 10. S. Front St., Philadelphia PA 19106,<br>makes a black box to which you can hook 64<br>momentary normally-open switches and get<br>MIDI notes out.<br>What kind of switches can you use?<br>The sky's the limit: light switches, doorbell<br>switches, reed switches, infrared or cadmium<br>selenide photocells, contact switches, touch<br>switches, proximity switches, ultrasound-<br>activated switches, moisture-activated<br>switches, odor-activated switches...you name it.<br>Among the ideas PAVO suggests for novel<br>MIDI controllers: [1] sewing reed switches into<br>your clothing and generating a MIDI composition<br>by your movements; [2] attaching multiple<br>photoelectric switches to various parts of a<br>room and generating MIDI notes by shining a<br>laser; [3] building your own custom MIDI <br>percussion controller or keyboard.<br>Of particular interest for folks on this forum<br>is [3].<br>The PAVO MIDI computer (a black box with a<br>64-lead ribbon cable coming out of it and MIDI<br>IN and MIDI OUT connectors) comes in kit form.<br>The cost is $265 U.S. and with that you get the<br>PROM of your choice.  (PAVO black boxes can do<br>a *lot* of things; the 64-note MIDI controller PROM<br>is only *one* of many PROMS they offer.  You can,<br>for example, turn the black box into a "translating<br>randomizer" merely by substituting another PROM<br>into the ZIF socket inside the black box.  In this<br>mode the PAVO black box selectively translates one <br>type of MIDI message into any other type of MIDI message,<br>randomizing them within user-selected parameters<br>entered into the front panel.  However this post<br>concerns only the 64-note custom MIDI controller<br>EPROM, so if you want more info on the many *other*<br>exotic applications of their MIDI computer black<br>box, write PAVO directly. That address again:<br>PAVO, 10. S. Front St., Philadelphia PA 19106)<br>The limitations of the PAVO box, are to be fair,<br>numerous: first, you're limited to 64 input switches.<br>(If you need a 128-key controller, buy two black<br>boxes and hook their outputs through a MIDI merge<br>box; ditto 192-key controller, etc.  At $250 per<br>black box, this isn't all that expensive--especially<br>compared to the *outrageous* highway-robbery cost<br>of $2000 for a 36-pad MIDI marimba bought <br>commerically!)<br>Second, the switches can't be more than 25 feet from<br>the PAVO black box (and should probably be a lot<br>closer for reliable operation).  Most limiting of all,<br>the black box does not accept velocity information<br>from the switches.  Thus you must set the velocity<br>of the MIDI notes either via a pot on the front panel<br>of the black box, or by means of a MIDI controller<br>foot pedal hooked into the data stream with a MIDI<br>merge box.  (It's possible that you might be able<br>to wire an 8-bit A/D converter to the frame of the<br>MIDI controller and feed it into the front pot of the<br>PAVO black box, but since it's not part of the original<br>design...you'd have to do it at your own risk.)<br>All in all, these limitations are minor compared to<br>the advantages offered by this widget.  For the first<br>time, you can build your own custom MIDI percussion<br>setup.  One of the first and most obvious applications<br>that comes to mind would be to set up a set of plywood<br>or pine squares in the form of a 64-note Bosanquet<br>keyboard and attach the squares to reed or touch<br>switches, then solder the switches to the ribbon<br>cable leads.  Plus in the black box, turn it on, and presto!<br>You've got your own Bosqnquet-style percussion controller.<br>This would be ideal especially for those of us you yearn to<br>work in large JI arrays (say, Wilson 31 or 41 or 43, not<br>to mention D'Alessandro or the hebdomekontany) with<br>a percussion-type controller.  <br>By fitting the switch array with a DB-25 connector, one<br>could easily disconnect one percussion controller and <br>reconnect another one, thus allowing a performer to move<br>within a less than minute from, say, Partch 43 to 53-tone<br>equal temperament.  Since switches are cheap (check the<br>latest JDR MICRODEVICES catalog) and plywood or pine<br>even cheaper, it should be a breeze to build half a dozen<br>different percussion arrays, each suited to a given tuning.<br>(Remember that since we're dealing with MIDI, one need<br>only saw the pieces of wood and glue switches to 'em--<br>all tuning's done in the MIDI synth.)<br>Neoprene coverings on the plywood or wooden percussion<br>pads would help give the percussion pads a more lifelike<br>"feel," and again it's cheap and easy.<br>Building the PAVO black box sounds pretty simple.<br>They offer a videotape showing the complete process (for<br>those of you who haven't dealt with a soldering iron and<br>a volftmeter before), as well as a diagnostic EPROM. Plug<br>in the EPROM and it'll automatically check your solder<br>connections, chips, glue logic, and run a test on the MIDI<br>ins and outs as well as the 64-lead ribbon connector (via<br>loop-through).<br>PAVO claims that assembly of one of their black boxes<br>takes 5-7 hours, and given the apparent simplicity of<br>the circuitry inside their box, that sounds reasonable.<br>It's basically nothing but an antique 6809 8-bit<br>microprocessor with an EPROM, a kilobyte or so of<br>static RAM and some glue logic and hex buffers to<br>keep the inputs and outputs from fricasseeing if you<br>accidentally hook a MIDI out to the black box's MIDI OUT.<br>All told, this is spectacular development for  those of us<br>who burn with the bestial desire to build Bosanquet<br>MIDI controllers!<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Sun, 22 Oct 1995 23:59 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id OAA00139; Sun, 22 Oct 1995 14:58:49 -0700<br>Date: Sun, 22 Oct 1995 14:58:49 -0700<br>Message-Id: <951022215607_71670.2576_HHB46-1@CompuServe.COM><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2187 href="#2187">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/23/1995 7:54:49 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: xenharmonic notation in Finale<br>---<br>The estimable Paul Rapoport has created a<br>microtonal music font for use with Finale.<br>This was a significant advance, hampered by<br>Finale's generally 12-centric mode of operation.<br>Well, times have changed.  The latest version<br>of Finale--rev 3.5--just arrived, and it has<br>features to delight the heart of the most<br>hardened microtonalist.<br>Most notably, the NONSTANDARD KEY SIGNATURE<br>DIALOGUE BOX now contains an enhanced KEY STEP<br>MAP DIALOG BOX.  What, pray tell, does this signify?<br>Buckle up, chromedomes--time for a trip into<br>the bowel of Finale's infinite set of dialog boxes...<br>First, click on the KEY SIGNATURE TOOL.  (It's easy<br>to tell; this is the icon that looks like a rodent<br>having sex with a VCR.  As opposed to the icon<br>that looks like a cyclotron swallowing a squid--<br>that's the Speedy Note Entry tool.)<br>When the Key Signature dialog box appears,<br>choose NONSTANDARD from the dop-down menu.<br>Click NEXT twice, then click the KeyMap icon.<br>Okay.<br>Now you're into a dialog box which allows you to<br>define a microtonal key signature.<br>First, you need to decide whether you want what<br>Finale mystifyingly calls a "Linear Key Format"<br>or "Nonlinear Key Signature."  At this point permit<br>me to quote from the Finale Reference (Vol. 3,<br>ver. 3.0, which also applies to Finale ver. 3.5): <br>"In this dialog box, you specify how many notes<br>will constitute an "octave" (it's twelve notes in the<br>traditional system).  You also sepcify how many of<br>these are "diatonic" (seven in the traditional system),<br>and where the "chromatic" steps occur in the scale. (In<br>the traditional system, the chromatic steps occur between<br>every pair of diatonic steps except steps 3 and 4 and steps<br>7 and 8.<br>"If you're creating a linear key format, note that your work <br>in the Key Step Map dialog box must follow certain rules in <br>order to meep the definition of a lienar key format.  The<br>total diatonic steps, for example, must be an odd number.<br>Furthermore, the bottom and top halves of the scale must<br>contain the identical arrangement of diatonic and <br>chromatic steps.  These principles ensure that there is a<br>progression of keys, although it may not be a circle of fifths<br>as there is in traditional key structures. (Finale will<br>correctly interpret, transcribe, and play back music in<br>a format that hasn't been constructed accordin go these<br>rules.  Theformat, however, won't be technically and<br>musically correct; you may get unexpected results when<br>you transpose--or add chord symbols to--music in such a<br>key system).<br>"You may wonder what the relationship is between your MIDI<br>keyboard and the unusual key maps you can construct in this<br>dialog box.  The principle is simple: each key on your keyboard<br>*always* corresponds to a note in your key map.  If you've<br>established a quarter-tone key system, for example, you'd<br>have to drastically alter your playing style in order to input<br>a simple C scale, because Finale now thinks that the first<br>four notes on your keyboard are C, C-quarter-sharp, C-sharp, <br>and C-three-quarter-sharp.  You'd have to play C, E and G#<br>"keys" on your keyboard to *notate* the C, D and E on the<br>screen."<br>Well, there it is, kiddies.  Just what we've needed lo these<br>many years.  With this upgrade, Finale appears to support <br>most of what's required for notating rationally a wild<br>microtonal piece performed on the MIDI keyboard.<br>The dialog box labelled KEY STEP MAP is fairly straightforward.<br>It includes a control for TOTAL STEPS (the total number of<br>steps in the scale) and DIATONIC STEPS.  The remainder left<br>over by subtracting diatonic steps from total steps is,<br>obviously enough, the number of chromatic steps. <br>This begs the question of what to do in a JI scale when<br>faced with, say, the 11/9, or the 11/8...are these<br>diatonic or chromatic steps?  The question doesn't<br>appear to have much meaning to me, but those of you<br>who've delved into Finale for the purposes of notating<br>high-limit JI may have a different opinion.  Be interested<br>to hear from those of you who've done this!<br>By creating a nonlinear key signature you can generate<br>a notation for a tuning with no circle of fifths, and<br>no sequence of keys.  This is useful both for equal temperaments<br>with no fifths (6,8,9,11,13,16,18,23 equal tones per octave)<br>and for non-just non-equal-tempered scales like the free-free<br>metal bar scale, scales formed from ratios of infinite continued<br>fractions, etc.<br>The ticket to getting Paul Rapoport's nonstandard accidentals<br>to appear next to the correct notes is the ATTRIBUTE dialog<br>box.  <br>To quote the Finale manual again (Volume 3, page 300):<br>"For any such key system you create, you can specify a number of<br>special attributes, such as the symbols you want to use in the key<br>signature (instead of the b and # symbols).<br>*Harmonic Reference.  This number identifies the note that all other <br>dialog boxes in Finale's key system will consider to be the C, or<br>fundamental root tone.  Enter zero for C, 1 for D, 2 for E, and so on.<br>There's little ever to change the default setting in this box (zero,<br>or C.). [Note: Unless you're notating Harry Partch's music, with his<br>1/1 of G!]<br>*Middle Key Number.  This number specific the MIDI key number<br>that corresponds to the Harmonic Reference Number. <br>(..)  You can use this parameter to good advantage if you want<br>to transform your synthesizer into a transposing synthesizer (as <br>far as Finale is concerned). For example, if you set the middle<br>Key Number to 48 (C below middlel C), Finale will interpret<br>every note you play as a note an octave higher (...)<br>*Symbol Font.  This number corresonds to the font from which<br>the symbols you want to use for accidentals are drawn.  To <br>choose a new font, click Symbol Font; Finale displays'<br>the Font dialog box, form which you can choose the new font.<br>*Symbol List ID. This number identifies a symbol list you've created--an <br>array of accidental AMounts (where one sharp has an Amount of 1,<br>one flat has an Amount of -1, and so on) and corresonding chracters you<br>want to appear in the key signature to represent them.  To create a <br>symbol list, click Symbol List ID; the Symbol List gialog box appears,<br>in which you can define the character you want to appear in <br>place of the usual sharp, flat, double-sharp, or other standard symbol.<br>(See SYMBOL LIST DIALOG BOX).<br>*Go to Key Unit.  Enter a number in this text box to specify the<br>number of scale steps Finale should consider to be between <br>each pair of keys on your MIDI keyboard.  In other words, if you've<br>specified a quarter-tone scale, tell Finale that the Key Unit is 2--<br>there are two scale tones, not one, between one synthesizer key and<br>the next.  (If your synthesizer *can* produce quarter tones, however, <br>leave the key unit at 1, so that Finale will correctly play back your<br>quarter-tone score.<br>"If you've specified the correct Key Unit value, Finale will transcribe <br>and play any music perofrmed in the usual way correctly.  If you<br>created  quarter-tone scale without changing the Key Unit, by contrast,<br>you'd have to drastically modify your playing sytle, because Finale would <br>treat your keyboard as show here." [Note--the diagram in the<br>manual shows a quarter-tone keyboard replete with microtonal<br>accidentals]"<br>Hot rats, boys!<br>This is a real breakthrough.  It's what we've needed for years.<br>It's what Lippold Haken's LIME *should* have included, but didn't.<br>One final point: for those you whose wee widdle hearts go pit-a-pat<br>at the thought of a musical staff with more than 5 lines, Finale<br>also allows this.  You can completely redefine the staff, with <br>as many lines (within practical limits) as you like.  Folks like<br>Leo de Vries whose twinline 31-tone notation used more than 5<br>staff lines will jump for joy at this feature in Finale 3.5<br>Yes, Finale is still not quite as simple as quantum <br>electrodynamics.  Those dialog boxes are not easy to find,<br>or easy to use correctly.  But they're there.  And for the first<br>time, they make possible transcription of xenharmonic music <br>via  computer.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Mon, 23 Oct 1995 20:00 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id KAA20043; Mon, 23 Oct 1995 10:59:33 -0700<br>Date: Mon, 23 Oct 1995 10:59:33 -0700<br>Message-Id: <199510231752.NAA26693@freenet5.carleton.ca><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2190 href="#2190">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/24/1995 7:33:51 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: The accuracy of tunable MIDI synthesizers<br>---<br>>From time to time a recurrent gripe surfaces throughout the microtonal <br>community.  It centers on the supposedly "crude" tuning accuracy of <br>the typical synth module.  Ezra Sims is the most  vocal proponent <br>of this notion: he claims that the coarse tuning resolution of modern <br>MIDI synths makes them unusable for just intonation.  <br>Does this claim have any basis in fact?<br>First, a word about tuning tables and synths. Tuning tables on MIDI <br>synths have standardized on two accuracies: 1024 TU per octave and <br>768 TU per octave.  By far the most common tuning table standard is <br>768 TU/oct (64 steps per 12-TET scale step). This is the standard <br>used for tuning tables in the E-Mu Proteus I, Proteus II, Proteus <br>3, UltraProteus and Morpheus synths, along with the Yamaha TX11 and <br>TX81Z and the Waldorf Wave and MicroWave synths. (Dick Lord also  <br>states that a tuning table accuracy of 768/oct is buried inside the <br>Ensoniq VFX, VFX-SQ, TX10, EPS,  EPS-16+ and ASR-10.  Most post-1988 <br>Ensoniq synths are microtunable and let the user input values to the <br>nearest cent, but the tuning tables when entered have a tendency to <br>jump around after you've set 'em.  This would be consistent with a <br>tuning table quantum of 1.5625 cents, or 768 tuning units per octave.)<br>In any case it's clear that the 768 tuning units per octave has become <br>a de facto standard.  So it's worth  discussing in some detail the <br>question of the  purported "crudity" of this TU (tuning unit).<br>The first important point is that there is a big difference between <br>the *SIZE*  of the TU in the synth's tuning table, and the  <br>*ACCURACY* of a specific tuning entered into that tuning table. <br>Everyone knows, for example, that the accuracy of a synth with a tuning <br>table having 768 parts per octave is 1.5625 cents: that is, 1200/768 <br>cents.<br>Everyone knows this, and it's  wrong.<br>In fact, the accuracy of the synth depends on the  particular tuning <br>chosen. For example: if you tune your synth to 12 equal tones per <br>octave, the worst error is zero cents--and the average error is zero <br>cents.  This, because 12 is evenly divisible by 768 (768/12 = 64) <br>so each step of 12/oct falls exactly on a TU in the synth's tuning <br>table.  Thus for 12/oct (every 64 TUs), 24/oct (every 32 TUs), 48/oct <br>(every 16 TUs), 96/oct (every 8 TUs), 192/oct (every 4 TUs), 384/oct <br>(every 2 TUs) and 768/oct, the average error = the worst error of <br>the worst-tuned note...namely, zero cents.  For these scales, you <br>get perfect tuning accuracy within the limits of the jitter of the <br>synth's clock crystal and the sample-and-hold in the D/A converter. <br>---<br>What about *other* tunings than power-of-two multiples of 12?<br>To a first approximation, the *average accuracy*  of  any given <br>tuning should be somewhere around (1.5625/2) cents = 0.78125 cents.  <br>This assumes that in the worst case a scale-step lies no more than 1/2 <br>a tuning unit away...a logical enough assumption, as it turns out. <br>Remember:  if a given note is *more* than 50% of a TU above the <br>one chosen, accuracy could be gained by jumping  up to the next <br>higher tuning unit.  <br>For example: if a desired scale-step were 1.6 tuning units away from, <br>say, 324 TU, we could gain accuracy by setting the synth to 326 TU <br>so that the error would be -40% of a TU instead of +160% of a TU.  The <br>same argument applies if the desired tuning step is more than 50% <br>below the set tuning unit. This cuts our 1st-approximation guesstimate <br>of the average error down to 1/2 of 1.5625 cents, for an average error <br>of 0.78125 cents.  But even this average error is actually too large.<br>A moment's thought tells us that the accuracy is likely to be <br>significantly better than that on average, because it's *highly* unlikely <br>that every single step in our scale will be maxed out at the worst <br>possible 50% error of a TU error.  Thus, at first glance, the average <br>accuracy is likely to be much less than 50% of a TU-- that is, <br><< 0.78125 cents.<br>How likely?<br>Well, at this point I'll diverge into a brief paragraph on the integrals <br>of  Gaussian vs. non-normal distributions over a given region.  The <br>integral of such a statistical distribution within an interval gives <br>the signed probability of an event within those numerical parameters; <br>for a normal or Gaussian distribution this is generally expressed <br>in terms of standard deviations from the mean.  The measurement is <br>non-linear, so that (if memory serves) 2 standard deviations out from <br>the mean excludes nearly 98% of the probable outcomes.<br>Alas, this logic presumes a perfectly  Gaussian distribution of <br>scale-steps.   <br>Clearly no musical tuning follows this distribution; a graph of the step <br>size of equal-tempered scales, for instance, shows a rising line <br>y = mx + b, not a bell curve. Similarly,  a graph of the free-free metal <br>bar scale successive step size is proportional to the square of the  <br>hyperbolic cotangent (see Rossing, 1992, for details), while a graph <br>of the distribution of step-sizes of Harry Partch's 43 tones is a <br>stepped histogram with a bunch of near-equal clumps (since  21/20's <br>84.5 cents - the 33/32's 53.2 cents falls within 0.5 cents of the  <br>81/80's 21.5 cents - the 33/32's 53.2 cents...and so on).  That is, <br>a number of the successive step-sizes in Partch's 43-tone  scale are <br>nearly identical, so their distribution again does not look anything <br>like a bell curve. (Again, it's a shame there are no graphics available<br>on this tuning forum. Since the internet is hurtling us into the future<br>at the speed of light, naturally we're stuck in 1970 with dark ages<br>ASCII-only on-line technology.  Naturally!)<br>Using  back-of-the-envelope guesstimates which would make even the <br>most reckless mathematician cringe, a flat-line ET scale- step <br>distribution by the halfway point would have considerably less area than <br>a Gaussian bell curve, while beyond the halfway  point it'd have lots <br>more area...so call it (1.8 + 0.25), or maybe 2.05 or so times the total<br> Gaussian area, while a hyperbolic cotangent's area over the domain would<br> at a  wild guess come out to perhaps 70% of the area of a bell curve...  <br>So the expected average error in an ET scale should be about twice that <br>of the bell curve average error, while for the free-free metal bar <br>scale it should be perhaps 70% of the (1.5625/2) cents/step average.  <br>(End of digression.  Bet you never thought a discussion of tuning <br>accuracy on synths would involve probability integrals!)<br>What does all this mean?<br>It means that the actual tuning accuracy for a 768 TU/oct synth is <br>likely to be completely different from what we'd expect from our <br>simplistic argument above (which led to the conclusion that the accuracy <br>should be << 0.78125 cents per scale step on average).<br>On reflection, this is obvious.  Most real-world tunings will exhibit <br>a mix of large and small errors, with the largest error being a bit <br>less than 0.78125 and the smallest errors (excluding the always-zero <br>root note or 1/1) probably hovering around 0.01 or so. So to a second <br>approximation the average error should range twixt 0.2 cents and 0.4 <br>cents, depending on the exact shape  of the statistical distribution <br>of step-sizes in the tuning, and the exact location of the mean <br>step-size.<br>This tells us that to get real concrete answers, we'll need to do <br>some actual number-crunching and try a mini-Monte Carlo analysis. <br>So let's see what the actual worst scale-step, best scale-step and <br>average (total cents error divided by total number of scale-steps) <br>is for a number of different tunings:<br> <br>[1] For Partch's Monophonic fabric of 43 just tones the  error for <br>each step of the scale is:<br>SCALE STEP   THEORETICAL   TUNED ON SYNTH    CENTS ERROR<br>NUMBER           IN CENTS	       		IN CENTS<br>0 (1/1)	     	[0.0]	        [0.0]	      	[0.0]<br>1 (81/80)	 21.5062896       21.87		0.368710403<br>2 (33/32)	 53.272943         53.125	 -0.147943229<br>3 (21/20)      	84.4671934       84.375 	-0.092193469<br>4 (16/15)	111.7312853     112.5	       0.768714742<br>5 (12/11)	150.6370585     150.0	     -0.6370585<br>6 (11/10)     	165.0042285    165.625	      0.620771502<br>7 (10/9)	182.4037121    182.8125      0.40878787<br>8 (9/8)		203.9100017    204.6875      0.777498271<br>9 (8/7)         231.1740935    231.25          0.075906482<br>10 (7/6)	266.8709056    267.1875      0.316594408<br>11 (32/27)  	294.1349974     293.75	    -0.384997396<br>12 (6/5)	315.641287      315.625	    -0.016287<br>13 (11/9)	347.4079406   346.875 	    -0.532940629<br>14 (5/4)       386.3137139   385.9375      -0.376213864<br>15 (14/11)	417.5079641   417.1875      -0.320464092<br>16 (9/7)	435.0840953   434.375	    -0.709095252<br>17 (21/16)	470.7809073   470.3125	    -0.468407332<br>18 (4/3)	498.0449991   498.4375	     0.392500873<br>19 (27/20)	519.5512887   520.3125	     0.76121127<br>20 (11/8)	551.3179424   551.5625	     0.244557637<br>21 (7/5)	582.5121926   582.8125	     0.3003074<br>22 (10/7)   	617.4878074   617.1875	    -0.300307392<br>23 (16/11)  	648.6820576   648.4375	    -0.2444557627<br>24 (40/27)  	680.4487113   679.6875	    -0.761211264<br>25 (3/2) 	701.95500	701.562		-0.39250086<br>26 (32/21)  	729.219092    729.6875	     0.468407348<br>27 (14/9)   764.9159047   765.625	     0.709095272<br>28 (11/7)   782.4920359   782.8125	     0.320464118<br>30 (8/5)    813.6862861	  814.0625	     0.376213871<br>31 (18/11)  852.5920594  853.125	     0.53294064<br>32 (5/3)    884.358713	  884.375	     0.016287012<br>33 (27/16)  905.8650026  906.25	     	0.384997406<br>34 (12/7)   933.1290944   932.8125	    -0.316594386<br>35 (7/4)    968.8259065    968.75	    -0.075906467<br>36 (16/9)   996.0899983   995.3125	    -0.777498257<br>37 (9/5)   1017.596288    1017.1875	    -0.40878786<br>38 (20/11) 1034.995771  1034.375	    -0.62077149<br>39 (11/6)  1049.362941	 1050.0	    	 0.63705851<br>40 (15/8)  1088.268715   1087.5	     	0.768175<br>41 (40/21)  1115.532807  1115.625	     0.09219348<br>42 (64/33)  1146.727057  1146.875	     0.14794324<br>43 (160/81) 1178.49371   1178.125       -0.3687104<br> <br>The average error per scale step is 0.40561  cents. The worst error <br>is 0.777 cents--roughly 3/4 of a cent--and the best-tuned scale step<br>has an error of 0.016  or about 1/60 of a cent.  These numbers are <br>well within the  range of our second approximation back-of-the-envelope <br>calculation.<br> <br>[2] For  Wilson's first stellated tetrachordal hexany (Chalmers, "Divisions <br>of the Tetrachord," 1993, pg. 124:<br> <br>THEORETICAL   THEORETICAL 	TUNED ON SYNTH    CENTS ERROR<br>NUMBER         IN CENTS	  	 IN CENTS       	  <br>0 (1/1)	      [0.0]		   [0.0]	   [0.0]<br>1 (28/27)	   62.960903	    62.5	  -0.460903<br>2 (16/15)      111.731285	   112.5	    0.7687147<br>3 (784/729)    125.921807	   126.5625	    0.6406922<br>4 (448/405)    174.692189	   175.0	    0.3078108	   <br>5 (256/225)    223.462570           223.4375	  -0.0250705<br>6 (35/27)      449.274617	   450.0	    0.72538227<br>7 (4/3)	   	498.044999	   498.4375      0.39250087<br>8 (48/35)        546.815380	   546.875	    0.05961948<br>9 (112/81)       561.005903	   560.9375	  -0.068403<br>10 (64/45)       609.776284	   609.375	  -0.40128439<br>11 (1792/1215) 672.737188	   673.4375	    0.70031172<br>12 (224/135)   876.64719	   876.5625	  -0.08469<br>13 (16/9)         996.089998	   995.3125    -0.77749825<br> <br>A median has little meaning for these sets of numbers, since<br>no error appears more than twice and there are many errors<br>in that category.  A median decile might have more significance,<br>but its musical meaning is debatable--at least as debatable<br>as that of the mean or average error.<br>The average error is 0.41635 cents/step, similar to that of the Partch <br>scale.   As before, absolute cents are summed and divided by the total <br>number of scale degrees, and the 1/1 is ignored so as not to artificially <br>lower the average error.<br>[3] Archytas' enharmonic (Mixolydian, B-b)  from Chalmers, "Divisions <br>of the Tetrachord," 1993, pg. 104:<br> <br>THEORETICAL   THEORETICAL 	TUNED ON SYNTH    CENTS ERROR<br>NUMBER             IN CENTS	    IN CENTS     <br>0 (1/1)	      [0.0]		  [0.0]		    	    [0.0]		<br>1 (28/27)     62.960903	   	  62.5		          -0.460903<br>2 (16/15)     111.731285	  112.5	          	0.7687147<br>3 (4/3)		498.044999	  498.4375              0.39250087<br>4 (112/81)    561.005903	  560.9375	         -0.068403<br>5 (64/45)     609.776284	  609.375	         -0.40128439<br>6 (16/9)      996.089998	  995.3125            -0.77749825<br> <br>The average error per scale step is in the same ballpark: 0.47818 cents <br>per step.<br> <br>[4] Ptolemy's intense chromatic (from Chalmers, "Divisions of the  <br>Tetrachord," 1993, pg. 102:<br> <br>THEORETICAL   THEORETICAL 	TUNED ON SYNTH    CENTS ERROR<br>NUMBER              IN CENTS	    IN CENTS       <br>0 (1/1)		[0.0]		   [0.0]	   	  [0.0]<br>1 (28/27)	   62.960903	   62.5	       -0.460903<br>2 (10/9)	  182.403712	   182.8125	        0.4087878	<br>3 (4/3)	  	498.044999	   498.4375           0.39250087<br>4 (3/2)	  	701.955001             701.5625        -0.39250086<br>5 (14/9)	  764.915904	   765.625	        0.70909527<br>6 (16/9)	  996.089998	   995.3125         -0.77749825<br> <br>In this case the error's somewhat higher than previously: average <br>error of 0.523515 cents per step. Withal, still quite small.<br>For all the just intonation scales considered above, the average of  <br>the average errors/scale step is 0.458 cents.  This implies that if <br>you tune an arbitrary JI scale, your average error/step will be around <br>0.4 cents, with the average error increasing slightly as the number <br>of steps in your JI scale decreases.<br>As is readily apparent, 0.4 cents is a far cry from the 1.5625 cents <br>generally quoted.  Clearly for JI scales the tuning *accuracy* <br>(for real-world scales) of a 768 TU/octave synth is *far* better <br>than has been bruited about by microtonalists who don't know their <br>math.<br>So much for the tuning accuracy of a JI scale on a 768 TU/octave  <br>synth.  But what about equal tempered scales?<br>Rather than stupefy you with a recitativo of the error per scale step <br>for various equal temperaments, here's the  output from my simple <br>BASIC program for various ETs:<br> <br>TONES/OCT 	AVERAGE ERROR/STEP  WORST ERROR  BEST ERROR<br>		IN CENTS	     IN CENTS         IN CENTS<br>[5] 5/oct	0.375		   0.625		0.0<br>[6] 13/oct	0.3883115	   0.600952      	0.0<br>[7] 19/oct	0.3895362	   0.65789	 	0.0<br>[8] 31/oct	0.3902204	   0.705688      	0.0<br>[9] 41/oct	0.3040017	   -.7241209    	0.0<br>[10] 53/oct	0.39048162	   -.7370605    	0.0<br>[11] 72/oct	0.34722140	   0.5208282    	0.0<br> <br>Total average error: 0.369 cents, slightly lower than in the JI scales <br>considered above, probably because the ET scales have a fixed step <br>size thus a more even distribution of error sizes.<br>As you can see, the average error per scale step is just about as <br>low for ETs as for the just intonation scales above.  And in  all <br>cases less than 0.4 cents.  Again, a damn small tuning error.<br>To give you an idea of how small: at 100 Hz the ratio twixt two notes <br>using harmonic-series overtones (one note tuned with perfect accuracy <br>in the target scale, one note tuned in the best approximation allowed <br>by the synth) would amount to a whopping 2^[0.3040017/1200]  = 2^<br>[2.833475  exp -4] = 1.0001964 for the 41/oct case.  At a fundamental <br>of 100  Hz this would produce an out-of-tune note of 100.01964 Hz, with <br>a  fundamental beat rate of 1 beat every  50.911 seconds. (Of course, <br>the 2nd harmonic would beat at twice that rate, with additional sum <br>and difference tones...and so on.)<br>Now, come on, people...  Can you *really* hear the difference <br>between 1 beat every 51 seconds and the normal internal beating and <br>vibrato from a real-world acoustic instrument?<br>Is that reasonable?<br>Is an average beat rate of 1 per 51 seconds really something to get <br>all het up about?  Is anyone in your audience going to jump up and <br>shout "I can hear it!  It's out of tune!  There was a full two <br>thousandth of a beat in that sixteenth note at metronome marking 100!"<br>Please.<br>How many notes in the average JI or  xenharmonic equal-tempered  <br>composition would last long enough to hear even *one fourth*  of a full<br> beat-complex?  <br>Even assuming (that is) that your acoustic-instrument performers <br>were exactly, perfectly, precisely 100% in absolute theoretical tune <br>with the ideal frequency of the note required, to a full 6 or 7 digits <br>of precision! <br>Now, let's think about this, people.  This cursory little statistical <br>analysis tells us unequivocally that even with a purportedly "coarse" <br>tuning grid like 768 TU per octave, any audible error when playing <br>a synth with a live ensemble *far* more likely to be caused by <br>the *live  ensemble*  rather than the synth.<br>Bearing in mind that Partch's tuning accuracy (which he required in <br>tuning his acoustic instruments) was "better than 2 cents," how likely <br>do you think it that any of the performers *or* the audience <br>will hear errors in the synth tuning averaging around 1/3 of a cent?  <br>That's a tuning precision 6 times better than the accuracy Partch <br>demanded! The only possible conclusion to be gained from this little <br>investigation into the statistics of tuning accuracy is that concerns <br>about the "coarseness" and "inaccuracy" of a 768 TU synth are wildly <br>overblown. Now, some of you might argue about the significance of an <br>"average" tuning error (isn't the audience likely to hear and remember <br>the  *worst-tuned* notes, rather than some numerical "average"?).<br>Rather than dispute the point, let's grant it.<br>Even so..the worst tuning error in most cases is still likely to be <br>no more than twice the averages cited above.  That is, about 0.68 <br>cents--*WORST CASE*.<br>This means that the absolute worst-tuned note<br> played with a 768 tuning-unit synth would be mistuned by a ratio of<br> 2^[0.68/1200] = 2^[5.66 exp -4] <br>= 1.0003929:1.  For a properly-tuned note of  100H z this would <br>produce an out-of-tune note of 100.03929 Hz, and a fundamental beat <br>rate of 1 beat every 25.45 seconds.<br>Can anyone seriously contend that this kind of so-called "inaccuracy" <br>is anything that even the keenest-eared member of the audience would <br>ever hear in anything but an hour-longLaMonte Young drone composition?<br>>From now on, let's have no more of these preposterous claims that <br>is a very coarse and inadequate grid for [fill in the blank...just <br>intonation, equal temperaments, meantone,whatever]."  The facts do <br>not support such a contention.<br>In fact, if Johnny Reinhard can produce a computer-analyzed solo from <br>of any of his live acoustic performances in which the average note <br>was no farther off than 1/3 of a cent, I'll eat his entire  collection <br>of microtonal manuscripts.  With Worchestershire sauce.  In one sitting!<br>In real-world live acoustic solos, performed notes are generally played <br>*much* farther off than 0.3 to 0.4 cent...especially at rapid tempi <br>above 200 bpm. Sundberg's computer analyses show accuracies for <br>professional musicians in the neighborhood of 10 cents, while Shackford's<br> computer analyses show average accuracies for symphony performers in the<br> neighborhood of 15 cents.  This is *worlds* away from the average 1/3 <br>cent error we've found here, and indeed the coefficients of thermal <br>expansion for wood and metal are such that an acoustic instrument would <br>almost certainly detune by *more* than 0.3 to 0.4 cents simply by <br>being moved from a cold car into a warm concert hall.<br>So let us have no more claims that "768 TU per octave are inadequate <br>for microtonal music."<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Tue, 24 Oct 1995 19:51 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id KAA05819; Tue, 24 Oct 1995 10:50:32 -0700<br>Date: Tue, 24 Oct 1995 10:50:32 -0700<br>Message-Id: <9510241742.AA03583@danhicks.math.nps.navy.mil><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2193 href="#2193">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/25/1995 10:38:45 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Live xenharmonic recording<br>---<br>As more and more of you get together and<br>produce live microtonal music (whether with MIDI<br>instruments, acoustic instruments, or<br>a combination of the two), sooner or <br>later you'll want to record your xenharmonic<br>performances on DAT.<br>Here are the fruits of my experience in<br>recording live to DAT:<br>[1] The first thing to remember is that <br>whenever a "pro" is involved, the recording<br>will be crap.  <br>In my experience "professional sound <br>engineer" is a code phrase that actually<br>means "incompetent toad."  Most of these<br>people are ex-stereo salesmen who wouldn't<br>know a balanced line from their own bum.<br>Among the examples of expertise I've seen<br>demonstrated by "pro recording engineers:"<br>using ordinary drugstore rubbing alcohol to<br>clean the heads of a 16-track tape deck; <br>using a Calrec soundfield microphone to<br>zero in on someone snapping a rubber band<br>while 5 other xenharmonic instruments were<br>playing live; accidentally forgetting to<br>record one of the tracks of a critical stereo<br>master during a live take; and clipping most<br>of a digital recording. <br>This last is worth a mention or two.  One of<br>the hallmarks of a "professional" recording<br>is that the digital audio clips a lot. A WHOLE lot.<br>Fortunately, all these problems can be<br>eliminated very simply: if there's a "pro"<br>involved in the recording process, get rid<br>of him. (It's always a him. Women don't<br>seem to be able to plumb such Stygian<br>depths of ineptitude.)<br>Do the recording yourself.  The results will<br>be *infinitely* superior.<br>[2] The first problem you'll encounter is<br>the ground loop.  This is a pesky 60 Hz hum that<br>can drive you out of your mind.  It's caused<br>by two grounds at slightly different<br>potentials; 60 Hz wall current flows between<br>the 2 grounds, producing an audible buzz.<br>Ground loops can arise at many points in the<br>audio chain.  The 1st and most obvious place is <br>the wall socket.  In this case, 2 different<br>pieces of audio equipment are hooked together <br>electrically (say, a synth plugged into a mixer)<br>but plugged into 2 different wall sockets.<br>A ground loop can occur if the ground<br>on one wall socket is faulty;  in that case<br>current will flow from one wall socket to the<br>other through your equipment (an electrical<br>signal always seeks the lowest level of<br>electrical potential).   <br>Another particularly interesting cause of<br>ground loop is a connection between your<br>computer's MIDI port and your synth.  This<br>is NOT supposed to cause a ground loop<br>because the MIDI's supposed to be optoisolated;<br>my best guess is this sometimes occurs because<br>the metal shell of the MIDI cable is connected <br>both to the digital ground of the computer and<br>the analog and digital grounds of the synth,<br>causing current to flow twixt the analog<br>ground of the synth and the computer's<br>backplane.  In this case you'll also get a<br>distinctive whining noise--clock noise<br>from the computer.   <br>The way to solve all ground problems is with<br>an isolation transformer.  The Ebtech Hum<br>Eliminator handles both balanced and <br>unbalanced lines and does a good job.  It's<br>also dirt cheap: < $60 for 2 stereo<br>channels.  I keep 3 of these on hand at all<br>times whenever I do live recordings, since<br>(as usual) if you ask any "pro" for an<br>isolation transformer, he'll fumble around<br>like a lobotomized trilobite & come up with a<br>single mono balanced line version.  (As<br>always, the "pro" is too inept to realize that<br>in the real world most synths use stereo<br>unbalanced line outs.)<br>If all else fails, you *can* fix ground loop<br>hum in the mix.  Digitize the audio to your<br>hard disk, feed .25 seconds of the hum into<br>the Dolson DNOISE program, then filter<br>it out of the recording on your hard disk<br>by running DNOISEwith the Fourier<br>filter generated by the hum. Warning: this<br>usually adds considerable reverb, since the<br>notch filters generated by DNOISE are usually<br>set at harmonics of 60 Hz, and as we all know<br>running a bunch of different FFT bins at once<br>through a soundfile always & unavoidably adds<br>reverb due to the nature of the short-time FFT.<br>[3] When live instruments are combined<br>with synths, it's important that everyone<br>be able to hear hi/rself.  Often the<br>live instrumentalist will use outboard<br>effects and a small speaker to enhance the<br>sound; thus as a recording engineer you'll<br>often be faced with the problem of recording<br>a live instrument with a speaker nearby.<br>If you feed the output of your recording to<br>reference speakers so that everyone can<br>hear what the mix sounds like, you'll <br>inadvertently recreate Robert Ashley's classic<br>electronic music composition "The Werewolf."<br>The only reliable way to deal with feedback<br>in my experience is with a feedback <br>eliminator.  Turning down the monitor<br>speakers doesn't work because no one<br>can hear the total mix; moving the small<br>speaker back from the mike doesn't work <br>because the live performer can't hear <br>what hi/r output sounds like.<br>The Sabine feedback eliminator is in my<br>experience the best way to deal with the<br>problem.   Because it's a digital widget,<br>it's especially effective in killing screech<br>& howl before it starts.  There are other<br>feedback eliminators on the market, but<br>this one is cheaper and does a better job<br>than anything I've come across.  The cost<br>is about $250.<br>Naturally a "pro's" solution to the problem of<br>feedback is: "Uh, uh, hm, uh, play lower."<br>Typically useless; typically incompetent.<br>[3]  When recording to DAT or ADAT, you'll<br>discover that Robert Fripp's rules of <br>recording apply: <br>*The SPL level of the group during live<br>performance will always be at least<br>twice the level during the sound check.<br>*The percussionist will always hit the<br>microphones at some point during the<br>performance.<br>*If the monitor speakers are placed close<br>enough to the performers that they can<br>hear themselves, there will be feedback;<br>if the monitor speakers are placed far<br>enough away from the performers to<br>avoid feedback, they won't be able to<br>hear themselves.<br>*The tape will always run out during the<br>best part of the performance.<br>To avoid these inevitable problems,<br>try the following:<br>*Set the DAT record level during a<br>sound check, then back it off by half, then<br>drop it by another 3 dB.   Most DATs<br>are actually at -10 dB when they read<br>0 dB, so this will save your bacon during<br>really loud sections.  If the sound levels<br>are generally within recording limits<br>but momentarily rise by extraordinary<br>amounts (this can occur with metallophone-<br>type percussion instruments), add a compressor<br>between the mixer and the DAT. <br>*Place a coincident XY pair of mikes<br>directly above the percussionist.  Very<br>few percussionists will try to play<br>empty air.<br>*Instead of using monitor speakers, use<br>headphones for everyone in the group<br>whenever possible.<br>[4] Placement of microphones is<br>critical for live recording.  It differs<br>with each room, acoustic instrument,<br>and type of mike.<br>You might be surprised to learn that<br>with acoustic instruments, different<br>frequencies radiate in different directions.<br>Thus placing a mike front center and 30 <br>degrees below a cello will pick up one<br>set of low frequencies, while moving <br>the mike to the left or right will pick<br>up another set of mid-frequencies. This<br>is one of the reasons why you'll often<br>need a whole passel of microphones in<br>different locations around one <br>acoustic xenharmonic instrument.<br>Cardioid condenser mikes should be<br>placed as close as possible unless<br>the source is metal bars or tubulongs;<br>in that case they should be placed at<br>least 8 feet to 10 feet away.<br>When miking a guitar, you'll find that<br>you get more realistic sound if you<br>aim the mikes slightly away from the<br>guitar's center hole.  The entire body<br>of the guitar radiates sound, and for<br>best results place one mike up by the<br>fingerboard and another mike down<br>below the center hole, aimed at the<br>instrument's body.<br>The same appears to be true of the cello,<br>the viola and the violin. In those instruments<br>the bridge is one of the "hottest" sources<br>of sound, and a mike moderately distant<br>from the bridge, aimed at the body of<br>the instrument, often needs to be balanced<br>by another close-in mike aimed at another part<br>of the instrument to get a recording that<br>sounds like the live instrument.<br>Again, as noted, to get the "full" sound<br>of the instrument you may have to combine<br>the output from a bunch of different mikes<br>in different positions.  (This is one reason<br>why so many sampling CDs sound different<br>from one another; only 2 mikes were used,<br>and on each CD the mikes were placed in<br>different positions!  Yes, Virginia, mike<br>placement is CRITICAL!)<br>Wind instruments can exhibit sharp<br>transients, so *always* use a puff filter.  <br>This can be something as simple as a clean<br>sock placed over the mike or as elaborate<br>as a $50 screen from the local music<br>store.  The acoustic result tends to be<br>the same.<br>If you're using PZM mikes, you can <br>increase dynamic range by hot-wiring<br>two 9 volt batteries in parallel.  This<br>will increase the apparent noise of the<br>mike, so you'll have to use an additional<br>hiss elminator between the PZM mike<br>and the mixer. (More on hiss elimination<br>in a moment.)<br>PZM mikes operate unlike other mikes--<br>they produce the best results if they're<br>firmly attached to large rigid slabs of wood,<br>metal or glass.  If possible, bolt the PZM<br>mike to the floor or the wall! (Warning: if<br>your recording site is near a street, you'll<br>pick up low frequencies from traffic through<br>the wall. A notable problem on recordings<br>made with PZMs in London, since in London<br>every recording studio is near a street with traffic.)<br>The PZM mike also has a peculiar pickup pattern: <br>totally hemispherical.  Whereas cardioid mikes<br>will do an excellent job of rejecting<br>off-axis sounds, the PZM mike picks up<br>everything indiscriminately within 180<br>degrees of its soundfield.  This means<br>that the PZM mike is suited only<br>for an extremely quiet recording <br>environment.  By contrast, many of<br>my recordings with condenser mike<br>make been made in houses over which<br>jet planes have been flying--yet the<br>jet plane rumble isn't audible in the<br>final recording because of the cardioid<br>condenser's superb rejection of off-<br>axis sound.<br>The PZM mike is apt to overload during<br>high transients.  It should be placed <br>farther away than a condenser mike. <br>While a condenser mike will suffer<br>drastic bass rolloff if it's farther than<br>about 1 foot from the sound source,<br>a PZM mike (firmly attached to a<br>rigid plane of wood or metal)  will<br>exhibit excellent flat frequency <br>response at almost any distance.<br>The Calrec soundfield mike is a special<br>case.  It's noisy, but 4 of 'em output<br>to an ADAT will allow you to "zoom"<br>in after the recording on any of the<br>corners of an imaginary tetrahedron.<br>This can actually let you fix some<br>recording problems in the mix.<br>[5] Different engineers prefer<br>different philosophies of mike <br>placement.<br>The 3 most common are the <br>coincident XY pair, the binaural <br>pair, and the widely separated pair.<br>Coincident XY produces excellent<br>results with a group in which everyone<br>has about the same SPL; the binaural<br>pair produces remarkable stereo<br>versimilitude but only if the listener<br>uses headphones.  The widely separated<br>pair (or quad, or octet) is useful for<br>instruments physically distant and with<br>very different SPLs, but tends to<br>produce a final recording without<br>a convincing soundstage.  <br>In general, the smaller the number of<br>mikes, the more realistic the soundstage<br>of the recording. Some of my CDs are reissues<br>of Mercury Living Presence recordings<br>made with coincident XY pairs in<br>1957-1959 and they sound more true<br>to life than almost any recordings made today.<br>With instruments which exhibit <br>significant sustain (like a psaltery)<br>you may want to place a  mike<br>inside the body of the instrument.  If so,<br>leave the sides open.  Otherwise the<br>transients will blow the top out of<br>your mix and force you to record at<br>such a low level as to produce junk. Mixing<br>the output with the sound picked up<br>from 2 nearby mikes can help to<br>capture the live reverberant sound better<br>than a pure coincident XY or binaural pair.<br>It's important to realize that <br>microphones are acoustic<br>cyclopses: they see *only and perfectly*<br>that tiny bit of the soundfield at<br>which they're aimed.   To get a<br>recording that sounds like what your<br>ears hear at a live performance, you'll<br>often have to jump through hoops and<br>use bizarre and irrational mike placements<br>and mixes.<br>One of the greatest fallacies in dealing<br>with microphones is the old canard: "If<br>your ears can hear it, the mike will<br>pick it up."  This is NEVER true.<br>Sounds which are clearly audible to your<br>ears during a live performance will<br>invariably be ignored by the mikes;<br>sounds which your ears cannot hear<br>during a live performance will be<br>magnified unbearably by the mikes.<br>Small changes in mike placement can<br>produce extreme changes in the <br>recording. <br>Above all, trust your ears by listening<br>to the test recordings on your DAT:<br>if the test recording doesn't sound<br>like the live performance, change<br>things--no matter how conceptually<br>perfect your mike placement or<br>mix levels.<br>[6] All live recordings have hiss.<br>Digital microphones, digital mixers,<br>digital synths, digital recorders--<br>doesn't matter.  There will STILL be<br>hiss.<br>In my experience the biggest source<br>of frying bacon is the effects unit.<br>Even if it's a 24-bit reverb, it will<br>hiss like crazy.  The only solution to<br>this is to put a hiss eliminator on <br>the effects unit BEFORE the stereo<br>returns come back into the mixer.<br>There are a lot of models of hiss<br>eliminator on the market.  They all<br>work on the same principle: a<br>level-sensing circuit activates<br>a voltage-controlled filter which<br>closes down depending on the<br>sensitivity setting.<br>The Hush IIcx is fairly cheap and<br>works well; a used KLH Burwen<br>Dynamic Noise Reduction unit<br>will also work well; dbx makes<br>(or used to make) a single-ended<br>noise reduction unit that worked<br>well; and other companies make<br>similar widgets.  They're all in<br>the range of $150-$200. <br>You'll need at least 2 of these <br>for any recording session. 1 to<br>kill the hiss from the effects<br>unit(s) coming into the mixer,<br>another to kill the hiss after<br>it leaves the mixes and goes<br>into your DAT or ADAT.<br>[7]  Fripp's rule of thumb that<br>the tape always runs out during<br>the best part of the performance<br>can be easily end-run.  I always<br>record with 2 digital recorders--<br>one recording live from mikes,<br>another recording the straight<br>mix output from the mixer.  As<br>Warren Burt can testify, this<br>approach works--what one <br>recording misses, the other<br>gets.  Starting one machine<br>later than the other assures that<br>you'll never be burned by <br>lack of tape.<br>[7] "Pro" engineers will place great<br>stock in balanced vs. unbalanced<br>lines.  In my experience balanced<br>lines are useful mainly in running<br>audio cables from the mixer to<br>the DAT.  As long as your other cable<br>runs are short & you're not recording<br>next to a microwave relay tower or<br>a commercial radio tower, there's<br>no practical advantage in using balanced<br>lines. (Unless the stage is a long ways<br>away from the mixing console! A cable run<br>of more than 15 or 20 feets demands a balanced<br>line, no question.) <br>"Pro" engineers will claim that balanced<br>lines eliminate ground loops.  Naturally,<br>this isn't true.  Balanced lines are just<br>as prone to ground loops as unbalanced<br>lines when the digital grounds of digital<br>synths are involved.  The sad fact is that<br>you'll still need isolation transformers<br>even if you use balanced lines on all<br>of your equipment. One further point:<br>if at any point in the audio chain you<br>introduce an unbalanced line, the whole<br>audio chain might as well be unbalanced.<br>A single unbalanced line can (& usually <br>will) introduce a ground loop.  Bear in<br>mind that the unbalanced part of the<br>audio loop can be inside a wall socket <br>with 3 holes but no true ground!<br>So much for the myth that "balanced lines<br>eliminate ground loops."<br>[8] You should bring along your own<br>speakers, your own preamp, your own<br>surge suppressor, your own power strips<br>and your own line conditioner/backup UPS<br>to any public recording session.  Last year<br>I had the delightful opportunity to handle<br>audio on a live performance in which<br>the "pro" sound engineer in charge thought<br>it would be a real smart idea to let<br>20 people plug coffee machines and hot<br>plates and toaster ovens into the same<br>outlet the performers were using to<br>power their digital synths.<br>The result was  interesting <br>(as in the Chinese curse).<br>[9] Always bring 4 of everything--4<br>3-prong-to-2-prong plugs (because<br>the place where you perform won't <br>have 3-prong plugs), 4 1/4-inch phone<br>jack-to-RCA cables, 4 XLR-to-phone-jack<br>transformers, 4 MIDI mergers, 4 mini-plug-<br>to-headphone adapters, 4 durable<br>equipment bags, 4 everything.  2 are<br>never enough and someone always needs<br>one extra.<br>[10] All these pieces of advice deal<br>with digital recordings rather than<br>analog.  Alas, there's just no comparison<br>twixt DAT and analog reel recordings.<br>The reel recordings don't measure up.<br>Despite the frenzied claims of the<br>LP and reel-to-reel fanatics, DAT<br>offers infinitely superior sound<br>quality to any possible reel recording.<br>--mclaren<br><br>Received: from sun4nl.NL.net [193.78.240.1] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Thu, 26 Oct 1995 09:25 +0100<br>Received: from eartha.mills.edu by sun4nl.NL.net with SMTP<br>	id AA06609 (5.65b/CWI-3.3); Thu, 26 Oct 1995 06:30:36 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id WAA09429; Wed, 25 Oct 1995 22:29:20 -0700<br>Date: Wed, 25 Oct 1995 22:29:20 -0700<br>Message-Id: <199510260528.WAA03929@hopf.dnai.com><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2196 href="#2196">ðŸ”—</a>Allen Strange &#x3C;STRANGE@sjsuvm1.sjsu.edu&#x3E;</h3><span>10/25/1995 11:32:27 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>Folks:<br><br>  In B, Maclaren's last post (when does he find time to write all this stuff)<br>reference is made to Robert Ashley's "The Werewolf" - the analogy is great<br>but I believe the title is "Wolfman"-it was published in one of the wonderful<br>Source Magazines of years-gone-by.<br><br>=========================================================================<br>|                          Allen Strange                                |<br>|             http://cadre.sjsu.edu/music/strange.html                  |<br>|_______________________________________________________________________|<br>| Electro-Acoustic Music     | International Computer Music Association |<br>|        Studios             |        2040 Polk St., Suite 330          |<br>| School of Music            |        San Francisco, CA 94109           |<br>| San Jose State University  |       Telephone + (408) 395-2538         |<br>| 1 Washington Square        |          Fax + (408) 395-2648            |<br>| San Jose, CA 95192-0095    |      Email: icma@sjsuvm1.sjsu.edu        |<br>| Telephone +(408) 924-4646  |                                          |<br>| Fax +(408) 924-4773        |     We hope to see you at the ICMC96     |<br>| <strange@sjsuvm1.sjsu.edu> |         On the Edge in Hong Kong         |<br>|                            |         ICMC96@cs.ust.hk for info        |<br>|=======================================================================<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Thu, 26 Oct 1995 11:12 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id CAA10774; Thu, 26 Oct 1995 02:12:04 -0700<br>Date: Thu, 26 Oct 1995 02:12:04 -0700<br>Message-Id: <199510260253.XAA09265@chasque.apc.org><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2198 href="#2198">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/26/1995 7:01:00 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: New xenharmonic CD<br>---<br>"Ping-Pong Anthropology," by The 13th Tribe, is yet<br>another microtonal CD by yet another world music <br>group well worth hearing.<br>In this case the members of the avant ensemble are:<br>Erik Balke, a Norwegian folk musician and student of<br>African and Balinese music; Werner Durand, a German<br>and Silvia Ocougne, a Brasilena.<br>Balke and Durand perform on harmonic-series PVC pipes<br>while Ocougne uses prepared acoustic guitars whose<br>strings are hammered, plucked and pulled.  Skin drums<br>and plexiglas tubes are also used.<br>The music uses a "call and answer" technique in<br>combination with digital delays, and the result is<br>something like ethnic music for a tribe of children<br>living in the rafters of a geodesic dome.  The first<br>track, "Dream Hunters," along with track 3, "Hazar," and <br>track 7, "Ping-Pong Anthropology," are particularly<br>memorable.  All three performers (along with French<br>guest perfomer Pierre Berthet on tracks 8 & 9) use<br>higher members of the harmonic series to weave<br>extended melodies.  The effect is reminiscent of some<br>of the earlier compositions of Denny Genovese, although<br>with greater rhythmic density and a concommitant use<br>of digital electronics to generate a sleet of ricocheting<br>"ghost" notes.<br>This CD is available for a limited time from Experimental<br>Intermedia.  Not nearly as expensive as you'd expect<br>for an import--about $17.  Highly recommended.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Thu, 26 Oct 1995 16:03 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id HAA15182; Thu, 26 Oct 1995 07:03:28 -0700<br>Date: Thu, 26 Oct 1995 07:03:28 -0700<br>Message-Id:  <9510260700.aa23177@cyber.cyber.net><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2199 href="#2199">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/26/1995 7:03:28 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: trivial errata in the series of psychoacoustics posts<br>---<br>As some of you might have guessed, my series of 25 psychoacoustics<br>posts constitute a distilled and simplified early version of a significantly<br>longer and more detailed  monograph on tuning and psychoacoustics.<br>This paper should appear in Xenharmonikon 18, perhaps in 1997. Until<br>then, it behooves me to point out that some errors crept into<br>the posts--some apparently due to end-of-line word deletions during<br>uploads, etc.<br>Other errors are entirely my own fault.<br>In Topic 8 of Digest 508 a dropped word at the end of a line <br>produced a significant distortion of the intended meaning.  <br>The full and accurate text is:<br>---<br>It is well known that the description of the ear to which Doty,<br>Worrall and Alves (known as the place theory of hearing) refer is<br>incomplete and conflicts with much of the psychoacoustic<br>evidence.  "A second difficulty with the place theory lies in <br>the fact that, in complex sounds, components are often heard<br>that are NOT present in the Fourier analysis.  Or loudness <br>judgments of components may be made which do not agree <br>with the amplitudes obtained for Fourier components.  It is <br>certainly true that there are phenomena which cannot at the <br>present time be explained by the plaheory of hearing." <br>[von Bekesy, Georg, "Hearing Theories and Complex Sounds," <br>Journ. of the Acoust. Soc. Am, 35(4), April<br>1963, pg. 589]  Be it noted that von Bekesy is the researcher <br>most responsible for compiling experimental evidence for <br>the place theory. (In fact he won the Nobel prize for it.)<br>---<br>Leaving out the italicized word "NOT" from the posted text<br>produces a distinctly false impression.  Mea culpa.<br>---<br>Several other  errata appeared in Digest 511, topic 6:<br>The title of the reference listed as [5] should be "The Physics<br>and Psychophysics of Music" by Juan Roederer, 2nd ed., 1973.<br>(There is now a third edition, 1995, same author, same title.)<br>My post incorrectly listed the title as "Introduction to the<br>Physics and Psychophysics of Music," etc.  Important if you<br>try to look up the book in a computerized library system!<br>Under the reference listed as [6]  the sentence should read<br>"...more detailed than any text but Pierce (1992)."  This is my<br>flub.  Because John R. Pierce's "The Science of Musical Sound"<br>from 1992 has a virtually *identical* title to Johan Sundberg's<br>"The Science of Musical SoundS" (S on the end) *ALSO* <br>published in 1992, I confuted them here.  The sense of the<br>paragraph is that Sundberg's 1992 book offers more complete<br>references and a wider consideration of psychoacoustic ear/brain<br>models than any general-reading text other than Pierce's book <br>(also from 1992). <br>--mclaren<br> <br> <br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Thu, 26 Oct 1995 18:33 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id JAA22990; Thu, 26 Oct 1995 09:32:38 -0700<br>Date: Thu, 26 Oct 1995 09:32:38 -0700<br>Message-Id: <Pine.3.89.9510261244.A27249-0100000@mcmail.CIS.McMaster.CA><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2206 href="#2206">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/27/1995 8:21:21 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: A new way of regarding non-octave<br>  scales; Jose Wurschmidt's categorization:<br>  implications for non-octave composition<br>---<br>As Erv Wilson has remarked, "The field of<br>microtonal scales is absolutely infinite."<br>The closer one looks at any given category<br>of tunings, the more detail one sees.<br>This is nowhere more apparent than with<br>non-octave scales: specifically, that subset<br>defined by the Nth root of K.<br>As everyone realizes, non-octave scales are<br>so new and so unfamiliar to Western ears that<br>their properties remain largely unexplored. <br>While Enrique Moreno (1992) and myself (1989,<br>1992, 1993, 1995) have made a start, much<br>theoretical work remains.<br>One of the more striking characteristics of<br>non-octave scales is that they often exhibit<br>a marked disjunction between what Jose <br>Wuerschmidt called the "defining interval"<br>and the "constructing interval."  Indeed, this<br>perceptual dissonance can be so great in <br>non-octave scales as to turn the ordinary rules<br>of harmony and melody upside-down and inside-<br>out, and often leads to puzzlement and frustration<br>among those who hope to compose with Nth roots<br>of K.<br>Gary Morrison has alluded to this problem in posts<br>on his non-octave 13.6363/oct scale (what he <br>calls "88 CET," an appelation which while accurate<br>stresses its defining rather its constructing interval;<br>and in the case of 13.6363/oct the constructing intervals<br>are actually the ones with most musical importance).<br>However I propose to discuss the issue on a more general<br>basis, covering all Nth roots of K.<br>First, a word about the terminology.  Jose Wuerschmidt was<br>a microtonal theorist who did seminal work during the<br>1920s: his article "Die Quinten- und Terzengewebe" ("The<br>Web of Fifths and Thirds") had a huge impact on subsequent<br>thinking about scale generation, and to a large degree <br>underlies Rothenberg's, Wilson's, Fokker's and Lucy's<br>approach to xenharmonics.   (Although they themselves are<br>often not aware of this; W's ideas diffused far & wide, often at<br>2nd- 3rd, and 4th-hand.) Wuerschmidt's essential idea<br>was that tunings are characterized by two kinds of intervals:<br>one, which he called "constructing intervals," which generate<br>the tuning via an implied underlying harmonic root progress<br>and which define the tuning's tonality--and a second kind of<br>interval, which Wuerschmidt called "defining intervals."<br>This is the interval which (in what Erv Wilson calls "logarithmic<br>space," as opposed to "ratio space") linearly defines the melodic<br>modes of the scale.<br>In the case of 12-TET, the constructing interval is clearly 2^[7/12].<br>Underlying this approximation one can reach back to a Pythagorean<br>(one might say archetypal) constructing interval 3/2, which places<br>12-TET firmly in the camp of the positive scales. (I.e., those whose<br>fifths exceed the 3/2 in size. Technically, Bosanquet's positive/negative<br>classification was originally intended to relate scales to the fifth of<br>12-TET, as anal-renentive detail-obsessives  will<br>doubtless point out, but modern usage relates equal tempered<br>scales to the 3/2. )  Other constructing intervals are equally<br>plausible: Erv Wilson has generated JI tunings based on cycles<br>of an interval given by the harmonic mean twixt 4/3 and 11/8,<br>and he has also generated JI tunings based on cycles of 6/5s and <br>5/4s.   One could equally well imagine JI tunings based on cycles<br>of 7-limit, 11-limit, 13-limit and other constructing intervals;<br>Johnny Reinhard has generated a tuning based on the squares of<br>prime numbers.  Other constructing intervals are possible.<br>Returning to equal-tempered scales, clearly harmonic progressions<br>other than the 3/2 have been used in other cultures.  The Javanese and <br>Balinese do not appear to use a 3/2 at all, nor do the East Indian<br>srutis.   Even in this culture, some instruments favor the 5/4<br>rather than the 3/2--as for example vibes. <br>In the realm of the Nth roots of K, subdivisions of the 3:1--most<br>notably the Bohlen-Pierce scale, 13th root of 3--tend to preserve<br>the 3:1 as a constructing interval when the division is a small<br>number of scale-steps, but as the number of steps rises, other<br>constructing intervals can appear (depending on the exact Nth root<br>of K).<br>By constrast, the defining interval of 12-TET is the semitone of <br>100 cents.  This interval defines the melodic structures,  the leading<br>tones and modes possible in 12-TET.  Because of the size of the<br>12-TET defining intervals, many characteristic melodic structures<br>of antiquity cannot be accurately rendered; in 12-TET there is<br>no distinction between the diatonic and the chromatic semitones,<br>for example--nor can the Hellenic enharmonic genus' characteristic<br>plangent near-quartertone be rendered at all accurately.  The sharped<br>leading-tone favored by fretless string players (very well rendered<br>by 17-TET) cannot be faithfully reproduced in 12.  Ditto the string<br>player's flatted II in the root of a typical I-IV-V-II-I progression.<br>In fact, string players will tend to make a consistent pitch distinction<br>twixt II and IIb, while recovering pianists (and other musically<br>challenged individuals) will perceive no difference between the<br>two root notes.<br>However, the defining interval of the 13th root of 3 is the single<br>scale-step of 146.304 cents, very close in melodic size (and effect)<br>to a single scale-step of 8-TET.  Thus, while 12-TET uses a<br>whole-tone very similiar to the familiar tonal 9/8, 13th root<br>of 3 uses a defining interval not close to anything very tonal.<br>In fact the scale-step of 13th of 3 is a good approximation to<br>3 scale-steps of 24-TET, which forms an entirely anti-tonal<br>interval, lying as it does halfway between one 24-tone circle of<br>12 fifths and another; again, 146.304 cents is a reasonable counterfeit<br>of the neutral third formed by the geometric mean between<br>the 6/5 and 5/4, but again this is hardly a tonal interval in <br>the just intonation sense (since 350 cents corresponds to an<br>irrational number 1.224053543).<br>Thus 13th of 3 boasts quite tonal harmonic progressions, especially<br>if one deliberately mis-spells the chords with a 13-scale-steps<br>3:1 on the outside and a 292.608 2-scale-step third on the inside.<br>But the melodic defining intervals and thus the modes of 13th of<br>3 are utterly anti-tonal and inharmonic, and produce an<br>interesting clash with the constructing intervals.<br>In the Nth roots of 2, this kind of war twixt defining and <br>constructing intervals is rare.  Above 48 tones per octave it<br>does not exist; and below there are only a few examples. 35-TET<br>is one example, 26-TET another.  The most notable exemplar is<br>19-TET, in which the 189.47-cent whole-tone defining interval <br>clashes headlong with the very good 694.7368-cent constructing<br>interval of a fifth, unless purely diatonic progressions are used.<br>(That strategy quickly wears out its welcome unless the listeners<br>harbor a particular love for Christmas carols.)<br>Wendy Carlos' alpha and beta scales are characterized by virtually<br>just constructing intervals almost bang-on the just 3:2, but their<br>defining intervals are nothing like the 200-cent approximation of<br>the 9/8 with which we're familiar. <br>Thus the clash twixt defining and constructing intervals must<br>be considered a particular resource of non-octave Nth root of K<br>scales.<br>Moreover, because many Nth roots of K share identical constructing<br>intervals while boasting entirely different defining intervals,<br>the adroit scale designer can fix the constructing interval and<br>generate new scales by searching by alternate Nth roots of K with<br>a different N but the same K.    <br>For example, one might decide one wanted a just 5/4.  In that<br>case one would fix the constructing interval (a chain of 5/4s)<br>and use a successive set of Ns to generate alternate<br>non-octave scales and then explore their characteristics.<br>The most obvious example is of course the set of equal divisions<br>of the 5/4 ordinally greater than and ordinally less than the <br>familiar 4-equal-part division of the approximate 5/4 used<br>in 12-TET.<br>Maintaining a just 5/4 and using 5 divisions gives a scale-step<br>of  [386.31371/5] cents, which yields a non-octave scale of<br>1200/77.26274 tones/oct = 15.5314 tones/oct.  Using 3<br>divisions of the 5/4 (one less than the familiar 4, just as we<br>above explored one more than the familiar 4) we obtain<br>a scale-step of [386.31371/3] cents, for a non-octave scale<br>of 1200/128.77123 tones/oct = 9.31885 tones/oct.  In both<br>cases the constructing interval will be a 5/4, but the defining<br>intervals are quite different.<br>One result of this procedure is to generate a family of harmonically<br>related non-octave scales among which one can "transfer" (to<br>use Ivor Darreg's, and earlier still, Augusto Novaro's, terminology)<br>in a non-octave analogy to traditional tonal modulation.  In the<br>case of standard Western modulation, changing to another key<br>maintains the defining interval while moving by the constructing<br>interval; non-octave "modulation" of the kind described above<br>turns this process on its head by maintaining the constructing<br>interval but often moving by the defining interval.<br>Other obvious elaborations abound, but that must be left for<br>another post.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Sat, 28 Oct 1995 04:08 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id TAA15674; Fri, 27 Oct 1995 19:08:53 -0700<br>Date: Fri, 27 Oct 1995 19:08:53 -0700<br>Message-Id: <951027220824_78406650@mail02.mail.aol.com><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2212 href="#2212">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/28/1995 12:45:59 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: The Glechniszahlen-Reihe Monster<br>---<br>Along with the Sierpinski gasket and the<br>Wierstrass curve, the Gleichniszahlen-Reihe<br>Monster is one of the more interesting<br>number-theoretic constructs.<br>Consider the sequence:<br>1<br>1  1<br>2  1<br>1  2  1  1<br>1  1  1  2  2  1<br>..<br>Is there a pattern here?<br>The answer's embarassingly simple: row 2<br>is "one 1," referring back to the previous<br>row.  Row 3 is "2 ones," referring to row 2.<br>And so on.<br>This "likeness sequence" (a loose translation<br>of the German name) grows quickly.  Row 27,<br>for example, contains 2017 entries.<br>Clearly the Gleichniszahlen-Reihe Monster can<br>be generalized to any two relatively prime<br>numbers.  The monster then takes the form:<br>p  q<br>1  p  1  q<br>1  1  1  p  1  1  1  q<br>3  1  1  p  3   1  1  q<br>1  3  2  1  1  p  1  3  2  1  1  q<br>..<br>What does this have to do with tuning?<br>Well, the Gleichniszahlen-Reihe Monster<br>offers an attractive method of generating<br>modes from a tuning.  It also provides a<br>scheme for traversing ratio space to generate<br>scales (if the units of the sequence are <br>considered as coordinates in ratio space).<br>Lastly, the Gleichniszahlen-Reihe Monster<br>could be used as a melodic engine for algorithmically<br>generating note-sequences in any tuning (if<br>the units of the sequence are considered as indices<br>of an array containing xenharmonic pitches).<br>For more info, see Hilgemeir, M., "Die Gleichniszahlen-<br>Reihe," in Bild der Wissenschaft, vol. 12, 1986,<br>pp. 194-195.<br>--mclaren <br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Sat, 28 Oct 1995 18:53 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id CAA24365; Sat, 28 Oct 1995 02:54:13 -0700<br>Date: Sat, 28 Oct 1995 02:54:13 -0700<br>Message-Id:  <9510280952.aa18004@cyber.cyber.net><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2216 href="#2216">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/29/1995 1:17:07 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subjedt: Xenharmonic uses of FFTs<br>---<br>The FFT (to paraphrase DSP expert F. Gump)<br> is like a box of chocolates: you never<br>know what you're going to get out.<br>Because of the close connection between<br>the micro-level of harmonic or inharmonic<br>partials, and the macro-level of just,<br>equal-tempered and n-j n-e-t tunings,<br>the FFT deserves a more detailed and more<br>knowledgable discussion than it has to<br>date received on this forum.<br>As everyone knows, today's digital <br>time-stretching and pitch-shifting<br>algorithms (exemplified by SoundHack<br>and the Dolson vocoder) have reached a<br>high state of perfection.  This kind of<br>software allows you to reliably change<br>the pitch (or length) of any sound with<br>digital exactitude, under exquisitely<br>precise software control.<br>Everyone knows this, but it isn't true.<br>A number of folks on this forum have gone<br>so far as to claim that the FFT "tells you<br>what's going on inside a sound."<br>Alas, not so.<br>In fact the short-time FFT analysis of<br>a signal changing  in time gives you<br>a series of snapshots.  Each snapshot is<br>an average of what goes on during that<br>time interval.  You get *NO* information<br>whatever about goes on *BETWEEN* spectral<br>snapshots.<br>To get around this severe limitation in our<br>knowledge about the waveform being analyzed,<br>scientists and acousticians use a sophisticated<br>scientific technique.   It's called "a wild guess."<br>Between spectral snapshots spat out by the STFFT<br>analysis, audio analysis programs make a set of<br>arbitrary assumptions.  In effect, guesses.<br>Namely: they guess (arbitrarily) that the frequency<br>components do not change very much, or very fast,<br>and that they remain nearly harmonic all the time.<br>None of these assumptions are true for any sound<br>in the real world, but they are sometimes *almost*<br>true for some sounds, some of the time.<br>Some sounds have nearly harmonic overtones that<br>change relatively slowly except for the initial<br>10 milliseconds of the attack.  Alas, during the<br>first 1/100th of a second of almost every sound, short-<br>time FFT analysis produces garbage output and the<br>results must invariably be fudged with various<br>ad hoc rules of thumb and guesstimates.<br>This occurs because--during the initial attack of<br>a soun--both the frequency and the magnitude<br>of the partials change very rapidly, and the FFT<br>completely falls apart when applied to spectra<br>changing rapidly in both phase and magnitude<br>at the same time.  (This is inherent in the nature<br>of wave phenomena, and is in fact the basis for<br>the Heisenberg Uncertainty Principle when applied<br>to de Broglie matter waves.)<br>The net result is that the FFT in fact does *not*<br>tell you "What's going on inside a sound."  Instead,<br>the FFT *sometimes* gives you a hint under<br>*some* circumstances of *some* of what<br>*might* be going on inside *certain* sounds<br>at the micro-level...part of the time.<br>However,  the short-time FFT also introduces<br>a great many distortions into the information<br>it generates.  The short-time FFT also destroys<br>some of the information being analyzed. <br>Some people have claimed otherwise: memorably,<br>Mark Dolson.  The statement is always incorrect<br>when applied to the short-time FFT, and often<br>incorrect when applied to the simple FFT.<br>Under no circumstances can<br>the output of an FFT be taken as gospel,<br>and in many cases the FFT lies outright.<br>Doubtless many of you will be shocked to<br>learn this.  "But the textbooks say..." <br>Nope. <br>All too many textbooks are written by<br>folks without a lot of hands-on practical<br>experience, and they usually deal with ideal<br>theoretical cases ONLY.  For good reasons, <br>engineering and physics texts are  written<br>to make the subject matter as transparent<br>and comprehensible as possible.  As a result,<br>few introductory texts go so far as to tell<br>you the remarkable number of ways in which<br>today's sophisticated DSP algorithms can<br>turn your input into total trash.<br>Perhaps you've been seduced by the siren sound<br>of that cognomen "digital."  Anything that's<br>"digital" *must* be accurate--right?  It *must*<br>be reliable--right?  After all--the Fourier transform<br>is a classic mathematical technique...how can<br>it *lie* to us?<br>To repeat one of my favorite riffs, all methods<br>of analysis are reliable only insofar as the<br>quantity being analyzed fits the assumptions<br>on which the analysis is based.  Aiming a<br>telescope at a virus doesn't tell you much;<br>using a microscope to study galaxy M31 is<br>futile.<br>In particular, mathematical techniques produce<br>accurate results only when the input honors<br>the boundary conditions of that technique.<br>This is no surprise to those of us on the physics<br>side of the fence, but it seems to come as a <br>constant shock to some other folks.  While <br>physics dudes understand & accept that<br>all mathematical models of reality are merely<br>*approximations* of the extremely complex<br>real world--and usually crude approximations<br>at that--this is a lesson that has yet to percolate<br>into everyone else's consciousness.  Thus one<br>often sees engineers with a mathematical hammer<br>looking at everything in the universe as though<br>it's some kind of nail.<br>The FFT is a classic example.<br>Surprisingly, this can be good thing.  To an engineer,<br>distortion is a no-no...but to a composer, distortion's<br> *dandy.*  If a mathematician puts a sound<br>into the FFT and gets out weird digital glop<br>that strikes the ear as xenharmonic & unspeakably bizarre <br>& nothing like the input...well, that's bad news for<br>a math nerd but great news to a xenharmonist.<br>So rejoice: not only does the FFT often produce<br>utter junk on output, it often spits out sonically<br>*interesting* junk.<br>Think of it as "found art," DSP-style.  <br>This makes DSP pitch-shifting and time-stretch<br>algorithms (like SoundHack) splendid synthesis<br>modules!  Because of the FFT's propensity to<br>act in a highly non-linear and bizarre manner,<br>it can mixmaster even the most mundane inputs<br>into utterly fascinating digital grunge.<br>But don't take my word for it.<br>Instead, let's consider 3 hands-on examples that<br>show just how wildly the FFT can misbehave:<br>[1] Try this one--take a short noisy percussive<br>sound (say, a breaking light bulb, or the thwack<br>of a hammer, or a recorded gunshot) and time-<br>stretch it by a factor of 100.   Surprise!  Although<br>intuition would lead you to suspect that the output<br>would simply be a very long very loud rumble,<br>such is not the case!  Instead, what you get out<br>bears *no sonic relation whatever* to the input:<br>the output is a wild series of rising and falling<br>sine waves, a strange and xenharmonic surf of<br>exotic glissandi and portamenti--1000 violins<br>run amok with tremolo from hell.<br>[2] Now take a short 100-sample burst of noise--<br>say, from an arc welder, or off a radio being <br>tuned--and time-stretch it by a factor of 100, <br>then  another factor of 100 (10,000 all told).<br>Surprise!  The output will be a long digital<br>shriek composed of many sine waves rising<br>and falling.  Surprise #2: the shriek will<br>gradually die away into silence after several<br>minutes.  Yes, even though the input was <br>noise of a constant level, the output is not<br>only a set of pitched gliding sine waves, but<br>one which fades away into *nothing!*<br>[3]  Digitally pitch-shift a perfectly harmonic sound<br>(say, a triangle wave or a square wave) by<br>an irrational factor...say, a 12-TET minor third.<br>Surprise!  The output sound will suffer from<br> periodic "blips" in its amplitude and<br>severe overall phasing--in fact the original<br>boring triangle or square wave will sound as<br>though it's been passed through a Leslie<br>speaker simulator and then a phaser, along<br>with a chopper modulator that makes<br>the sound's envelope flutter audibly.<br>---<br>How can such things happen???<br>Listen up: this may be the only time anyone <br>tells you the whole truth about the FFT.<br>In case [1],  time-stretching a sharp percussive<br>noise produced a series of wild rising<br>and falling sine waves because we tried to<br>use the FFT to analyze and resynthesize a<br>noise impulse as though it were made up of <br>a collection of sine waves.<br>Remember the admonition at the start of this<br>post?  A mathematical technique is *only*<br>useful for analyzing those inputs which<br>adhere to the assumptions underlying that<br>technique.  And in this case, our assumptions<br>were fatally flawed--we tried to model the<br>sound of a light bulb smashing as a set of<br>sine waves.<br>Sorry: this doesn't work in the real world.  <br>As opposed to pie-in-the-sky theoretical<br>inputs made up of perfectly harmonic sinusoids,<br>many common everyday sounds in the<br>real world are not even remotely well<br>modeled as collections of sine waves.  <br>What took place inside the FFT algorithm that's<br>at the heart of SoundHack's time-stretch<br>algorithms is worth examining in detail,<br>because it will demonstrate just how <br>badly such so-called "digitally perfect"<br>algorithms as the FFT can misbehave.<br>To see what happened, think back on the<br>way you got bell sounds out of an<br>old analog synth.  Remember?   First you'd<br>crank up the voltage controlled filter to<br>a whopping big Q, until it was just about<br>to warble into oscillation.  Then you backed the<br>filter's Q knob off just a bit and plugged<br>a short sharp impulse into the filter's<br>input.  On the Arp 2600 a trigger pulse<br>(which is generally *never* used as an<br>audio output--it's meant to trigger an<br>outboard synth or an analog sequencer or<br>envelope generator!)  made a dandy candidate.<br>What happened, of course, is that the<br>short sharp impulse hit the filter with<br>a whole bunch of freqencies. (Remember,<br>the frequency and time domains are inverse<br>to one another: an impulse narrow in the time<br>domain is broad in the frequency domain. <br>Thus a sharp short spike like a trigger<br>pulse contains a wide band of sine<br>waves in the frequency domain) The filter<br>stored those frequencies and smeared<br>them out over time.  Moreover, because<br>the filter had a very high Q it was near<br>the conditions necessary for self-oscillation,<br>and the burst of energy from the trigger<br>pulse pushed the filter over the edge and<br>made it "ring" for a while.<br>So the output was a rich clangy bell sound,<br>with lots of bizarre spurious sine waves<br>generated by the filter itself.  The capacitors<br>in the filter circuit delayed each of the many,<br>many sine waves in the trigger pulse by<br>a different amount, spreading them out<br>over time: and the self-oscillation of the<br>filter added huge numbers of overtones<br>at the natural resonance frequency of the<br>filter itself (a frequency determined by<br>the capacitance, inductance, and resistance<br>of the filter circuit).<br>The end result is that a perfectly ordinary<br>little click, when fed into that analog<br>filter, generated a completely unexpected<br>result: a deep inharmonic bell clang that<br>lasts several seconds.<br>If you'll remember that a filterbank is<br>at the heart of the FFT, you'll now realize<br>what was happening when you fed the poor<br>defenseless FFT that short sharp breaking-<br>light-bulb sound. <br>Extreme values of time-stretch are analogous<br>to raising the Q of an analog filter.  In this<br>case, the energy from each time-slice of<br>the FFT was carried out into many, many<br>other frames because the extreme<br>time-stretch cranked down drastically<br>the rate at which the short-time FFT was <br>permitted to change its output.<br>The net result is that the energy from<br>each FFT frame built up and built up,<br>until finally it sent the individual filters<br>of which the FFT is made into a brief<br>period of self-oscillation.<br>At the same time, the digital filterbank<br>which lies at the heart of the FFT<br>spread those sine waves out in time.<br>This explains the wild rising and falling<br>sine waves--whose amplitudes rise<br>and fall as their phases coincide<br>constructively or destructively.<br>This last phenomenon is the clue<br>to case [2], in which a noise burst<br>of constant level is changed into a<br>shriek which decays into silence.<br>Because of the extreme time-<br>stretch (here, a factor of 10,000!)<br>the many sine waves generated<br>by the FFT's filterbank bled<br>away at a rate controlled by the<br>internal "circuitry" of the FFTs<br>digital filters--in this case, the<br>various constants used inside <br>the FFT itself, which correspond<br>to delay times and filter gains and<br>tap coefficients. In effect, we<br>"whacked" the FFT with a<br>100-sample impulse and it<br>reverberated for a while, then<br>died away.  This is in fact a<br>classic example of the impulse<br>response of an FIR filterbank at <br>the heart of a real-world FFT.<br>In case [3] the filter tried to<br>approximate an irrational<br>quantity with the ratio of 2<br>integers.  In this case, the<br>attempt failed because the length<br>of the FFT wasn't very large, and so<br>we tried to approximate an irrational<br>number with 2 *small* integers.  <br>Remember:  an FFT algorithm<br>does pitch-shifting by changing the<br>decimation factor of the input FFT<br>of the sound and then changing the<br>output sample rate conversion filter<br>so that the ratio of the two quantities<br>is as close as possible to the desired<br>pitch shift ratio.  However, in the<br>case of a ratio as irrational as 2^(4/12),<br>the FFT algorithm falls apart--because<br>ultimately it's limited by the fundamental<br>frequency of the sound itself.  If the<br>sound's fundamental is, say, 100 samples<br>in length, then the FFT *must* use a 128-point<br>window to preserve the fundamental of<br>the input sound.  This limits the granularity<br>by which the decimation factor/sample rate<br>conversion filter  can be changed.  And thus<br>(as usual with the FFT) we get a trade-off:<br>to pitch-shift a sound with extreme precision,<br>we must reduce the window size of our<br>FFT--but this amounts to throwing away most of<br>the frequency information in the original sound. <br>Conversly, the more precise our frequency analysis<br>of the input, the more coarse and granular the<br>amount by which we can ratchet the pitch<br>up or down via DSP methods.<br>---<br>Now that you've more insight into just how<br>bizarrely the FFT can behave, you might want to<br>try your hand at using the FFT to make microtonal<br>music.  This is a happy hunting ground for<br>the imaginative xenharmonist!  Talk about "found<br>scales..."  With a sound tool like SoundHack or<br>the Dolson vocoder, you can obtain "found scales"<br>from almost any kind of percussive sound--nor <br>do you need access to a digital audio workstation<br>or a mainframe!  You can do  impressive and <br>wildly microtonal-sounding compositions with the FFT<br>right on your home Mac or PC.<br>Here are some suggestions for ways to produce<br>*highly* xenharmonic music using the FFT:<br>[1] Try ring modulating a harmonic-timbre sound<br> & then  pitch-shifting or time-stretching it.<br>(To ring modulate a sound, just multiply it by <br>a fixed sine wave or set of sine waves.  Most<br>DSP tools allow the user to generate a fixed<br>signal with an arbitrary set of frequencies<br>and amplitudes, and also allow you to multiply<br>any signal by any other signal.)  <br>You'll discover that the more inharmonic a<br>sound, the wilder the output from the FFT--<br>regardless of the particular technique you<br>use.<br>[2] Try extreme time-stretching or pitch-<br>shifting of conversations.  Only a small part <br>of any given vocalisation consists of pitched<br>material: the rest is made up of glottals,<br>fricatives, plosives, labials, and the like.<br>Because these are *wildly* inharmonic<br>impulses, they're superb candidates <br>for teasing wacky microtonal goobidge from the<br>FFT.<br>[3] Try pitch-shifting or time-stretching<br>a sound by some large amount, then<br>save the sound in reverse order and<br>repeat the process.  As long as the<br>time-stretch or pitch-shift isn't a<br>power of 2, the result will be a<br>gobbling gibbering wobbling modulation <br>that's caused by the ratio of the two<br>incommensurate decimation rate-vs.-<br>FFT-widow-sizes.  This procedure<br>can generate some extremely unusual<br>timbres & highly xenharmonic pitches.<br>[4] Try multiplying one sound by another;<br>try dividing one sound by another.<br>You'll discover that division is equivalent<br>to high-pass filtering of one sound<br>ring-modulated by the other; it's incredibly<br>noisy.  Multiplying one sound by another<br>is equivalent to ring-modulating one<br>sound by the other.<br>Results are especially interesting if, say,<br>one input is Mozart and the other input<br>is The Sex Pistols.<br>[5] Try using an envelope follower to <br>control the amount by which you ring<br>modulate a sound; also try making<br>the relationship inverse. (That is,<br>division instead of multiplication.)<br>For pitched highly harmonic material,<br>this can turn a western symphony<br>orchestra is something like a <br>demented gamelan; it's endlessly<br>entertaining, particulatly with the<br>100 strings of Montovani.<br>[6]  Some DSP packages allow you<br>to use a phase vocoder to generate<br>a set of time-varying filters.  This<br>is a real gold mine.  The mundane<br>usage is to analyze speech and<br>apply the time-varying filters to<br>a flute, an electric guitars, etc.,<br>ad nauseum.<br>But it becomes *really* interesting<br>if you abuse & misuse the algorithm<br>by "analyzing" the sound of a<br>thunderstorm, say, or a recording<br>of bugs frying on an electric bug<br>zapper, and then apply the weird<br>non-linear time-varying filters thus<br>obtained to, say, the sound of a<br>ditch witch, or a building being <br>demolished.   The end result, as<br>Carter Scholz put it, is akin to<br>"Lloyd Bridges giving a lecture on just <br>intonation while wearing a scuba <br>regulator and breathing helium."<br>*Highly* xenharmonic!<br>--mclaren<br><br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Sun, 29 Oct 1995 18:03 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id BAA05391; Sun, 29 Oct 1995 01:04:04 -0800<br>Date: Sun, 29 Oct 1995 01:04:04 -0800<br>Message-Id: <Pine.3.89.9510291016.A12098-0100000@styx.ios.com><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2218 href="#2218">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/29/1995 8:35:42 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Our friends at Ensoniq<br>---<br>To date little has been said regarding the<br>Ensoniq corporation.  Someone needs to point<br>out how much we owe  people like Steve Curtin,<br>and his fellow Ensoniq engineers.<br>Let's start with the fact that if you want a<br>sampler with built-in tuning tables,  were it <br>not for Ensoniq you'd be in deep guano.<br>It's incredibly important that a sampler include<br>a tuning table.  Without one, the only<br>reliable way to break out of 12 on a sampler<br>is to use a separate sample for each MIDI note.  <br>This gobbles memory at a *staggering* rate.  For a 2-<br>second stereo sample at 44.1 Khz spread over (say)<br>36 notes, this would demand 6.05 megs of RAM <br>*per MIDI channel.*<br>For 16 MIDI channels, that's a mind-boggling<br>96.89 megs of RAM!<br>By contrast, if your sampler allows you to<br>use a tuning table you save an *incredible*<br>of RAM.  Moving to more than 12 tones<br>per octave lets you spread each sample over<br>even *more* keys than in 12--for a 31-tone<br>equal tempered tuning, for instance, you can<br>spread each sample over 31/12 times as<br>many MIDI notes.  This means that if you've<br>got a multi-sampled sound that spreads<br>each sample over (say) 3 MIDI notes in 12,<br>a tuning table allows you to *drop* memory<br>requirements by letting you spread each sample<br>over 8 MIDI notes.  <br>Compare the two situations.  In one case, the<br>lack of a tuning table forces you to gobble RAM<br>by using 36 separate samples; in the other case,<br>a built-in tuning table lets you *save* that RAM<br>by using only 36/7.8 = 5 separate samples. The<br>savings in RAM is ENORMOUS: a full <br>[1 - (36 - 5/36)] * 100 = 80%!  <br>This really matters.  <br>We're not talking about just 10% or <br>even 20% or 30% savings of RAM here...a tuning <br>table makes an ENORMOUS differece.  It lets<br>you use 1/2-1/6 of the memory you'd otherwise use.<br>This is *crucial* because the problem with every<br>sampler is lack of RAM.  No matter how much <br>you've got it's never enough.  And forcing the<br>microtonal user to burn up gobs and gobs of RAM<br>by duplicating each sample on every single MIDI<br>note is so wasteful as to defy description.<br>Clearly, Ensoniq's inclusion of a tuning table (a<br>separate tuning table for each layer of each sample,<br>in fact) on the ASR-10 qualifies as one of<br>the biggest gifts to microtonalists ever. <br>Period.<br>Of course, there's more.<br>Ensoniq builds reliable products.  They sound pretty<br>good.  Other companies have flashier technology,<br>but Ensoniq's synths sound about as excellent as<br>anything out there.  The big *musical* advantage<br>Ensoniq enjoys, of course, is that they've supported<br>micrtonality by including built-in tuning tables<br>every since 1989.   I'm not sure why they made that<br>decision--there doesn't seem to be a lot of <br>economic benefit in tuning tables.  However, I can<br>say that I've bought a bunch of Ensoniq gear ever<br>since they started building tuning tables into their<br>synths.  As long as they keep including tuning tables,<br>I'll keep buying their equipment.<br>This is particularly noteworthy behavior for a large<br>synth manufcaturer because many of the other clueless<br>and brain-dead synth companies still refuse to include<br>full-keyboard microtuning.  Especially the Japanese.<br>Weird, when you think about it.  Which culture uses<br>a non-12 pentatonic scale?  (The Japanese)  And which<br>culture is more frenziedly committed to 12-TET?<br>(The Japanese!) Kawai, Akai and many others<br>fanatically refuse to let their instruments be retuned.<br>They're adamant about it to the point of psychosis.  The<br>behaviour is almost Manson-like in is self-destructivness,<br>yet they persist.<br>As a result I won't buy Kawai or Akai synths.  Let 'em<br>rot: they can come out with a synth that does<br>everything buy makes coffee and I still wouldn't even<br>use it as a boat anchor.<br>Ensoniq's commitment to microtonality deserves special<br>mention on this forum.  I have nothing but good things to<br>say about their synths. (it would nice if they dropped their<br>prices, but then I wish all mfrs would drop their prices;<br>what else is new?) Bottom line: if you're serious about<br>microtonality, eventually you will discover that kludges<br>and gyrations and contortions and weird clumy work-<br>arounds like tuning each note with pitch-bend, etc.,<br>just don't work after a certain point.  You run out of<br>MIDI bandwidth, notes start to get dropped, attacks <br>sound twangy, and the logistics of such kludges just<br>become insupportable for even moderately complex<br>compositions.<br>In the end, a built-in full keyboard tuning table is <br>an absolute  necessity for serious MIDI microtonality.<br>And Ensoniq and Yamaha are the only two synth <br>manufacturers that have consistently stuck to<br>their support for tuning tables.  <br>Best of all, Ensoniq--unlike Yahama--has refused to<br>throw away its best technology.  Yamaha's insane<br>decision to stop making FM synths is a mistake Ensoniq<br>would never have made: instead, Ensoniq just keeps<br>making its instruments bigger, better and more<br>capable.  Ensoniq refuses to give up on a product. <br>They just keep adding features and upgrading the<br>ROMs until the synth does everything you could reasonably<br>want.  That's a good attitude for a synth company to<br>have, especially nowadays when the Japanese are<br>coming out with a new model every 6 months that<br>renders obsolete all previous RAM cartridges, editors, <br>voice disks, etc.  but doesn't sound any different or<br>do any more than the Japanese synths of 5 years ago.<br>Bottom line?<br>Everyone on this forum should offer Steve Curtin and<br>his fellow engineers at Ensoniq a very long,<br>very appreciative round of applause.<br>We owe them a lot.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Mon, 30 Oct 1995 07:07 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id VAA17788; Sun, 29 Oct 1995 21:07:07 -0800<br>Date: Sun, 29 Oct 1995 21:07:07 -0800<br>Message-Id: <951030050412_71670.2576_HHB30-6@CompuServe.COM><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2224 href="#2224">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/31/1995 10:27:18 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Models of reality, the Fourier<br>  mindset, and negative eigenvalues in<br>  Sturm-Liouville problems<br>---<br>Charles Lucy has been regularly pilloried<br>in this forum for his doubts about the<br>Fourier analysis model of acoustic<br>systems.  Several months ago, in Topic<br>1 of Digest 404, John Chalmers also stated <br>that "I can think of no physical principle <br>which would favor flat fifths over natural..." <br>This is a concise expression of a general<br>attitude among acousticians and music<br>theorists, most of whom are not fully<br>conversant with the physics behind the<br>conventional textbook description of<br>vbrating strings and air columns.<br>In fact there are good solid physical  reasons <br>why no simple harmonic mechanical oscillator<br>ever produces strictly harmonic oscillations,<br>and will instead tend to generate partials<br>which are either systematically stretched<br>or shrunk by comparison with the expected<br>harmonics.  There are also excellent physical<br>reasons why 2- and 3-dimensional physical<br>oscillators will in general not exhibit either<br>linear or harmonic oscillatory behavior at all.<br>This point bears on Lucy's criticism of the<br>Fourier analysis mindset that characterizes<br>much of the discussion of this forum, and<br>in a larger sense it also bears on the question<br>of which tunings we use--or even contemplate<br>using.<br>Ultimately, the musics we choose to make are<br>limited by our model of the world.  Whenever<br>we tune an instrument, we inevitably begin<br>to impose a structure on physical reality:<br>and the type of structure we choose to impose<br>is determined by our preconceptions.<br>In the West and Mideast, ever since the time<br>of Pythagoras and almost certainly (before<br>that) the Babylonians and the Egyptians, we<br>(in the West) have conceived of the universe as ruled<br>by number.  The predictive value of number is a<br>touchstone of classical Hellenic thought.<br>This had profound implications<br>for the kind of music made in Greece and<br>the European cultures.<br>However, other cultures bring other<br>preconceptions to the process of tuning.<br>There is no evidence (as Marc Perlman has<br>pointed out) that the Javanese, the Balinese,<br>or any of the other cultures of Southeast<br>Asia conceive of the universe as a manifestion<br>of number, except perhaps in the Kabalist<br>sense implied by gematria, the geomancy of the<br>Dogon peoples of Mali, etc.  Thus their tuning systems do <br>not arise from mathematical or physical-acoustic<br>considerations, and as a result Javanese and<br>Balinese music does not employ the 2:1 octave,<br>4:5:6 harmonies or harmonic-series timbres. The<br>same is true of the  musics found in Africa,<br>Central Asia, most of the South Seas islands and<br>South America.<br>None of these cultures appear to conceive of<br>music in the mathematical framework typical<br>of Western thinking; indeed, as Jon Appleton<br>has pointed out, in many other cultures<br>music is often not analyzed at all, but regarded<br>as belonging to same realm as magic.<br>Thus one's preconceptions exert a potent<br>influence on the kind of music one chooses <br>to make, and different models of reality<br>produce different kinds of tuning.<br>The simple harmonic oscillator equation<br>is one model of reality.  <br>There are many others even within the<br>confines of Western mathematics.<br>According to the simple harmonic motion <br>equation, the displacement<br>x = A*sin(sqrt(k/m)*t) + B*cos(sqrt(k/m)*t)<br>where k is the spring constant, m is<br>the mass, and t is the elapsed time<br>(A and B are constants of propotionality).<br>This is a recipe for perfectly harmonic<br>behaviour.   <br>But the equation which describes<br>simple harmonic motion is a drastic<br>simplification of reality, and there<br>are many other (more sophisticated)<br>mathematical models which describe<br>the same physical oscillatory system.<br>For example, when a simple tube is<br>excited with a laminar airflow the air<br>in the tube will oscillate at a characteristic<br>frequency determined by the length of<br>the tube, the density of the air, the<br>location and number of tone holes, etc.<br>Increasing the airflow produces a  stronger<br>second harmonic, and so on, according<br>to this model.<br>But in the real world two modes of<br>oscillation (fundamental and second harmonic)<br>in a tube tend to "pull in" toward each other<br>so that the fundamental rises slightly in<br>frequency, while the second harmonic drops<br>slightly in frequency.  The simple harmonic<br>motion model of reality cannot explain this<br>because it views air molecules as billiard<br>balls connected by springs, and<br>the system cannot behave in any but<br>a perfectly harmonic way.<br>If instead we look at the air-filled tube as<br>an energy exchange system from a <br>thermodynamic viewpoint, or if we<br>view it as a state-space system, or<br>if we consider it from the standpoint<br>of continuum mechanics, the reasons<br>for the slight inharmonicity of the<br>oscillations become obvious.  Setting<br>up a fundamental mode of oscillation in the <br>the tube changes its acoustical admittance;<br>a second oscillation mode will then lose energy<br>or gain energy, depending on the phase<br>of its compressions and rarefactions <br>relative to that of the fundamental mode.<br>Since the system will tend to minimize its<br>overall potential energy the two acoustic<br>modes will couple; and because the <br>system is closed (negigibly energy is<br>lost via acoustic radiation), the energy lost<br>from the second mode of oscillation has<br>to go somewhere and not all of it will be<br>either transmitted out the bore of the <br>tube or lost as friction against the walls<br>or in the friction created by turbulent non-laminar<br>flow around the tone holes, etc.  Thus the<br>energy lost from the second mode of oscillation<br>will partly flow into the fundamental mode of<br>oscillation, which in turn forces a <br>change in its period.<br>This example serves as a warning about<br>the models we use to explain physical<br>system, and consequently to justify the<br>tuning systems we use.  In the case<br>just considered, the inharmonic behaviour<br>is slight--as long as flow of air through<br>the tube remains slow and laminar.  Thus <br>it can be handled by perturbation theory,<br>as in lord Rayleigh's "Acoustics" of 1896. But<br>as the airflow increases, the flow becomes <br>non-laminar.  Multiphonics appear;<br>then the oscillation patterns become<br>quasi-periodic, start to break up, and<br>finally become completely aperiodic.<br>The oscillation turns to noise.<br>Viewed as a simple energy exchange<br>system, our model cannot explain this.<br>But if we step back yet again and realize<br>that the energy-exchange system we've<br>been picturing is a drastic simplification<br>the reason for this behaviour becomes clear.<br>If, instead, we view the partial differential equations <br>which describe the interaction of non-linear<br>acoustic admittance,  non-laminar airflow and<br>radiated, transmitted and absorbed mechanical<br>energy, and boundary conditions from the<br>viewpoint of complexity theory...  Then it becomes<br>obvious why the system beahves as it does.<br>"Little is known concerning boundary value<br>problems for general nonlinear differential<br>equations..." [Courant and Hilbert, "Methods<br>of Mathematical Physics," 1962, pg. 367.<br>For the class of hyperbolic PDEs which<br>describe one-dimensional physical<br>oscillatory systems, perturbation theory<br>is the classical method of dealing with<br>the increased airflow described above. <br>But as we've seen this does not work<br>beyond a very limited regime.  Nonlinear<br>dynamics must be invoked beyond the region<br>of non-laminar airflow, and in this regime<br>the oscillations in the tube move from<br>being ordinary attractors in phase space<br>to being strange attractors, whose behaviour<br>not only jumps back and forth between<br>aperiodicity and quasi-peridiodicity, but<br>also spans the complete gamut from<br>pure noise to harmonic oscillation. Viewed<br>in phase space, the operation of the compressions<br>and rarefactions in the air of the tube follow<br>orbits which can be bounded, yet not precisely<br>predicted, and which depend crucially on<br>initial conditions.<br>Lest you imagine such chaotic behaviour is<br>restricted only to airflow in tubes,<br>note that in the case of the wave equation<br>describing the general nonhomogeneous <br>vibrating string "whenever an eigenvalue is<br>negative an aperiodic motion occurs <br>instead of the corresponding normal<br>mode." [Courant and Hilbert, "Methods of<br>Mathematical Physics," Vol. 1, pg 292]<br>Thus chaotic oscillation can occur<br>even in vibrating strings--in fact<br>in any one-dimensional oscillator<br>described by a Sturm-Liouville<br>eigenvalue problem.<br>This is not commonly known.<br>Why?   <br>Because every textbook on acoustics<br>which treats the wave equation and<br>the vibrating string  assumes<br>that the egienvalues will never become<br>negative.  As a result, the true complexity<br>of the behjvaiour of even so-called<br>"simple" 1-D physical oscillatory systems<br>is masked from the unquestioning students.<br>(These simplifying assumptions are made<br>so that the equations can be quickly and<br>easily solved.  The usual dodge is to claim<br>that "negative eigenvalues have no physical<br>significance." As so often in physics and<br>engineering, this is a fudge.  In fact <br>the problem is just systematically<br>restricted and our viewpoint successively<br>limited until we arrive at equations which <br>undergrad-level mathematics can dispatch <br>with elegance in a neat closed form.)<br>And what does all this have to do with<br>tuning?<br>The debate on this forum has mostly centered<br>around a restricted set of musical tunings--<br>JI, meantone, a few equal temperaments which<br>well approximate the lower members of the<br>harmonics series.  And this tiny subset of<br>tunings is derived from simplistic physical <br>models (as we've seen).  These acoustic models<br>are described by the usual textbook<br>solutions of the wave equation, simple<br>harmonic motion, and the rest of the<br>18th- and 19th-century baggage.<br>But the reality can be very different from<br>the universe predicted by these 18th-century<br>mathematical models.  <br>"For three centuries science has successfully<br>uncovered many of the workings of the<br>universe, armed with the mathematics of<br>Newton and Leibniz.  It was essentially a<br>clockwork world, one characterized by<br>repetition and predictability. (..) Most of<br>nature, however, is nonlinear and is not<br>easily predicted. (..) In nonlinear systems<br>small inputs can lead to dramatically<br>large consequences." [Lewin, Roger, <br>"Complexity," 1993, pg. 12]<br>By now it should now be clear why the Fourier <br>transform has gained such popularity, and also <br>why Charles Lucy's doubts about it are<br>well-founded.  In "a clockwork world,<br>one characterized by regularity and<br>predictability," a mathematical technique<br>which breaks all physical oscillations<br>down into sets of perfectly periodic<br>sinusoidal functions with no beginning<br>and no end makes a lot of sense.  In a<br>clockwork 18th-century universe, the<br>Fourier transform enjoys enormous descriptive<br>power.<br>But we now know that the 18th-century clockwork<br>model of the world is not a complete picture.  In the<br>real world, where chaotic strange attractors<br>characterize the action of real oscillatory<br>systems, the Fourier transform often falls apart.<br>And instead of describing reality, the Fourier<br>transform can put blinders on us and prevent<br>us from seeing the world as it really is.<br>In some cases, this is unimportant--because<br>the oscillations of real physical systems are<br>sometimes only a little different from the simplistic<br>clockwork-universe description of the Fourier<br>Theorem.  In instruments like strings, winds<br>and brasses (after the initital attack of the<br>tone is over, and if the instruments aren't<br>played too loudly, and if we're talking only<br>about the notes in the middle range of these<br>instruments) a short-time Fourier analysis<br>tells us *something* about what's going on<br>in *some* of the notes, during *part* of<br>their duration.  But even for this restricted<br>class of sounds, Fourier techniques fail <br>during the first 10 milliseconds or so of the<br>note's attack. FFTs fail because when t < 10ms  <br>the amplitude and frequency of the component<br>partials are both changing with great rapidity,<br>and the Fourier transform *cannot* provide<br>accurate information about both the period<br>*and* the spectrum of an input function. An<br>increase in resolution in one parameter forces<br>a descrease in resolution in the other.  This is<br>inherent in the mathematics of the FFT, and<br>*cannot* be sidestepped.<br>A much greater limitation on the Fourier mindset<br>is the fact that most of the musical instruments used <br>by most of the cultures in the world are not violins<br>or French horns or flutes.  Most of the musical<br>instruments used by other cultures are two- <br>or three-dimensional oscillators which <br>generate inharmonic partials & noise, and store<br>energy from one vibrational cycle to the next...<br>so that their behaviour is often extraordinarily <br>non-linear.  See Rossing's discussion of the<br>energy storage from one cycle to the next in<br>a tam-tam, for example. [Rossing, 1992]<br>For such instruments, the Fourier description<br>is a hindrance rather than an aid to understanding.<br>And the class of tunings to which we in the west <br>have systematically restricted<br>ourselves--namely JI, meantone and equal<br>temperaments with good approximations of <br>the lower harmonics--are also inadequate for<br>such instruments. <br>This perhaps addresses John Chalmers' doubts<br>about the validity of any "physical system that<br>would favor flat fifths over natural." Simply<br>moving from one-dimensional physical oscilaltors<br>to two- and three-dimensional oscillators<br>generate fifths which are either *very* flat or<br>*very* sharp (depending on the oscillatory<br>geometry)...indeed, the whole 18th- and 19th-century<br>armamentarium of Western acoustic terminology is <br>inapplicable to such  physical oscillators: "fifth" and <br>"third" and "natural harmonics" are terms without<br>meaning for such physical systems. The tam-tam<br>or the metallophone or the vibrating drumhead<br>or (as we've seen) even purportedly "simple"<br>one-dimensional systems like the vibrating<br>string often operate in the region of complexity...<br>a region of oscillation that lies between the<br>complete chaos of noise and the clockwork perfection<br>of perfect harmonicity.  The Fourier view of<br>the universe does not yield useful information<br>when applied to such acoustic systems, or<br>even when applied to a vibrating string characterized<br>by negative eigenvalues in the associated<br>Sturm-Liouville equations.<br>One of the central revelations of complexity<br>theory is that patterns lie hidden in chaos.<br>Emergent order appears ex nihilio when <br>systems reach the edge of chaotic behavior,<br>as in woodwind multiphonics, etc.  In fact<br>the Brookhaven National Laboratory phsyicist<br>Per Bak has developed the hypothesis that<br>dynamical systems naturally evolve toward<br>a critical state in which the edge of chaos<br>spontaneously generates order. [See Bak, P.<br>and Chen  K,. in Scientific American, Jan. 1991;<br>also see Packard, N., "Adaptation Toward the<br>Edge of Chaos," Technical Report, Center for<br>Complex Systems Research, University of<br>Illinois, CCSR-88-5, 1988.]<br>What does this have to do with tuning &<br>music?<br>It seems possible (if not probable) that<br>non-just non-equal-tempered tunings <br>represent an adaptation toward spontaneous<br>order generated by the non-linear dynamical<br>systems used in so many other musical<br>cultures (i.e., two- and three-dimensional<br>physical oscillatory systems: drums, <br>flat or curves metal plates, non-linearly<br>coupled oscillators like those used in<br>parts of Africa in conjuction with resonant<br>strings, etc).<br>Interestingly enough, throwing away the<br>Fourier transform does not mean a loss<br>of predictive power.  Many other analytic<br>models for acoustic systems exist: Walsh<br>transforms, Daubechies wavelets, Gabor's<br>acoustic quantum, and even more recent<br>non-linear mathematical transforms such<br>as the slope transform [See Maragos, P., <br>"Slope Transforms: Theory and Application <br>to Nonlinear Signal Processing," IEEE<br>Trans. Sig. Proc.,  43(40, Paril 1995, pp. <br>864-877.]<br>The fact that so astute and insightful<br>a thinker as John Chalmers could fall<br>into the trap of looking at all tuning<br>systems and physical oscillators through<br>the narrow distorting lens of the<br>Fourier transform is an indication of<br>the power the Fourier mindset to<br>brainwash the unwary.  While the Fourier<br>transform is a marvellous mathematical tool,<br>is does not describe all of acoustic reality--<br>only a small part of it.<br>Thus  Charles Lucy's doubts about the<br>universal value of the FFT are well<br>founded, and the attacks he has suffered<br>for voicing these doubts in this forum<br>are an indication of just how thoroughly<br>the Fourier mindset can blind us to the<br>wonderfully complex nature of real <br>instruments, real tunings and real music<br>in the real world.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Tue, 31 Oct 1995 20:59 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id KAA08873; Tue, 31 Oct 1995 10:58:57 -0800<br>Date: Tue, 31 Oct 1995 10:58:57 -0800<br>Message-Id: <v01530502acbc2e7c1883@[194.137.64.56]><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2228 href="#2228">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>11/1/1995 10:05:06 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Music & western science<br>---<br>On encountering the interesting book<br>"Measure for measure: a musical history<br>of science," by Thomas Levenson, one<br>passage in particular caught my eye:<br>"Music and science have been intertwined in<br>Western thinking from the moment of their<br>shared origins, of course: the first even<br>vaguely scientific theory of the universe<br>was a musical one, Pythagoras' arrangement <br>of the planets on the scaffolding of his musical<br>intervals, with every heavenly body sounding<br>out its note in what became known as the music<br>of the spheres." [Levenson, T.,  1994, pg. 13]<br>Even though this is probably incorrect (the<br>Bablyonians, Egyptians & Sumerians likely<br>originated most of the musical and geometric<br>discoveries attributed to Pythagoras), Levenson<br>makes a cogent point.<br>To a large extent the current schism in music can be<br>described by the three stages of Western science:<br>Newtonian science, quantum theory and nonlinear<br>dynamics.<br>The Newtonian model of the universe is a giant<br>clockwork mechanism.  Harmonic cycles naturally<br>arise from such a scheme: the well-known <br>example in elementary physics textbooks of<br>planetary orbits as clocks naturally suggests the<br>idea of ratios between oscillating cycles of <br>both planetary and (inside the atom) electron-<br>orbital motion.<br>In the macroscopic everyday world, tides,<br>rates of chemical reaction, the compounding<br>increase in velocity produced by uniform Newtonian <br>acceleration, as well as the  densities of<br>Maxwell's electric and magnetic fields as a<br>function of distance from the charge center all<br>produce sets of ratios.  In a Newtonian universe, it's<br>hard to escape from ratios--and many of them <br>involve small integers.<br>Such a worldview inevitably tilts toward just intonation.<br>This bias is not necessarily conscious.  It is so pervasive<br>that it often shows up as an unconscious or even<br>as a subsconscious  assumption--a "well, of <br>course...obviously" set of musical axioms <br>from which all subsequent musical theorems derive.<br>In the quantum universe, however, particles are<br>replaced by probability  waves--exotic<br>critters often called "wavicles."  The best way <br>to deal with a quantum universe is a pragmatic<br>approach: sum the probabilities, assume the<br>most likely interaction, calculate the likely result.<br>This sort of approach suggests equal temperament--<br>not a perfect intonation, but given the pragmatic<br>realities (and the uncertainties in performed<br>pitch and actual tuning) the best compromise.<br>Chaos theory views the universe as a playground<br>for nonlinear dynamics.  Here, bifurcation and<br>period-doubling render predictions useless even<br>when made by the most powerful computers: <br>an *infinite* number of digits is necessary<br>to represent initial conditions accurately.<br>In the real universe of nonlinear mechanics,<br>planetary orbits grow chaotic and cannot be<br>used as celestial clocks over more than a few<br>hundred million years. (See "Newton's Clock,"<br>Ivars Peterson, 1994.)<br>This view of the universe stresses the nonlinearity<br>of real physical processes and naturally gives rise<br>to non-just non-equal-tempered tunings (that is,<br>tunings not generated either by Nth roots of K or<br>by ratios of integers).  These tunings are just<br>as "natural" as the harmonic series...yet such tunings<br>are profoundly alien to Western music.<br>It occurs to me that a good deal of the friction on<br>this tuning forum between advocates of this or that<br>tuning system derives from a deeper cognitive<br>dissonance twixt contrary worldviews.  One of the implicit<br>goals of the JI crowd seems to be a clear distinction<br>between consonance and dissonance: this implies, presumably,<br> that consonance can be unambiguously defined as<br>*sensory* consonance, and that more complex notions<br>like concordance and ambisonance can be derived<br>directly therefrom.  In a universe thus ordered,<br>the JI view is that of a cosmos capable of balance,<br>rationality, harmony and what the Hellenes called<br>"taxis," along with the related concept of "logos"<br>(which only very rarely means "word:" more often<br>"logos" mean "underlying order behind," as in<br>meteorology = "the underlying order behind the<br>sky.")<br>The main goal of the equal-tempered crowd, by contrast,<br>seems to be "to get something that works with usable<br>instruments."  Equal temperament aficionados stress<br>the ease of modulation, the ready-to-use simplicity of<br>their tunings.  No infinite sea of commas, no troubling<br>hard-to-classify intervals like the 11/9 or the 9/7.<br>This accords with a subconscious view of the universe<br>as a place in which uncertainty and chance conspire to<br>defeat efforts to attain harmony, balance, simplicity:<br>instead, the best we can hope for (according to this<br>view) is a workable compromise.<br>The chaos-theory worldview is by far the most radical.<br>It's one that's still working its way through our culture.<br>While the Newtonian cosmos produced Baroque music<br>and Christopher Wren's architecture, and the quantum<br>worldview produced modernism and Bauhaus glass-cube<br>monopitch-roof architecture, the chaos-theory universe hasn't<br>yet made its full impact felt on art and music and<br>literature.  A few compositions like Bruno de Gazio's<br>algorithmic works of the early 1990s and Mark Trayle's<br>Mattel Power Glove compositions have filtered into<br>our consciousness...but by and large the *weltbildung*<br>suggested by chaos theory seems hallucinogenic to <br>Western artists and composers and writers.  The idea<br>that the universe is a place shaped by violent, complex, <br>unexpected events which grow out of microscopic<br>chance events...well, it's  not a comfortable one.<br>The notion of huge effects blossoming from trivial causes<br>is not something with which Aristotelian dramatic<br>theory is well equipped to cope.  It's as though Oedipus were<br>and his entire family were to die horribly from infections <br>caused by scratching mosquito bites(!) In music, however,<br>the seeds of this kind of exponential and uncontrolled<br>growth of emergent structure  have always been nascent<br>in Western tradition.  Ever since composers began to<br>generate huge compositions from small cellular<br>motifs, the notion of order boiling out of chaos seems<br>to have lurked just outside the peripheral vision of<br>Western music theory.<br>Of course, non-just non-equal-tempered tunings<br>are particularly alien to our (read: white European) <br>concept of music. <br>And so it's fascinating to note the historical Western<br>response to the Indonesian gamelan, which uses a<br>classic n-j n-e-t tuning (in fact, each gamelan<br>uses a different one).<br>The first time a Western composer appears to have<br>encountered the gamelan was when Debussy heard <br>one at the Paris Exposition in 1895.  He was struck<br>most forcefully by the rhythms, which he ecstatically<br>described as "complex enough to put the finest<br>Western composers to shame" (or words to that effect;<br>this is from memory).<br>Mantle Hood's importation of a gamelan in 1956 appears<br>to have sparked Lou Harrison's interest, and a general<br>American gamelan movement--ironically founded on<br>tunings using just intonation.  As Marc Perlman has<br>pointed out,  this is a radical departure from actual<br>Javanese/Balinese tuning practice...  And it indicates<br>just how completely *unable* Western composers are<br>to assimilate the Javanese tuning in its *own terms.*<br>Indeed, Lou Harrison himself admitted to being<br>terrified of the non-just non-equal-tempered intervals<br>of "slippery slendro;"  without the Western rationalistic<br>landmark of small integers, he found himself at sea.<br>And finally during the 80s and early 90s digital signal<br>processing compositions produced with the spectra<br>and tones of gamelans (for example, Robert Valin's<br>"Tat tvam asi," 1990, UMUS CD "Bali In Montreal,"<br>UMM CD 104) again emphasize Fourier manipulations and <br>transformations.  *Again* the Western composer is <br>reduced to grasping at harmonics and integer-ratio<br>frequencies *even* when manipulating the raw<br>non-integer, inharmonic, non-just non-equal-tempered<br>partials and spectra of Javanese/Balinese<br>gamelan: *again,* there is a complete inability to<br>incorporate the gamelan worldview into the composer's<br>milieu and assimilate it as part of Western compositional<br>process. Instead, the Javanese n-j n-e-t tuning and<br>chaos-theory worldview of clashing rhythms producing<br>a mysteriously regular emergent order can *only* be<br>assimilated by the Western composer/theorist<br>if *first* coated with the antibodies of Fourier theory<br>and harmonic overtones.<br>Thus it's fascinating to observe the clashes between<br>these three factions on this tuning forum.  My <br>observations concerning non-just non-equal-tempered<br>tunings matched to n-j n-e-t additive-synthesis timbres<br>have provoked incomprehension, with some outright<br>hostility and no little puzzlement thrown in; meanwhile,<br>the main hot spot seems to be the flash point between <br>equal temperament advocates and JI enthusiasts.<br>This is particularly revealing because it shows not<br>only the tremendously long lead time for new ideas <br>to percolate from the sciences into the arts, but it<br>also clearly demonstrates the enormous staying power of<br>classic worldviews. Many writers on just intonation<br>evoke a view of Apollonian poise and balance, and a<br>yearning for perfect order.  Indeed, the title of one<br>of the best current compilation series of JI music is in<br>itself revealing: "Rational Music For An Irrational<br>World."  A vision of literally classical order in a disarrayed<br>universe.   And (also revealingly) JI composers see<br> have a fondness for classical Hellenic subject <br>matter: from Partch's exceptional series of settings<br>of Greek drama to Fonville's setting of poems by<br>Sappho, the nostalgic quest for order and balance<br>harks back to the Italian Renaissance, the early part of <br>the 19th century in England, and the early 20s<br>of this century in England and America.  In such a<br>worldview, Keats' Greek vase is the ideal: "Heard melodies<br>are sweet, but those unheard/are sweeter; therefore,<br>ye soft pipes, play on;/ not to the sensual ear, but,<br>more endeared,/Pipe to the spirit ditties of no tone..."<br>[Keats, John, "Ode On A Grecian Urn," lines 11-14]<br>(Sounds almost as though Keats yearned for a yet-<br>unheard xenharmonic music far outside the 19th<br>century 12-tone equal tempered scheme of things...)<br> Modernism rarely evokes such longings.  Instead, the<br>emphasis in modernist music is often on statistical<br>and probabilistic effects. From the regular distribution<br>of pitch classes in the 2nd School of Vienna to the<br>thermodynamically- and quantum-theory inspired<br>stochastic sound-clouds of Xenakis, much modernist<br>music might almost be called  "quantum probability-<br>clouds made audible."  Subsequent refinement of these<br>procedures in algorithmic compositions programs <br>changed the emphasis, but not the essential inspiration--<br>nor the worldview implied.<br>And thus the best of modernist compositions conjure<br>up for me a statistically determined universe of <br>strange and terrifying beauty...and notably one in which<br>tuning is a secondary consideration.  Modernist <br>music appears to have emphasized the processes by<br>which pitches were *ordered,* rather than by which they<br>were *derived.*<br>Perhaps the existence of this forum signals a shift<br>toward the third or nonlinear worldview.  As the ideas<br>of chaos theory and complexity theory seep<br>into our culture, the notion of emergent order generated<br>at the edge of nonlinear musical processes becomes<br>more "natural" (the single word most fiercely<br>argued over on this forum, and perhaps the one word<br>used by the largest number of subscribers with the<br>largest numbers of different meanings) and more<br>acceptable.<br>Pushing forward, it's hard to see where this worldview<br>might take music...  The terrain ahead is indeed<br>alien.  One imagines algorithmic compositions generated<br>by nonlinear processes in which even the tuning is<br>produced at run-time, and is a different non-just non-<br>equal-tempered set of pitches in each performance.<br>On the level of the microstructure of musical tones,<br>Sethares', Pierce's, Carlos', Dashow's and (yes) my<br>notion of matching partials to tuning raises many<br>possibilities from hierarchical order in n-j n-e-t<br>compositions: notes whose overtone structure changes<br>kaleidoscopically as the pitches run through various<br>timbral strange attractors.  Jean-Claude Risset, Paul Lansky,<br>John Chowning, James Dashow, William Schottstaedt, <br>Richard Karpen, Mark Trayle, Cindy McTee, Richard Boulanger,<br>Hugh Davies, Jonathan Harvey, Warren Burt, William Sethares <br>and others have already produced compositions which<br>give a glimpse of this brave new musical world: and they<br>are indeed breathtakingly beautiful. <br>Still, very little work has been done in this area.  To quote<br>Ivor Darreg, "It will require the work of many composers <br>for many years to map out the vastness of xenharmonic <br>territory."<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Wed, 1 Nov 1995 20:55 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id KAA19194; Wed, 1 Nov 1995 10:55:39 -0800<br>Date: Wed, 1 Nov 1995 10:55:39 -0800<br>Message-Id: <199511011848.AA22720@net4you.co.at><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2234 href="#2234">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>11/2/1995 8:38:00 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: The Gelfond-Schneider Theorem and<br> non-just non-equal-tempered scales<br>---<br>It occurs to me that n-j n-e-t scales undoubtedly<br>seem more mysterious than either just or equal<br>tempered tunings because the mathematical<br>basis of n-j n-e-t scales is not as obvious.<br>This post attempts to clarify that mathematical<br>basis.<br>First, a word about traditional tunings:<br>If we describe the scale steps of any given<br>tuning as a number between 0 and 1, the<br>mathematical basis of just tunings is simple<br>and straightforward:  k[n] = A/B  where both<br>A and B are integers.  The only ambiguity here<br>is the question of whether or not A and B are<br>"small."  This is clearly a matter of personal<br>taste.  John Chalmers and Your Humble E-Mail<br>Correspondent consider many of Erv Wilson's<br>CPS  tuning to be examples of just intonation, and<br>thus made up of the ratio of "small" integers:<br>however, many of those integers are not small<br>in the usual sense defined by Partch, Doty,<br>Johnston, et al.  For example, the [1,7, 19, 37]<br>hexany consists of ratios of numbers to the<br>generator 7*19*37 = 4921.  This number is<br>"small" compared to a googol, or to the <br>number of atoms in the Local Cluster of<br>galaxies: but it is large compared to, say,<br>31 or 43.  Thus, some tuning theorists <br>would consider this Wilson CPS tuning *not*<br>to be a just tuning, while others *would.*<br>It is a matter of taste.<br>For equal-tempered tunings, the scale-<br>step is described with equal simplicity:<br>k[n] = 2^[n/M]<br>In this case every scale-step of every<br>equal-tempered tuning is described by<br>an irrational number.<br>So far, so good.   Just tunings have scale<br>steps described by ratios of integers: <br>equal-tempered tunings have scale steps<br>described by irrational numbers. <br>An irrational number is a real solution of an<br>algebraic equation.  An integer is the<br>real solution of an ordinal arithmetic <br>equation.<br>Thus tunings can be defined by the class<br>of equations to which the ratios which define<br>the scale-steps of the tuning form solutions.<br>For example: <br>Algebraic equations involve a finite<br>number of integers raised to integer<br>powers:  say, X = A + By^2 + Cy^5.<br>Ordinal arithmetic equations involve integers:<br>X = A/C + D or X = A*B, etc.<br>(You might have noticed that my definition<br>of integers is circular.  This is because the<br>question of what an integer is happens to<br>be a very deep one.  It is indeed very,<br>*very* difficult to define an integer in<br>abstract terms without using an equation<br>which involves integers.  If memory serves,<br>the Bourbaki collective devoted an entire<br>volume to the definition of an integer.)<br>This gives us a handle on what is meant<br>by a "non-just non-equal-tempered scale."<br>Clearly, if the scale-steps of a just scale<br>are *integers* and if the scale-steps of<br>an equal-tempered scale are *irrationals,*<br>then the scale-steps of a non-just non-<br>equal-tempered scale must be given by<br>transcendental numbers.<br>What is a transcendental number?<br>How is such a number defined?<br>Is there a general mathematical procedure<br>for obtaining transcendental numbers?<br>This, as it happens, is also a deep question.<br>In fact it is often *VERY* difficult to *prove*<br>mathematically that a given number is<br>transcendental.<br>For instance, e^pi is known to be <br>transcendental--but pi^e has never<br>been proven transcendental (though most<br>mathematicians believe it to be).<br>In fact the number pi itself was not<br>proven transcendental until 1882. <br>(F. Lindemann, in the paper "Ueber die<br>Zahl Pi," took that honor.)<br>One of the perplexities which attend<br>transcendental numbers is the fact<br>that while there is a general criterion<br>for determining whether a number is an<br>integer (Does it satisfy an ordinal arithmetic<br>equation?) and for determining whether<br>a number is irrational (Does it *NOT*<br>satisfy an ordinary arithmetic equation and is it <br>a real root ofan algebraic equation?) there <br>appears to be NO general criterion for <br>determining whether a number is <br>transcendental.<br>Consequently, many different (non-obvious,<br>counterintuitive) equations generate<br>transcendental numbers.<br>For example, the number i^i is <br>transcendental--in fact it is equal to<br>e^[-pi/2] = 0.2078795.   ("i" here refers <br>to the square root of -1.)<br>This sounds absolutely insane, but it<br>happens to be true...and provable!<br>Like quantum mechanics, many of<br>the results of mathematics follow<br>the rule: "If it makes intuitive sense<br>to you, then you don't really understand it."<br>The real part of log(i) is also<br>transcendental: log(i) = i*pi/2.<br>Thus, while there's no general<br>formula or method for generating<br>transcenedental numbers, quite a<br>few transcendental numbers have<br>been discovered over the last few<br>milennia...mainly by chance.<br>Here are few:<br>Liouville numbers have been<br>proven transcendental. They were<br>discovered in 1851 (much later<br>than pi or e) and are given by the<br>formula: Sum from k = 1 to<br>infinity over a[k]*r^[-k!] where<br>"!" means "factorial" and a[k]<br>is an integer twixt 0 and r.   <br>There are infinitely many<br>Liouville numbers.  For instance,<br>if all a[k] = 1 and base r = 10,<br>we get 1/10 + 1/(10^[1*2]) +<br>1/(10^[1*2*3]) + ...  =<br>0.1100010000000000000000001000...<br>Depending on how the a[k] are<br>chosen, many different Liouville<br>numbers arise. One might pick the<br>a[k] as the fractional part of the <br>decimal expansion of e, or pi, <br>or of an irrational number such<br>as 2^[1/3], etc. <br>Euler's constant gamma is transcendental.<br>It's given by the limit for n = - infinity<br>of the series 1 + 1/2 + 1/3 + 1/4 + ...+ <br>1/n - ln(n)<br>Gamma = 0.577215...<br>Catlan's constant is another lesser-known<br>number. It has not yet been proven <br>transcendental, but mathematicians<br>widely believe it to be. It's given by<br>the formula G = sum of (-1)^k/(2k+ 1)^2<br>= 1 - 1/9 + 1/25 - 1/49...<br>Chapernowne's number is also generally<br>believed transcendental.  It is constructed<br>by concatenating the digits of the<br>positive integers: C = <br>0.1234567891011121314151617181920...<br>As mentioned in my series of posts on<br>generating non-just non-equal-tempered<br>scales last year, the zeta function also yields<br>transcendental numbers.  However, my<br>post did not specify that the zeta function<br>must be evaluated at rational points: zeta(K)<br>can be either real or imaginary, since K can<br>be either real or imaginary.  For K not equal<br>to a real integer, zeta(K) is in general not<br>transcendental.  However this still leaves us<br>with zeta(2), zeta(3), zeta(5), etc., all<br>trascendental.<br>Of particular interest in the construction<br>of non-just non-equal-tempered scales is<br>the Gelfond-Schneider theorem.  According<br>to this theorem, any number of the form a^b is <br>trascendental where a and b are algebraic (a<br><> 0, a <> 1) and b is not a rational number.<br>This formula spews out an infinite number<br>of transcendental numbers, since (for example)<br>Hilbert's number, 2^[sqrt(2)] is clearly<br>transcendental, ditto 2^[sqrt(5)], 3^[fifth root of 7],<br>etc.<br>Feigenbaum numbers are also transcendental.<br>These numbers arise from chaos theory and<br>are related to properties of dynamical systems<br>which exhibit period-doubling and other chaotic<br>behaviour.  The Feigenbaum number is<br>4.66920160910299067185320382046620161725...<br>Alas, equations involving transcendental numbers<br>do not necessarily produce solutions which are<br>transcendental.  e^[i*pi] = 1, an integer, while (e^[i*pi]) + <br>2*phi = sqrt(5), an irrational number.<br>Clearly phi, the Golden Ratio, is not transcendental<br>since it is the solution of an algebraic equation:<br>phi = [sqrt(5) - 1]/2 = (5^[1/2] - 1)/2<br>One of my own amateur mathematical discoveries<br>(I've not seen it published elsewhere, at any rate)<br>is an infinite number series given by the iterated absolute <br>log of K, where K is an integer.  I believe (but cannot<br>prove) that the scale-steps given by the terms of<br>this series form a non-just non-equal-tempered<br>scale.<br>This is a peculiar and interesting series of numbers<br>since the terms oscillate between 0 and 1.  The first<br>term is transcendental, but I have not been able to<br>prove that the succeeding terms are (or are not)<br>transcendental.<br>For instance, the first 10 terms of the iterated <br>abs log of 2 are:<br>i[1] = abs(log(2)) = 0.30103...<br>i[2] = abs(log(i[1])) = 0.5213902...<br>i[3] = abs(log(i[2])) = 0.2828372...<br>i[4] = abs(log(i[3])) = 0.5484636...<br>i[5] = abs(log(i[4])) = 0.2608521...<br>i[6] = abs(log(i[5])) = 0.2338806...<br>i[7] = abs(log(i[6])) = 0.6310057...<br>i[8] = abs(log(i[7])) = 0.1999666...<br>i[9] = abs(log(i[8])) = 0.6990424...<br>i[10] = abs(log(i[9])) = 0.1554964...<br>and so on.<br>There does not appear to be an obvious<br>pattern to the terms.<br>If one were so inclined, one might call<br>this the McLaren series: this is surely<br>the first post on this tuning forum to<br>feature an original mathematical<br>discovery, albeit a trivial one.<br>As can be seen, all of the above methods<br>for generating transcendental numbers<br>can produce an infinite variety of 'em.<br>Depending on the pattern of generators<br>(the numbers you plug into the various<br>equations to produce transcendental<br>numbers), you get an endless variety of<br>non-just non-equal-tempered scales.<br>The choice of whether to terminate the<br>series with a 2/1 or not is a matter<br>of taste.  (One might call it "terminating<br>the series with extreme prejudice.")<br>In that case, one obtains a non-just<br>non-equal-tempered scale which repeats<br>at the octave.  Choosing another termination<br>integer (or irrational) would produce a<br>non-just non-equal-tempered scale without<br>octaves.<br>As can readily be seen, these are the obverse<br>of the equal tempered class of octave and<br>non-octave scales.  My limited experiments<br>with non-just non-equal-tempered octave<br>and n-j n-e-t non-octave scales appear to<br>show that there is a marked  difference in "sound"<br>between the two classes of tunings.  As Gary<br>Morrison so aptly put it, "non-octave scales<br>sound like rich thick chocolate milk shakes."<br>They are very exotic and harmonically rich,<br>and seem to have a sonic colouration which<br>lends an eldritch quality to the compositions<br>one produces in such scales.  <br>For n-j n-e-t non-octave scales, the same<br>appears to be true, only more so.  They are<br>among the most exotic and sonically luxuriant<br>of all tunings in my experience, and an<br>extraordinary realm for new music exploration.<br>--mclaren<br> <br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Thu, 2 Nov 1995 18:40 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id IAA29513; Thu, 2 Nov 1995 08:40:23 -0800<br>Date: Thu, 2 Nov 1995 08:40:23 -0800<br>Message-Id:  <9511020838.aa10245@cyber.cyber.net><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2243 href="#2243">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>11/3/1995 9:00:50 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>>From : mclaren<br>Subject: Larry Polansky & adaptive tuning<br>---<br>Long ago in a galaxy far away, Larry Polansky<br>wrote an article entitled "Paratactical tuning."<br>In it he posited a  system of dynamic tuning which<br>adaptively changes the size of interval classes<br>depending on musical context.<br>While in one sense this is a sophisticated<br>software method for facilitating modulation<br>in JI (similar to such arrangements as<br>Harold Waage's logic-gate just intonation system<br>which detected fingering patterns and retuned<br>intervals so as to produce maximally beatless<br>chords regardless of key)...in another sense<br>Larry was getting at something much deeper.<br>Paratactical tuning is far more than mere dynamic<br>retuning to produce the "best" chords according<br>to the location of the current 1/1.  Because Larry P.<br>leaves it pretty much open-ended as to what<br>the criteria are. They could be "which 1/1 are we<br>on?" but they could easily be something else.  Once<br>it's all in software, the rule-set that determines<br>how JI intervals shift can respond to a lot more than<br>local key center...for instance, the software could<br>respond to the player's dynamics, or the shape of<br>the melody line, or the nature of the harmonies<br>being played.  More: Larry suggests that the<br>criteria for the rule-set geoverning the adaptive<br>tuning might be open-ended as well--possibly even<br>dynamic.  <br>One could imagine, for instance, an adaptive <br>tuning which morphs JI intervals from "plaintive"<br>to "luminous" or from "tense" to "resolute." (As<br>William Schottstaedt has so dextrously done<br>in an intuitive fashion in the fourth movement<br>of his composition "Water Music," albeit in<br>that case moving from 13-TET to Pythagorean.<br>If you haven't heard this composition, you're<br>missing a truly spectacular piece of music.)<br>As a first advance, this leads directly to<br>a systematization of Lou Harrison's "free style"<br>of composition, in which successive intervals<br>are tuned not with reference to a fixed 1/1, but<br>with respect to the previous note.  Clearly such a<br>practice produces a much more complex system of <br>just tonality--but, as Boomsliter and Creel pointed <br>out, this might also more closely mirror the way<br>the average person hears music.  Our hearing appears<br>to be relative rather than centered on an absolute<br>1/1 (except for those rare listeners with absolute<br>pitch), if the psychoacoustic evidence is to be<br>credited.<br>However, Larry's idea of adaptive tuning goes<br>much further than simply the B&C idea of the<br>"the long pattern hypothesis."   While useful,<br>B&C's concept of melodic sections moving between<br>separate and distinct 1/1s is in itself limiting<br>because it posits simplistic patterns of linear<br>movement twixt striaghtforward JI melodic<br>contours, overtone structures, etc.<br>When combined with the concept of morphological<br>metrics, Larry Polansky's paratactical (or adaptive) <br>tuning really begins to open a *lot* of new doors. <br>For instance, changing one morphological metric<br>into another introduces (on the level of the melodic<br>phrase) a complex set of requirements between<br>vertical and horizontal interval-relations.  As<br>Larry so insightfully realized, this is an ideal<br>case for adpative tuning: and with sufficiently<br>complex software, paratactical tuning does <br>indeed seem the ideal solution to this ever-present<br>tension twixt vertical and horizontal relationships<br>in the context of changing from one vertical or<br>horizontal morph to another.<br>But when you throw in the concept of changing<br>from one *timbral* morphological metric to another<br>at the same time....!  Then, adaptive tuning--in<br>this case extended downward into the micro-level<br>of the individual overtone--is the *only* practical<br>solution to the complexities introduced.  Because<br>of the extraordinary explosion of interactions<br>between timbre, vertical and sequential structure<br>in tihs case, a set of adaptively tuned overtones<br>offers by far the simplest solution. (Jean-Claude<br>Risset and John Chowning and Bill Sethares and<br>James Dashow have produced some compositions<br>which use elements of this technique: the pieces<br>are astonishingly beautiful, yet only a preliminary<br>step toward the total integration of timbre with<br>harmony.  Because of the incredibly cumbersome nature <br>of "doing it all by hand" in Csound, further advances<br>along this line seem likely to be made only with<br>the aid of some sort of automated morphological<br>metric software.) <br>However, there's even more to Larry's idea than this.<br>At the highest level, adaptive tuning can be <br>thought of a way to generate a single "composite"<br>instrument from a number of subinstruments. If<br>you think of each dynamically-retuned section <br>of the score as a specific subinstrument, the real<br>depth of Larry's idea becomes clear.  In order to<br>wander over the entire solution space  you'd need<br>huge numbers of actual physical instruments--not<br>a reasonable solution.  Thus Larry substitutes *virtual*<br>instruments.   And adaptive tuning shows its true<br>power by effect switching betwen those virtual<br>instruments instantaneously: the net result is<br>infinitely more efficient & flexible than either the <br>Partch solution of limiting the composition to a <br>single key, or  the Harrison solution of requiring the<br>performer to be painstakingly exact in moving from one<br>just ratio to another as well as keep in hi/r head<br>where the melody has been and where it's going<br>to (in terms of moving 1/1s).<br>Larry has written a composition that puts some of<br>these ideas into practice.  Due to be premiered<br>in Japan, it looks to this old score-reader like  <br>another remarkably beautiful JI composition, yet<br>(as mentioned) it's more than that...  Larry's <br>upcoming piece promises to significantly<br>advance the state of the microtonal art.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Fri, 3 Nov 1995 19:14 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id JAA00103; Fri, 3 Nov 1995 09:14:02 -0800<br>Date: Fri, 3 Nov 1995 09:14:02 -0800<br>Message-Id: <Pine.SUN.3.91.951103090144.11512C-100000@garcia.efn.org><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2254 href="#2254">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>11/4/1995 11:53:34 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Bach wars<br>---<br>Many forum subscribers have added their 2 cents<br>to the long-running "Bach wars."  For my part,<br>permit me to say that the posts by all concerned<br>were absolutely superb.  Full of detailed quotes,<br>specific references, cogent reasoning.  Paul Hahn,<br>Gary Morrison, Manuel Op de Coul, Aleksander Frosztega,<br>Johnny Reinhard and Helmut Wabnig did a marvellous <br>job of distilling the references and citing competing<br>sources.<br>As to who is right or wrong, that is not nearly<br>as interesting as the citations themselves.  This<br>controversy, raked over in admirable detail, gives<br>*all* of us the references and direct quotes required<br>to decide for ourselves.  That should be the goal of <br>scholarship...and in the "Bach wars" series of posts,<br>all subscribers concerned have adhered to high <br>standards of scholarship and logical reasoning.<br>Unlike so many posts in which sarcasm, appeals<br>to authority, or sheer naysaying substituted for<br>a reasoned debate, the "Bach wars" have proven <br>enormously enlightening.   Reading this series of<br>posts has taught me a good deal about an important<br>question in the history of tuning.  Congratulations<br>to everyone who posted on the subject.  You've all<br>shown us how interesting and educational this forum<br>can be at its best.<br>---<br>As to the specific question of the "Bach wars" posts--<br>"What tuning did Bach use?"--it does not behoove me<br>to speak directly, given the abysmal nature of my<br>ignorance about the period and the people involved.<br>However, some general observations seem in order:<br>[1] "Statisticum radix scientiae malorum."  It is my<br>firm belief that misuse of stastistics is the root of all<br>bad science. (As opposed to pseudo-science, like the<br>N-rays which destroyed Rene Blondlot's reputation <br>in 1906 and the abominable E-rays which constitute<br>such a blot on the credibility of German science<br>today.  E-rays are nothing but dowsing performed on<br>purported electromagnetic radiations, which radiations<br>can neither be detected by any known instruments nor<br>cut off by any known form of shielding.  Yet they <br>"cause cancer."  What's the German word for "scam"?)<br>One of the worst uses of statistics is what I call <br>"stripmining the noise floor."  When you've got too<br>little data to form a reliable representation of a<br>statistical universe, or when you've got dribs and<br>drabs of data collected at time A, time B, time C,<br>under wildly different conditions and with dubious<br>controls...you're basically pushing linear parametric<br>statistical methods beyond their useful limits. You're<br>trying to statistically analyze noise...trying to<br>make soup out of dishwater, mathematically speaking.<br>The result?<br>Hard numbers that look convincing but turn out to be<br>"junk science."<br>My best guess is that the "What tuning did Bach use?"<br>controversy is undecidable because all participants<br>concerned are stripmining the noise floor.<br>---<br>Let me give some concrete examples:<br>Statistical analysis of Bach's harpsichord compositions<br>looks like a reasonable strategy at first glance. However,<br>Bach's collected harpsichord compositions do not form<br>a reliably complete representation of an underlying<br>statistical universe for the following reasons:<br>[1] Bach wrote his harpsichord compositions over a number<br>of years.  Some were penned in Cothen, some earlier, some<br>later.  If Bach's style of composition changed, this throws<br>into doubt one of the underlying assumptions of a statistical<br>analysis: namely, that all samples derive from the same<br>statistical universe.  To use an acoustics analogy, this is<br>like taking half your measurements of reverberation time<br>in a closet and half your measurements in Carnegie Hall.<br>You've got a mixed set of data and you're lumping all the<br>data points together willy-nilly.  A guaranteed shortcut <br>to "junk science."<br>[2] Bach may have written some compositions for a harpsichord,<br>others for clavichord.  Does the statistical analysis take<br>this possibility into account?  Do scholars know for *certain* <br>which compositions were written for which instrument?   Did<br>Bach (or his patron, the prince) use different tunings on<br>different keyboard instruments?  Are we *sure*?  Are<br>scholars *sure* that many of Bach's compositions weren't<br>written to be played on *both* a harpsichord *and* a<br>clavichord (whichever might have presented itself and<br>been available) and might thus have represented Bach's attempt<br>to compose music which sounded good *regardless* of the<br>particular tuning used?<br>For example, the clavichord might have used one well temperament,<br>the harpsichord another--or the clavichord might have used, say,<br>Kirnberger III, while the harpischord might have used equal<br>temperament because harpsichord continuo often had to<br>accompany an instrumental ensemble at Cothen. (Remember,<br>Bach's harpsichord concerti were written at Cothen.)<br>Did the statistical analysis take these issues into account?<br>If not, why not?<br>[3] Many assumptions are inevitably implicit in any linear<br>parametric statistical analysis.  In order to calculate r values,<br>you have to fix parameters and make guesstimates about their<br>influence and constancy.   If you correlate verbal IQ test scores<br>with length of stay in the US for new immigrants and assume<br>strong causality, you come to the bizarre conclusion that <br>emigrating to the United States raises people's <br>intelligence.  <br>You get this garbage answer out of linear parametric statistics<br>because you put garbage *into* the equations: namely, garbage<br>assumptions.  Without basis, you assumed two parameters to <br>be deeply causally connected for the wrong reason, and ran too<br>far ahead of yourself with the results.<br>This raises questions about the Bach statistical study.  Questions<br>of *both* causation *and* correlation. What are the *specific* r values<br>by interval category for Bach's compositions?  Do they imply<br>causation?  If so, what *kind* of causation? For a classic<br>example of garbage science, see the r values buried in the appendix<br>of Charles Murray's "The Bell Curve."  You'll find r values between<br>0.4 and 0.6.  As a rule, an r below about 0.75-0.8 is a sure-fire<br>indicator of smoke & mirrors. The correlation is so weak that the<br>researcher had better answer some *very* tough questions or<br>risk being called slipshod, or worse, a fraud.<br>So I for one want to know those r values on the Bach statistics.  <br>Did the Bach statistical analysis use linear regression?  <br>Quadratic?  Cubic?  Least-squares?<br>What's the mean, median and the standard deviations for the r values<br>of each interval broken down by year of composition?  What do these<br>profiles tell us about causation?  Was multiple regression used on<br>*different variables*?  Were the results compared?  What did *that*<br>say about causation as opposed to correlation or <br>even mere coincidence (AKA low r values)?  Did the<br>statistical analysis even bother to consider such issues?<br>If not, I want to know why.  Bach may in some compositions have<br>been interested in exploring unusual dissonances: thus at certain<br>points in his career his compositions might have *deliberately*<br>used "bad" intervals in a given well temperament (if indeed he used<br>a well temperament).  But at other times in his career, he might <br>have been more interested in exploring unusually perfect consonances<br>in a given well temperament.  This would change the intervals<br>Bach tended to use over time: did the statistical analysis take<br>this into account?<br>We know for a fact that Bach's 7th chords were considered wildly<br>dissonant and highly outre in his day.  Therefore it seems  <br>reasonable to posit that he might have systematically explored<br>sets of intervals unusual for composers of the period.  Did the<br>statistical analysis take this into account?  Or did the statistical<br>analysis arbitrarily assume that Bach would have used the most<br>consonant (read: beatless) intervals in a given well temperament<br>most often, and the least consonant intervals least often?<br>More complexly, Bach (being the genius he was) might have switched<br>his interests constantly, exploring one set of unusual dissonances in<br>one composition, another set of exotic consonances (available only<br>in a given well temperament) in another composition.  Conflating<br>all of the interval data into a single linear regression would destroy<br>all of this information and produce *wildly* misleading answers.<br>In this case, multivariate analysis would be called for.  Was it<br>applied?  Was multidimensional statistical analysis used?  Did<br>the researcher test for correlation between (say) timbre *and*<br>interval and interval, or only twixt interval and interval?<br>[4] Bach might have preferred certain intervals (even if he used<br>equal temperament) for numerological or ecclesiastical reasons.<br>We know with surety that he considered C minor and D minor "special"<br>keys.  Only a few of his compositions use these keys: they are<br>statistically underrepresented.  Bach clearly invested these keys<br>with some special significance, because he reserved these keys<br>for his most ambitious works.  The Chaconne (of which Bach wrote<br>exactly ONE), for instance, uses d minor: so does the famous prelude<br>and fugue.  The passacaglia & fugue (again Bach wrote only ONE<br>passacaglia) uses c minor...and so on.<br>Does the statistical analysis take this into account?  Depending<br>on the well temperament (if such a tuning was indeed used),<br>d minor and c minor might well have exhibited special intervallic<br>properties.  We can be reasonably certain from statistical analysis,<br>for example, that a number of Buxtehude's later compositions use<br>keys which when transposed down on the meantone Luneborg organ offer<br>unusually consonant sets of intervals.<br>Did the person who performed the statistical analysis take this<br>possibility into account? Did s/he run a separate analysis on<br>this assumption?  Were the results compared with the straightforward<br>statistical analysis?  <br>If not, why not?<br>Bach could have had many reasons for using certain intervals.<br>We know, for example, that Bach was numerologically inclined.<br>In one of his chorales the melody enters 10 times, representing<br>the 10 commandments: other examples abound.  Does the statistical<br>analysis of Bach's use of intervals take into account the possibility<br>that he might well have used a given interval-set for reasons *other*<br>than considerations of acoustic consonance and dissonance?<br>This same objection applies to fugue subjects and counter-subjects.<br>One fugue of the 48 deliberately uses all 12 tones of the chromatic<br>scale in succession, for instance: does the statistical analysis<br>take into account the effects of such part-writing?<br>[5] Some of Bach's klavier compositions were originally written<br>for organ, some are alterations or emendations of works written<br>for instrumental ensemble, and some are greatly modified versions<br>of other composer's works--specifically, the "transcriptions" of<br>pieces by Vivaldi, which are very much more than mere<br>transcriptions.   Does the statistical analysis take this into account?<br>If not, why not?<br>---<br>Statistical arguments for or against this or that historical trend<br>fill me with foreboding. They're a fertile breeding ground for "junk<br>science" (without the researcher *intending* to do junk science, of<br>course--or even realizing it).  So many assumptions and <br>presuppositions are implicit in any linear parametric statistical <br>analysis of historical data as almost to force me to proclaim:<br> "a pox on all historical statistical studies!"<br>Classic examples of "junk science" from statistics abound<br> in economics. For instance, those bogus United States GNP <br>charts going back to 1876--charts which completely ignore the fact<br>that the U.S. switched from an agrarian economy in the early 19th<br>century to a steam-driven Bessemer-furnace economy in the late 19th <br>century to an oil-and-steel-driven machine-tool economy in<br>the early 20th century to an information-driven service <br>economy in the late 20th century.  What's the net discounted dollar<br>value of a bushel of tobacco in 1876 compared to the net discounted<br>dollar value of a megabyte of computer code in 1996?  The<br>question is unanswerable.  You're not just comparing apples<br>and oranges, you're comparing apples and *mu-mesons.*  The<br>question doesn't even make *sense.*<br>Again, sociological historical studies purporting to show <br>improvements in "quality of life" as the century progressed<br>are equally flawed.  While in 1880 there were no antibiotics,<br>it was also standard for a middle-class family to have 2 or 3<br>live-in servants.  If you're a healthy person, would you be<br>willing to trade lack of antibiotics for being waited on hand<br>and foot and having your meals cooked for you and your washing<br>done by a crew of servants?  Would this be an overall improvement<br>or decline in your standard of living, as opposed to today?<br>The answer isn't obvious to me.  Again, apples compared<br>with oranges.  Again, garbage science produced by a misuse of<br>statistics.<br>All told, the value of historical statistical studies of Bach's<br>interval-usage seems at best right on the borderline of<br>junk science, and at worst little more use than <br>examining bird entrails.<br>---<br>This leaves us with the written historical record.<br>Does any specific numerical record exist of the frequencies<br>to which Bach tuned each of the keys on his harpsichord?<br>Clearly not.<br>Thus we are left with inadequate data.  *Grossly* inadequate<br>data.  Regardless of what tuning you think Bach used, the<br>fact remains that (unless we want to swim in the VERY<br>murky waters of statistical historical numerology) we must<br>fall back on vaguely-worded hearsay testimony about Bach's<br>tuning.<br>My standard for this kind of historical hearsay is: would you<br>convict someone of murder on the basis of this stuff?<br>In this case, no way.  You don't need O.J.'s Dream Team<br>on this one.  The testimony is so weak and so open to<br>interpretation that even a grand jury would no-bill the <br>defendant.  It wouldn't even get to trial.<br>Thus my sense here (reading the "Bach wars" posts) is again <br>that the question is undecidable on the basis of the hearsay<br>testimony from Bach's relatives and acquaintances. <br>Many of the quotes supposedly come from "eyewitness"<br>accounts--but can we be *sure* it was *actually* <br>an eyewitness account, or was Forkel remembering<br>long after the event?  Or did Forkel miss the incident<br>entirely, and perhaps have to rely on C.P.E. Bach's <br>recollection?  Or was it one of those "a friend of my<br>cousin's brother told me he heard someone say..." things, <br>gussied up in first-person narrative form?<br>What's that?<br>Did someone mention "false memory syndrom"...?  Meaning:<br>people tend *not* to remember the event itself, but what<br>someone else *told* them about it...?<br>We know *some* generalities with reasonable certainty:<br>Bach was considered "old-fashioned" during his lifetime,<br>and his style was out of date long before he reached middle<br>age.   The  homophonic, racier, faster-paced "Italian<br>style" was much more in vogue by the 1720s than Bach's<br>almost quattrocentric polyphony.<br>Did this influence what friends and acquaintances <br>remembered about Bach's tuning?  Did they unconsciously<br>exaggerate the "meantone" quality of Bach's music because<br>of the old-fashioned nature of his polyphony?  Or did they<br>instead unconsciously redact their memories of his tuning <br>procedures so as to "modernize" Bach and unwittingly<br>make his music more fashionable to fit in with the new <br>music everyone was used to?<br>I don't know the answer to these questions.  Before making<br>up my mind about "what tuning did Bach use?"  I'd sure like<br>to.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Sun, 5 Nov 1995 04:39 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id SAA29690; Sat, 4 Nov 1995 18:39:15 -0800<br>Date: Sat, 4 Nov 1995 18:39:15 -0800<br>Message-Id: <951105023715_71670.2576_HHB54-5@CompuServe.COM><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2260 href="#2260">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>11/5/1995 2:30:11 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: academia, jibes, hurt feelings, the search <br>  for truth<br>---<br>With his usual insight and common sense, Bill Alves<br>offered some tart rejoinders to my posts on <br>psychoacoustics.<br>As to the question of who is or is not ignorant, it is <br>sufficient to observe: "Hic ego barbarus sum quia non<br>intelligor illis."  But Alves' point about my  "bigoted <br>statements about academics" is right on the money.<br>Your Humble E-Mail Correspondents pleads guilty...<br>with an explanation.<br>To paraphrase Richard Preston, "Music is a lesser activity<br>than religion in the sense that we've agreed not to kill each<br>other but to discuss things."  To the extent that any of<br>my statements about academia or people with PhDs has<br>hindered the discussion on this forum, or poisoned it<br>with unnecessary bad feeling, I certainly apologize.<br>For making bigoted statements about no-talent academics<br>who try to maintain a brain-dead status quo, however,<br>I do NOT apologize.  I *AM* bigoted against such people. <br>I intend to *continue* my bigotry against such people,<br>and wherever possible to deeper and broaden the scope<br>of my bigotry against these no-talents.  I make no apologies <br>whatsoever for this kind of bigotry.  On the contrary: I<br>*celebrate* this kind of bigotry.  Indeed, in an apotheosis<br> of political incorrectness, I *glory* in my bigotry<br>against people with big reps and no competence,  big<br>degrees and no talent, big grants and no imagination.<br>I exult in my capacity to distinguish twixt crap and<br>the beaux arts.  If this is bigotry, *great.*  Sounds like<br>a PLAN!  <br>Lemme at 'em!  <br>Come get some, !@#%#+#@%$ers!<br>It's hard to say whether the no-talent duffers are in the<br>majority or the minority in music departments.  Many folks<br>with PhDs in music use a kind of protective coloration: they<br>keep a low profile, don't make waves, and quietly go about<br>their radical xenharmonic explorations while giving an<br>outward appearance of conformity to the Perversions of<br>New Music ideal. (Namely, that the very model of the modern<br>composer is one who talks and talks and talks and talks, and<br>hardly every produces any music...and then only dribs and drabs<br>of warmed-over Webern and kludged-up Cage.  Above all, ya<br>gotta have a theory!  Theeee-ory!  Theeee-ory!  Git yer red-hot <br>theee-ory! Ice cold muuu-sic, red hot theeee-ory!<br>Can't enjoy the music without a theee-ory!)<br>Many of the academics who subscribe to this forum are<br>extraordinarily talented polymaths.  For example, Larry<br>Polansky fills me with awe: this guy not only writes <br>original & groundbreaking articles, he's not only a terrific<br>teacher & thesis adviser (by all accounts), he's not only<br>a fine amateur ethnomusicologist, but he's also a world-class<br>computer programmer *AND* a startlingly talented composer.<br>Is there *anything* this guy can't do?  Is he in next year's<br>olympics?  Has he climbed Mount Kilamanjaro yet? Will<br>he be the first xenharmonist in space?<br>William Schottstaedt is another example.  A top-notch<br>programmer, able to design entire object-oriented music<br>languages in a single bound, debug cranky antique computer<br>systems faster than a speeding bullet, but then he ducks<br>into a phone booth and becomes...a world-class composer.<br>Amazing.<br>David Cope is not only a fine composer, by all accounts a<br>splendid teacher, an excellent writer (the "New Directions<br>In Music" books are classics of their kind in each of their<br>various editions), but he's also a world-class AI music<br>programmer whose LISP syntactic models of composition<br>have broken genuinely new ground in the field.  <br>Astounding.<br>Johnny Reinhard is not only one of the world's great<br>scholars of microtonality, a bibliomane with the most<br>impressive library of microtonal scores on the planet,<br>an administrative wizard who single-handedly forced<br>the New York concert scene to bow to microtonality,<br>AND a living link between thousands of xenharmonic <br>composers, researchers and performers...but Johnny <br>is *also* the reincarnation of Jimi Hendrix as a <br>bassoon player.  Virtuoso par excellence.<br>And speaking of universally talented people...<br>William Alves himself is an extremely impressive guy.<br>Not only a first-rate JI composer, but a scholar of<br>tuning history, a crack computer programmer, a DSP<br>wizard, *and* a fine teacher (by all reports).  Another<br>polymath.<br>To continue in this vein would  embarrass *a great many*<br>PhDs who subscribe to this forum...  Suffice it to say that<br>this tuning forum represents an extraordinary confluence<br>of exceptionally talented academics.  It's fashionable to claim<br>that "the day of the Renaissance man (woman? person?) is<br>past."  Whoever believes this hasn't logged onto the tuning <br>forum.<br>Having said all that, permit me to add not my own words,<br>but those of Norbert Weiner:<br>"What sometimes enrages me and always disappoints and<br>grieves me is the preference of great schools of learning<br>for the derivative as opposed to the original, for the<br>conventional and thin which can be duplicated in many<br>copies rather than the new and powerful, and for arid<br>correctness and limitation of scope and method rather<br>than for universal newness and beauty, wherever it<br>may be seen." [Weiner, Norbert, "The Human Use of<br>Human Beings," 2nd edition., 1954, pg. 135]<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Mon, 6 Nov 1995 00:48 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id OAA10844; Sun, 5 Nov 1995 14:48:24 -0800<br>Date: Sun, 5 Nov 1995 14:48:24 -0800<br>Message-Id: <199511052247.RAA08615@freenet3.carleton.ca><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2267 href="#2267">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>11/6/1995 9:18:32 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject:  RATED NC-17: ALL COMPOSERS OVER AGE<br>  17 MUST BE ACCOMPANIED BY THE GHOST OF JOHN CAGE<br>---<br>"Modernism is now being seriously challenged for the first<br>time in almost a century or more.  Which, considering the <br>really awful degree of narcissism, nihilism, inanity and <br>self-indulgence that late modernism has allowed itself,<br>is probably the best thing that could happen to it. What<br>has been permanently lost is the sense of the absolute<br>that the modernist movement once gave to its loyal <br>followers.  And to that we can say: good riddance.<br>We are none of us now--either artists or critics or the <br>public--quite as susceptible as we once were to the <br>idea that at a given moment in time, history ordains <br>that one and only one style, one vision, one way of <br>making art or one way of thinking about it, must <br>triumph and all others be consigned to oblivion." <br>[Kramer, Hilton, The New York Times, 28 March 1982,<br> Section 2, pg. 32]<br>Most awful of all modernist excesses, naturally, <br>are those perpetrated by John Cage and Pierre <br>Boulez.<br>Of course everyone already knows this.  There's no <br>controversy about it.  The facts have long since been<br>admitted in those code phrases so beloved of the<br>New York critical establishment.<br>When TIME magazine (in its Cage obit, 1 November 1993, <br>pg. 87) oozes: "There was always the whiff of the<br>charlatan about John Cage," we all know what they<br>REALLY mean.  ("Cage was a con artist without a shred<br>of musical talent.")  They just don't want to come right<br>out and *admit* it because (after all) it would prove<br>embarrassing to explain why so many New York<br>critics kow-towed to Cage for so many years.<br>And when Roger Reynolds oohs and ahhs in an<br>interview-cum-suck-up with the Great Mountebank,"Your main<br>contribution has been to expand the idea of what it is<br>reasonable to do in music," we all know what Reynolds<br>is *really* saying:  "John Cage gave audiences the<br>musical equivalent of a golden shower for 40 years."<br>Of course, Reynolds doesn't want to come right out<br>and actually *say* that.  "Epater le bourgeoisie" doesn't<br>go over too well in the land of Oprah and Geraldo<br>unless you sugar-coat the pill.<br>And thus, while we all know and covertly admit that<br>John Cage was a stunt man whose musical fame  is<br>conducive to an understanding of how the Egyptians<br>could have worshipped insects...even so, none of us<br>really want to *admit that.*<br>This is peculiar, especially on a microtonal discussion<br>forum like this one.  After all, Cage's early prepared-<br>piano works flirted with the edges of the 12-tone equal<br>tempered scale.  It's hard to say that Cage's early <br>prepared piano pieces are in any particular tuning--<br>least of all 12--and certainly the "Imaginary Landscape"<br>for radios skirted the idea of departing from 12 via <br>electronic sounds.<br>Naturally, none of these early gimmicks provoked <br>enough critical attention: and so stunt man Cage was<br>obliged to find some really TALL buses over<br>which to jump his musical Evel Kneival act.  4<br>minutes 33 seconds...a burning piano...whatever.<br>The end result, naturally, was that pathetic orgy of<br>gimmickry, fetishism and sheer silliness that<br>characterized Cage's so-called "musical" output<br>post-1948.<br>And so, instead of doing something to advance music,<br>he vanished into the tarpit of "narcissism, nihilism,<br>inanity and self-indulgence" so aptly described by<br>Kramer.<br>Boulez is a different story.<br>While Cage displayed dazzling early sparks of musical<br>talent in his "Three Constructions" and his prepared<br>piano pieces only to throw away his abilities in favor<br>of a career scamming the gullible (the compositional<br>equivalent of L. Ron Hubbard's reign as Dianetics<br>guru), Boulez never betrayed any such rudiments of <br>compositional talent. <br>Boulez's music created a tremendous impression in<br>the 1950s--until people actually heard it.  Thereafter,<br>his popularity dropped off sharply.<br>To be sure, Boulez's "acknowledged masterworks" <br>(acknowledged by the other dry-as-dust theorists,<br>all of whose judgments and compostions are now<br>equally inconsequential and outdated) sound pretty, <br>albeit in an inoffensive Muzak-y sort of way...  <br>Boulex had a gift for orchestration.  <br>But after about 5 minutes of "Le Marteau sans Maitre," <br>or "Pli Selon Pli," you  realize it's just warmed-over <br>Webern with a  Chet Baker arrangement.<br>Why listen to a pale imitation?  <br>Why drink from the toilet, instead of the tap?<br>Why listen to Boulez when the original--<br>and much more interesting--Chet Baker is available<br>on CD?  To say nothing of Webern.<br>All told, it's a shame that Boulez had no compositional<br>talent, nor any original ideas.  Because in the early 1950s <br>Boulez (unlike Cage) actually thought seriously and at<br>length about microtonality:<br>"In considering his electronic means, the composer<br>has first to free himself from the conception of absolute<br>interval.  This can certainly be done. The tempered system<br>of twelve equal semi-tones seems to lose its necessity<br>at the very moment at which it passes from chromatic<br>organization to the Series.  There have already been<br>experiments with intervals of less than a semi-tone: of<br>uarter-, third- and even sixth-tones. (...) In fact, to<br>select a fundamental unit other than the semi-tone, <br>means to conceive a kind of temperament peculiar to<br>a single composition; all intervals are to be heard as <br>derviing from this fundamental tempering, thus affecting<br>the listener's conditions of perception. (...)  This tempering<br>may take place within the octave...or, it is equally possible<br>to construct in such a way that the interval with which <br>the demarche of the scale commences in other than the<br>octave.  (...)  In this way it would be possible to derive from<br>one structure based on wide intervals, i.e., having a wide<br>compass and a semi-tone as the unit, a corresponding<br>structure based upon micro-intervals, in which the compass <br>would be greatly reduced and where the unit would be either<br>a very small interval or irregular intervals defined by a<br>series. [Boulez, P., "At the End of Fruitful Lands..." Die Reihe, <br>Vol. 1, No. 2, 1955: English translation 1957]<br>Alas, such ideas would have resulted in an actual *expansion*<br>of available musical resources...  And that could not be<br>permitted.  Like rock music, the modernist avant garde was<br>always a fanatically reactionary cult cloaked in the image<br>of a revolutionary vanguard.  Any *real* emancipation of<br>the dissonance leading to a break with the sacred 12 tones<br>would have thrown into disarray the whole Tammany Hall-style<br>patronage system of orchestras, conductors, concert halls,<br>the Beaux Arts, circle-jerk New York music critics, and the<br>rest of the corrupt musical machine.  Without the Tammany Hall<br> of 12 equal tones per octave,  those who benefited from the <br>patronage system of the Sacred 12 Tones (like Boulez, who <br>now makes megabucks recycling tired 12-equal dribs and <br>drabs as a conductor) would find themselves<br>out of a job.<br>Boulez on a street corner?<br>Begging for dimes?  Holding up a sign WILL CONDUCT IN 12 <br>FOR FOOD???<br>Ye gods.<br>Such could not be permitted. Thus, after flirting with<br>tdea of actually breaking free of his pathological<br>dodecaphilia, Boulez threw in the towel and made the<br>obligatory obeisance to the Sacred 12 Tones.<br>The result was predictable:<br>"Just as Marxist-Leninist thought led to forms of<br>government meant to remedy the excesses supposedly<br>caused by the exhaustion of capitalism, so Schoenbergian-<br>Boulezian practice was touted as the alternative to<br>an exhausted system called `tonality.'  These attempts<br>to revolutionize, respectively, our economic and musical<br>worlds had several other things in common besides<br>the Germanic origin.  The application or enactment of<br>both ideologies required that their alternatives--and<br>those who would support them--be publicly denounced <br>and discredited, and a form of double-speak was<br>employed in support of these `revolutionary' ideas.<br>The apologists writing in Pravda held sway in support<br>of a failing system in the same way that Herbert<br>Eimert, Milton Babbitt, and Charles Wuorinen dominated<br>the pages of Die Reihe and Perspectives of New Music<br>for many years.  What is so interesting is the <br>suddenness with which these applications of <br>science--some have said pseudo-science--to economics<br>and music have been rejected and are now seen as<br>merely interesting experiments that failed<br>because they denied basic human realities:<br>economic and cultural diveristy in the political<br>realm and the necessity for perceptual forms of<br>organization and the power of intuitive processes <br>in the world of music." [Appleton, Jon, "Machine Songs<br>III: Music In the Service of Science--Science in the<br>Service of Music," Computer Music Journal, vol. 16,<br>No. 3, Fall 1992, pp. 17-21]<br>Which leaves us back where we started.  Now that<br>everyone has tacitly admitted that Cage and Boulez<br>were mere pimples on the rear end of 20th<br>century music, it's time to look around for a new<br>graven idol.  The next Great Composer (now that<br>we've realized that the most famous so-called "Great <br>Composers" of the 1950s didn't produce anything of<br>lasting interest)...akin to the Next Great Rock Star.<br>In both cases the focus is the same: keep the rubes<br>gawking, wow 'em with glitter and glitz, dazzle 'em<br>with music videos & half-naked girls (or, in the<br>case of prestigious New Music Journals, ritzy-<br>looking hypercomplex diagrams and equations)<br>and hit 'em with jargon....anything to keep the rubes<br>from realizing that it's all just a dog and pony<br>show. (Meanwhile, the REAL great composers like<br>Nancarrow, Risset, Chowning, et alii, go all but unnoticed<br>and all but remarked.)<br>And so the focus in new music has again turned <br>toward the cheery cherub with the cheekiest charts, <br>the wildest word-count, the most scrumptious-<br>looking (read: indecipherable) scores:<br>Namely, Ferneyhough.<br>This is an interesting aberration, and it spotlights<br>one of the deepest ruts into which post-<br>modernist music has fallen.  Namely, the<br>obsession with *intellectualizing* music.<br>Why do Western composers and critics and<br>music theorists so fanatically chart and<br>diagram and plot out and schematize modern<br>compositions?<br>Primarily (one suspects) in order to justify<br>the long-held euroschlock "doctrine that<br>Western European art music is superior<br>to all other music of the world," which<br>"remains a given, a truism. Otherwise<br>intelligent and sophisticated scholars<br>continue to the use the word `primitive'<br>when referring to the music of Africa,<br>American Indians, aboriginal Australians,<br>and Melanesians, among others."  [Becker,<br>Judith, "Is Western Art Music Superior?"<br>Musical Quarterly, Vol. 72, No. 2, 1986, pg.<br>341]<br>Yo!<br>Western composers and performers might<br>not be able to produce rhythms as complex<br>as those of the Balinese gamelan, or tunings<br>as subtle as those used in the sub-Saharan<br>ugubhu, or to move audiences as deeply<br>as do the "weeping" pitches of Kaluli <br>gisalo songs, but...hey!  <br>At least *we* euro-dudes can ALWAYS<br>come up with bigger, better, more<br>impressive *charts* of our compositions<br>than any other musical culture on earth!<br>(A typically priapic male obsession.  "Mine<br>is bigger than yours..."  My compositional<br>diagram, that is.  No wonder there are<br>so few famous women composers.  Can anyone<br>imagine a *woman* wasting 6 months of her<br>life straight-edging a bunch of chicken-scratches<br>that explain something everyone can already<br>*hear*???)<br>Thus the bizarre and otherwise incomprehensible<br>elevation of such  duffers as  Ferneyhough...whose <br>scores are, indeed, quite  impressive--as grafitti.<br>Indeed, nary a subway train in New York or a wall<br>in South Central L.A. is as crammed with in-group<br>jargon and chock-a-block with meaningless verbiage as<br>one of Ferneyhough's articles. (In fact one very<br>prominent member of this tuning forum laughed<br>out loud while perusing one of Ferneyhough's<br>ludicrous "Perversions of New Music" articles,<br>chuckling: "Looks like the guy follows the same<br>aesthetic when writing as when composing... Or<br>should one say, the same lack thereof?"  NO, folks,<br>it wasn't this little lad, but someone much better<br>known.) <br>This teaches an important lesson to microtonalists:<br>if ya wanna get famous, ya gotta make diagrams.<br>1/1 has made a start at this--ratio-space<br>charts look impressive, and to infants<br>or the mentally retarded or the average new music<br>doyen they'll doubtless exert an irresistable<br>attraction.<br>Baby go goo-goo at pwetty pitchah! <br>Of course, this is the Motown approach to <br>popularizing microtonality.  According to this<br>guerilla strategy (practiced extensively in New <br>York), the objective is a "crossover" composition<br>that "breaks through" into the white male<br>New York  critical establishment.<br>As with the de-funked un-gotten-down R&B of  <br>Motown records, all potentially controversial and<br>threatening aspects of the music must be<br>shaved off and polished away, leaving a<br>bland whitebread generic product sufficiently<br>"mainstream" to attract a mass audience.<br>And while the New York composers/performers<br>represent the Motown approach to microtonality,<br>those of us on the West Coast represent the<br>Stax approach.<br>"F*** 'em!" is the West Coast philosophy with<br>regard to the New York critical establishment:<br>if they can't stand the microtonal heat, let<br>'em flee the concert hall. This alternative<br>approach to popularizing microtonality <br>relies on the rasty nasty snazzy sound of<br>strange intervals and unfamiliar musical<br>forms to attract the adventurous concert-goer<br>and CD buyer.  While the New York crowd blows <br>dust off musty scores like Dick Stein's 1906 1/4-tone<br>cello piece for a concert at Juilliard, the<br>West Coast crowd blasts the audience with<br>full-bore hard-core microtones from the <br>git-go in exotic tunings like 13-TET and<br>13-limit JI and harmonic series 1-60.<br>Each approach has its merits.  Stax or Motown,<br>both seem to attract their share of "mainstream"<br>"crossover" audience from standard bland 12.<br>Regardless of the approach, it remains an<br>unfortunate fact that "I have learned that if<br>I produce a complex structural diagram of a piece<br>of music from anywhere, the students will listen<br>to the piece more carefully and will regard it with <br>greater respect.  A structural diagram gives the<br>music a legitimacy it does not have without <br>the analysis." [Becker, Judith, "Is Western Art<br>Music Superior?" Musical Quarterly, Vol. 72, No<br>2, 1986, pg. 346.]<br>So here's a helpful suggestion: when giving lectures or<br>concerts, microtonalists should project an overhead<br>transparency of the New York subway system and<br>throw in some gibberish about "pitch class<br>matrices" and "all-interval sets" and "maximally<br>symmetric stochastic distributions."  This will<br>wow the eurogeeks and ensure that the microtonal<br>music is listened to with *great* attention.  <br>After all, it requires hardly *any* skill or<br>intelligence to perpetrate this kind of musico-<br>theoretic scam, and the rewards are VAST...as <br>Cage and Boulez have so amply demonstrated.<br>--mclaren<br> <br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Mon, 6 Nov 1995 19:21 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id JAA25588; Mon, 6 Nov 1995 09:21:02 -0800<br>Date: Mon, 6 Nov 1995 09:21:02 -0800<br>Message-Id:  <9511060919.aa20661@cyber.cyber.net><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2277 href="#2277">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>11/7/1995 9:55:58 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: More about n-j n-e-t scales<br>---<br>"As physicians have always their instruments<br>and knives ready for cases which suddenly<br>require their skill, so you must have principles ready<br>for the understanding of things..." [Marcus<br>Aurelius, "Meditations"]<br>Because of the general lack of incomprehension<br>and puzzlement at my mention of non-just non-<br>equal-tempered scales, it's clear that some<br>further info is required. <br>In general, I'm not talking about linear or<br>meantone tunings.  While it's true that these<br>are technically non-just non-equal-tempered<br>scales, most of 'em are just one or another<br>way of bending twelve tones to obtain a<br>more consonant third or fifth in a traditional<br>Western triad.  This surely has its value,<br>but meantone scales decidely represent the<br>outermost extreme conservative  side<br>of non-just non-equal-tempered scales.<br>Instead, the kind of n-j n-e-t tunings I'm<br>concerned with--and have been since the<br>git-go--are those tunings which break<br>completely with the Western mold.  Some<br>of these kinds of tunings have octaves, others<br>don't.  In general, they're so wildly foreign<br>to any conventional harmonic or scalar <br>vocabulary that there is hardly any intelligible<br>way to talk about such scales as yet, except<br>as raw numbers.<br>For example:<br>One of the simplest ways of generating such<br>a completely non-Western non-just non-equal-<br>tempered scale is by taking the natural logarithm of<br>the factorial of a set of integers:<br>1! = 1, ln(1) = 0<br>2! = 2, ln(2) = 0.693147<br>3! = 6, ln(6) = 1.7181759<br>4! = 24, ln(24) = 3.17805383<br>5! = 125, ln(125) =  4.82831373<br>6! = 720, ln(720) = 6.5792512<br>7! = 5040, ln(5040) = 8.52516136<br>and so on.<br>Taking ratios so as to eliminate<br>dependence on the base of the logarithm,<br>we have:<br>scale step 1: 1.0<br>scale step 2:  2.478808<br>scale step 3:  4.5849625<br>scale step 4:  6.9657842<br>scale step 5:  9.4918531<br>scale step 6:  12.299208<br>These values can be octave-reduced or not.<br>If not, the scale will have no octaves.  <br>If octave-reduced, carrying out the procedure<br>will produce ever larger numbers of scale-<br>steps within the octave, never overlapping.<br>This is an inherently fractal process, first<br>described by Thorwald Kornerup in his Golden<br>Section scale.<br>In a sense the procedure is analagous to<br>that of just intonation, in which successive<br>addition and subtraction of various small-<br>integer-ratio intervals produces an ever-larger<br>profusion of unequal divisions of the octave. <br>However, there are a number of differences.<br>At this point it's useful to introduce the<br>concept of the "inharmonic series."  By<br>analogy with the harmonic series, an<br>inharmonic series serves as the backbone<br>of a non-just non-equal-tempered scale.<br>In this case, the inharmonic series is <br>Log(N!) where N runs from 1...infinity.<br>Of course choosing N by some other criterion<br>(perhaps by some recurrence relation: say,<br>N4 = N1 - sqrt(N2 + N3^2)*N1) would produce<br>an entirely different inharmonic series.  There<br>are an infinite number of inharmonic series,<br>each generated by choosing N by a different<br>method and then applying some non-linear<br>operation to N.<br>By contrast, the familiar harmonic series is<br>obtained by setting N = the class of integers<br>and performing the simplest possible linear<br>operation on them--namely, the unary<br>operation (which leaves the operand unchanged).<br>Inharmnic series are important as a source<br>of modulation and of vertical structures<br>in non-just non-equal-tempered scales.<br>One of the most interesting implications<br>of non-just non-equal-tempered tunings,<br>however, is the prospect of generating<br>a scale of note durations (read: rhythms)<br>derived from the scale steps, by analogy<br>with the comparable procedure in traditional<br>Western music.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Tue, 7 Nov 1995 20:04 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id KAA19700; Tue, 7 Nov 1995 10:04:49 -0800<br>Date: Tue, 7 Nov 1995 10:04:49 -0800<br>Message-Id: <9511071803.AA09055@ ccrma.Stanford.EDU ><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2288 href="#2288">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>11/8/1995 4:18:10 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Rhythm, tuning & the extension of Charles<br>  Seeger's 1930 article into n-j n-e-t scales<br>---<br>"Look within.  Let neither the peculiar quality of<br>anything nor its value escape you."  [Marcus Aurelius,<br>"Meditations"]<br>With typical insight, Ivor Darreg once commented that<br>the rhythms of Baroque music arose from the 18th-century<br>love of clockwork and chronometry.  And in fact one<br>of the greatest achievements of Enlightment technology<br>was the development of a ship's chronometer capable of<br>keeping sufficiently accurate time to allow Royal Navy<br>ship to navigate along lines of longitude. The inventor won<br>a 10,000-pound prize--at the time a huge fortune.<br>In a larger sense, the infrastructure of music (the tuning) has<br>probably always exerted a potent influence over its overt<br>superstructure--specifically, over the rhythms used.  <br>It's only in the last century, however, that the relationship<br>appears to have been restored to the approximate level<br>of complexity characteristic of the music of the late 14th<br>century.<br>Just intonation music naturally lends itself to a <br>complementary arrangement of ratios of small integer <br>numbers of beats.  Ben Johnston pioneered this idea in <br>the rhythms of his quartets.  Thus a 4:3 will often <br>be mirrored with 4 beats against 3, a 6:5 with 6<br>beats against five, and so on. Toby Twining picked <br>this procedure up from Johnston, and employs it in<br>his own just intonation choral compositions: the<br>polyrythms consistently mirror on a larger time-scale<br>the vibrational ratios produced at the waveform level.<br>This is not a new idea.  The masters of ars subtilitas<br>in the 1380s played with this idea extensively and<br>with great subtlety: and in the 1920s Leon Theremin <br>implemented it with his now-lost instrument "the<br>rhythmicon."  Theremin's instrument responded to <br>the presence of dancers in a space (sensed by <br>changes in capacitance as detected by 3 sensors) <br>and produced polyrhythms accompanied by just <br>intonation ratios.  As it turns out, just intonation<br>intervals are very much easier to generate with<br>analog electronic circuits than equal-tempered <br>intervals.  So Theremin's rhythmicon was <br>an early JI synthesizer as well as an interesting<br>example of very early integration between rhythm<br>and tuning.<br>In this century the massive strip-mining and <br>subsequent exhaustion of the 12-tone equal-<br>tempered tuning appears to have led to an<br>increasing dissatisfaction with chronometric<br>18th-century rhythms.  Thus the history of avant<br>garde music in the 20th century is a history of <br>ever less regular rhythm.  First 3 against 4...<br>most famously in the section of "Rite of Spring"<br>where the conductor is supposed to conduct 3<br>beats with one hand and 4 beats in the other.<br>Then, onward and upward to other beat-ratios.<br>"As tonally in 900, so rhythmically in 1900,<br>the relations 2:3 and 3:4 represented the <br>ultimate in harmonic comprehensibility." <br>[Seeger, Charles, "On Dissonant Counterpoint,"<br>Modern Music, Vol. 7, No. 4, 1930, pp. 25-31]<br>Copland's 1924 piano concerto  and<br>Gershwin's Rhapsody in Blue from the same<br>period both use extensive syncopation and <br>hemiolas.  Elliott Carter's metric modulation<br>procedures extended the irregularity of the<br>basic pulse, as did Bartok's essentially barline-<br>less compositions, ditto Varese's "Density 21.5,"<br>"Arcana," "Ionisation," etc.--in many cases <br>using a new key signature every<br>barline.  The real break came when Khaikosru<br>Shapurji Sorabji introduced multiple embedded<br>n-tuplets during the 30s and 40s, and when<br>Nancarrow started stretching the tempi<br>of multiple polyphonic lines by different<br>rates simultaneously.  You get multiple<br>simultaneous tempo-shift curves going on<br>that deform time in a completely plastic<br>way: rhythmic regularity has completely<br>disappeared.  The basic pulse is continuously<br>changing even within the individual note.<br>This has led to rhythmic complexities<br>like those of Michael Gordon's "Yo, Shakespeare!",<br>or Trimpin's, computer-controlled vorsetzer works,<br> or Warren Burt's "I Have My Standards"<br>and "Notes From the Jungle of Intonational <br>Complexity."  <br>It seems likely that the reason for this<br>increasing irregularity and complexity in<br>rhythm is that composers simply beat the<br>12-tone equal tempered scale to death. <br>By the 9th century A.D. they had introduced <br>the third as a consonance, by the 18th<br>century they'd started using sixths  as <br>consonant intervals, by the 1920s and 1930s<br>the major and minor 2nd and major and<br>minor 7ths as part of the spectrum of<br>consonance.  Schoenberg's "emancipation<br>of the dissonance" effectively placed all<br>intervals on a continuous scale--there<br>were no longer any "forbidden" intervals.<br>Everything could be a consonance, depending<br>on context--and the "rules" of consonance and<br>dissonance could be turned upside-down, if <br>desired.  Charles Seeger's "dissonant counterpoint,"<br>introduced in 1916, was a typical example:<br>"Dissonant Counterpoint...is essentially an<br>inverted species counterpoint, the species of <br>the older discipline remaining intact but<br>*dissonance* (seconds, tritones, sevenths,<br>ninths) becoming the norm and *consonance*<br>(thirds, fourths, fifths, sixths, octaves)<br>requiring preparation and resolution." [Nelson,<br>Mark, "In Pursuit of Charles Seeger's Heterophonic<br>Ideal: Three Palindromic Works by Ruth Crawford,"<br>Musical Quarterly, Vol. 72, No. 4, 1986, pg. 459.]<br>The above prescription is a blueprint for <br>post-Webern modernism up to the late 1970s:<br>and indeed, the exhortations of Kyle Gann's<br>music professors to "use more good solid <br>20th century intervals--tritones, minor<br>seconds, major sevenths," is of course nothing<br>but standard Palestrina species counterpoint<br>turned inside out: the "good" intervals of the<br>1500s have become the "bad" intervals of the<br>1920s-1970s, and vice versa.  Modernism did<br>not expand the language of music, of course:<br>there were no new intervals introduced.  The<br>list of preferred intervals had merely been<br>swapped for the list of intervals formerly<br>proscribed. Thus,  by the 1930s there was nothing<br>left to do with harmony or melody in the 12-tone equal<br>tempered system.  The harmonic resources<br>had been played out.  The 12-tone tuning had been<br>strip-mined, leaving a hole in the ground and an<br>enormous amount of bad wannabe-Webern.<br>That left rhythm.<br>So, starting circa 1948,  composers began to explore <br>ever more complex, ever more irregular divisions of<br>the beat.<br>More than one commentator has suggested that<br>Nancarrow represents some kind of "ultima<br>thule" for rhythmic complexity in this progression<br>toward ever more complex time-relationships.<br>However,  this is obviously incorrect.<br>One of the most interesting frontiers in xenharmonic<br>composition is, in fact, the extension of rhythm<br>in accord with the tuning of non-just non-equal-<br>tempered scales.  This is nothing more than a self-<br>evident expansion of Charles Seeger's 1930<br>suggestion  of "a recognition of rhythmic harmony<br>as a category on a par with tonal harmony." [Seeger,<br>Charles, "On Dissonant Counterpoint," Modern Music,<br>Vol. 7, No. 2, 1930, pp. 25-31.]  (Since this is an<br>obvious extension of Seeger's classic modernist<br>insight, naturally no academic has yet suggested<br>it. Score another one for the same no-talent PhDs who<br>barred the greatest tape music composer of the<br>20th century from the Columbia-Princeton Electronic<br>Music Center because of his "lack of credentials"--<br>the composer being, of course, Tod Dockstader.)<br>As we've seen, just intonation compositions naturally<br>lend themselves to small integer ratios of beats (as<br>Johnston, Twining, Partch, et al., have skilfully shown).<br>Indeed, Kenneth Gaburo produced a composition, "Lemon Drops,"<br>using a bank of sine wave oscillators at the U. of Illinois,<br>which uses the same principle of moving micro-ratios<br>on the waveform level into macro-ratios on the level<br>of time of the individual measure. (Circa 1972?)<br>And, as we've seen, equal tempered compositions appear<br>to lend themselves  to much more complex <br>divisions of the beat: embedded n-tuplets, metric<br>modulation, and so on.  On the macro-level of<br>the individual measure this is very similar to approximating <br>an irrational number with two large rationals. If<br>you've heard a complex rhythm like 7 in the time of<br>4 inside 11 in the time of 9 inside 3 in the time of 2<br>inside 17 in the time of 13, you realize that the end<br>result is a set of timings that sound nearly like<br>ratios of irrational numbers--above a sufficient<br>level of embedded n-tuplets, no underlying pulse is<br>audible at all.  This is obviously akin (on the macro-level)<br>to the ratio of irrational numbers on the micro-level of<br>the individual waveform which defines an equal-tempered<br>scale, in which all pitches are some Nth root of K.<br>By analogy, the next step in rhythmic complexity is<br>self-evident:  move to ratios of transcendental numbers<br>on the macro-level of the beat, mirroring the non-just<br>non-equal-tempered pitches of n-j n-e-t scales.<br>Our present system of notating music has no way of<br>dealing with such divisions of the beat.  They are really<br>impossible to notate with anything like conventional<br>musical notation.                                5       11   17<br>While regular pulses like cut time or  8  or  8  +  8  can<br>be easily notated, and even very complex ratios made up of<br>embedded n-tuplets *can* be written down in conventional<br>notation, the kind of rhythmic pulsations I'm talking<br>about here lie completely outside the range of Western<br>notation.  The system just breaks down.  Conventional<br>notation can't handle these rhythms *at all.*<br>Let me give an example, so you can get an idea of what<br>I'm talking about here:<br>At a tempo of 60 each quarter note lasts exactly one<br>second.  So common time (4/4) produce measures<br>lasting 4 seconds, with each quarter note lasting one second,<br>each eighth note last 1/2 second, each 16th note lasting<br>1/4 second...and so on.  A triplet 8th note would use 3<br>8th in the time of 2, so each 8th note would last 1/3 second.<br>This is a simple extension of micro-ratios at the<br>waveform level into macro-ratios at the level of the beat.<br>A more complex embedded tuplet might require, say,<br>a measure in 4/4 to have 11 eighths in the time of 8 eighths,<br>with 5 in the time of 4 inside it, with 3 in the<br>time of 2 inside that.  If we had a measure like this:<br>4  |-------- 11:8------------------------------------------|<br>4  |----5 : 4---------------------| 8th 8th 8th 8th 8th 8th 8th<br>     8th 8th 8th |----3:2--------|<br>                         8th  8th  8th<br>Working from the outside in, the divisions of the beat are:<br> <br>the last 7 8th notes have a duration of 8/11 of 1/2  second =<br>8/22  of a second;  the first 3 8th notes have a duration of<br>4/5 of that, or 4/5*8/22 = 40/110 or 20/55 of a second,<br>and the 3 eight note sof hte inenrmost n-tuplet have a <br>duration of 2/3 that, or 40/165 of a second.  This is <br>number complex enough that any underlying pulse (if<br>audible) is quite obscure and irergular-sounding.  Again,<br>a reasonable analogy to the irrational Nth root of K <br>ratios of equal-tempered pitches.<br>However, moving on to non-just non-equal-tempered<br>tuning produces a new level of rhythmic complexity,<br>when the individual scale pitches are projected<br>upwards into the macro-level of the individual measure.<br>A typical n-j n-e-t scale is one of the subset of tunings<br>produced by taking ratios of inifnite continued fractions.<br>The fraction N1 +  N2<br>                           ___ <br> 		        N3 +<br>      			   __<br>			   N4 + <br>			       __<br>			       N5 + ...<br>in general produces numbers which are neither simple <br>integers nor Nth roots of K.   For example, if N1...NJ<br>= 1, the result is 1.61803399, or phi (the Golden Ratio).<br>By using a very simple computer program (3 lines)<br>to evaluate such a continued fraction out to, say,<br>N20, it's easy to calculate the frequencies of<br>such scale-steps to an accuracy of 7 figures.<br>The first 5 infinite continued fractions for<br>N1...NJ = 1 through 5 are:<br> <br>f1 = 1.618034<br>f2 = 2.414213<br>f3 = 3.302775<br>f4 = 4.236067<br>f5 = 5.192582<br>f6 = 6.162277<br> <br>If we let f0 = 1.0, this gives 6 scale-steps.  Now,<br>notice that these ratios when expressed as rhythms<br>*cannot be notated in any conventional way.*<br>There is just no reasonable method of writing<br>down a rhythmic system in which the longest<br>note lasts 1.0, the next longest note last 1/1.618034,<br>the next longest note lasts 1/2.414213, the next<br>longest note lasts 1/3.302775, and so on.  The<br>concept is totally alien to anything in our<br>notational convention.  <br>These kinds of rhythms just blow Western notation<br>right out of the water.   In fact, not only can we<br>not *write music* that *notates* such divisions<br>of the measure, at present we cannot even *talk*<br>about such divisions of the measure with a <br>comprehensible vocabulary.  We do not even have<br>the *words* to begin a discussion of such temporal<br>divisions.  We are, literally, mute.  <br>Why does this matter?<br>It matters because one of the clearest and simplest<br>compositional strategies involving non-just non-equal-<br>tempered scales is to work with such rhythms on<br>the level of the individual measure, then in blocks of<br>phrases which last for times proportional to these<br>ratios, then in sections of the work which last for<br>times also proportional to these ratios on a larger<br>time-scale.  This continues traditional musical practice<br>in a sensible and straightforward way: namely, by<br>systematically extending  the micro-level<br>of frequencies up into the macro-level of the beat.<br>In such a non-just non-equal-tempered composition,<br>all timbres could (using Csound) easily be made up of<br>additive sets of freuqnecies described by a non-just<br>non-equal-tempered tuning, and all the durations<br>of the notes *also* described by the same<br>ratios, along with durations of sections, movements,<br>etc.<br>However!<br>Trying to keep track of the rhythms is mind-bending<br>and maddening.  Because of the total inadequacy of<br>notational systems or even vocabulary, I have been<br>forced to notate these rhythms as delta start times:<br>that is, note durations--which must then be<br>added to the absolute run time (as demanded by<br>Csound).  It's *incredibly* meticulous, and requires<br>a *great deal* of bothersome calculation.<br>Interestingly, the rhythms sound jazzy and almost<br>improvisational.  They are not conventional.  And<br>in particular, when two or more strata of such rhythms<br>are going at once, made of notes broken down<br>into subvalues of these infinite continued fraction<br>convergents, with each note-stream at a tempo<br>also described by the an infinite continued fraction,<br>the results are truly exotic.<br>Next post, some suggestions for a generalized<br>rhythmic vocabulary that would at least allow<br>an approach to coherent manipulation of time-<br>streams and durations derived from non-just<br>non-equal-tempered tunings.<br>--mclaren <br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Thu, 9 Nov 1995 06:50 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id UAA26952; Wed, 8 Nov 1995 20:50:30 -0800<br>Date: Wed, 8 Nov 1995 20:50:30 -0800<br>Message-Id: <951109043956_71670.2576_HHB32-6@CompuServe.COM><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2292 href="#2292">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>11/9/1995 10:28:53 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: A new rhythmic vocabulary<br>---<br>"All things come from thence, from<br>that universal rule either directly proceeding<br>or by way of sequence." [Marcus Aurelius,<br>"Meditations"]<br>The previous post explored the outer<br>edges of rhythm by suggesting an<br>extension of the waveform periodicity<br>in the frequency domain of non-just<br>non-equal-tempered scales up into<br>the beat level of the individual measure.<br>As mentioned, there is a complete and<br>utter lack of generalized rhythmic<br>vocabulary to talk about these kinds<br>of divisions of the beat.  We can talk<br>sensibly in Western music about "half notes,"<br>"3 eighth notes in the time of 2," and so on,<br>and we can even (with some difficulty)<br>talk about "40% of a half note" (notated<br>as the N-tuplet `8 in the time of 5'),<br>but when it comes to something like<br>1/1.61803399 of a half note, conventional<br>Western notation falls mute.  Indeed, there<br>is not even the ghost of a clue where to<br>start talking about such divisions of the<br>beat except in raw numbers--which are<br>tremendously hard to deal with intuitively,<br>or manipulate as ensembles without huge<br>amounts of gratuitous calculation.<br>What does this have to do with tuning?<br>It seems clear that the natural way to compose<br>in non-just non-equal-tempered scales is to<br>extend the frequencies into divisions of the<br>beat.  But what we want is a simple way of<br>manipulating such rhythms.  Ideally, we should be<br>able to easily and simply apply such familiar<br>concepts as rhythmic augmentation and diminution<br>to sets of rhythms derived from the pitches of<br>non-just non-equal-tempered scale frequencies.<br>If we can't do this, it cripples us at the start <br>in composing with non-just non-equal-tempered<br>scales.<br>First, let me suggest a generalization of the<br>standard Western rhythmic vocabulary.<br>Traditionally, divisions of the beat are <br>handled with a descriptive vocabaular that<br>directly specifies the division of the beat:<br>half note lasts one half a whole note,  quarter<br>note lasts one quarter of a whole, triplet<br>quarter packs 3 quarters into the time of 2,<br>and so on.  This is fine as far as it goes. But<br>extending to anything other than simple<br>integer divisions of the beat is impossible:<br>there's no such thing as a "1.618034-note."<br>Instead, permit me to suggest what the<br>computer programmers have christened<br>a "call by reference," rather than the<br>"call by value" of conventional Western<br>rhythmic vocabulary.<br>Instead of using words for the divisions<br>of the beat that describe the actual <br>values, suppose we use a rhythmic <br>vocabulary which describes the successive<br>position of the rhythm in a hierarchy from<br>long to short.  This kind of rhythmic <br>vocabulary could be applied to an unlimited<br>range of different divisions of the beat, rather<br>than the extremely limited set of integer<br>divisions of the beat which can be described<br>by traditional Western usage.<br>PRIMARY -- longest duration within the measure<br>SECONDARY -- next longest duration<br>TERNARY -- next longest<br>QUATERNARY -- next longest<br>..and so on.<br>With this change of vocabulary, it suddenly<br>becomes possible to write down a set of<br>rhythms derived from our non-just non-equal-<br>tempered scale:<br>P S S P T P <br>Given the non-just non-equal-tempered<br>scale described in the previous post, this<br>is a set of notes of duration:<br>1.0 1/1.618034  1/1.618034 1.0 1/2.414213 1.0<br>In the context of this new rhythmic vocabulary,<br>all of the traditional techniques of Western<br>rhythm can be applied.  Here, augmentation<br>refers to multiplying all notes by the value<br>of 1/SECONDARY beat duration.  <br>In traditional Western usage, the secondary<br>beat duration is always 1/2, so augmentation<br>is always a simple doubling of note durations.<br>Contrariwise, diminution is a simple havling<br>of note durations.<br>In the context of the rhythms derived from our<br>non-just non-equal-tempered scale, however,<br>augmentation means multiplying all note<br>durations by 1.618034, while diminution <br>means multipying all note durations by <br>1/1.618034.<br>Embedded tuplets can also be carried over<br>into the new rhythmic scheme, with a<br>concomittant increase in rhythmic<br>complexity.  A triplet in traditional Western<br>usage is obtained by adding the primary to<br>the secondary duration; here it's obtained<br>by doing the same thing, but the result<br>(instead of being a 3:2 duration) is a 2.618034:1<br>duration.  And so on.<br>This gives us at least some reasonable way<br>to *talk* about rhythmic divisions derived<br>by time-scaling our non-just non-equal-tempered<br>micro-level of frequency up into the level<br>of the individual measure.  Because of the<br>obvious implications for new kinds of compositional<br>techniques, this derivation of rhythm from<br>non-just non-equal-tempered scale<br>frequencies clearly demands further<br>exploration.<br>The next post will discuss generalizations of<br>vertical structures in non-just non-equal-tempered<br>scales, along with an examination of consonant<br>vertical structures in a representative non-just<br>non-equal-tempered scale, along with several<br>kinds of near-equivalents to conventional modulation<br>between keys (equal temperaments) or 1/1s (JI).<br>---mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Fri, 10 Nov 1995 00:38 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id OAA22718; Thu, 9 Nov 1995 14:38:39 -0800<br>Date: Thu, 9 Nov 1995 14:38:39 -0800<br>Message-Id: <Pine.3.89.9511091753.A26367-0100000@email.ir.miami.edu><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2298 href="#2298">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>11/10/1995 10:56:58 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: A generalized approach to harmony<br> in non-just non-equal-tempered scales<br>---<br>"Observe constantly that all things take place<br>by change, and accustom yourself to consider that<br>the nature of the universe loves nothing so much<br>as to change the things which are to make new things <br>like them.  For everthing that exists is in a manner<br>the seed of that which will be." [Marcus Aurelius, <br>"Meditations"]<br>Bill Sethares and Your Humble E-Mail Correspondent<br>have both struggled for more than a year with the<br>vertical implications of non-just non-equal-tempered<br>scales.<br>While Bill's spectral mapping procedure offers a<br>way of adroitly controlling *sensory* consonance<br>and dissonance in n-j n-e-t scales, this is quite a<br>different matter from the tonal substructure implicit<br>within the scale.<br>Douglas Keislar's PhD thesis makes this clear. By<br>rendering a scale like (say) 13/oct more consonant<br>on the level of individual partials interacting<br>within the critical band, we do *not* produce<br>any greater sense of overall "tonality" for the listener.<br>Even with smoothly beatless chords, 13-TET *still*<br>sounds profoundly anti-tonal and non-cadential. Even<br>though a I-IV-V-I may be made beatless through the<br>miracle of modern digital signal processing, it still<br>doesn't sound like "the way the scale wants to behave."<br>And thus other compositional strategies must be <br>employed, different from  those dragged out of 12-TET <br>and press-ganged into service. <br>In short, "I don't think we're in Kansas anymore, Toto."<br>And outside of 12-TET, you'd better take that into <br>account...or your compositions will sound like very<br>badly out-of-tune 12-TET leftovers.<br>These complexities are sufficient to give pause to<br>a composer contemplating a work in 19- or 53-tone<br>equal, or (say) 13-limit or 31-limit JI; but when<br>it comes to non-just non-equal-tempered tunings,<br>what's a xenharmonic composer to do?<br>The first and most important point in generating<br>vertical structures in non-just non-equal-scales<br>is to recognize that some general procedures *do*<br>carry over from other tunings, albeit in highly<br>modified form.<br>John Chalmers has elaborated a classical method<br>for scale construction which he calls "tritriadic"<br>scale generation.  The basic idea (based on a very<br>ancient principle) is that scales have typically<br>been generated by taking the Tonic,  forming a triad;<br>then a Mediant, and forming a triad, and finally<br>a Dominant, and forming a triad.  The set of tones<br>formed by the union of all the pitches in the triads<br>has conventionally produced the scales characteristic<br>of Western music.  John's inspiration was to vary<br>the frequency ratios of the T, D and M chords to<br>generate variant scales. (John Chalmers' tritriadic<br>techniques have been unjustly neglected as a topic<br>for this tuning forum; if something doesn't change,<br>clearly I shall have to author several future posts<br>on the subject.) <br>Interestingly, something akin to this procedure can be<br>employed with non-just non-equal-tempered tunings.<br>One of the more obvious n-j n-e-t scales is the<br>set of modes of the ideal vibrating cylinder free at<br>both ends.  These are given by Lord Rayleigh (1896)<br>in his "Theory of Acoustics," Vol. 2, pg. 25, refining<br>the result obtained by Hoppe in 1871:<br>The frequency f of each partial is proportional to<br>sqrt[[s^2]*[(s^2 -1)^2]/(s^2 + 1)]   <br>Setting s successivey to 2, 3, 4... and referring each<br>tone to the fundamental of the inharmonic series,<br>the partial frequencies are:<br>f0 = sqrt(4*9/5) = 2.68328/2.68328 = 1.0<br>f1 = sqrt(9*64/10) = 7.58946/2.68328 = 2.82842<br>f2 = sqrt(16*225/17) = 14.55197/2.68328 = 5.4320<br>f3 = sqrt(25*576/26) = 23.5339/2.68328 = 8.77057<br>f4 = sqrt(36*1225/37) = 34.5329/2.68328 = 12.8696<br>f5 = sqrt(49*2304/50) = 47.5173/2.68328 = 17.7086<br>f6 = sqrt(64*3969/65) = 62.5135/2.68328 = 23.297422<br>f7 = sqrt(81*6400/82) = 79.510699/2.68328 = 29.631905<br>f8 = sqrt(100*9801/101) = 98.508682/2.68328 = 36.71204<br>f9 = sqrt(121*14400/120) = 120.00417/2.68328 = 44.72294<br>f10 = sqrt(144*20449/143) = 143.49913/2.68328 = 53.47899<br>&c.<br>Reducing these values to cents gives<br>Pitch 1 = 0 cents<br>Pitch 2 =  1799.99 cents<br>Pitch 3 =  2926.97 cents<br>Pitch 4 =  3759.204 cents<br>Pitch 5 =  4423.074 cents<br>Pitch 6 =  4975.653 cents<br>Pitch 7 =  5450.5181 cents<br>Pitch 8 =  5866.8954 cents<br>Pitch 9 =  6237.8177 cents<br>Pitch 10 = 6579.5317 cents<br>Pitch 11 = 6889.0807 cents<br>&c.<br>The primary consonant vertical structure in this<br>system will be the complex Pitch 1 + Pitch 2 + Pitch 3.<br>This is the *least* compact vertical structure available;<br>notice that, because of the wide spacing between<br>members of this inharmonic series, Plomp & Levelt's<br>findings tell us that this primary vertical structure<br>in this n-j n-e-t tuning will be consonant (provided<br>that the timbre is made up of partials tuned to this<br>scale) because no two partials will fall within the<br>same critical band.<br>However, there are other consonant vertical structures<br>than the primary: for example, members 2, 3 and 4<br>of this inharmonic series could be used as a chord.<br>This would produce:<br>Secondary vertical structure: <br>Pitch 1 = 0 cents<br>Pitch 2 =  1126.98 cents<br>Pitch 3 = 1959.214 cents<br>A third-order vertical structure comes from<br>members 3, 4 and 5 of the inharmonic series:<br>Pitch 1 = 0 cents<br>Pitch 2 = 832.234 cents<br>Pitch 3 = 1496.104 cents<br>And a fourth-order vertical structure comes<br>from members 4, 5 and 6 of the inharmonic series:<br>Pitch 1 = 0 cents<br>Pitch 2 = 663.87 cents<br>Pitch 3 = 1216.449 cents<br>A fifth-order vertical structure comes from<br>member 5, 6 and 7 of the inharmonic series:<br>Pitch 1 = 0 cents<br>Pitch 2 = 552.579 cents<br>Pitch 3 = 1027.4441 cents<br>A sixth-order vertical structure comes<br>from members 6, 7 and 8 of the inharmonic series:<br>Pitch 1 = 0 cents<br>Pitch 2 = 474.858 cents<br>Pitch 3 = 891.2424 cents<br>A 7th-order vertical structure comes from<br>members 7, 8 and 9 of the inharmonic series:<br>Pitch 1 = 0 cents<br>Pitch 2 = 416.3773 cents<br>Pitch 3 = 787.2995 cents<br>And an 8th-order vertical structures comes<br>from members 8, 9 and 10 of the inharmonic series:<br>Pitch 1 = 0 cents<br>Pitch 2 = 370.9223 cents<br>Pitch 3 = 712.6363 cents<br>This is a slightly stretched neutral triad with<br>both the fifth and the third somewhat sharper<br>than the values of Erv Wilson's hypermeantone<br>scale. <br>A 9th-order vertical structures comes<br>from members 8, 9 and 10 of the inharmonic series:<br>Pitch 1 = 0 cents<br>Pitch 2 = 341.714 cents<br>Pitch 3 = 651.263 cents<br>This vertical structure is not consonant because<br>the distance between Pitch 2 and Pitch 3 is less<br>than a critical bandwidth (290.5 cents) in the midrange<br>of human hearing.  (At extremely high frequencies this<br>vertical complex would sound consonant, primarily<br>because the upper partials lie above the range of human<br>hearing.)<br>Subsequent nth-order vertical complexes will<br>clearly be less consonant.<br>This gives us a set of harmonies which can be<br>transposed to different steps of the scale to<br>produce inharmonic progressions.  (Again, we<br>assume the partials are matched to the tuning.)<br>Several points of note:<br>First, John Chalmers' tritriadic scale generation<br>techniques can be employed with the 8th-order<br>consonant vertical structure.  It will produce <br>modes significantly different from those familiar<br>from the harmonic series.  <br>Second, the inharmonic series considered here<br>requires us to travel farther up to find a familiar<br>vertical structure than does the ordinary harmonic<br>series.  In the classical Western case, the 4th-order<br>vertical structure using harmonic series members<br>4, 5 and 6 forms the basis of Western harmony. Here,<br>the 8th-order vertical structures using inharmonic<br>series members 8, 9 and 10 form the basis of <br>n-j n-e-t harmony in this particular inharmonic<br>series.  <br>Third, different inharmonic series can easily be<br>generated by modifying the equation for the modes<br>of a vibrating tube.  For instance, instead of<br>The frequency f of each partial being proportional to<br>sqrt[[s^2]*[(s^2 -1)^2]/(s^2 + 1)] , we could set<br>f proportional to <br>sqrt[[(s + 1)^2]*[(s^2 -1)^2]/s^2]<br>or<br>sqrt[[(s + 3)^2]*[(s^2 -1)^2]/(s+1)^2]<br>or<br>sqrt[[(s + 5)^2]*[(s^2 -3)^2]/(s+1)^2]<br>or<br>cube root of[[(s + 1)^2]*[(s^2 -1)^2]/s^2]<br>or<br>cube root of [[(s + 1)^3]*[(s^2 -1)^2]/s^3]<br>or<br>sqrt[[(s - 1)^2]*[s^3]/s^2] <br>and so on.  Clearly there are an infinite<br>number of equations describing non-just<br>non-equal-tempered scales, which can be obtained<br>merely by varying the equation for the modes<br>of a vibrating cylinder. <br>A larger question is: What physical oscillator<br>geometry corresponds to a given arbitrary<br>equation?  This is an extraordinarily difficult<br>problem.  It may be insoluble.  While the inverse<br>problem--given an arbitrary oscillator geometry,<br>can the equation describing the modes of the system<br>be found?--can at least be attacked numerically<br>(if all else fails), the problem of obtaining an<br>oscillator geometry from an inspection of the<br>equations describing the modes of a cylinder may<br>not have a single-valued solution.  That is, different<br>physical oscillatory system may produce the same<br>frequency spectrum. <br>This has been proven true in several cases, particularly<br>the case of different drum geometries, and may<br>be true for all physical oscillators. (For discussion of <br>a general mathematical proof of this proposition, see <br>Gordon, C., Webb D., and S. Wolpert, "One Cannot Hear <br>the Shape Of A Drum," Bulletin of the American <br>Mathematical Society (New Series), July 1992, Vol. <br>27, No. 1, pp.134-138)<br>Thus far, we have examined only the overtone-<br>equivalent members of the inharmonic series.<br>What about subinharmonic vertical structures?<br>That is the subject of the next post.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Fri, 10 Nov 1995 23:33 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id NAA16690; Fri, 10 Nov 1995 13:33:38 -0800<br>Date: Fri, 10 Nov 1995 13:33:38 -0800<br>Message-Id:  <9511101332.aa06606@cyber.cyber.net><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2314 href="#2314">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>11/13/1995 9:45:55 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: n-j n-e-t vertical structures - part 5<br>---<br>"The safety of life is this: to examine everything <br>all through, what is it of itself, what is its <br>nature, what is its form..." [Marcus Aurelius, <br>"Meditations"]<br>Of the nature of vertical structures in a <br>typical subinharmonic series, some has<br>been said: more remains.<br>By analogy with just intonation, the subinharmonic<br>series formed from the vibrational modes of<br>an ideal vibrating cylinder are obtained <br>by inverting the values<br>f0 = sqrt(4*9/5) = 2.68328/2.68328 = 1.0<br>f1 = sqrt(9*64/10) = 7.58946/2.68328 = 2.82842<br>f2 = sqrt(16*225/17) = 14.55197/2.68328 = 5.4320<br>f3 = sqrt(25*576/26) = 23.5339/2.68328 = 8.77057<br>f4 = sqrt(36*1225/37) = 34.5329/2.68328 = 12.8696<br>f5 = sqrt(49*2304/50) = 47.5173/2.68328 = 17.7086<br>f6 = sqrt(64*3969/65) = 62.5135/2.68328 = 23.297422<br>f7 = sqrt(81*6400/82) = 79.510699/2.68328 = 29.631905<br>f8 = sqrt(100*9801/101) = 98.508682/2.68328 = 36.71204<br>f9 = sqrt(121*14400/120) = 120.00417/2.68328 = 44.72294<br>f10 = sqrt(144*20449/143) = 143.49913/2.68328 = 53.47899<br>&c.<br>to obtain<br>fsub0 = 1/sqrt(4*9/5) = 2.68328/2.68328 = 1.0<br>fsub1 = 1/sqrt(9*64/10) = 7.58946/2.68328 = 0.353554<br>fsub2 = 1/sqrt(16*225/17) = 14.55197/2.68328 = 0.1840942<br>fsub3 = 1/sqrt(25*576/26) = 23.5339/2.68328 = 0.1140176<br>fsub4 = 1/sqrt(36*1225/37) = 34.5329/2.68328 = 0.0777024<br>fsub5 = 1/sqrt(49*2304/50) = 47.5173/2.68328 = 0.0564697<br>fsub6 = 1/sqrt(64*3969/65) = 62.5135/2.68328 = 0.0429232<br>fsub7 = 1/sqrt(81*6400/82) = 79.510699/2.68328 = 0.0337474<br>fsub8 = 1/sqrt(100*9801/101) = 98.508682/2.68328 = 0.027239<br>fsub9 = 1/sqrt(121*14400/120) = 120.00417/2.68328 = 0.0223598<br>fsub10 = 1/sqrt(144*20449/143) = 143.49913/2.68328 = 0.0186989<br>&c.<br>Forming the subinharmonic series starting on inharmonic series<br>member 10 produces:<br>faleph    = 53.47899*0.027239    =  1.4567142<br>fbeth     = 53.47899*0.0223598   =  1.1957795<br>fgem      = 53.47899*0.0186989  =   1.0<br>Reducing, this becomes<br>faleph = 831.77662 cents<br>fbeth  =  309.52791 cents<br>fgem   =  0 cents<br>Of particular interest here is the quasi-sixth formed by<br>falph, which happens to identical with phi, the golden<br>ratio.   This vertical complex is very similar to one discussed by<br>Thorwald Kornerup, and it is particularly interesting<br>in this context to observe that this one arises *naturally*<br>out of an ordinary physical process--namely, a subinharmonic<br>series based on the modes of an ideal vibrating cylinder.<br>Since Kornerup's Golden Scale is well known and <br>discussed in detail in Mandelbaum's thesis (among other<br>references), further discussion of this similar scale is<br>of less interest than a consideration of general principles<br>for organizing vertical progressions in n-j n-e-t scales.<br>Thus, this example may serve to show the subtle<br>links between relatively familiar non-just non-equal-tempered<br>tunings and the purely mathematical derivation of n-j n-e-t<br>scales from combinations of inharmonic and subinharmonic<br>series.<br>Clearly, both the inharmonic series vertical strucures *and* the<br>subinharmonic series structures may be formed on any scale<br>member.<br>Equally clearly, one might imagine "modulating" between<br>entirely different inharmonic or subinharmonic series.  <br>In that case, one could bring along the vertical complexes<br>derived from one inharmonic series into another, entirely<br>different, inharmonic series. For example, a series of<br>vertical structures derived from the inharmonic series<br>of the clamped metal bar might be played first in<br>the n-n n-e-t scale derived from the modes of the clamped<br>bar, then the same progression of vertical structures <br>might continue to play while the tuning changed to<br>that of an ideal vibrating sphere, and the tuning might<br>then change into that of an ideal vibrating cylinder, and<br>so on.<br>In fact one could just as easily "modulate" between different<br>modes of vibration of a sphere: zonal harmonics, torsional<br>vibrations, etc., each giving rise to a different non-just<br>non-equal-tempered scale.<br>This is a process conceptually akin to "modulation" in<br>JI and equal temperament, but more complex: for the<br>subinharmonic series formed on a given n-j n-e-t are,<br>as we have seen, in general not as closely related to<br>the vertical structures formed from inharmonic series<br>as is the minor triad to the harmonic series of the major<br>triad in traditional Western harmony.<br>Regardless, this set of posts may have given a glimpse<br>of the universe of new harmonies and melodies awaiting<br>the composer adventurous enough to dare composing<br>in non-just non-equal-tempered tunings.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Tue, 14 Nov 1995 07:55 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id VAA08993; Mon, 13 Nov 1995 21:55:42 -0800<br>Date: Mon, 13 Nov 1995 21:55:42 -0800<br>Message-Id: <951114005507_105935759@mail04.mail.aol.com><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2384 href="#2384">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>12/17/1995 8:31:26 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject:  Xenharmonic CDs<br>---<br>Time once again to give brief reviews of<br>the latest xenharmonic laser cookies...<br>First and most impressive, Marc Battier's<br>"Transparence."  This CD is available from<br>EMF, Joel Chabade's Electronic Music<br>Foundation.  Their catalog is available<br>on-line from emusic@aol.com.<br>Battier uses a single sentence from Henry<br>Chopin as source material for a virtuoso<br>set of digital signal processing<br>manipulations.  This CD is beautiful,<br>non-12-sounding, and endlessly varied<br>and interesting.<br>Many of the manipulations appear to center<br>around resonant filters: the effect is to pick<br>out distinctly non-12 pitches and generate<br>effects which sound nothing like the original<br>material. <br>The entire CD can be thought of as a giant set<br>of "variations on a theme" of a single acoustic<br>input.  Highly recommended!<br>Next, Anna Homler's "Do Ya Sa Di Do."  Ms.<br>Homler specializes is singing what sound like<br>Japanese or Korean chants against sampler-<br>manipulated electronic backgrounds.  The<br>net effect is often impressive, and distinctly<br>outside the standard 12-tone equal-tempered<br>scale.<br>The most xenharmonic tracks on this CD are<br>No. 1, in which she fringes her chant with<br>an aureole of xenharmonic "inflexional"<br>pitches (as in Balinese and Javanese vocal<br>music, where slendro and pelog are generally<br>used as a pont of departure, or as in the<br> vocal xenharmonies of Sinead O'Connor, <br>Louis Armstrong, Ofrah Haza, et alii).<br>Most wildly microtonal, however, is track<br>9--where Ms. Homler produces squeaks and<br>whistles which the human vocal track does<br>not appear to have been designed to<br>accomodate.  The effect is xenharmonic,<br>beautiful, and altogether exotic.<br>The CD is available from:<br>Homler, PO Box 48770, Los Angeles CA<br>90048.<br>Ben Johnston's "Calamity Jane to her Daughter"<br>on the CD "Urban Diva" is an impressive example<br>of extended just intonation.  This just array<br>appears to extend upward to around 31-limit,<br>and offers a formidable challenge to the<br>aspiring po-mo vocalist.<br>Forunately, soprano Dora Ohrenstein is more<br>than up to the challenge.  Her rendition proves<br>both sonically idirescent and emotionally<br>compelling.<br>*Highly* recommended!<br>The CD "Urban Diva" is available from Composer's<br>Recordings Inc., 73 Spring St., New York NY 10012-<br>5800, phone # (212) 941-9673.<br>Last and decidedly least: Chris Brown's<br>"Lava."  This composition combines electronically<br>manipulated sounds with live percussion and<br>digital keyboards.  <br>Alas, the piece quickly grows unbearably<br>repetitive and wearisome.  Most of the electronic<br>manipulations involve uninteresting delay or<br>filter effects applied to inherently ugly percussive<br>sounds.  The result is less than impressive.<br>My patience did not extend to the end of this CD.<br>Not recommended.<br> <br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Sun, 17 Dec 1995 17:48 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id IAA24152; Sun, 17 Dec 1995 08:48:09 -0800<br>Date: Sun, 17 Dec 1995 08:48:09 -0800<br>Message-Id:  <9512170815.aa22014@cyber.cyber.net><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2385 href="#2385">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>12/17/1995 8:48:09 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Sonics Arts Gallery concert<br>---<br>On Friday, 5 November, Your Humble E-Mail<br>Correspondent gave a concert along with Jonathan<br>Glasier at the Sonic Arts Gallery in San Diego.<br>The program consisted of:<br>[1] Dual pianos tuned to different 12-pitch subsets<br>of 34/oct.  With J. Glasier on one piano and myself<br>on another, we explored 34-tone equal temperament<br>in a piece which sounded as though one person was<br>playing, albeit with superhuman facility.  By judiciously<br>switching MIDI channels during the piece to obtain the<br>third 12-tone set of 34-equal, the entire 34/oct scale<br>was covered.<br>[2] The second piece also featured Glasier and YHC on<br>dual MIDI keyboards--this time using a 5 and a 7-pitch<br>subset of 34-TET with gamelan-like timbres.  The<br>general effect was that of a digital trip to Bali.<br>[3] The third piece used harmonic series 1-60 for<br>an old favorite, also played at last year's sonic arts<br>gallery concert series.  A staple concert piece, extremely<br>xenharmonic.<br>[4] The fourth piece used a TX802 harmonium timbre <br>and a cello to explore Harry Partch's 43-tone just array<br>[5] In the fifth piece, a vibraphone timbre counterpointed<br>pizzicato cello--also in Partch 43.<br>[6] The fifth piece juxtaposed exotic synth timbres in<br>the Carlos Gamma non-octave scale against Tibetan bells,<br>waterphone, and struck pieces of scrap metal to generate<br>an eerie and unfamiliar sound-world.  This may be the<br>first time Carlos Gamma has been performed at a public<br>concert.<br>All told, the concert was a success.  In attendance: Ted<br>Melnechuk, the xenharmonist Ralph David Hill, and a variety<br>of other sonically adventurous folk.  <br>The placement of contact mike on the cello did not produce<br>good recordings of the Partch pieces, but the other concert<br>pieces were recorded on digital tape and will form part of<br>a forthcoming compilation tape.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Mon, 18 Dec 1995 16:29 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id HAA03300; Mon, 18 Dec 1995 07:28:56 -0800<br>Date: Mon, 18 Dec 1995 07:28:56 -0800<br>Message-Id:  <9512180728.aa02212@cyber.cyber.net><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2386 href="#2386">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>12/18/1995 7:28:56 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Chalmers' Constant and a<br> family of constants giving rise to<br> yet another non-just non-equal-tempered<br>  scale<br>---<br>As John Chalmers has pointed out, the<br>iterated absolute log function produces<br>a set of unpredictable numbers unless it<br>starts with a certain number.<br>In that case, the series enters a fixed point.<br>If the function is called the mclaren series,<br>clearly this constant should be named <br>Chalmers' Constant.  It lies between <br>0.399012979 and 0.399012978.<br>This constant is different for each <br>logarithmic base.  Thus a family of<br>constants is implied.  For base e,<br>the constant lies between 0.567143289<br>and 0.567143291.  For other bases,<br>the constant is different.<br>This implies in turn an infinite number<br>of non-just non-equal-tempered scales.<br>One could, for example, generate one<br>such scale from the constants for the<br>logarithmic bases of the primes:<br>C[1] = fixed point for iterated log base 3<br>C[2] = fixed point for iterated log base 5<br>C[3] = fixed point for iterated log base 7<br>C[4] = fixed point for iterated log base11<br>C[5] = fixed point for iterated log base 13<br>C[6] = fixed point for iterated log base 17<br>C[7] = fixed point for iterated log base 19<br>C[8] = fixed point for iterated log base 23<br>and so on.<br>Another scale could be generated by<br>taking<br>C[1] = fixed point for iterated log base pi<br>C[2] = fixed point for iterated log base e<br>C[3] = fixed point for iterated log base F<br>C[4] = fixed point for iterated log base L<br>C[5] = fixed point for iterated log base C<br>C[6] = fixed point for iterated log base G<br>and so on, where F is Feigenbaum's<br>constant, L is the first Liouville number,<br>C is Chapernowne's number, G is the<br>Euler gamma constant, and so on.<br>As musical intervals all these values<br>appear to be particularly intractable<br>from a just intonation point of view;<br>large rational fractions are needed to<br>approximate virtually all of them.  Clearly<br>these musical intervals do not fit into<br>the just scheme of things.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Mon, 18 Dec 1995 16:31 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id HAA03909; Mon, 18 Dec 1995 07:31:02 -0800<br>Date: Mon, 18 Dec 1995 07:31:02 -0800<br>Message-Id:  <9512180729.aa02219@cyber.cyber.net><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2387 href="#2387">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>12/18/1995 7:31:02 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: a new iterated function for<br>  generating non-just non-equal-tempered<br>  tunings<br>---<br>While boring holes for resonators in a<br>pentatonic percussion instrument to be<br>installed at the Exploratorium, a new <br>iteration function occurred to me.  Since<br>these functions are a fertile breeding<br>ground for non-just non-equal-tempered<br>scales, this one might prove of interest<br>to forum subscribers.<br>Operating an industrial drill press is<br>extremely peaceful work--excellent for<br>mathematical contemplation.<br>The function is an alternating series:<br>start with a number, take the tan(x),<br>and whenever it drops below 1.0, take<br>e^x.<br>The first 10 terms of the function are:<br>i[1] = abs(tan(sqrt(2))) = 6.334119167...<br>i[2] = abs(tan(6.334119167)) = 0.05097795...<br>i[3] = abs(e^(0.05097795)) = 1.05229964...<br>i[4] = abs(tan(1.05229964)) = 1.752641506...<br>i[5] = abs(tan(1.752641506)) = 5.438434336...<br>i[6] = abs(tan(5.438434336)) = 1.126353452...<br>i[7] = abs(tan(1.126353452)) = 2.099871982...<br>i[8] = abs(tan(2.099871982)) = 1.710348942...<br>i[9] = abs(tan(1.710348942)) = 7.1119178021...<br>i[10] =  abs(tan(7.1119178021)) = 1.106677438...<br>I believe but cannot prove that all of these<br>numbers are transcendental.  Numbers > 2.0<br>when octave-reduced, and < 1.0 when added to 1.0,<br>produce a musical scale:<br>p[1] =  795.7728117 cents<br>p[2] =  86.07888146 cents<br>p[3] =  88.25468083 cents<br>p[4] =  971.4371163 cents<br>p[5] =  531.8296507 cents<br>p[6] =  205.991463 cents<br>p[7] =  164.8027358 cents<br>p[8] =  929.1488291 cents<br>p[9] =  996.2863799 cents<br>p[10] = 175.4817393 cents<br>As usual, there does not appear to be any<br>obvious pattern in these numbers.<br>Another number arises from this series:<br>1 + the number of successive iterations<br>required for switchover between e^x<br>and abs(tan(x)), or vice versa.  That<br>number is: <br>1.21311151312121913141313111313...<br>This number also appears to be<br>a transcendental.  Can you prove it?<br>As a musical interval this equates to<br>a neutral third of 334.4597716 cents.<br>This is a third which has not to<br>my knowledge appeared previously<br>in the musical literature.<br>--mclaren<br> <br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Mon, 18 Dec 1995 16:33 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id HAA04502; Mon, 18 Dec 1995 07:33:07 -0800<br>Date: Mon, 18 Dec 1995 07:33:07 -0800<br>Message-Id:  <9512180731.aa02233@cyber.cyber.net><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2390 href="#2390">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>12/18/1995 6:19:28 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: transcendental numbers, the entropy<br> of musical scales, and Shannon's theorems<br> applied to tunings<br>---<br>Some time ago, Gary Morrison very unjustly<br>impugned his own mathematical abilities (which<br>are considerable) in the process of asking the<br>question: What is a transcendental number?<br>Looking back at my previous posts on the subject,<br>the source of the confusion is easy to spot. <br>My statement: "In general, it is extremely <br>difficult to determine whether a given number<br>is transcendental or not" could be interpreted<br>in several ways.<br>One could take the statement to mean that<br>the Turing halting problem for a general<br>algorithm that sieves the field of reals<br>and always produces all transcendental<br>numbers has not yet been solved.  <br>Or one could take the statement to mean:<br>"It's impossible to define the term <br>'transcendental number.'"  This is surely<br>untrue.<br>There are many ways to define a<br>transcendental number.  One way is:<br>a transcendental number is the solution<br>of a transcendental equation--that is,<br>an equation involving logarithms or<br>antilogarithms.<br>This is not always true, since the equation<br>e^[i*pi] + X = 0  has the solution 1.  However,<br>perhaps one could say that a transcendental<br>number is one which arises *only* as the<br>solution of an equation involving logarithms<br>or antilogarithms.  (Manuel and John Fitch may<br>jump on me for this one; it may not be 100%<br>true all the time.  Can you think of a counter-<br>example?)<br>Another way of defining a transcendental number<br>is: It's a number which is not the solution of an<br>ordinal arithmetic equation or an algebraic<br>equation with rational-fraction coefficients and<br>exponents and a finite number of terms.<br>Algebraic and arithmetic equations can, of course,<br>also involve an infinite number of terms: pi and e<br>both arise as a result of many different infinite<br>series, the most spectacular of which were <br>discovered by Srinivasas Ramanujan.  <br>Pi and e also arise from equations involving<br>logarithms and antilogarithms: X^[i*pi] + 1 = 0<br>defines e, while e^[i*X] + 1 = 0 defines pi.<br>This latter definition is close to Grolier's,<br>although strictly speaking Grolier's definition<br>is incorrect since it appears to leave out the<br>requirement that a transcendental number<br>cannot be the solution of an arithmetic or<br>algebraic equation with a *finite* number of<br>terms.  (Many of Ramanujan's series involve<br>algebraic products & quotients but an infinite <br>number of terms.)<br>Transcendental numbers also tend to arise when<br>the exponents of an algebraic equation are<br>imaginary. <br>Another way of defining a transcendental number<br>is by the amount of information required to <br>describe it.  How complex an algorithm is<br>needed to generate the number?  How long does<br>it take to run?<br>Claude Shannon proved elegantly that the amount<br>of information required to generate (or parse) a<br>message is proportional to the log to the base 2<br>of the number of bits in the message.  By this<br>standard, an integer requires very little<br>information to parse (or generate).  Even if very<br>long, any finite integer can be entirely written<br>down.  Once the last digit is written, your're<br>finished. A simple "copy this array" algorithm<br>suffices. <br>A rational fraction requires somewhat more<br>information to parse (or generate).  However,<br>the algorithm required to describe the digits <br>in the number 1/9 (for example) is still simple:<br>"Keep writing ones."  I.e., 1/9 = .11111...<br>The information contained in an algebraic<br>irrational is somewhat greater.  (There are<br>two kinds of irrational reals: algebraic<br>irrationals and transcendental irrationals.<br>Algebraic irrationals are those numbers which<br>arise as real roots of equations involving rational <br>coefficients and rational exponents.<br>Transcendental irrationals arise when the<br>algebraic exponent, for example, is itself<br>an algebraic irrational--as in Hilbert's number,<br>2^[sqrt(2)]. )<br>In the case of an algebraic irrational, the algorithm<br>required to generate the number is lengthier<br>than that required to generate the decimal<br>expansion of a rational fraction--thus the<br>algebraic irrational contains more information<br>than does a finite rational fraction.<br>However, transcendental numbers appear to<br>require the most information of all.  To my<br>knowledge, there is as yet no known algorithm<br>by which the entire field of reals may be sieved <br>and by which all transcendental numbers will<br>always be found.  Yet, since we live in a Goedelian<br>universe,  such an algorithm might well exist--<br>and worse still, it might be very simple.<br>Another way of stating this proposition is that<br>the simplest description of a transcendental<br>number appears to be...itself.  If true, this<br> makes transcendental number unique.<br>It has been speculated that the digits in the<br>decimal expansion of transcendental numbers<br>never repeat.  One subscriber has even stated as<br>much on this forum.  However, this proposition<br>has never been proven mathematically.  (Most<br>mathematicians believe this supposition to be<br>true, but belief is *not* the same thing as proof.)<br>Thus it is not yet known how random the digits of (say)<br>pi or e really are.  Many functions, graphs and plots<br>seem random from one perspective, but when rotated<br>they reveal hidden patterns.  The same might be<br>true of pi or e.  So it's entirely conceivable that<br>out beyond a googol decimal places, all the<br>digits of pi might turn to 1's, for example.<br>A disturbing thought...yet one which cannot be<br>dismissed until a proof of the true randomness <br>of pi's digits is found.<br>In view of this possibility, the randomness of<br>a transcendental number's digits cannot be<br>defined. If an infinite number of pi's digits<br>are, say, 1, or 3, or 9, or what-have-you, after<br>a given point, then clearly the number is hardly<br>random at all.<br>However, in order to determine this by brute<br>force we would have to calculate an *infinite*<br>number of digits in pi's decimal expansion. <br>For no matter how far we go, there's always<br>the possibility that at the next digit, the <br>digits fall into a predictable and eternally<br>repeating pattern.<br>Thus the devilish undecidability in so many<br>cases of the question: "Is a given number<br>transcendental?"<br>For example: the number 1 + a googol zeroes<br>+ 1 + an infinite number of zeroes might be<br>transcendental.  <br>Is it?  <br>I don't know.  You don't know.  It's impossible <br>to calculate. No proof exists that this number is<br>transcendental (or not transcendental).  <br>Thus we will likely never know.<br>Mathematicians widely believe the digits<br>in pi to be completely random.  If so, this<br>provides another way of defining transcendental<br>numbers: by the power spectral density of<br>their decimal expansion.<br>By taking the Fourier transform of a number's<br>decimal expansion, its spectrum can be<br>determined.  The spectrum will contain Dirac<br>delta functions at those frequencies which<br>define a periodicity.  Thus the number <br>1.212121212.... will have a sharp spike in<br>its spectrum at 2, since the decimal expansion<br>has a periodicity of 2 digits. There will be little <br>energy anywhere else.<br>Integers have an FFT which forms a narrow<br>or broad Gaussian, depending on the length <br>of the integer.  Rational fractions have<br>broader spectra: algebraic irrationals have<br>spectra which are broader still.  <br>Transcendental numbers (if the<br>mathematicians are right) likely have flat<br>spectra: that is, their digits never<br>repeat.  (This has not been proven, but<br>is universally believed.) <br>Since Parseval's Theorem tells us that the<br>Fourier Transform of the autocorrelation<br>function is the power spectral density, this<br>is only as we would expect--it is, after all,<br>merely another way of saying that the digits of<br>transcendental numbers appear to exhibit<br>no correlation with one another.  There is<br>no pattern hidden in the decimal expansion.<br>Returning to the question of musical scales,<br>this gives us another way of defining tunings:<br>by their entropy.  <br>Since statistical mechanics teaches us that<br>entropy is a measure of the total number of<br>available states in a system, clearly the <br>number of states available in a number's<br>decimal expansion is greatest for transcendental<br>numbers and least for integers.  <br>The next digit in a transcendental number could<br>be anything: the number has maximum extropy.<br>Thus the entropy of a musical scale and<br>be defined by summing the entropies of the<br>numbers which comprise it.<br>The harmonic series clearly has least entropy;<br>next come JI scales made up of rational<br>fractions, next equal tempered scales made<br>up of algebraic irrationals, and finally<br>non-just non-equal-tempered scales made up<br>of transcendental numbers.<br>In this sense, transcendental numbers can be<br>thought of as micro-universes, containing an<br>infinite possible number of available states,<br>and requiring an infinite amount of energy<br>to parse.<br>Although the full workings of the ear/brain<br>system are not yet completely understood,<br>it is safe to assume that however it operates,<br>the human auditory system can be modelled<br>as some sort of state-space machine.  <br>In this case, we have a possible explanation<br>for the response of the ear to the octave<br>as well as Enrique Moreno's extended chroma<br>phenomenon.   Since information is logarithmically<br>proportional to energy (another of Shannon's<br>theorems), it requires the least amount of<br>information/energy to parse a musical<br>interval which is an integer ratio of another<br>interval.  Next most energy is required to<br>parse JI scales, still more to parse scales<br>involving algebraic irrationals (ET scales),<br>and the most energy/information is required<br>when parsing non-just non-equal-tempered<br>scales.<br>This accords well with Gary Morrison's and<br>my own findings about non-octave scales.<br>JI scales sound more "bland" than equal<br>tempered scales--or one might prefer<br>to put it the other way around and say<br>that Nth root of 2 tunings sound muddier<br>and more turbulent than JI tunings. Non-octave<br>scales sound "like thick rich chocolate milk<br>shakes," as Gary has pointed out, and my<br>own experience with non-just non-equal-<br>tempered scales indicates that these<br>tunings sound most complex and sonically<br>luxuriant of all.<br>However, this hypothesis is not supported<br>by the psychoacoustic data which demonstrate<br>clearly that listeners universally hear intervals<br>about 15 cents > the octave as "pure octaves"<br>and intervals of 2.0 as "too flat" and "out of<br>tune."  Moreover, this assumes that the <br>human auditory system can be modelled as<br>a Turing machine which obeys linearity<br>and the superposition principle.  However,<br>the data appears to indicate that many parts<br>of the human auditory system are non-linear<br>and do not obey the superposition principle.<br>In this case, the analogy with finite<br>automata may not be apt.<br>Lastly, if one wanted to go completely over<br>the edge, one could describe numbers in terms<br>of their dB signal-to-noise ratio by comparing<br>the normalizing power spectral density of<br>the integer 1 to the psd of the target number.<br>In this case transcendentals would exhibit<br>a zero dB signal-to-noise ratio, while integers<br>would exhibit no noise whatever and thus an<br>infinite signal-to-noise ratio. (Describing<br>numbers in terms of their signal-to-noise<br>ratio sounds absolutely insane until you<br>realize that this explains the extreme<br>noisiness of digital reverb systems; the<br>input signal becomes progressively degraded<br>by roundoff error during its trip through the<br>recirulating delay lines of the reverb<br>algorithm, and thus each sample of the<br>input suffers a progressive randomization<br>of its bits and thus a progressive decrease<br>in its singal-to-noise ratio.)<br>Incidentally, Gary's purported "mathematical<br>idiocy" pales before my own.  Alert readers<br>will still be guffawing at my statement that<br>"i is the square root of -1."  Obviously untrue,<br>since -i is also the square root of -1...  As<br>Manuel op de Coul so delicately pointed out<br>during our meeting across the street from<br>Disneyland (an apt venue for wild-eyed<br>microtonalists).<br>Moreover, e^[i*pi] = -1, not 1.<br>No duh dude, as Gauss would doubtless say.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Tue, 19 Dec 1995 15:20 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id GAA28265; Tue, 19 Dec 1995 06:20:47 -0800<br>Date: Tue, 19 Dec 1995 06:20:47 -0800<br>Message-Id: <199512191519.QAA09965@elevator.source.co.at><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2394 href="#2394">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>12/19/1995 2:32:36 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: A window of opportunity for synth<br>  manufacturers<br>---<br>Csound allows users to generate csound<br>timbres in real time from MIDI input.  At<br>present, this capability is limited.  But as<br>time passes and massively parallel<br>P7 desktop machines become typical,<br> this will change.<br>This means that synthesizer manufacturers<br>have a limited window of opportunity.  They<br>can either get off their rear ends and start<br>building *real* synthesizers--instead of digital<br>sample playback boxes full of canned sounds<br>burned into ROM--or they can go the way of<br>the dinosaurs.<br>Within 5-10 years, the average computer<br>user will be able to generate complex<br>and interesting csound timbres in real<br>time via MIDI using a standard desktop<br>computer.<br>This brings up the issue of Csound's support<br>for real-time microtonality.<br>There isn't any.<br>Having mentioned this to John Fitch, and<br>have received no reply, it seems appropriate<br>to bring it to the attention of the rest of the<br>forum subscribers.  If you examine the source<br>code for Csound, you'll discover that Csound<br>translates MIDI note input into real-time<br>frequencies by using a 2^N/12  function.<br>Yes, having thrown off the shackles of<br>the piano keyboard and all limitations on<br>scale and tuning, Csound now makes it<br>possible for us to...play in 12 tones per<br>octave via MIDI.<br>Unbelievable.  Disgusting.  Outlandish.<br>Yet true. <br>Csound is locked into 12-TET for MIDI<br>playback until someone, somewhere<br>changes the source code.  Naturally, since<br>this is the prime venue for non-12<br>computer applications in musical tuning,<br>not a single person on this forum has<br>ventured to deal with the problem.<br>Thus, as always, we head forward into<br>the past at the speed of light!  Soon,<br>extraordinary sounds will issue from<br>our desktop computers...sounds locked <br>into 12-TET, thanks to the crippled<br>artifically limited MIDI-to-Csound<br>routines frozen into the current<br>generation of Csound.<br>There's another issue of concern to<br>microtonalists:<br>Has anyone noticed that frequencies<br>in the HETRO output are specified as<br>16-bit integers?  With a frequency<br>range of 20 Khz, this gives a precision<br>of 20000/32768, not adequate to<br>describe the fine frequency shifts<br>that take place within individual<br>partials during the course of real-<br>world musical notes.  2/3 of a cent,<br>for instance, is 4% of a 72-TET scale<br>step.  While this kind of tuning accuracy<br>is perfectly acceptable for the overall<br>musical scale-step, it is surely INadequate<br>for specifying the fine frequency shifts that<br>give each changing overtone its "lifelike"<br>sound during resynthesis, especially when<br>the resynthesized timbre plays in a microtonal<br>tuning.<br>Naturally, no one has bothered to mention this<br>and naturally, no one has bothered to correct it.<br>More neglect of microtonality in the very field<br>(computer music) which ought to be most<br>congenial to new tunings & new scales.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Tue, 19 Dec 1995 23:36 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id OAA04729; Tue, 19 Dec 1995 14:36:47 -0800<br>Date: Tue, 19 Dec 1995 14:36:47 -0800<br>Message-Id:  <9512191434.aa18824@cyber.cyber.net><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2395 href="#2395">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>12/19/1995 2:36:47 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: The dirty truth about Csound<br>---<br>Since no one has ever bothered to respond<br>to any of my e-mail about the problems<br>with Csound,  time to go public.<br>Around 40% of the features of Csound do<br>not work and appear to be unimplemented.<br>Most of these features deal with spectral<br>modification of input signals, but the delay<br>line features also do not work. <br>One at a time, Csound's current problems are:<br>[1] One of the most obvious reasons to use<br>Csound is to analyze input timbres with<br>the Csound HETRO program and resynthesize<br>them with the partials warped into the<br>frequencies maximally consonant for a given<br>tuning.  <br>Naturally, HETRO does not work and Csound's<br>ADSYN routines does not work.  Way back<br>when, HETRO was written as an add-on to <br>analyze input sounds with a hetrodyne filter.<br>It blew up if the input exceeded 32 kilobytes<br>in length.  The problem was inherent to the <br>HETRO code, not the machine on which it ran.<br>Barry Vercoe fixed this problem in December<br>1994 but in so doing changed the format in<br>which HETRO stores numbers.  The old format<br>stored partials in pairs: frequency, amplitude,<br>timeslice, frequency, amplitude, timeslice...&c.<br>The new format uses the same data structure<br>but the timeslice is now variable and indicates<br>a detla-t in milliseconds to the next envelope<br>breakpoint.<br>In the old HETRO, the user specified the number<br>of breakpoints and the spectral analysis output<br>automatically took care of giving a spectral<br>"snapshot" every length/(number of breakpoints)<br>milliseconds.<br>In the new HETRO, an internal algorithm minimizes<br>the number of breakpoints.  This number is thus<br>entirely variable and the time between spectral<br>"snapshots" for each harmonic is unpredictable.<br>Alas, Csound cannot read spectral analysis files<br>in the new HETRO format.<br>This is of some concern to xenharmonists on this<br>tuning forum, inasmuch as one of the main areas<br>of interest for microtonalists working in computer<br>music is modifying acoustic spectra to render them <br>maximally consonant in a given tuning.<br>Thus, the two primary routines designed to analyze <br>and resynthesize Csound timbres are vaporware.<br>ADSYN and HETRO no longer work.<br>(Naturally, various forum subscribers will<br>deny this, and naturally they'll be--let us say--<br>"deliberately mistaked.") <br>This is a classic example of academic garbageware,<br>a subject to which I shall return in future posts.<br>Garbageware promises wonderful results, doesn't<br>work, and is always undocumented and bug-ridden.<br>Garbageware is always written by someone with 3<br>PhDs as a diversion, and naturally no support is<br>ever available for the software, since the programmer<br>is now in the Arctic studying the mating habits of the<br>krill shrimp under the permanent ice pack.  Garbageware<br>always *almost* works--it does *just enough* to<br>tantalize the unwary user, but *never* enough to<br>be useful.<br>Naturally, no one has bothered to mention<br>garbageware in Computer Music Journal, ARRAY, or<br>anywhere else--so it's up to me (as usual).<br>Csound's "spectral modification" routines are<br>a classic example of garbageware.<br>If you try to use HETRO, you'll get an output<br>file, all right--an output file unreadable by<br>Csound.  (Various people will now claim this<br>is not so, and they'll be--let us say--"deliberately<br>mistaken.")<br>Try it.  Feed a sound into the HETRO program.<br>You'll get a .HET file out.  Now feed it into<br>your Csound program using the ADSYN command.<br>Guess what?  You'll get the message "bad<br>file read."<br>Yes, Barry Vercoe has changed the Csound<br>HETRO format without telling anyone.  Thus<br>Csound's ADSYN command now cannot be used,<br>and has not run since the December 1994<br>build of Csound.<br>(Again, many forum subscribers will claim<br>this is not so, and again they'll be--let us<br>say--"deliberately mistaken.")<br>[2] Let's talk about ADSYN.  This is an almost<br>entirely undocumented feature of<br>Csound.  Vercoe's docs from a 1989 release<br>of Csound (not present in the current 1994<br>release of Csound available on John Fitch's<br>bulletin board) claim that "more details about<br>ADSYN will be given later."  They never are.<br>ADSYN's command syntax is a mystery.  No<br>one knows what it is.  Why?  Because only<br>Vercoe knows the full command syntax for<br>ADSYN, and he isn't telling. <br>Thus ADSYN is useless and might as well<br>not be a part of Csound.  (Again, various<br>forum subscribers will deny this, and<br>again they'll be--let us say--"deliberately<br>mistaken.")<br>[3] One of the most grotesque paradoxes<br>of Csound is that the program is theoretically<br>capable of generating the world's most <br>impressive reverb.  Naturally, no diagrams or<br>sample reverb programs exist.  Of course<br>many diagrams and sample reverb programs<br>exist for MUSIC11 or other ancient programs; and<br>and of course all these sample reverb programs <br>require special instructions not present in<br>the C versin of Csound. Naturally, no one has ever <br>made public the code for any of the high-quality<br>reverbs used in Csound instruments from places<br>like CCRMA or IRCAM.  Therefore (naturally!)<br>the only reverb currently available to users of<br>Csound is the 1970-vintage reverb using<br>4 all-pass filters and 2 comb filters.  This is<br>one of the world's worst-sounding reverbs:<br>it sounds like a tile bathroom.<br>The result?<br>If you want to add high-quality reverb<br>to your Csound composition, you must<br>compile the Csound compisition dry and<br>then play it through a commercial digital<br>reverb unit, then re-record the reverberated<br>Csound composition.<br>(Naturally, various forum subscribers will deny<br>this, and naturally they'll be--let us say--"deliberately<br>mistaken."  There is a less polite term.)<br>This is so grotesque and so unthinkably<br>bizarre as to defy credibility.  Yet there it is.<br>You want high-quality Csound reverb?  Record<br>your Csound composition through a PCM-80<br>or an Alesis Quadraverb and re-record it.<br>When you realize tha this means many, *many*<br>layers of re-recording to get different levels of<br>reverberation on a Csound compotiion, you<br>begin to realize the utterly insane nature<br>of the situation.  Yet it persists.  No high-<br>quality digital reverb instrument has ever been <br>published, no source code for a Csound<br>high-quality reverb is available anywhere, <br>at any time, in any way, for any reason.<br>(Naturally, various forum subscribers will deny<br>this, and naturally they'll be--let us say--<br>"deliberately mistaken.") <br>[4] Aside from a hi-fi type "tone control"<br>and a sharply resonant filter called reson,<br>Csound offers no facilities whatever for<br>spectral modification of input sounds. (Naturally,<br>various forum subscribers will deny this, <br>and naturally, they'll be--let us say--"deliberately<br>mistaken.")  <br>Mark Dolson's LPC and the Lansky LPC routines<br>built into Csound produce unbearably distorted<br>output with so many artifacts as to be musically<br>unusable. Cutting down the input volume doesn't<br>help.  Naturally, Paul Lansky's own LPC-<br>processed sounds exhibit *none* of these<br>artifacts...so (naturally) Paul Lansky must <br>be using a bunch of special C code he hasn't<br>bothered to make public.<br>However, not only do the Dolson and Lansky<br>LPC modules in CSound produce unlistenable<br>garbage audio output, there are no other<br>less sophisticated spectral modification<br>routines in Csound (aside from the reson<br>and tone modules).<br>There is, for example, no way to apply <br>a 50-peak formant filter to an input sound,<br>or to a Csound instrument on output.  There is,<br>for example, no way within Csound to apply the<br>equivalent of a graphic or parametric<br>equalizer to the sound.  There is assuredly<br> no way to apply anything like 256 bands<br>of boost and cut to various frequencies,<br>with the boost and cut specified to the fraction<br>of a dB.<br>Naturally, this would be trivial given Csound's<br>processing capacbilities.  So, naturally,<br>it's impossible.<br>(Again, various forum subscribers will deny this,<br>and again they'll be--let us say--"deliberately<br>mistaken.")<br>[5] The IRCAM fof module is almost completely<br>undocumented. I've never been able to get it to<br>work.  <br>[6] The -f option to output floating point format<br>soundfiles doesn't work.  Output is a blaring roar.<br>Pure high-quality noise.<br>[7] On the GCC builde of Csound for the IBM PC,<br>instrument .orc files crash when the number of<br>variables exceeds 65535.  It's fairly easy to<br>exceed that number with a single large additive<br>synthesis instrument--day, 128 partials with<br>128-point amplitude and frequency envelopes.<br>So let's see: <br>Fof doesn't work, HETRO and ADSYN don't work,<br>there's no way to build reverb in Csound, the -f<br>flag doesn't work, and there are no spectral <br>modifiers other than RESON and TONE--and the<br>Dolson and Lansky LPC produce unlistenable<br>distorted garbage output when used inside<br>Csound.  You can't compile large additive<br>synthesis .orc files.  And the Dolson PVOC routines<br>produce the message MATH ERROR and a register<br>dump after time-stretching long files, but it<br>doesn't appear to affect the soundfiles.<br>That's a good 40% of Csound that doesn't work.<br>While this sounds awful, it's actually a tremendous<br>achievement.  A full 60% of Csound actually WORKS.<br>By contrast, the winner and all-time champion of<br>academic garbageware,  F. R. Moore's cmusic, is<br>100% non-functional.<br>Carrying on the UCSD music department's tradition<br>of producing unusable junk software, csmusic is *classic*<br>garbageware.  In the words of one of the members of<br>this tuning forum: "Even I know better than to download<br>that crap.  With more than 3000 files in hundreds of<br>directories, it would probably take a month of recompiles<br>just to get cmusic to work on the machine it was<br>written for--much less port it." <br>As world-class garbageware, cmusic exhibits<br>all 4 of that species' salient characteristics:<br>[1] It's totally undocmented, and totally <br>unsupported.  A vaguely-worded ASCII <br>file always arrives with the garbageware<br>executables--"You can do X, Y and Z with<br>this wonderful pieceof software developed at<br>IRCAM!"  And naturally, there's not a ghost<br>of a clue *how* to use the software.  Naturally,<br>the command syntax always involves something baroque<br>and outlandish--CRT-ALT-SHIFT-LEFT PARENTHESIS-<br>+-BACKSLASH-SUB-COLON-COMMAND-F7, or <br>some such.  Naturally, you'll *never* find this out<br>from the "docs" which arrive with the<br>garbageware, so naturally the software<br>is useless.  Inputting a "?" or "HELP COMMAND"<br>message always produces the message "INCORRECT<br>SYNTAX."<br>[2] Garbageware always needs 5 special hidden install files<br>to run on *your* computer.  Meanwhile, it comes with 5693<br>different install files for OTHER computers--a PRISM compiler <br>for the Connection Machine, an assembly loader for the <br>Commodore PET, and an INSTALL routine that runs on the <br>mercury delay line of a 1948 ENIAC--but if you want<br>to run the Garbageware on *YOUR* computer (a Mac or a<br>PC), hey!  Guess what?<br>Yep. <br>You're out of luck.  <br>Naturally!<br>Yes, indeedy, the special install files *aren't* included <br>with YOUR version of the garbageware.  And where can<br>you find them?<br>You can't!<br>The programmer wrote the garbageware to run only on<br>(say) his Kaypro Robby, and never anticipated that anyone<br>would run the software on an exotic outre machine...<br>like, say, a Macintosh or an IBM PC.<br>[3] Once you get the garbageware up and running,<br>you'll discover some delightful bugs.  The <br>garbageware goes south on Tuesday during full <br>moons but only when it's raining.  Naturally,<br>the developer at IRCAM  or wherever<br>will describe this as a "special feature."<br>One of the most interesting of the "special<br>features" of the latest GCC compile of<br>Csound is that it never stops compiling on<br>long scores.  Yes, the compile continues from<br>forever to forever--infinite compilation!  What<br>an advance!  Why not devote an issue of Confuser<br>Music Urinal to this marvellous feature???<br>Do you have 400 megs free on your hard disk?  Want<br>to use it up?  Compile a 7-minute Csound score under <br>the GCC Csound--you'll use up all 400 megs in 1 file!<br>Meanwhile, if you want to end the comiple session,<br>you do so by hitting CTRL-BREAK.  Clever command<br>syntax, eh?<br>[4] Last and best of all,  you'll finally come<br>across docs for the garbageware--docs to version <br>2.19 from Carnegie-Mellon.  However,<br>all ftp sites curently carry v. 5.62 from<br>CCRMA.  And guess what?<br>Yep!  The command syntax has changed toally!<br>The command CSOUND -D -H %1 %2 now does<br>something interesting and different--perhaps, say,<br>wiping your hard disk and reformatting it.  (Gosh.<br>What a useful feature...)<br>Hurrah for academic garbageware!  Without<br>it, where would we be?<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Wed, 20 Dec 1995 06:05 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id VAA07412; Tue, 19 Dec 1995 21:05:36 -0800<br>Date: Tue, 19 Dec 1995 21:05:36 -0800<br>Message-Id: <951220000424_59067722@mail06.mail.aol.com><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2399 href="#2399">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>12/20/1995 1:02:56 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject:  The collapse of innovation <br>in post-1988 synthesizer technology<br>---<br>In a previous post, Your Humble E-Mail <br>Correspondent mentioned the general<br>excellence of Ensoniq's synths.  They<br>sound about as good as anything else out<br>there,  Ensoniq synths are rock-solid<br>reliable, and their sampler operating<br>systems are particularly intuitive and<br>easy to use.  Anyone who battled the<br>hellish TX16-W Yamaha sampler operating<br>system or the botched E-Mu sampler OS's<br>from the late 80s is well qualified to<br>appreciate the excellence of the EPS/<br>EPS-16/ASR-10's operating system. <br>However,  there's still plenty of room<br>for improvement in the Ensoniq line.<br>Someone posted a query about that--how<br>can anyone say Ensoniq isn't up to date<br>technologically?<br>Here's how:<br>[1] The ASR-10 needs more RAM.  A *LOT*<br>more RAM.  Right now, the Kurzweill 2500<br>series can take up to 128 megs.  This<br>is a reasonable minimum amount: 256 megs<br>would be more like it.  But 128 megs is a<br>start.<br>The ASR-10, by contrast, is stuck with 16 megs.<br>This is around 90 seconds of sampling time at<br>44.1 khz stereo.  Completely unacceptable.  Far<br>too small an amount of RAM to be useful.<br>Part of the problem is the kbd controller chip<br>Ensoniq uses to address the RAM, part of the<br>problem is the burden of maintaining backwards<br>compatability with the EPS/EPS-16 &c.  <br>Backward compatability must go.  The ASR-10's<br>successor needs more RAM.  A *LOT* more.  <br>With EDO, the people at Ensoniq need to start<br>thinking in terms of *gigabytes* of RAM.<br>(As always, readers will call this "insane"<br>today, "a little over the top," in 6 months,<br>and "very sensible, but somewhat conservative"<br>in a year.) <br>[2] A rule of thumb is that a decent saxophone<br>or clarinet needs 25-40 multisamples.  The<br>ASR-10 allows 8 layers per instrument, <br>8 instruments total.  This is utterly inadequate.<br>Backward compatability must go.  Dump the 8<br>layer limit.  At least 127 A-B crossfades should<br>be allowed per multisampled instrumnet, at least<br>16 MIDI channels/instruments at a time.<br>[3] David Doty made a point about accessing various<br>layers during performance.  Clearly Ensoniq needs<br>to upgrade the ASR-10's successor to allow MIDI<br>access to each of the 127 layers within an<br>instrument.  Since these would often be used for<br>alternate tunings, it's a particular priority.<br>[4] Ensoniq may want to think about implementing<br>some new technology.  <br>Ever since innovation ground to a screeching halt<br>in the synthesizer industry, somewhere around 1988,<br>industry pundits have wondered why sales of<br>digital keyboard instruments have dropped<br>steadily.<br>There's no mystery. <br>The Korg M-1 provided the original and ever since<br>then all the keyboard manufacturers have concentrated<br>on cranking out endless xerox copies of that instrument,<br>all using exactly the same antique technology:<br>sample playback.<br>With the exception of the Yamaha VL-1M/VL-7 and<br>the E-Mu Morpheus, all current synthesizers are <br>nothing but sample playback machines that spit back<br>digital recordings burned into ROM when you press<br>a key.<br>Now, there's nothing wrong with sample playback. It's<br>a fine technology.  But after a while,  you get tired of<br>hearing nothing but sample playback.<br>Even today's samplers use exactly the same technology--<br>with the only wrinkle being that *you* get to choose <br>what digital recording is regurgitated when you press<br>a key, instead of *the synth company** choosing the sound.<br>All today's synths are basically nothing but digital<br>Mellotrons.  Where's the synthesis?<br>Does anyone remember the origin of the term "synthesizer"?<br>These instruments are supposed to *generate new sounds.*<br>Instead, we get yet another canned B-3 sample<br>burned into ROM.  And no matter how mich reverb, phasing,<br>ring modulation, flanging or delay you slather on top of<br>a sound burned into ROM, it all sounds pretty much the<br>same.<br>Around 1988, synth companies stopped making synthesizers.<br>Instead, they all followed the cattle stampede toward<br>the easy dollar.<br>The net result is that there is today hardly any reason<br>to buy one synth from one manufacturer rather than another.<br>Ensoniq's tuning tables make a difference.  But if they *really*<br>want to increase sales, how about building some actual <br>synthesizers for a change?<br>Even Yamah has dropped the ball.  Today, if you want to<br>buy an FM synth you're out of luck.  You have to buy one<br>used, or pay for a Kyma.<br>The brutal reality is there are *dozens* of synthesis<br>methods: digital additive, subtractive, frequency<br>modulation, amplitude modulation, Chebyshev<br>distortion, Miller Puckette's formant synthesis,<br>Lansky's LPC synthesis, phase vocoder analysis/<br>resynthesis, Daubechies wavelets, Walsh function <br>analysis/resynthesis, Dashow's exponentiation<br>synthesis, Hiller & Ruiz's physical modelling<br>synthesis, waveguide synthesis, many others.<br>Yet aside from Yamaha's VL-7/VL-1M physical<br>modelling synth, not a single manufacturer has<br>implemented *any* of these synthesis techniques<br>in a currently available commercial synthesizer.<br>Amazing.<br>Shocking.<br>Yet true.<br>If Ensoniq wants to jump-start synth sales,<br>they might think about implementing some of<br>these synthesis techniques.<br>Now that Korg's OASYS synthesizer has been<br>discontinued--yet another case of classic<br>vaporware--and the Gibson/G-WIZ labs' FAR<br>Fourier resynthesizer cannot be purchased<br>by anyone, anywhere, for any reason, at any time,<br>any way, shape or form...well, now that these<br>vaporware instruments have bitten the dust,<br>what else is there on the horizon?<br>Zero.<br>Zilch.<br>Zip.<br>Squat.<br>Diddly.<br>Nada.<br>These synths have joined the parade of<br>vaporware formed by the Prism synthesizer<br>(remember that one?), the additive synth<br>built from the Amiga's Amy sound chip<br>(256 additive partials--it gobbled the Amiga's<br>entire CPU and memory so the company dumped<br>it and licensed the rights to a start-up which<br>was promptly sued out of existence), and the<br>marvellous Technos 16pi...a synthesizer which,<br>if it had ever existed, would have been <br>superlative.<br>Well, chances are this is all blue-sky<br>fabulation.  Chances are Ensoniq won't bother<br>to actually build synthesizers.  Too much work.<br>And the MR rack tends to bolster that <br>viewpoint.  Yet another wannabe sample-playback<br>box, yet another digital Mellotron.  <br>It's ironic that Ensoniq is giving up the opportunity<br>to crush the Japanese synth companies.  What with<br>their little Yen crisis and teetering financial<br>system, this is an ideal chance for American synth<br>companies to steal back the initiative that was<br>lost when the Japanese licensed FM technology<br>and ground the American analog synth manufacturers<br>into the dirt back circa 1983.<br>In any case, these remarks should be understood<br>inthe context of making Ensoniq's excellent products<br>better.  Rather than angering the engineers and<br>management at Ensoniq, perhaps these words <br>will irk them into improving already fine<br>synths.<br>N.B.: Even though the Kurzweil 2500 series offers<br>gobs of RAM, the sampler does *NOT* have a<br>full-keyboard tuning table.  Thus my next sampler<br>will be an ASR-10.  Also, Dave Rossum at E-Mu<br>needs to take a look at Ensoniq's multiple tuning<br>tables and realize the *immense* importance of<br>more than one tuning table.  JI compositions<br>which change key centers demand multiple tuning<br>tables, as does work with (say) a Wilson 70-note<br>hebdomekontany in only 128 MIDI notes.  Allen<br>Strange has mentioned that he gets only 3 octaves<br>of Partch's 43-tone just scale in MIDI's 128 notes;<br>using the same timbre on 3 MIDI channels tuned<br>3 octaves apart would increase his range to<br>9 octaves.  And, as usual, Ensoniq is the *only*<br>current manufacurer to support multiple tuning<br>tables.<br>Thus, for many microtonal applications, Ensoniq<br>synths remain the only real choice.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Wed, 20 Dec 1995 22:57 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id NAA26137; Wed, 20 Dec 1995 13:56:54 -0800<br>Date: Wed, 20 Dec 1995 13:56:54 -0800<br>Message-Id: <v01530501acfddf656c7a@[128.83.112.40]><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2407 href="#2407">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>12/21/1995 4:00:01 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: unsavory habits of the musical intelligentsia -- or --<br>  the 12-TET musical elite have a point, but if they comb their hair<br>  properly, it won't show<br>---<br>The savage dictatorship of the concert-hall-and-conservatory<br>musical establishment, which Greg Taylor is pleased to<br>imagine the product of my paranoid delusions, will brook<br>no deviation from the totalitarian musical status quo.<br>The clearest example of this Orwellian and ruthless<br>state of musical conformity is of course the string<br>quartet.  Offhand, there's no reason at all why 4 fretless<br>string instruments couldn't perform in any scale desired--<br>19-TET, 31-TET, 53-TET, 11-TET, the free-free metal<br>bar scale, the Bohlen-Pierce scale, or any other tuning.<br>Naturally, any string quartet that gets handed such a score<br>will burn the offending sheaf of music paper and<br>bury the ashes.  Naturally, all string players have been<br>programmed to perform in 12, only 12, always 12, forever<br>12.<br>Another example of ruthless 12-TET tyranny is the computer<br>music scene. Given the opportunity to explore any possible<br>musical scale, any possible set of harmonies, any conceivable<br>set of melodic pitches, the contributors to Confuser Music Urinal<br>choose to...explore 12 tones per octave. (For the most part. There<br>are a few exceptions. Dashow, Schottstaedt, a few others. All<br>have been ostracized and marginalized for their troubles.)<br>This is reminiscent of aged Devil's Island convicts who, being<br>set free of their ball-and-chain, still drag one foot and move<br>with snail-like gait.  In this case the musiKKKal establishment has admirably attained its implicit goal of brainwashing<br>all & sundry into the use of 12 tones per octave: indeed, the Red<br>Chinese during the Korean war could hardly have hoped for better<br>results with U.N. prisoners.  Such a state of mindless (musical)<br>conformity would bring joy to the heart of Stalin, and<br>send Hitler to sleep with an ecstatic smile on his face.<br>After composing some pieces recently in the Greek enharmonic <br>genus for an upcoming performance in a San Diego experimental<br>music club, the true bestiality of the current musiKKKal  status<br>quo really began to become clear to me.  Think of it: for hundreds<br>of years, it would have been a simple matter to retune a harpsichord<br>or a piano to the Greek enharmonic...yet *no one* did so.  This is an<br>case of conformity unexampled in the history of mind control.<br>Such machine-like zombification would make even Mussolini cringe--<br>yet, somehow, we accept this grotesque and obscene lockstep<br>mentality as "the progress of music."  ("From 12 to 12...in the beginning<br>was 12, and 12 was the Word, and the Word was 12..."  One's puke-<br>meter pegs. One's gag reflex kicks in. And *still* it continues...)<br>The enharmonic genus is, as Ralph David Hill has pointed out, "almost<br>the most beautiful of all the Greek genera," and simple to <br>obtain on a 12-TET retunable instrument.  No note would need to be<br>retuned by more than about half a semitone.  Yet not a single composer,<br>not a single adventurous soul, dared to compose a piano sonata in<br>the Greek enharmonic genus.  Too, with 12 pitches available, more<br>than one key center could have been explored: yet this was apparently<br>too terrifying an extremum for generation upon generation of<br>composers to contemplate.<br>In the words of the Outer Limits episode "O.B.I.T.": "O savage <br>despairing planet!  When we come here to live, you will fall<br>without a single shot.  Enjoy the few years left to you..."<br>Naturally these brutal and disgusting facts will be prestidigitated<br>away by gtaylor and his cronies with yet more smoke and mirrors,<br>reason upon  complicated and  unlikely reason why the iron fist of <br>12 equal tones doesn't *actually* rule inside the velvet glove of the <br>musiKKKal concert-hall-and-conservatory establishment.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Fri, 22 Dec 1995 16:29 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id HAA22330; Fri, 22 Dec 1995 07:29:49 -0800<br>Date: Fri, 22 Dec 1995 07:29:49 -0800<br>Message-Id:  <9512220730.aa20418@cyber.cyber.net><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2408 href="#2408">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>12/22/1995 7:29:49 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Transfinite systems Nugget or Gold Brick<br>---<br>Having obtained a used Mattel Power Glove from<br>one of the members of this tuning forum, I<br>recently learned that the company which makes<br>the widget that goes twixt the Power Glove<br>and the Mac ADB port has changed its address.<br>Called the number for Transfinite Systems.<br>Someone answered.  Not Transfinite Systems.<br>Didn't know what had happened to the company.<br>Folks, it shouldn't be this goddamn hard.  You<br>try and you try and you try, and the net result<br>is: zero.<br>Does anyone out there have a new address or<br>phone number for Transfinite Systems?<br>Does anyone out there have a lead on a Gold Brick<br>or a Nugget interface box?<br>--mclaren<br><br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Fri, 22 Dec 1995 16:32 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id HAA22937; Fri, 22 Dec 1995 07:32:34 -0800<br>Date: Fri, 22 Dec 1995 07:32:34 -0800<br>Message-Id:  <9512220730.aa20424@cyber.cyber.net><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2409 href="#2409">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>12/22/1995 7:32:34 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject:  Yamaha VL-1M and VL-7<br>---<br>   The Yamaha VL-7/VL-1M physical modelling<br>synthesizers implement tuning in a weird way.<br>Here's the skinny:<br>  You can't edit the 2 user tuning table I01 and I02.<br>Instead, you have to edit them on a TG-77 or SY-77<br>or on JICalc, then do a sys-ex dump to the VL-7/<br>VL-1M.<br>  Why Yamaha chose to implement microtuning this<br>way is beyond me.  It certainly makes it less<br>convenient to retune the instrument.  As a plus, <br>user tunings are reportedly stored with the <br>instrument patches and are loaded from the disk<br>automatically.<br>  The way Yamaha implements physical modelling<br>on the instrument is also peculiar and worth a <br>metnion.  The physical model is fixed: a blown tube.<br>To get a Karplus-Strong plucked string sound (typified<br>by the fretless bass and sitar patches), the physical<br>model's mouthpiece is connected to its output.  A <br>kludge--but one that works.  A recirculating system<br>is created which, with appropriate losses for<br>acoustic admittance, mimcs the Karplus-Strong<br>algorithm pretty well.<br>  To get a vibrating string, the tube is apparently<br>shrunk down to near-zero width.  The resulting<br>one-dimensional tube subs for a vibrating string<br>and apparently also allows the user to apply a<br>mouthpiece with "embrouchure" to the vibrating<br>string--something not possible with a standard<br>Hiller-Ruiz vibrating string physical model or<br>the classic Julius Smith waveguide physical<br>model of the string.<br>  Rumor has it that Yamaha has a MAX patch <br>available that'll allow users to completely<br>change the internal physical model.  Instead<br>of being limited to a blown tube, the user can<br>dunk with internal VL-7 parameters and specify<br>any acoutsical system desired.  Apparently, the<br>MAX patch comes with a WARNING -- KNOWLEDGE<br>of PHYSICAL ACOUSTICS IS REQUIRED TO USE<br>THIS EDITOR.  Apparently it's easy to specify<br>an acoustic system which *cannot* produce<br>sound output. (Arthur Benade called these<br>things "tacit horns."  Nice design, no sound.)<br>  Does anyone have any knowledge of this<br>mythical MAX patch?  As a xenharmonizing<br>future VL-7 owner, this question is of<br>some interest<br>--mclaren<br><br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Fri, 22 Dec 1995 16:51 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id HAA23570; Fri, 22 Dec 1995 07:51:24 -0800<br>Date: Fri, 22 Dec 1995 07:51:24 -0800<br>Message-Id: <0099B415E1E82CFE.5467@ezh.nl><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2435 href="#2435">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>1/4/1996 8:23:26 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Paul Rapoport's article <br>"The Notation of Equal Temperaments"<br>---<br>Xenharmonikon 16, available now from Frog Peak<br>Music or from John Chalmers, contains Paul's<br>latest essay on non-12 notation.<br>This is a subject littered with caltrops. To date, no<br>one has succeeded in producing a universal notation<br>which allows both easy performance AND analysis <br>of xenharmonic music.<br>Nonetheless, Paul makes many good points in <br>this article.<br>"Despite the considerable history of ETs, few<br>theorists have studied their properties or created<br>musical notations for them systematically.  Because<br>most of the ad hoc solutions in notation of one ET<br>do not extend easily to many other ETs, such solutions<br>obscure similarities in related temperaments."<br>[Rapoport, P., XH 16, pg. 61]<br>However, the worm soon munches its way free of the<br>apple: "This article explores almost exclusively ETs<br>of the octave and implications based on harmonics<br>no higher than 5."<br>The implicit presumption? That one ought to strive for <br>a unified system of notation which relates all the<br>especially 12-like tunings with good fifths.<br>While this is a laudable goal, one needs must ask:<br>why spend so much effort on the 12-like tunings?<br>By far the most interesting equal temperaments<br>are those which have *little or nothing* in common with<br>traditional Pythagorean and 5-limit tunings.  There<br>exist many oddball equal temperaments which<br>cannot be notated usefully by a 5-limit scheme,<br>yet whose "sound" compels ever-growing interest.<br>In this regard, 9-TET, 10-TET, 23-TET, 22-TET<br>and 21-TET stand out in particular.<br>9-TET, for example, violently abjures traditional notation,<br>yet it remains an endlessly fertile breeding ground<br>for xenharmonic compositions. In fact Erv Wilson has<br>called it one of his favorite tunings.<br>Paul derives several guiding principles:<br>[1] Additional signs must be perceptually distinct<br>from one another.<br>[2] Notation must reflect the determined nature of<br>the termperament.  If there's more than one<br>way of deriving the temperament, there should <br>be more than one way of notating it.<br>[3] Additional signs beyond bb X, etc, should be<br>created for kommata representing the differences<br>in pairs of multiples of just intervals.<br>The first 2 points are eminently sensible. <br>Point 3 seems incomprehensible to me.  If you're<br>going to relate your equal temperament explicitly to <br>just intonation via the notation used, you might as<br>well abandon equal temperament and go straight to<br>just intonation.  Few equal temperaments < 48 are awfully<br>JI-like, and all of 'em contain internal structures <br>which inevitably frustrate the attempt to view<br>them as this or that outgrowth of just intonation.<br>As a result, many of the intervals which Paul <br>defines as "kommata" do not function as such in <br>equal temperaments below 48-TET. For instance, in 22-TET<br>a single scale-step is numerically a fair approximation<br>of the Pythagorean komma, but it does NOT REMOTELY<br>function like a just interval in context.(Significantly,<br>Paul does not discuss 22-TET.)<br>Again, the 1/17 octave interval in 17-TET, while<br>numerically near-indistinguishable from the <br>difference twixt the 6/5 and the 5/4, sounds in<br>practice like a semitone.   In an actual 17-TET<br>composition, this interval contains NO audible <br>implications of just intonation whatever.<br>31-TET contains an interval quite close to the<br>41.059 cent "diesis," yet a single scale-step of<br>31 conjures up no auditory ghost of just<br>intonation.  In fast chromatic runs,  the 31-TET<br>scale-step functions like a very strange semitone,<br>and when used as a passing-tone twixt chords <br>its function is a somewhat small chromatic<br>passing-tone.<br>The idea of imposing on any but a few ETs with very<br>good fifths (all > 48, 46, 43, 41, 39, 37, 36, 34, <br>31, 29, 24, 19, 17, 12) a set of just kommata purporting<br>to represent the substructure of the tuning<br>seems suspect to me.  Many intervals numerically<br>close to JI kommata do not function as such<br>such in the context of the equal tempered scales below<br><br>48-TET, and the futile attempt to force them to do so <br><br>produces mediocre music.  <br>Examples of such music include some of Easley <br>Blackwood's "Twelve Microtonal Etudes For Electronic<br> Music Media," a project only partially successful. <br>The etudes which hew most closely to Blackwood's<br>theoretical and notational principles prove LEAST<br>successful as music: in particular, 17-TET, 16-TET,<br>19-TET and 20-TET.  Blackwood jams 19-TET into a<br>12/oct straitjacket, and his 19-tone etude<br>suffers greatly from his refusal to showcase 19's<br>exotic non-Pythagorean intervals.<br>In the 16-TET etude, Blackwood derives an awkward<br>pseudo-tonal mode which goes against the inherently<br>anti-tonal, non-cadential grain of the tuning,<br>and the result sounds bad. The 17-TET etude suffers <br>grievously from Blackwood's unwillingness to recognize<br>& use the 5-unit neutral third as the ONLY functional<br>triadic third, while the 20-TET etude is mangled <br>by Blackwood's relentless insistence on generating<br>diatonic modes from 20/oct, rather than exploiting its<br>intercessant circles of NON-diatonic pentatonic 5ths<br>(as he did in 15-TET).<br>All of these problems stem from Blackwood's<br>doomed attempt to extend 12-like structures<br>into entirely xenharmonic tunings. He could have<br>avoided these faux pas if he'd ignored his<br>Pythagorean notational kommatic calculations and <br>relied on his ear instead of v, a, k, t and p.<br>To put it succinctly, Easley Blackwood concentrated<br>far too much on the "harmonic" and far too little<br>on the "xen" aspects of these xenharmonic scales.<br>By contrast, those etudes in which Blackwood <br>pretty much tossed out his theories and just sort <br>of gave up & winged it seem by FAR the most successful<br> musically: 13-TET, 23-TET, 14-TET.<br>Moreover:<br>In calling Blackwood's project "the most substantial<br>non-improvised recorded project in different<br>equal temperaments," Paul renders a decidedly<br> peculiar definition of "notation."  Most of us would<br>argue that William Schottstaedt's and Jean-Claude<br>Risset's and James Dashow's and John Chowning's<br>and Richard Karpen's and Richard Boulanger's <br>computer compositions are FULLY notated...they<br>simply use a notation radically at odds with Paul's<br>cherished Pythagorean common-practice-period-based<br>paradigm. <br>Moreover, my own MIDI compositions and those of <br>many other xenharmonic composers use a notation<br>which is also perfectly standardized, entirely<br>reproducible, and which allows others to examine<br>and analyze the compositions--we use the MIDI<br>file format in which notes are represented as numbers<br>from 0 to 127.  Again, presumably because this<br>notation is something that Beethoven wouldn't have<br>used, somehow our compositions don't exist and<br>aren't worthy of audition, analysis or (presumably)<br>mention.<br>Peculiar indeed.<br>This leaves aside, of course, algorithmically<br>composed xenharmonic music.  That's a whole 'nother<br>passel o' varmints, chilluns.<br>Yet all the pieces of music mentioned above are carefully<br>and painstakingly composed, note by note, with *AT<br>LEAST* as much attention to detail as shown in <br>Blackwood's scores.  The main difference is not<br>that "many such [electronic/computer music] works<br>are created without a score," but rather that they use<br>musical scores which Paul chooses *NOT* to recognize <br>as a valid symbology.<br>Thus, while Paul mentions "this article does not <br>address the issue of the utility of scores," it ALSO<br>(much more glaringly) does not address the issue of<br>whether a piece of carefully-composed, closely-<br>worked-out music notated in a completely untraditional<br>way (e.g., Csound .sco file or MIDI file) ought to be<br>treated as though it doesn't exist merely because<br>the notation cannot be viewed as a variant of<br>some 19th-century central European concoction.<br>(Slippery slope time: do Gregorian chants notated<br>with neumes qualify as musical scores?  If so, why <br>don't MIDI files printed out in piano-roll notation?<br>And why aren't sonograms of Risset's and Chowning's<br>and Dashow's and Schottstaedt's and Lanksy's <br>computer music pieces *also* scores?  ...We're on the<br>slippery slope, and it's gettin' slipperier by the minute...<br>In desperation,  one MIGHT claim that 19th century musical<br>scores allow acoustic performers to reproduce the music.<br>This (such logic goes) distinguishes them from MIDI<br>files or Csound .sco files.<br>But how many live acoustic xenharmonic concerts did<br>YOU attend last year?  And didn't ALL of 'em use one-of-<br>a-kind exotic homebuilt acoustic microtonal instruments?<br>So what good is a 19th-century-type score if there's only<br>one set of microtonal instruments in the world that <br>can play 'em?<br>..Slippery slope time, kiddies!  Let's face it: <br>essentially no one attends or gives live acoustic <br>concerts any more, and since 99.999999% of the music we<br>all hear is now delivered via electronic media, this is<br>a VERY weak and flabby and etiolated argument for ANY <br>particular flavor of musical notation.) <br>Paul's chart of kommata is admirably clear and his<br>ranking exemplary; he is probably right that,<br>for ETs with good fifths, the syntonic komma is<br>most important for quasi-19th-century notation.<br>Paul makes a good point in dealing with 17:<br>"the third in question (5 u) happens to lie very close<br>to half way between the actual just major third<br>(386.314 cents) and just minor third (315.64 cents).<br>It may therefore be interpreted as either or neither,<br>depending on musical treatment of the temperament."<br>This leads to an alternate notation which does not<br>involve sharps or flats, and proves much superior to <br>Easley Blackwood's notation for 17.   <br>However, those of us who've worked extensively<br>with 17 would go even farther--many of us would<br>contend that 17 has only ONE functional triadic third:<br>the 5-unit third.  The so-called "major" third in 17<br>is unbearably dissonant and useful only in melodies,<br>or vertically as a passing tone or a cambiata.   Thus <br>many of us would urge that the so-called "major" third<br> of 17 be notated as a species of fourth--since, like <br>that interval, it is functionally unstable when employed<br>vertically.<br>Paul's 2nd notation of 53 seems as good as any other. <br>It avoids the problem of too many flats and sharps, <br>as usual by substituting odd new symbols. Again,<br>this eases clutter but reduces sight-readbility. New<br>symbols instead of the familiar sharp & flat will<br>always prove more ambiguous for sight-readintg,<br>since they're by definition unfamiliar.<br>Paul's first notation for 25-TET seems less than<br>successful, since it uses note-names E & F.<br>25-TET's most obvious audible characteristic is<br>its pentatonic "mood." This, because 25 boasts<br>not one but 5 circles of identical 5-TET fifths.  <br>The 25-TET fifth sounds unmistakably pentatonic--<br>it's the same 720-cent fifth found in all multiples<br> of 5-TET up to 45-TET. <br>Thus, a notation which implies that there are<br>more tones than sharped- or flatted-versions<br>of C, D, E, G and A proves less than useful.<br>Paul's 2nd proposed notation admirably corrects<br>this problem and exposes the five pentatonic<br>circles of fifths, as does Paul's third<br>suggested notation. This is a big improvement<br>over Blackwood's notation, which retained<br>E and F and B and C as exact enharmonic <br>equivalents (talk about willful obfuscation!).<br>Paul also points out that even *his* generalized<br>notation breaks down for ETs without fifths.<br>As an example, he gives 13...which has certainly<br>resisted any attempt to force it into a traditional<br>notational mold.<br>This is inevitable.  No notation can cover all<br>equal temperaments.  The main question is:<br>where ought the notation to break down?<br>And how?<br>Curiously absent in this regard are tunings with<br>good fifths but absolutely no point of contact to<br>traditional tunings: 26-TET, 22-TET, 35-TET, etc.<br>Paul's treatment of 13-TET as every other note<br>of 26-TET strikes me as peculiar, inasmuch<br>as the two tunings bear not even the most remote<br>audible relation to one another.  Any relationship<br>is a purely augenmusik calculated-numbers-on-<br>paper sort of thing, and does not strike me as<br>productive.  Similarly, notating 11 as every <br>other note of 22 would be equally fruitless--the <br>mind can calculate, but the ear cannot hear, <br>a relationship between the two.  In both cases,<br>one must *listen* to the tuning and *throw out* the<br>numbers if they conflict with common sense.<br>In both cases, notation for 11-TET ought to bear<br>NO resemblance to notation for 22, ditto<br>notation for 13 and 26.  If the two tunings sound<br>utterly different, they should be notated utterly<br>differently.<br>Perhaps Paul should add this as a 4th general<br>principle...?<br>Paul's treatment of negative kommata (33-TET)<br>seems eminently reasonable.  By avoiding sharps<br>and flats, many notational paradoxes are averted.<br>Of course, dispensing with sharps and flats also<br>eliminates much of the analytic value of a <br>musical notation.  If you can't tell at a glance<br>whether one note is higher or lower than another,<br>it automatically poses problems for musical<br>analysis.  In this case, one might be better off<br>studying a printout of the MIDI note numbers, or<br>the Csound .sco file Hz values.  But for Paul's<br>purposes it is obviously better not to raise such<br>unsettling questions.<br>His treatment of 14-TET proves less satisfactory.<br>Alas, in 14 (as in 7-TET) the modes collapse back<br>into the keys.  There is no major or minor: 3<br>scale-steps give 257.1 cents, too small to<br>sound or function as a minor third, while 4<br>scale-steps yield 342.8 cents, a neutral <br>third antithetical to Pythagorean theory. 5<br>units = 423.5 cents,  too large to function<br>as any kind of recognizable major third.<br>This situation proves so puzzling to devotees of <br>19th-century-style symbology that it forces<br>the unwary notation-theorist to twist hi/rself<br>into knots to get out of the problem.<br>Notating 14 by taking every other note from 28<br>begs the problem.  In fact, the issue is that<br>14 has two circles of 7 identical fifths, whereas<br>28 has 4 of them, and they ALL use neutral intervals<br>as building-blocks.  The 2-out-of-28 dodge  <br>obscures this basic fact, and tends to dupe the<br>inexperienced xenharmonist into imagining<br>that 14 has something like a major or a minor<br>mode when in fact it has neither: merely two<br>overlapping neutral 7-tone scales melding into<br>a neutral 14-tone scale--and not a diatonic 14,<br>either.   Logic would indicate two simple<br>overlapping sets of identical A B C D E F G <br>symbols.  Perhaps  A  A*  B B* C C* D D* E E*<br>F F* G G*? (Ivor Darrg's notation.)<br>This example illustrates the problems that Paul's <br>generalized notation creates when there are<br>NO Pythagorean landmarks--in this case, because<br>the multiples of 7-TET up to 42-TET are constructed<br>from completely non-diatonic building blocks.<br>A Pythagorean musical paradigm fails when faced<br>with 7 anti-diatonic utterly equidistant tones:<br>it flails like a moth caught in a  searchlight.<br>The product of a xenharmonic notation based on <br>inappropriate diatonic kommatic assumptions is bound<br>to falter & collapse for multiples of 7-equal.<br>In fairness, Paul points out the problems his notation<br>encounters with 50-TET, which is certainly no<br>surprise:  no proposed notation has dealt adroitly<br>with such an oddball tuning.  (Ditto 32, 27, 29, and<br>particularly 35, which is probably the ultimate <br>nightmare from notation hell!)<br>Paul's introduction of numbers as superscripts is<br>clearly UNsuccessful.  The entire reason for using<br>symbols to notate notes, rather than Arabic numerals,<br>is that the human brain has evolved a marvellous<br>pattern-recognition facility which operates at vastly<br>greater speed than any possible number-calculation<br>facility.<br>Once memorized, symbols are instantly processed<br>by a huge glob of visual cortex.  Ergo, the<br>miracle of sight-reading.  Not so numbers.  Numeric<br>stuff crawls through the  forebrain, where it clogs<br>everything up and bogs everything down.<br>Thus, it is impossible to instantly sight-read<br>columns of numerals, whereas one can easily sight-read<br>and musically analyze a bunch of visually striking<br>symbols.<br>Combining numerals with symbols forces the<br>brain's spiffy pattern-recognition wetware to slow<br>down to the pace of the number-recognizing forebrain <br>(a much more recent and thus less efficient evolutionary<br>addition), auguring ill both for the prospective <br>sight-reader AND the would-be music theorist.<br>Paul points out that F. R. Herf's and E. Sims' 72-TET<br>notation is a one-off chimera, not useful for other <br>temperaments.  True, alas, and typical of all too many<br>xenharmonic notations based on but a single tuning.<br>The same could be said of Joseph Yasser's 19-TET <br>notation, etc.<br>Overall, the article is refreshing and offers<br>excellent insights.  While many of us would quarrel<br>with the issue of what constitutes notation, Paul<br>appears to have generally succeeded in producing<br>a notation flexible enough to accomodate non-weird<br>non-oddball equal temperaments below about 53--<br>or at least, those which boast good fifths.<br>In my judgment the "weird" tunings like 26<br>and 19 and 22 and 32 demand entirely separate<br>treatment.  Ideally, thse tunings ought to have their<br>OWN notations--preferably as distinct as possible<br>from any others.<br>It seems clear that sharps and flats are most useful<br>in those tunings which *sound* as though though they<br>have recognizable semitones.  Thus, use of sharps and<br>flats in 19 is wilfully perverse--and hellishly confusing<br>in 9 or 10.  There may be no way out of this conundrum.<br>The issue of ETs without fifths was deftly resolved<br>by Augusto Novaro, who simply proposed using<br>numbers instead of noteheads on a single staff<br>line.<br>Incidentally, by proposing a notation for 171-TET<br>Paul has also notated the non-octave scale Carlos<br>Gamma, since it is audibly identical to every 5th note<br>out of 171-TET.<br>A much larger issue is the quesion of whether 7 basic<br>note-names is or should be the be-all and end-all of<br>music notation.  Miller's article "The Magic Number Seven,<br>Plus or Minus Two" (J. Psychol., 1956) makes it clear that <br>the human brain can efficaciously process as few as 5<br>or as many as 9 different note-names.  Yet there have,<br>to date, been almost NO suggestions for eugmenting<br>the basic A B C D E F G seven note names by<br>including up to two more--say, H and I (NOT to<br>be confused with the German H for "B flat").<br>There have also been NO discussions whatever<br>to my knowledge about 6-note or 8-note modes,<br>especially in prime-number ETs.<br>(How about it, Mnauel?  Any chance of your <br>writing a computer program to find & list all<br>the 5-, 6-, 7-, 8-, and 9-note modes of every <br><br>relatively prime ET with fifths less than 21 <br><br>cents away from 3/2, from 5/oct through 53/oct?)<br>Why such 12-centric thinking?<br>Why must ALL xenharmonic equal temperaments<br>employ always and only SEVEN note names?<br>Why must ALL xenharmonic musical modes use always<br>and only 5 or 7 notes?  <br>True, 5 and 7 are relatively prime to 12--and so what?<br>6 and 8 and 9 are relatively prime to 19, or 17, or<br>29. <br>Why only 5- or 7-note modes when we move outside<br>of 12 tones/oct? <br>Why not 6? <br>Why not 8?<br>Why not 9?<br>Paul will probably take issue with some of<br>these points, particularly where music-theory students<br>analyzing pieces of xenharmonic music are concerned.<br>However, I would point out that so few xenharmonic<br>pieces of music have been composed--and so few<br>music students have gotten together to analyze them!--<br>that to date the issue remains a pie-in-the-sky<br>abstraction at best.<br>It is entirely possible that xenharmonic composition<br>will demand such a schismatic break with the past that<br>previous 19th-century notational paradigms must<br>be thrown out.  However, we must be wary of such <br>proposals.  John Cage and other foolish folk made <br>similar noises in the 50s about *their* brand<br>of foofaraw, and--as the magazine "The Wire" put it <br>so concisely in its November 1995 issue--"John<br>Cage's music was intensely theoretical and centered <br>around the cult of personality of John Cage, and as a <br>result most of it is today unlistenable." <br>Claims that "THIS musical revolution requires a COMPLETE<br>break with the past!" are perennial, and have never proven<br>true.  Thus we must view with the utmost skepticism any such<br>pronouncements made on behalf of microtonality.<br>For the moment, until this issue is resolved, Paul's article<br> seems an admirable advance in the state of the art of <br>microtonal notation.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Fri, 5 Jan 1996 08:43 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id XAA29081; Thu, 4 Jan 1996 23:43:23 -0800<br>Date: Thu, 4 Jan 1996 23:43:23 -0800<br>Message-Id: <01HZMVBYZ5YA9D7TAS@delphi.com><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2440 href="#2440">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>1/5/1996 2:16:09 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: novelty, craftsmanship and microtonality<br>---<br>Among its many blessings, musical modernism bequeathed <br>post-1945 composers  the freedom to explore new<br>musical forms and new musical languages.  Among its<br>many sins, musical modernism elevated novelty as<br>sole yardstick of musical value.<br>Like Marxism, musical modernism is now defunct.  Each<br>ideology  discredited itself after failing its promise to<br>engineer the ultimate state of human affairs.<br>In the case of Marxism, history had reached<br>its end...or so its followers were told.<br>Any day, "real soon now," world communism would produce<br>a workers' paradise.  <br>Similarly, in the case of musical modernism,<br>musical history supposedly ended in the 1920s with<br>Schoenberg's invention of the tone row and the various<br>fetishes concocted by post-Webern serialism.  After 1930,<br>(according to the modernists) no further musical<br>evolution was possible.  All future serious music, from 1930<br>until the end of time, could consist only of successively<br>more subtle refinements of serial atonal technique.<br>(Some would call them successively more bizarre<br>perversions of the basic fetish, but this is a matter<br>of terminology. Whether one calls one's attire "a stylish<br>informal outfit" or "leather S&M bondage gear" depends on<br>one's point of view.]<br>Of course the existence of *this* microtonal tuning forum<br>disproves musical modernism's claims.  If 12-tone<br>serialism was in fact the beginning and end of all musical<br>wisdom, why did subsequent generations of  composers <br>bother to reach outside the 12 sacred tones? After all,<br>serial atonality stood at the very apex of musical evolution--<br>so any deviation from that orthodoxy constituted a fall from <br>grace. Microtonality can only be viewed by the modernists<br>as, in John Cage's words, "just another wing on the chapel,"<br>one of the most breathtakingly short-sighted faux pas <br>by a Zen  master of short-sightedness.<br>Thus anything other than the standard 12 tones per octave<br>constitutes a debased state of musical practice, according <br>to the Holy Writ brought down from Mount Princeton by<br>Milton Babbitt and his toadies.<br>This, of course, shows up one of the most glaring flaws<br>of modernist dogma: in idolizing novelty for its own<br>sake,  modernism creates a self-destructive paradox.<br>To wit: if it's the ultimate endpoint of musical evolution, <br>then any other kind of music cannot be taken seriously.  <br>But if novelty is the exclusive measure of musical value, <br>then music MUST constantly change  in order to be taken <br>seriously.  <br>Thus modernism demands that, in order to measure<br>up, new music simultaneously remain the same and <br>constantly change.  Since this is obviously<br>impossible, modernist music faced irreconcilable internal<br>conflicts.<br>One harks back to the berserk computers in old Star Trek<br>episodes: "ERROR!  ERROR! ILLOGICAL! ERROR!"<br>There remains the question of which of the three tenets<br>of musical modernism can be salvaged for future <br>generations of composers--if indeed *any* of its tenets<br> can be salvaged.<br>The existence of this forum would tend to undermine<br>the odd notion that there is something sacred about<br>the number 12 when applied to divisions of the octave.<br>The whole idea is reminiscent of those alleged "666"s<br>in the Procter & Gamble's logo. <br>But what about the value of atonal serialism, and  <br>of using novelty as the exclusive basis for judging <br>the quality of new music?<br>Like most late 20th-century trends, the reaction against <br>serialism has gone overboard.  Some excellent serial<br> music was composed early in this century--almost<br>all of it prior to 1945. Perhaps with a reduction<br>in the total number of tones (Schoenberg's first serial<br>composition used 11 out of 12) or a change to new<br>tuning sytems, or the separation of the yoked requirements<br>of atonality and serialism (in 19-tone equal temperament,<br>for instance, a 12-tone serial row can modulate from one<br>key center to another--see M. Joel Mandelbaum's Prelude<br>No. VI, 1961) serialism will provide a useful direction<br> for future composers.<br>This leaves the question of  using novelty as a yardstick<br>for quality.<br>By itself, novelty is a dead end.  One of the most peculiar<br>and interesting experiences I've had recently is in<br>making up a computer hard disk file of 3 CD recordings<br>interleaved at random.  The three compostions are<br>the second movement of  Schoenberg's "Five<br>Orchestral Pieces" from 1915, Stockhausen's "Gruppen"<br>from 1958 and Elliott Carter's "Orchestral Variations"<br>from 1989.  Each of these compositions was created<br>about 30-40 years apart, yet the overall effect of listening <br>to them is that they're basically the same piece of music.<br>This illuminates the paradox of using novelty as the standard<br>for judging new music.  After a generation  of trying<br>all possible new combinations of instruments and<br>musical structures, new music got caught in a rut.<br>Very quickly all possible wacky schemes for generating<br>new shock-value stunts are used up: scraping phono cartridges,<br>shooting a machine gun at a piece of manuscipt paper,<br>rolling naked women in paint on a graphic score, <br>performing a score without sound so that only the<br>finger-clicks of the woodwinds and rustle of string players' <br>sleeves make noise; composing huge textural<br>pieces in which every piece in the orchestra perforrms a<br>different melody, notating impossible-to-play solo<br>instrumental pieces with far too many embedded<br>tuplets and extended techniques for humans<br>to perform; ad nauseum.<br>Wjether it's whipped cream and hamsters, or flipping coins<br>and burning pianos...the whole sorry spectacle tends to blur<br>after a while.<br>After a few years, every possible three-card musical <br>monte trick that could be tried *had* been tried.<br>Thereafter, so-called "serious" modern composers ran<br>up against the limits of the human perceptual system.<br>While they continued to produce music that *looked*<br>ever more complex on paper, to the human ear it *sounded*<br>the same as last week's purportedly "breakthrough" new<br>composition, and as next week's supposedly "groundbreaking"<br>new composition, because the human perceptual system<br>had saturated.  <br>Beyond a certain level of complexity, all those notes <br>lumped into a big random glob; beyond a certain<br>level of rhythmic subtlety, all the embedded n-tuplets<br>sounded like a Parkinson's patient  playing <br>"chopsticks." <br>Thus novelty (paradoxically) when pushed to its outermost<br>limit forced modern composers away from so many perceptible<br>and comprehensible musical structures that the only <br>structures and techniques left were imperceptible.<br>The result?<br>Random-sounding junk.<br>This is the state at which so-called "serious" composers<br>(most of whose compositions could not be taken seriously)<br>had arrived by the late 70s, and it is also the reason for<br>the existence of this tuning forum.<br>As a result,  novelty  is not a useful yardstick of compositional<br>value.  Any more than the length of a composition is useful as a <br>measure of value...  Other measures of compositional<br>quality must be found.  <br>I would suggest craftsmanship and competence, at <br>the risk of being burned at the stake--since these values<br>are even more discredited nowadays than atonal<br>serialism.  <br>As witness young composers like Alison Cameron--folks <br>with plenty of raw musical talent who haven't yet mastered<br>elementary musical skills like learning when to take a<br>breath (metaphorically speaking), or constructing a<br>musically interesting dramtic arc... Much less  the<br>arcane and forgotten art of counterpoint.<br>Oddly, although serialism and atonality have been completely <br>devalued by the doyens of today's musical avant garde, most <br>composers who call themselves post-modernists still worship <br>at the musty altar of novelty and still obsess over the <br>length of their compositions.<br>This is true even in microtonality, and it's proven a real<br>surprise to me.  More than one person has dismissed<br>this or that just intonation composition on the grounds<br>that "it's just another 7-limit piece," or "it's just another <br>example of 13-limit."  <br>We who compose outside the 12 tone scale should take note<br>(all puns intended) of this lamentable trend<br>and be on our guard against it.  Just as novelty was<br>ultimately self-destructive and trivializing when misused <br>as a measure of musical quality, it is equally self-<br>destructive when applied as the gauge of <br>a microtonal composition's worth.<br>One of the greatest sins of musical modernism was the<br>devaluation of basic competence in favor of stunts and<br>scams.  This ultimately led to the eradication of a whole<br>spectrum of basic skills from an entire generation <br>of composers.  <br>Until the recent advent of the MAX composition <br>language and the widespread use of MIDI in <br>post-modern music,  counterpoint was a lost<br>art among modern computer composers.  (With notable<br>exceptions: Lansky, Schottstaedt, et alii.) The ability <br>to write an interesting melody, add another equally <br>interesting melody on top of it, turn them both upside <br>down and add another interesting melody on top, then <br>reverse the whole front-to-back and add another interesting<br>melody on top, ad infinitum...  <br>This is a forgotten skill.<br>Just as few post-modern artists have any aptitude at<br>draughtsmanship because drawing is no longer<br>emphasized in modern art classes, today's generation<br>of composers have virtually no skill at counterpoint--<br>because it is a subject no longer emphasized in modern<br>music classes.  Instead, elaborate formal methods<br>are the focus of contemporary composition courses--<br>beginning (naturally) with pitch class matrix trivia and <br>progressing through ever-more-convoluted, ever-more-novel<br>algorithmic contortions.  (I should add here that the <br>current species counterpoint exercises used in<br>composition classes are not only useless in teaching<br>real-world contrapuntal skills, but probably destructive. <br>Students get the idea that counterpoint is a dusty 16th-<br>century academic exercise without redeeming practical<br>value; the only way to *truly* teach counterpoint is to<br>require students to compose *real* pieces of music<br>using the techniques perfected in the era of ars subtilitas.<br>Since few music teachers are nowadays qualified to do this,<br>it's hardly any surprise that counterpoint is a lost art.<br>After all--how many of today's music professors can<br>even *pronounce* "ars subtilitas," much less demonstrate<br>expertly the contrapuntal techniques perfected in that<br>era?)<br>I have not addressed the question of serial counterpoint<br>as such since with more than two widely-separated notes<br>serial counterpoint is neither interesting nor perceptible,<br>and thus cannot be said to exist save in an abstract sense.<br>To his great credit, Webern understood this; the bulk of<br>his middle-to-late works use no more than two notes<br>(lines) at once.  To their great discredit, subsequent <br>generations of serialists ignored this lesson.<br>For proof of my contention one need look no farther<br>than the alleged compositions of John Cage, John Corigliano,<br>Brian Ferneyhough and Larry Austin.  These duffers<br>demonstrate a complete lack of contrapuntal<br>skills--indeed, their level of contrapuntal ability<br>is so remedial as to embarrass even a junior high<br>school student. <br>Fortunately, MIDI and MAX have radically changed<br>the character of avant garde. Music and composers <br>of more recent vintage are beginning to discover <br>that some rudiments of contrapuntal craftsmanship <br>are helpful when algorithmically combining <br>separate melodic strata.<br>Oddly enough, formal gyrations and contortions<br>with this or that fractal or this or that chaotic<br>attractor do not suffice to produce interesting<br>melodies combined and manipulated in interesting<br>ways. <br>Gosh... What a shock, eh?<br>In the same way, the extinction of the short <br>composition is a trend much to be lamented.  Indeed,<br>short pieces of music survive nowadays only as<br>commissions for large orchestra--the truism being that<br>if you compose anything too long and too hard,<br>it will take more than 1 rehearsal to learn and the<br>orchestra won't play it properly as its one and<br>only public performance.<br>The idea that a 2-minute composition is inherently<br>less "weighty" or less "substantial" than a 2-hour<br>composition is a bizarre notion, and one I'm at a loss<br>to explain.  One would expect that the collapse of the <br>romantic-composer-as-titan myth would also have<br>discredited enormous complex multi-hour-long<br>pieces of new music as the ultimate ideal for<br>the po-mo composer...  But no.<br>Oddly enough, po-mo compositions seem to have<br>suffered *more* hypertrophy of late, rather than *less*--<br>po-mo works have grown even *more* Wagnerian<br>as the 20th century winds to a close.  Thus<br>Stockhausen's wacky unlistenable multi-<br>day-long opera "Licht," LaMonte Young's<br>preposterous day-long drones, and the rest<br>of the sorry spectacle of longer-is-better<br>snore-a-thons.<br>The idea that a 2- or 3-minute-long composition<br>isn't a serious piece of music seems to have taken root<br>even in this tuning forum.<br>Amazing!<br>It's a weird and outlandish delusion...<br>According to this off-kilter topsy-turvy logic,<br>Bach's inventions aren't "real music," they're<br>just "sketches" or "demonstrations."  This is<br>a concept so strange that it just bounces off<br>my brain...I cannot imagine the hebephrenic state<br>in which such a conclusion makes sense.<br>The quality of a composition depends, one<br>would expect, on the quality of the compostioin...<br>not on its tuning, its length, its instrumentation,<br>or any other incidental factor.<br>It seems to me that this is an especially mischievious<br>misconception, and one against which we must be <br>ever-vigiliantly on guard. Particularly in<br>the case of microtonal compositions.  With so<br>many tunings to explore, xenharmonic<br>composers are especially liable to produce<br>many short compositions rather than a few<br>long ones.  ("So many tunings...so little time.")<br>Thus the pathological and fetishistic<br>worship of sheer length--the more minutes,<br>the better the piece--is particuarly pernicious<br>when misguidedly applied to microtonality.<br>--mclaren<br><br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Sat, 6 Jan 1996 06:20 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id VAA19051; Fri, 5 Jan 1996 21:20:24 -0800<br>Date: Fri, 5 Jan 1996 21:20:24 -0800<br>Message-Id: <960106001847_33235881@mail04.mail.aol.com><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2444 href="#2444">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>1/6/1996 11:33:49 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: CLM, Linux, and microtonality<br>---<br>In graciously responding to some of my<br>gripes about Csound, William<br>Schottstaedt mentioned that his CLM<br>emvironment runs under Linux.  <br>This was news to me.  Since CLM is by all<br>accounts one of the most deluxe composition/<br>synthesis environments, it's welcome news<br>indeed.<br>This forum has, since its inception, served<br>as hang-out for 2 kinds of subscribers:<br>ordinary schmucks with IBM or Mac desktop<br>systems and mostly MIDI synths and software,<br>and the few, the rich, the tenured--who generally <br>use some flavor of UNIX (NeXTstep, typically) <br>to run software-based synthesis apps like CMix,<br>CLM, or Csound.<br>Relatively few of the ordinary yutzes (like,<br>say, moi) compose much with software-based<br>synthesis languages.  In part, this is because<br>it's so much faster & more efficient to use MIDI.<br>In part it's because the academic freeware<br>is so damn hard to use and almost completely<br>undocumented, but let's not beat *that* <br>dead horse.<br>This leads to a huge echoing chasm twixt<br>the academic microtonalists and their <br>dirt-poor scumsucker "just folks" counterparts.  <br>The two groups literally speak different musical <br>languages.<br>MIDI is a dumb, slow protocol that basically<br>tells dedicated hardware when to goose-step.<br>99% of MIDI's messages revolve around<br>modulation--vibrato, filter cutoff, tremolo <br>settings, reverb depth, envelope bias, etc.<br>There is no MIDI continuous controller<br>dedicated, for example, to making a timbre<br>more inharmonic or adjusting the Nyquist rate<br>of the synth.<br>MIDI commands reflect this concern<br>with note start times. There's a note-on, but<br>no message that tells the synth how long the<br>note will be--a clear indication of MIDI's design<br>as a real-time performance protocol. 90% of the<br>parameters in all MIDI synth patches control<br>real-time modulation--response to aftertouch,<br>vibrato depth as a function of wheel position, <br>attack rate as a function of key velocity, etc.<br>MIDI is a coarse-grained protocol.  If you <br>send more than 20 or 30 note-ons, you'll<br>get arpeggios instead of chords.<br>In contrast, the software synthesis languages<br>like CLM, Csound and CMix are relatively smart<br>and very finely granular.   While MIDI doesn't<br>know or care how a synth responds to a note-on<br>message, software instruments can change <br>their behaviour depending on the note's <br>pitch, its duration, the number and type of<br>other notes playing at the same time, the<br>location in space or in the overall composition<br>at which the note appears, etc.<br>Software synthesis instruments are typically<br>specified at the level of the individual overtone<br>and involve no real-time modulation parameters.<br>Computer composers often write programs to<br>explicitly generate dozens or even hundreds of<br>parameters for each software-synthesized note<br>outside of real time, so responsiveness to <br>real-time modulation parameters is a<br>non-issue when composing in Csound or CLM<br>or CMix.  The parameters are "built in" for each<br>individual note and can be exquisitely fine-tuned.<br>This has important consequences for microtonal<br>composition.<br>Software-synthesized xenharmonies tend to be<br>very finely wrought, with layer upon layer of<br>acoustic complexity.  Software-synthesis<br>microtonality appears to be centered as much<br>around timbre as around notes.  Even in the works<br>of those composers notable for their contrapuntal<br>skill (Paul Lansky, William Schottstaedt, Bill<br>Alves, Jonathan Harvey) timbre remains uppermost<br>as a factor in the "non-12" sound of the music.<br>By contrast, MIDI microtonality centers almost<br>entirely on harmony and melody. Timbre is of minimal<br>concern, because commercial synthesizers offer<br>nothing in the way of detailed fine-grained<br>control over that parameter.<br>Retuning individual overtones remains outside of<br>the purview of the MIDI composer, *especially*<br>during the course of the composition.  (William<br>Sethares has written some custom FORTRAN <br>routines to read LEMUR analysis files and warp<br>FFT'd sounds into a given tuning, but this is<br>a rare exception, takes gobs of time, and demands<br>a sampler with enormous amounts of  RAM.  Thus Bill<br>Sethares remains the lone exception in this regard.)<br>The very model of the MIDI microtonal composer<br>is Warren Burt, whose compositions are essentially<br>contrapuntal and harmonic.  Timbre is a non-<br>issue.<br>This gives an interesting 18th-century "gebrauchmusik"<br>sound to Warren's compositions, even though they<br>use rhythms, melodies and harmonies no 18th-century<br>composer would ever contemplate, while it gives<br>the compositions of someone like Paul Lansky an<br>oddly modernistic sound--despite the fact that Lansky<br>often uses conventional 12-tone equal temperament<br>(as in the "idle chatter" series of compositions, all<br>in g minor, whitebread 12/oct).<br> To date there's been little contact twixt the two<br>camps of microtonalists.  Thus, many MIDI xenharmonists<br>confidently make statements about timbre, consonance<br>and dissonance which are simply untrue when software<br>synthesis (allowing individual partials to be retuned)<br>is involved.  In like manner, many academic microtonalists<br>lose sight of the musical forest by exploring mathematical<br>partition-function and pitch-class set/chaotic note generator <br>minutia, rather than asking the larger questions: What kind<br>of intervals does this tuning have?  How does it "sound"?<br>How can harmony and melody be used in this tuning in<br>ways which differ productively from harmony and melody<br>in 12/oct?<br>Thus, the investigations of John Clough, Gerald Balzano<br>and Carlton Gamer appear to have had much more impact <br>on MIDI microtonalists (for example) than on software<br>synthesis composers.<br>Meanwhile, the ideas of folks like William Sethares and<br>James Dashow appear to have percolated more thoroughly<br>into the software synthesis camp than the MIDI contingent.<br>This has led to further confusion and miscommunication.<br>Academics often write some of the most insightful<br>discussions about the internal structure of non-12 tunings,<br>while non-academics often write some of the most<br>useful monographs on the "sound" of non-12 tunings<br>and the interaction of tuning with timbre.<br>NeXTStep might have bridged the gap twixt these two<br>microtonal factions--but alas!  That operating system<br>is now dead and buried.  It's been overpriced FAR out<br>of reach both of academics *and* the rest of us, and is<br>now essentially defunct except on antique legacy <br>machines like the NeXT cube. (A machine roughly<br>25 times slower than the P6 @ 200 Mhz.)<br>Recently, however, Linux appeared...and this<br>operating system might finally offer a bridge twixt <br>the two worlds of microtonal composition. <br>Linux is extremely stable, according to my UNIX-<br>guru friend. Under X Windows, it's reportedly easy<br>to use.  The big stumbling block right now appears<br>to be setting up Linux to run under X Windows<br>with your particular monitor...  The process is<br>more complex than superstring theory.<br>(Do YOU know the "dot rate" of YOUR monitor?<br>Not me!!)<br>Only within the last 5 years have desktop<br>IBM machines grown fast enough to fully shoulder<br>the burden of software synthesis.  But now that<br>it's happened, IBM PC prices have dropped so<br>far so fast that it's hard to imagine anyone in or<br>out of academia will be using NeXT cubes or  <br>other legacy antique machines for very much longer.<br>The InfoMagic  4-CD set of Linux with complete<br>X Window support and all utilities now runs a<br>whopping $20 down at your local software store.<br>It's very hard for me to believe that NeXTStep-486,<br>at a cost of 5 thousand dollars (yes, $5000.00),<br>will survive the competition with the $20.00  Linux<br>operating system.<br>Linux can read DOS disks and apparently<br>offers the user the option of setting aside one<br>partition of the hard disk for DOS files.  This<br>clearly would go quite a ways in bridging the<br>gap between software and MIDI synthesis.  <br>Ideally, as a microtonal composer, I want total<br>control over EVERY asect of the composition--<br>and reasonably easy, fast, efficient control.<br>Combining Linux-based spectral modification<br>programs with CMIX, a sampler, and MIDI sequencers<br>might accomplish this.<br>My ideal system would let me tear apart an<br>acoustic sound, retune the individual partials,<br>then generate real-time scores with the ease<br>and simplicity of a MIDI sequencer.<br>Obviously this goal lies some years in the future,<br>but the Linux and DOS/Windows combo seems at<br>least a step in that direction.<br>Right now this kind of integration is essentially<br>impossible.  Even the NeXT cube didn't offer<br>MIDI sequencing with audio synchronization,<br>nor analysis with real-time resynthesis.<br>But now, with Linux, there might finally be a<br>bridge between these two styles of microtonal<br>composition.  Especially if & when someone<br>produces a microtonal synthesis program like James<br>McCartney's SuperCollider that runs in real<br>time on an *affordable* computer (the Power Mac<br>is not currentlfordable and probably never<br>will be--everyone with $4000 to spend on<br>a Power Mac raise your hand, please).<br>Such a program would bode well for interactive<br>real-time (those 90s buzz-words!) acoustic-and-<br>digital microtonality.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Sun, 7 Jan 1996 00:16 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id PAA00718; Sat, 6 Jan 1996 15:16:46 -0800<br>Date: Sat, 6 Jan 1996 15:16:46 -0800<br>Message-Id: <v01530501ad145f4f4c0b@[128.83.112.162]><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2448 href="#2448">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>1/6/1996 7:36:15 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject:  A wish list for microtonal<br> synthesizers<br>---<br>Let me tell you a story...<br>The tale starts back in 1975, when Hal Alles<br>at Bell Labs designs a spiffy board that <br>spits out 256 separate additive sine waves &<br>uses it to build the Bell Labs DIgital<br>Synthesizer.<br>Fast forward to 1978:<br>Crumar (then a big synth manufacturer, now<br>defunct) decided to build a digital synthesizer<br>based on Alles' board.<br>4 years later, Crumar rolled out the Synergy.<br>This instrument was controlled by (gasp!)<br>two Z-80 chips.  Super hi-tech, eh?  Wow!<br>A full eight bits of computing power! And<br>running at the awesome speed of 4 Mhz!!!  <br>Well, now that the laughter's over, here's<br>a sobering thought:<br>The Synergy STILL has, even TODAY, by far<br>the most complex architecture of any digital<br>synthesizer ever built.<br>Hello!<br>Ensoniq?<br>Are you there?<br>Q: What's the most important part of any<br>synthesizer?<br>A: Envelopes, envelopes, envelopes!<br>The complexity of the synthesizer's envelopes<br>ENTIRELY determines how complex and subtle its<br>sounds can be.<br>A synth with the world's most elaborate synthesis<br>algorithm, the most exotic & beautiful wavetables<br>ever designed, and the most sophisticated effects<br>buss in christendom, still sounds like crap if it<br>uses crude 4-stage ADSR envelopes for the <br>oscillators.<br>It's shocking and alarming to me that the Synergy,<br>designed in 1978, STILL has not been approached in<br>the sophistication and flexibility of its envelopes.<br>The Synergy allowed up to 16 envelope points<br>for each oscillator. You could set any two of<br>the points as loop points for sustain<br>when the key was held down.  <br>But wait!  There's more!<br>You voiced each oscillator TWICE--one 16-point<br>envelope for minimum key velocity, the other<br>16-point envelope for maximum key velocity.<br>Then the synth interpolated between those<br>2 envelopes in real time for all other <br>key velocities.<br>This gave the oscillators a remarkably subtle<br>"lifelike" quality.<br>But wait!  There's more!<br>You also voiced each oscillator TWICE for<br>the frequency envelopes--which could also<br>contain up to 16 points, for both min and max<br>key velocity.<br>The synth gave you a pool of 32 oscillators.<br>You could assign 'em any way you liked.<br>You could add oscillators or use 'em to <br>modulate one another--MORE flexibility.  Not<br>only that, but you could choose from 8 different<br>waveforms--for each individual oscillator.<br>But wait!  There's more!<br>Lastly, the Synergy let you set the amplitude<br>of each oscillator for each group of 3 keys--this<br>was essentially what Yamaha now calls "fractional<br>scaling."  <br>In effect, a digital formant filter.<br>The result?<br>Unparallelled subtlety and complexity of sound.<br>The Synergy has NEVER been equalled by ANY<br>other digital synthesizer in this regard.<br>It had aperiodic vibrato--that is, it allowed you<br>to mix a controllable amount of digital noise<br>with the LFO...again, giving the Synergy<br>a remarkable lifelike vibrato or tremolo.<br>Now, let's fast-forward 20 years...<br>Desktop supercomputers...cheap 1 gig disk drives...<br>magneto-optical storage...DSP chips cranking out<br>hundreds of MIPs...Csound on desktop machines<br>running at lightning speeds...<br>And guess what?<br>NO synthesizer manufacturer has YET implemented<br>envelopes REMOTELY as flexible and complex<br>as those on the antique 2-Z-80-controlled<br>Synergy of 1978.<br>C'mon, folks!<br>The problem CAN'T be hardware!  We've got hardware<br>up the wazoo.  We can handle such a synthesis <br>architecture with elan.  Today's synths could eat <br>those kinds of envelopes for breakfast.<br>Yet no one, absolutely NO synthesizer manufacturer,<br>has implemented such flexible envelopes.<br>To its credit, Ensoniq has done slightly better<br>than the rest of the synth manufacturers in this<br>regard.<br>Ensoniq's 8-point interpolating amplitude envelopes<br>are the closest I've seen...but that ain't <br>too close.<br>As a microtonal composer, my most basic need<br>is for a synthesizer with complex, flexible envelopes<br>each of whose oscillators can be precisely detuned.<br>The ideal would be a synth that can do what my<br>Csound instruments do: a synth that allows<br>20-point frequency AND amplitude envelopes with<br>30 to 60 oscillators at a time in real time.<br>Offer me such a synth with a tuning table, and I'll<br>fight through a nest of amphetamine-crazed<br>echidnas to buy it.<br>Until then, I gotta ask myself: why does the latest<br>issue of Confuser Music Urinal make a big deal<br>about an article that describes a chip with 127<br>additive oscillators?<br>C'mon, folks.  The Synergy offered 32 oscillators<br>(2 banks of up to 16 each) back in 1978. <br>Gimme a break.<br>It's time we moved up to the level of sophistication<br>attained 20 years ago with a pair of 4 Mhz eight-<br>bit Z-80s, don't you think?<br>--mclaren<br><br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Mon, 8 Jan 1996 16:48 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id HAA13530; Mon, 8 Jan 1996 07:48:32 -0800<br>Date: Mon, 8 Jan 1996 07:48:32 -0800<br>Message-Id:  <9601080749.aa17311@cyber.cyber.net><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2449 href="#2449">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>1/8/1996 7:48:32 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Bruce Kanzelmeyer's post,<br> Neil Haverstick's ideas about Bach,<br> guy xenharmonists vs. girl xenharmonists<br>---<br>As usual, Bruce Kanzelmeyer makes a number<br>of excellent points.  His post of some<br>weeks ago questioned the utility of<br>ever-more abstract investigations into<br>the mathematics behind various tuning<br>systems.<br>On balance, I agree. In the end the music's<br>what matters. If the elaborate theories lead<br>to music that sounds like crap--as in the case<br>of IRCAM, Pierre Boulez, Brian Ferneyhough,<br>John Cage, and Milton Babbitt, well, hell.<br>Dump the theory.  <br>Go back to noodling on the B3 in a <br>lounge in Schenechtady.<br>Questions of musical quality are necessarily<br>subjective.  My best take on the state of<br>the art in xenharmonics is that a whole lotta<br>good music's being produced.  Some of it<br>comes out of highly theoretical considerations--<br>some of it comes out of a wing & a prayer.<br>Given the unsavory tendency of the 20th century<br>to take every trend to its wildest possible<br>extreme, obviously there WILL be theorists who<br>run amok with math at the expense of music, sanity, <br>and general good taste. This is surely a trend<br>we need to keep an eye on in microtonality,<br>as in the rest of contemporary music.<br>The 20th century will NOT be remembered as an<br>era of moderation, but instead as a profligate and<br>outlandishly undisciplined period of wild excess<br>where every possible harebrained scheme was pushed <br>to the outermost edge of its wackiest implications, <br>and then several light-years beyond.<br>Well, what else is new?  What other century gave<br>us both a Hitler AND a Ghandi?  What other century<br>boasted BOTH a Piet Mondrian AND a Pablo <br>Picasso?<br>But there's room for a lot of different<br>apoproaches in a field as large as non-12<br>composition...  As Ted Melnechuk put it,<br>"Music's house has many mansions."  It seems<br>unfair to penalize or ostracize good microtonal<br>composers  just because they arrived at their<br> end product via the route of mathematics,<br>rather than intuition--or whatever other approach<br>is the fashion de jour.<br>Incidentally, this is similar to the schism twixt<br>guy & girl xenharmonists on this forum.  Women<br>consistently get repelled by the math, the relentless<br>theory, the endless terminology. Their usual <br>objection seems to be: <br>"Where's the music???"<br>Guys seems to be afflicted with a certain amount of<br>"number macho."  Something along the lines of, "Hey!<br>MY list of intervals is bigger than YOURS!"<br>Women have persistently  called fsr more discussion of<br>aesthetc isses in microtonal music...  A topic<br>which male subscribers to this forum appear to be<br>unwilling to touch.<br>Not sure why.<br>(There are exceptions. Laudably, the Scarlet Aardvark.)<br>Maybe aesthetic concerns are too touchy-feelie?<br>Maybe talking about the MUSIC, rather than the<br>NUMBERS, would leave the males a wee bit...vulnerable? <br>Or perhaps such colloquy might even touch upon <br>(horror of horrors!) the EMOTIONAL impact of <br>xenharmonic music, rather than this or that <br>komma or skhisma?<br>Well...hard to say.<br>But it do bear thinkin' on, chilluns.<br>Typical of a sizable contingent on this forum, Bruce<br>evokes the horrors of musical chaos and paints <br>a glowing picture of Appolonian order.  Of course,<br>some of us LIKE chaos.  Some of us view chaos as<br>a fertile maelstrom wherein brew dandy new<br>worlds of harmony & melody...  As Ilya Prigoine<br>points out, order only appears in thermodynamic<br>systems at the edge of disorder.  Without uncontrolled<br>and promiscuous chaos, a system tends to enter<br>stagnant cyclic states.<br>Of course the JI crowd will view this notion with the<br>utmost horror..."son cosas de la vidas."<br>Re: Bruce's objection that listeners will inevitably<br>disagree, etc. etc., & there's a margin of error<br>in all auditory systems, therefore the psychoacoustic<br>data can be explained away...<br>Nope.<br>If we were talking about ranges of error or some<br>such, the complexities of the human auditory system<br>COULD be swept under the rug.  But it ain't<br>that simple.<br>Alas, the psychoacoustic data clearly show that<br>many auditory stimuli produce contradictory<br>results when applied under different circumstances.<br>This is a conclusion that CANNOT be swept under<br>the rug.  NO amount of talk about "ranges of error"<br>or "imperfections in the ear/brain system" will<br>suffice to esplain away outright paradoxes and<br>contradictions in the human auditory system.<br>This kind of argument was put forward in the 1870s<br>to bolster Helmholtz's crumbilng Fourier analysis<br>model of the ear.  The argument didn't explain away<br>Seebeck's siren experiment, the extreme contradiction<br>twixt calculated jnds and observed just noticeable<br>differences, nor did it explain combination tones,<br>the Zwicker tone, or any of the other paradoxes<br>and puzzles which continue to plague modern <br>psychoacousticians.<br>Alas, such arguments failed in the 1870s and they<br>still fail today.  In the end, the only resonable<br>conclusion is that a LOT of complex phenomena are<br>taking place in the ear/brain system, many of<br>which appear to require contradicotry and mututally<br>exclusive explanations...and no one model of hearing<br> suffices to explain even a significant fraction of<br>the extant data.<br>As for Neil Haverstick's deification of Bach...well,<br>permit me to demur.  Bach was a fine composer who<br>also churned out a fair amount of Muzak.  His cantatas<br>are classic Muzak, the notebook of Anna Magdalena<br>Bach is pure make-work, and many of his chorales<br>and even a few of the 48 constitute mere busywork<br>noodling-around.<br>Bach was certainly an excellent composer when he<br>was at the top of his form.  Equally certainly,<br>he wasn't always.<br>In particular, the destructive idea that no human<br>can excel Bach is bizarre and outlandish.<br>In fact, Bach's lute suites (which are transcriptions<br>of his cello suites, by the way) are good music...<br>But infinitely inferior to the far more impressive <br>lute masterpieces of the late renaissance.<br>John Dowland in particular wrote many superb pieces<br> for lute which put Bach's lute suites to shame.<br>The idea that Bach is some sort of unapproachable<br>god strikes me as just plain silly. <br>As for Neil's contention that there are very few<br>great pieces of xenharmonic music, well, <br>bosh and twaddle.  I can name 20 masterpieces<br>of xenharmonic music without breaking a sweat:<br>[1] Easley Blackwood's 15-tone etude<br>[2] Easley Blackwood's 23-tone etude<br>[3] Paul Lansky's "Late Autumn"<br>[4] Richard Boulanger's "In Slow Glass"<br>[5] Gary Lee Nelson's "Fractal Mountains"<br>[6] William Schottstaedt's "Water Music"<br>[7] Jean-Claude Risset's "Inharmonique"<br>[8] John Chowning's "Stria"<br>[9] Larry Polansky's variations on "My Funny<br> Valentine"<br>[10] Ivor Darreg's "Prelude No. 1 for 19-tone<br>guitar"<br>[11] Ezra Sims' "Quintet" (1987)<br>[12] Charles Ives' "Three Pieces for Quarter-Tone<br>Piano"<br>[13] Julian Carillo's "Prelude A Cristobal Colon"<br>[14] Ivan Vyshnegradsky's "Quartet en quarts a tons."<br>[15] Alois Haba's opera "Die Mutter"<br>[16] Edgard Varese's "Arcana" <br>[17] Louis & Bebe Barron's tape score for "Forbidden Planet"<br>[18] Ben Johnston's Quartet No. 4<br>[19] Mayumi Reinhard's "Peach"<br>[20] Jonathan Harvey's "Mortuos Plango Vivos Voco"<br> And I could rattle off 30 or 40 other masterworks of<br>non-12 music without any trouble at all.  But, as always,<br>there's neither time nor space.<br>The idea that there are "very few xenharmnic masterpieces"<br>just doesn't jibe with the facts. On the cotnrary: it seems<br>clear that xenharmonic composition as a field has<br>generated a hugely disproportiate number of masterworks--<br>and at a rate that seems to be *constantly increasing.*  <br>--mclaren <br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Tue, 9 Jan 1996 02:48 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id RAA21888; Mon, 8 Jan 1996 17:48:11 -0800<br>Date: Mon, 8 Jan 1996 17:48:11 -0800<br>Message-Id: <199601090147.BAA22400@smtp-gw01.ny.us.ibm.net><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2479 href="#2479">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>1/21/1996 4:07:15 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: The adoration of the Cage-i (Round 2 of 15)<br>---<br>A recent recording session involved overdubs of<br>a cassette tape of harmonic series members 1-44<br>made 10 years ago by Jeff Stayton with megalyra <br>solos recorded last week.<br>After hearing the resulting composite, Bill<br>Wesley offered some choice comments.<br>"That sounds like an interesting use of chance. As<br>opposed to John Cage's *stupid* use of chance."<br>"You mean the idea of flipping coins to choose notes?<br>What's stupid about that, Bill?"<br>"You get a bunch of random pitches.  White noise.<br>But the human ear is specifically adapted to detect<br>and filter out noise--because if you can't hear a<br>sabre-tooth tiger's roar through the noise of the <br>jungle, you're dead.  So what did John Cage elevate<br>to highest status in his brain-dead musical theories?<br>Just what the human ear is best designed to<br>throw out...noise.  Another word for chance."<br>"But wait a minute, Bill.  Cage worshippers like to<br>point out that he didn't just pick notes at random--Cage<br>*constrained* the choice of notes and phrases.  In <br>'Music of Changes,' for instance, he used coin flips <br>to choose among constrained start-times and <br>transpositions of a set of pre-composed phrases."<br>"It doesn't matter, Brian.  If you throw the aces<br>out of a card deck, that doesn't make the distribution<br>of cards any less random after you shuffle 'em."<br>"That's a good analogy.  I wonder why none of these<br>people seem to understand that?"<br>"Because the cult of personality tends to impair judgment.<br>In the end, no matter how you constrain it, noise is noise.  <br>Even if you narrow down the choice to two notes, it's<br>still random.  And you'll detect and be bored by that<br>randomness."<br>"I've noticed that, Bill."<br>"It's why, even if you alternate between only two<br>phrase start-times, your ear will hear the random<br>distribution and find it trivial."<br>"You make a good point there, Bill.  I have to admit<br>it certainly is easy to pick a conversation out of the<br>noise of a crowded room. And it certainly explains<br>why 'Music of Changes' sounds like complete  crap."<br>"Exactly.  Noise is noise, no matter how you constrain<br>it. The notion that there's anything interesting about<br>a random distribution is a stupid idea--pure and simple.<br>It's dumb.  But then, that's the whole point."<br>"Eh?"<br>"It's what always happens in a group of monkeys.  Whenever<br>some lesser monkey shows  imagination or initiative, the <br>alpha males always crush him.  They've got to--to  maintain <br>the status quo."<br>"I don't understand, Bill."<br>"The whole idea behind Cage's music is that he wasn't part<br>of a revolution at all.  He was part of a *suppression* on the<br>part of the aristocracy.  The rich people want to play golf<br>all day and swig martinis.  They don't want *anyone* to rock<br>the boat.  You start adding extra pitches to the octave, and who<br>knows what's next?  Everything could come unglued. So the <br>artistocracy hire someone like Cage to crush people with <br>*real* imagination and drive them out of music."<br>"People with imagination?  You mean...like, microtonalists?"<br>"Yep."<br>"Well...  Cage *did* call microtonality 'just another wing <br>on the academy...'"<br>"Sure. The whole point of Cage's music was to take anyone<br>with enthusiasm and originality and horrify him to the<br>point where he gets out of the field and goes to work at<br>McDonald's."<br>"Isn't that kind of harsh, Bill?  After all, people like Warren<br>Burt are already accusing me of 'showing bad manners<br>freely, and displaying an appalling lack of gentleness and<br>generosity' to people like Cage.  God only knows what they'd<br>say if I repeated *your* comments on the tuning forum."<br>"Of course they accused you of showing 'bad manners.' Creativity <br>is considered the *ultimate* in bad manners by the aristocracy.  <br>It's another way of maintaining the status quo."<br>"How's that, Bill?"<br>"You call imagination 'rude' and then hire people like Cage to<br>make sure that only cynical, empty people have any power<br> in the field  of music.  All that talk about 'removing intention<br>from the music' and 'letting the music be itself' was nothing<br>but another way of making music students into a bunch of<br>monks who flagellate themselves on command."<br>"Flipping coins never did seem like much of a musical<br>revolution, I must admit...  But, gosh, Bill--this is pretty<br>blunt talk, isn't it?"<br>"That's a laugh!  These people bleat about 'gentleness<br>and generosity'--and the minute you suggest emperor Cage<br>has no clothes, they come after you with a bowie knife<br>and murder in their eye.  So much for 'gentleness.'  So<br>much for 'generosity.'"<br>"It *is* strange...  You'd think the microtonalists would stick<br>together, despite their minor differences."<br>"Well, remember what Harry Partch said in his program<br>notes to 'Water, Water':<br>'The creative man is not specialized by inclination, but<br>by the autocracy of modern education. (..) Ordinarily,<br>however, he is so closely intimidated by his specialty<br>that if he decides to make some slight deviation<br>from the norm, in some creative work, it will seem<br>like a 'revolution,' both to him and to others, and<br>he can easily become the progenitor of a 'new' <br>movement.  But the deviation must be slight, because a<br>large deviation is not only incredible, it isn't even<br>recognizable.  In the end, it is just ridiculous.'"<br>"You mean a deviation like throwing out octave<br>equivalence, Bill?  Or pointing out that the <br>psychoacoustic evidence doesn't support just <br>intonation?"<br>"Exactamundo."<br>"Gee...when you put it that way, Bill, it *does* sound<br>as though Cage was just another toady."<br>"Right.  Another errand boy elevated by the musical <br>aristocracy into a position of godhood to keep the <br>*really* creative people from rocking the boat."<br>"Creative people?  Like Partch? Or Carrillo?"<br>"You got it."<br>"But if I ever dared to post something like *that* on the<br>tuning forum...ye gods. They'd go ballistic, Bill."<br>"Maybe.  But from what you've said, most of the academics <br>on that tuning forum are too lazy even to write a letter.<br>So I don't think *I* have anything to worry about."<br>"Come to think of it, Bill, you're probably right."<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Mon, 22 Jan 1996 07:38 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id WAA10477; Sun, 21 Jan 1996 22:38:53 -0800<br>Date: Sun, 21 Jan 1996 22:38:53 -0800<br>Message-Id: <9601212325167216@csst.com><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2483 href="#2483">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>1/22/1996 2:39:03 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: 10 smart ideas in late <br> 20th century music theory<br>---<br>Everybody knows that  the most important<br>composers and music theorists are those<br>who influence the largest number of<br>people.<br>Everybody knows this, and it's wrong.<br>The rock group KISS influenced far more people<br>than any avant-garde theorist or composer. Should<br>we devote a chapter of every modern music textbook<br>to KISS?<br>I propose a different (and more sensible) definition of<br>"influential."<br>If a dumb fad influences 500 composers to write <br>rotten music, the idea is NOT influential.  It's a craze,<br>like pogs, or hula hoops, or pet rocks. <br>And it has no importance.<br>But if a smart idea influences 5 composers to write<br>excellent music, then the idea IS influential.  And it<br>has *vast* importance.<br>As I've mentioned before, Tops 40s corporate rock and<br>the avant garde are evil twins. They both use identical<br>means of promotion: hoopla, ballyhoo, shock-value stunts<br>and the cult of personality. They both use identical means of<br>measuring a composer's importance: SHEER QUANTITY.<br>If rock star X sells 8 squillion CDs, he's a "genius" and<br>a "brilliant composer."  If avant garde music theorist<br>X inveigles 50,000 gullible students to spew out<br>reams of bad music derivative of the latest craze,<br>he's a "genius" and a "brilliant composer."<br>Obviously, a new definition of "influential composer"<br>is required.<br>Now, what this has to do with microtonality is obvious:<br>the two most influential (as opposed to faddish) composers<br>of the second half of the 20th century are clearly Conlon<br>Nancarrow and Harry Partch. <br>Neither of these guys were on the cognitive elite's TOP<br>TEN charts during the 50s or 60s.  On the contrary. As<br>Joel Mandelbaum has pointed out, "It is a matter of<br>everlasting shame that the musical establishment<br>gave Harry Partch the back of the hand treatment."<br>This alone should give all music students<br>pause.   <br>When you read the conventional history texts of 20th<br>century music, ask yourself: Why isn't microtonality <br>mentioned?  And why isn't music by "the big names" of<br>the post-1950s played any longer? <br>The answers to these questions are connected.<br>And they can be found in the following list of the 10 <br>best ideas of post-1950 music theory:<br>---------------------------------------------<br>SMART IDEA #1:<br>Joseph Yasser pointed out in his 1938 book "Theory<br>Of Evolving Tonality" that musical tunings change<br>with time.  Intonation fashionable in one era becomes<br>unfashionable in another.<br>Any composer who, in the 1940s or 1950s, had read<br>Yasser's book would have realized that serialism was<br>just another fad...neither better nor worse than<br>Venetian antiphonal brass choirs, Baroque quodlibet,<br>or late Medieval mensuration canons.  Yasser's realization <br>that tunings are not static, and that musical cultures<br>influence one anther and tend to blend and intermingle<br>over time, is a lesson that STILL hasn't been absorbed <br>by the writers of conventional music theory texts.<br>---------------------------------------------<br>SMART IDEA #2:<br>Harry Partch proposed abandoning the conventional<br>12 tones. Instead, he built his own instruments<br>and trained his own performers.  It doesn't much<br>matter what you abandon those 12 tones for...<br>just intonation?  Non-12 equal temperaments?<br>The original tunings of Dowland and Byrd and Bach?  <br>Non-just non-equal-tempered scales?<br>The crucial decision is to kick over the chess board<br>by building your own instruments.  This alone<br>changes the rules of the conservatory-and-concert-<br>hall con game.<br>The fact of the matter is that Partch's decision to<br>step on the 12-tone anthill breathed much-needed<br>life into post-1950s music... And the existence of<br>this tuning forum is testimony to the continuing<br>power of that idea.<br>--------------------------------------------<br>SMART IDEA #3:<br>Jean-Claude Risset's idea (following John Pierce's<br>and Max Mathews' 1966 & 1969 papers, & later taken <br>up by John Chowning, James Dashow, William Sethares<br> and most recently Parncutt and Strasburg in the <br>1995 PNM article  "'Harmonic'  Progressions of <br>Inharmonic Tones") of basing non-12-tone methods <br>of tonal and timbral organization on the findings <br>of modern psychoacoustics  was a brilliant one.  <br>It has consistently led to beautiful music.<br>-----------------------------------------<br>SMART IDEA #4:<br>Erv Wilson's notion of augmenting with permutation<br>techniques the conventional Partchian organization <br>by harmonic and subharmonic series (viz., the tonality <br>diamond).   Erv's technique offers a more tonally<br>efficient  alternative to Partch's tonality diamond, <br>and it has proven  exceptionally useful to just intonation  <br>composers.  <br>As Kraig Grady wrote in 1/1, "With the introduction <br>of Erv Wilson's combination product set, Just intonation <br>took a giant leap forward." [Grady, K., "Erv Wilson's <br>Hexany," 1/1,  7(1), 1991, pp. 8-11.]<br>If anyone needs further proof, Warren Burt's superb <br>composition "Vingt Enflures Sur L'Enfant Melvin" is<br>a vivid demonstration of the musical value of Erv's ideas.<br>----------------------------------------------<br>SMART IDEA #5:<br>Fokker's introduction of ratio space has influenced<br>generations of composers to produce interesting<br>and impressive music.  The idea has been extended by<br>Tenney, Polansky, Johnston, Chalmers, Scholz and<br>many others. One of the very best po-mo xenharmonic<br>compositions, "Lattice [2237]" by Carter Scholz, would<br>be impossible without Fokker's original organizing<br>principle.<br>----------------------------------------------<br>SMART IDEA #7:<br>Lou Harrison's notion that all music students should<br>be trained in at least one other culture's musical<br>traditions.  If this were done, it would end at one<br>stroke the onanistic over-theorizing, the bizarre<br>yearning to convert music into a species of <br>mathematics... Yes, it might even straighten out the <br>tortuous verbiage that has made a bottomless <br>chum bucket of 12-tone  music theory.<br>Lou's idea is a brilliant one, long overdue.<br>When will someone put it into practice?<br>----------------------------------------------<br>SMART IDEA #8:<br>Ben Johnston's idea of training conventional performers<br>in non-12 techniques.  Just as dinosaurs turned into<br>birds, the smart post-Webern serialists turned into <br>extended JI composers working with conventional<br>performers.  If Webern had lived, he'd obviously have<br>given up 12 by 1950 at the latest.<br>-----------------------------------------------<br>SMART IDEA #9:<br>Max Mathews did what all geniuses do when he<br>applied the computer to music:  something<br>that at first looked bizarre, then  became<br>blindingly obvious, and finally seemed inevitable.  <br>With its binary precision and enormous speed,<br>the computer was and is an ideal musical<br>instrument.  Max Mathews gave a huge impetus<br>to 20th century composition in general (and non-<br>12 composition in particular) by writing the<br>first acoustic compiler.<br>------------------------------------------<br>SMART IDEA #10:<br>Ivor Darreg pointed out in 1975 that every kind tuning<br>has its own "sound" or "mood" or "sonic fingerprint."<br>Choosing the "sound" of a composition by choosing<br>the tuning has proven an endlessly productive idea,<br>and inspired a wide variety of xenharmonic<br>composers.<br>------------------------------------------<br>It's worth noting that every one of these post-1950<br>ideas is inherently xenharmonic.  That ought to tell<br>us something about the direction of the vital <br>currents of late 20th century music...<br>Attention, music students!  How about asking your<br>professors why THESE ideas aren't mentioned in<br>your textbooks?<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Tue, 23 Jan 1996 08:01 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id XAA26305; Mon, 22 Jan 1996 23:01:20 -0800<br>Date: Mon, 22 Jan 1996 23:01:20 -0800<br>Message-Id: <v01520d03ad29b8d61abd@[10.0.2.15]><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2523 href="#2523">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>2/1/1996 3:56:58 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: melodic modes in 19 & 17<br>---<br>As mentioned some months ago,<br>efforts to force-fit the 19 tone<br>equal tempered scale into the <br>melodic patterns familiar throughout<br>Western music are doomed to <br>failure.<br>This, because there's nothing like a<br>semitone in the 19-tone system.<br>Since 19 is a member of the third-tone<br>family of scales, this is obvious.  Yet<br>many notation schemes and suggested<br>melodic modes depend on the mistaken<br>idea that 19 has something that sounds<br>or functions like a semitone.<br>In actual musical practice, two 19-tone<br>scale-steps do not sound anything like<br>a semitone--the resulting interval,<br>126.315 cents, sounds a full quarter<br>of a semitone larger than the semitone<br>found in 12.  Alternating this interval<br>with the 3-step whole-tone in 19<br>produces a queasy effect that cannot<br>be described as either "major" or<br>"minor"--instead, the overall impression<br>is that of a 7-out-of-48-tone mode<br>which sounds distinctly out of tune.<br>Since major and minor melodic modes<br>do not exist as such in 19, this creates<br>a substantial conflict.  After all, major<br>and minor *vertical* triads are easy to<br>play in 19--but a major or minor melodic<br>mode are not to be found.<br>So what's the solution?<br>The experience of the Southern California<br>Microtonal Group has shown definitively<br>that the concept of  major and minor<br>melodic modes must be abandoned in 19.<br>To avoid producing a bizarre and queasy<br>out-of-joint melody, 12-tone melodic<br>paradigms must be thrown overboard and new <br>forms used.<br>Recently, Jeff Stayton recorded a duet<br>with me in the 19-tone system.  Stayton<br>used one melodic mode, while Your Humble<br>E-Mail Correspondent used another.  Neither<br>mode, however, had any point of contact<br>whatever with 12--and as a result, the<br>combination sounded entirely natural in<br>19.<br>My melodic mode used ascending and <br>descending subsets of the following:<br>LssLssssLsL  L = 3 scale-steps in 19,<br>                      s = 1 scale-step in 19<br>This "super-mode" appeared as two<br>different modes, one ascending, the<br>other descending:<br>ASCENDING:<br>LssLsLLsL   (intervals shown as number<br>                     of 19-tone scale-steps)<br>I.e., <br>1  4  5  6  9  10 12  15  16 (20=1)<br>                     (scale degrees played: numbered<br>                     from 1 to 19, with 20 = 1)<br>DESCENDING:<br>LsLsLsLsL  (intervals shown as number<br>                    of 19-tone scale-steps)<br>I.e., <br>20=1  17  16  13  12  11  8  5  4   (20=1)<br>                   (scale degrees played: numbered<br>                     from 1 to 19, with 20 = 1)<br>Variety was added by borrowing additional<br>steps from the "super-mode" and adding<br>them ornamentally to either the ascending<br>or descending mode.<br>Jeff Stayton's guitar accompaniment used<br>an entirely different mode:<br>(Descending)<br>LsmssmsL  where L = 3 scale-steps in 19<br>                             s = 1 scale-step in 19<br>                             m = 2 scale-steps in 19<br>I.e., <br>4  20=1  19  17  16  15 13  12  9<br>		(scale degrees played: numbered<br>                     from 1 to 19, with 20 = 1)<br>Stayton varied his mode by substituting 2<br>single scale-steps for a 2-degree "m" step:<br>thus he might play<br>LsssssmsL instead of LsmssmsL, for<br>example.<br>The combination of these two melodic modes<br>worked smoothly and sounded entirely natural<br>in 19.  However, they do NOT derive from any<br>12-tone or Pythagorean paradigm.<br>More to the point, both of these modes use<br>*more* than 7 tones.  It has been my experience<br>when improvising in or writing scores in 19<br>that more than 7 tones are required for a <br>natural-sounding melodic mode.<br>This should not come as a surprise.  In 1956,<br>Miller's paper "The Magic Number Seven, Plus<br>or Minus Two" pointed out that the human<br>cognitive system is capable of easily <br>assimilating as few as 5 or as many as 9<br>"units."  If each step of the melodic mode<br>is thought of as a unit, this explains why<br>9-tone modes come so naturally to 19--<br>even though such modes use 2 more steps<br>than the Pythagorean-based 12-tone <br>melodic modes familiar from Western music<br>theory, a 9-tone mode still fits comfortably <br>the limits of the  channel capacity of the<br>human sensorium.<br>(By contrast, serialism's 12 notes are too<br>many.)<br>Thus my experience indicates that at least<br>8 and usually 9 steps are needed to create a<br>convincing and natural-sounding melodic<br>mode in 19.<br>On the other end of the perceptual scale,<br>the 17-tone equal-tempered scale sounds<br>best melodically when used with 5-step<br>or 6-step modes:<br>1  6  4  1  5  (ascending: intervals in <br>                      number of 19-tone scale-steps)<br>I.e.,<br>1  2  8  12  13  17  (18=1)<br>or<br>1  6  1  4  4  1 (ascending: intervals in number<br>                         of 17-tone scale-steps)<br>I.e., 1  2  8  9  13  17 (18=1) (ascending: scale <br>                      degrees played--numbered from<br>                       1 to 17, with 18 = 1)<br>Not all xenharmonic equal temperaments <br>require a complete rejection of 12-tone<br>melodic modes.  22, 24, 27, 29, 31, 36 and so on<br>all have familiar 7-note major and minor melodic<br>modes.<br>19, however, does not.  This startling contrast<br>between the familiar-sounding major and minor<br>triads available in 19 and the utterly alien-sounding<br>melodic modes is one of the greatest resources<br>of the 19 tone equal temperament.  Composers who<br>ignore this fact do so at the peril of producing<br>awkward-sounding out-of-joint music that<br>gives the impression of 12 badly mistuned.<br>--mclaren <br>ATDT *70, 633-4360<br> <br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Fri, 2 Feb 1996 04:20 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id TAA26453; Thu, 1 Feb 1996 19:20:00 -0800<br>Date: Thu, 1 Feb 1996 19:20:00 -0800<br>Message-Id: <960201221740_412518206@emout10.mail.aol.com><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2526 href="#2526">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>2/2/1996 9:57:52 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: A saga of low cunning and<br>feral persistence<br>---<br>As a chronically unrepentant electronics<br>gonzo, permit me a small confession:<br>Yes, I finally built myself a duplicate of<br>Harry Partch's Harmonic Canon I (minus<br>Harry's bad design features).<br>And it sounds INCREDIBLE.<br>Johnny Reinhard has roundly chided me<br>for slighting acoustic music.  Of course,<br>he's right.  <br>In the end, there's no substitute for live<br>acoustic music played by good performers<br>on real acoustic instruments.  The richness<br>and subtlety of the sound is nonpareil.<br>On the other hand, some of us are interested<br>in exploring worlds of timbre and massed<br>sonority which would not be possible to<br>realize (xenharmonically, anyway) without<br>the aid of "pushing a button on electronic<br>boxes." <br>Thus circumstances will doubtless force<br>me to continue "pushing buttons." If you<br>can get together a 100-piece orchestra<br>that can play accurately in 15-TET, though,<br>Johnny, let me know.  In that case my<br>computer will definitely be mothballed. <br>:-)<br>The Harmonic Canon is a marvel, though. A<br>universe of subtle & gorgeous xenharmonies<br>lie within its bridges and pinblocks.<br>For example, entirely different timbres can<br>be gotten by stroking the strings with one's<br>fingers; by plucking them with guitar picks;<br>by tapping them with a knitting needle; by<br>thumping them with a piece of a piano action<br>(Harry gets his revenge against the piano--<br>50 years late!); and by whanging the strings<br>with a soft paint roller.<br>Moreover, non-Partchian string-bending<br>koto-style performance techniques<br>bring out an entirely different side<br>of the instrument.<br>The great virtue of the Harmonic Canon<br>lies in its potential as a kind of mechanical<br>sequencer.  You set up various justly-intoned<br>melodies by moving the many independent<br>bridges, and you can get triplets, repeated<br>notes, single notes, entire melodic chains<br>playing at a rate entirely controlled by<br>the rate at which you move your finger or<br>your pick across the strings.  Add to this<br>the potential gestural effects--pitch-bent<br>ji chords, for instance, or dissonant clusters<br>obtained by rapidly brushing groups of<br>strings--and a single player has got a<br>whole galaxy of microtonal sounds at<br>hi/r beck and call.<br>Harry called this instrument his "blank<br>canvas," and after playing it for a while it's<br>easy to see why.  He also mentioned that<br>placing the bridges was almost as much of <br>an art as playing the instrument--another <br>truism which becomes even clearer with<br>personal experience in sliding 37-odd <br>bridges around.<br>The Harmonic Canon is to my mind the most<br>impressive of Partch's instruments.  It's one<br>of the few that can't be approximated by a sampler<br>or a DX7.  To everyone who's interested in<br>composing acoustic xenharmonic music, my first<br>suggestion wuold be: build a Harmonic Canon I.<br>Costs less than $100, and it'll open your<br>ears to a new cosmos of xenharmonic<br>harmonies and melodies.<br>To construct one, follow the plans in Harry's<br>Genesis Of A Music--sans the bad design ideas.<br>N.B.: Harry's bad design ideas were 1) Using<br>guitar tuning gears; 2) using glued wooden<br>pegs to anchor the guitar strings on the<br>other pinblock; 3) sliding that wacky plexiglas<br>pitch-bender under the strings.<br>Instead of tacking triangular wooden tongues<br>onto the end of the left-hand pinblock and <br>then mounting guitar tuning gears on 'em,<br>just anchor 44 piano tuning pins directly in the<br>left-hand pinblock.  It works fine.  The problem<br>with the wooden tongues is that they will<br>inevitably crack under all the tension from<br>those 44 guitar strings--Harry himself had<br>to bolt metal supports under the wooden<br>tongues to keep 'em from splitting off<br>entirely.  Moreover, the guitar tuning gears<br>never stay in tune long.  So the blasted original<br>Partch-design Harmonic Canon was *always*<br>going out of tune during performances.<br>By contrast, our Harmonic Canon stays in<br>tuen for days at a time and can support<br>a much higher tension--thus the sound is<br>louder, and the plucked or struck guitar <br>strings will ring much  longer than Harry's <br>strings did.<br>Also: avoid the wooden pegs.  Bad idea.<br>Instead, use 1/4" machine screws on the <br>right-hand pinblock.  (Make sure both<br>pinblocks are hardened rock maple.) <br>Under the screws, settle 5/16" washers.<br>Between the screws and washers thread the<br>guitar string, and voila!  The brass loop end<br>of the guitar string will automatically catch<br>tight when you sink the screws with a screwdriver.<br>This was Bill Wesley's inspiration, and it's<br>infinitely simpler and less trouble-prone than<br>Partch's original design.<br>Q: What did Partch do when he went surfing?<br>A: He used to "hang eleven."<br>--mclaren<br><br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Fri, 2 Feb 1996 19:01 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id KAA16240; Fri, 2 Feb 1996 10:01:20 -0800<br>Date: Fri, 2 Feb 1996 10:01:20 -0800<br>Message-Id: <0099D528F3AA41A5.9363@ezh.nl><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2533 href="#2533">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>2/3/1996 2:42:50 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Xenharmonics on a broken<br> shoestring<br>---<br>While it's easy to gripe about the lack<br>of this or that sophisticated synthesis<br>algorithm on today's MIDI synths, it's<br>sobering to realize how far we've come.<br>In many ways we live in the golden age of<br>xenharmonics.<br>A whole lot of dirt cheap fully retunable<br>MIDI synthesizers are available used--and<br>most of 'em for a pittance.  For example,<br>the prospective microtonalist can today<br>grab a used TX81Z for about $250, or a<br>used VFX for about $600.  These are both<br>excellent synthesizers.  Add an antique DOS<br>286 machine, used, for another $200 or<br>so, tack on a DOS sequencing program<br>like Cakewalk or Texture, a cheap MIDI<br>interface, and you can do an astounding<br>amount of sophisticated microtonal<br>composition.<br>Move up to a Windows 386 machine (for<br>about $100 more) and a program like<br>Finale, and you've got the ability to<br>score and perform compositions of<br>a complexity unthinkable a few years<br>ago. You can record xenharmonic scores<br>that world-class ensembles would have<br>had to practice for 6 months to perform!<br>None of this was possible just 10 years<br>ago.<br>So much inexpensive high-quality<br>equipment has washed up in the USED<br>section of the classified ads today <br>and in the backs of cheapo guitar shops<br>that it's mind-boggling.<br>A look at a 1986 issue of "Keyboard" puts<br>the situation in focus--back then, analog<br>MIDI synths were the state of the art. <br>2,000 note sequencers running on the <br>Commodore 64 were considered "powerful."<br>The only affordable sampler was the Mirage,<br>and to detwelvulate *that*, you had to<br>buy an alternative operating system from<br>Dick Lord in New Hampshire.<br>Recently, US Snail brought me the latest tapes <br>by Warren Burt and Gary Morrison.  While both<br>of these composers have asked me not to <br>review their work in public, they probably<br>wouldn't mind my saying that their <br>latest work is excellent.  <br>And in both cases what's especially <br>impressive is how much they were able <br>to do with modest resources.<br>Gary Morrison, for instance, has an obsolete <br>68030-vintage Macintosh with a DAT<br>machine, a two-track Sound Tools setup,<br>and an Ensoniq ASR-10.  Yet he's been able<br>to simulate a very convincing orchestral<br>wind and percussion ensemble.<br>Warren Burt has an equally modest set-up.<br>An "obsolete" 286 DOS laptop, a MIDI<br>interface, a little A/D-D/A box that hooks<br>into the computer's parallel port (cost<br>$150, maximum stereo output rate 22.05<br>khz), the public-domain program US from<br>the U of Illinois, a commercial DOS sample<br>editor, the Buchla Lightning MIDI controller,<br>a Proteus I, a Roland SCC-1 Sound Canvas<br>sound card, and a couple of reverb and delay <br>boxes, along with an obsolete 13-bit EPS<br>sampler. (Still an *extremely* useful synth--<br>as I can testify, since I still use one myself!)<br>Yet with this modest setup--which wouldn't <br>even rate a sneer from a Keyboard or Electronic<br>Musician reviewer--Warren manages to tease<br>a kaleidoscope of interesting  music.  <br>His latest work ranges from digital musique<br>concrete, to algorithmic music which<br>uses William Sethares' idea of matching<br>partials to the microtonal tuning, to pastiches<br>which employ public-domain algorithmic composition<br>programs  processing musical material from<br>neoclassical composers in a 19-tone extension<br>of serialism.<br>This kind of fine work done with so-called "obsolete"<br>MIDI equipment should tell us something important.<br>In the end, you don't really need a DigiDesign TDM<br>48-track Power Mac system.  You don't really<br>need NeXTStep-486 running on an 80686 machine.<br>You don't really need a monster 16-bit sampler<br>with 64 or 128 megs or RAM.<br>This kind of bleeding-edge technology is nice--<br>but it's not *necessary* to produce good microtonal<br>music.<br>In the end, what matters most is imagination and <br>ingenuity.  My own computer music never uses<br>a sampling rate higher than 20 khz; and you<br>can do a surprising amount with a 20 or 30<br>khz sampling rate on a 13-bit 1 megaword <br>sampler like the EPS.   <br>Moreover, vintage synths like the 1986 <br>TX81Z or the 1989 VFX have so many features <br>that it's difficult to believe *anyone*<br>has come close to exhausting their sonic<br>potential, even though they've been in use for<br>years and years.<br>Beyond that, there remains the largely unexplored <br>option of combining live acoustic home-built <br>xenharmonic instruments with digital synths<br>in live and recorded performances.<br>For some reason, microtonalists have long faced off<br>into oposing groups: the "acoustic only!" camp<br>and the "digital only!" camp.  But why not mix<br>and match instruments of both kinds?<br>Why not combine *both* sound-worlds?  <br>This is a direction we in the Southern California<br>micorotnal group have been pursuing for years, <br>and it has so far proven fruitful.<br>Recently I finished building my own copy of a<br>Harry Partch-style harmonic canon I.<br>Essentially a monochord multiplied times 44,<br>with movable bridges for each string, the<br>instrument turned out to be much simpler<br>to construct than my forebodings indicated.<br>Best of all, it cost less than $100.<br>Yet with a harmonic canon  you can tune up<br>all the tetrachords listed in John Chalmers<br>magnum opus "Divisions of the Tetrachord"--<br>four or five at a time, simultaneously.<br>Or you can tune up a single tetrachord with<br>a variety of harmonizations.<br>You can also get Partch's 29-note, 37-note, 39-note,<br>41-note and 43-note just scales, or 43-tone<br>or 41-tone equal temperament.   Not to mention<br>multiple courses of strings with lesser divisions<br>of the octave.  The harmonic canon is  an<br>endlessly useful instrument--it sounds splendid,<br>yet it's easy to maintain (run emory cloth along<br>teh strings to get rid of rust once a week, and dust<br>and oil the wood) and almost trivial to <br>build.<br>Building my own megalyra has proven even<br>easier, and cost considerably less than $100.  <br>These instruments require no special carpentry<br>skills--even a duffer like myself can cut and <br>plane maple and pine planks, drill holes, and<br>screw in 44 piano pins.  Making a megalyra<br>is literally no more complex than drilling<br>11 pairs of holes, sinking 11 pairs of<br>piano pins, and winding tight 11 pairs of <br>piano strings across a piezoelectric pickup.<br>That's essentially all there is.  (Hint: get<br>used rusted piano pins from a piano repair<br>shop.  You can emory-cloth the rust off the<br>pins, and they work just fine. The only real<br>expense is the piezo pickup, the 11 piano<br>strings, and the piano tuning hammer.  Once<br>again, rusted used piano pins work fine.)<br>Anyone can build these simple xenharmonic<br>instruments, yet the resulting music<br>sounds impressive in live performance--<br>especially when combined with digital MIDI <br>synths and/or playback of computer-generated <br>soundfiles.<br>When I see the latest issue of Computer Music<br>Journal, I have to wonder: Why aren't these<br>people talking about "more is less" in computer<br>music?<br>As Warren Burt has pointed out, in the age of<br>downsizing, most of our incomes are dropping <br>even more rapidly than the price of computer <br>hardware--so getting the mostest out of the <br>leastest is a matter of real concern.  <br>It's also a fun challenge.  <br>So every time that latest, greatest new<br>synth beckons to me from the music shop<br>window, a little voice in the back of head <br>whispers: You still haven't used more than<br>1/10 of the capabilities of the equipment <br>you've already got!<br>Frankly, both Gary and Warren  would do us<br>a favor if they'd  post more about getting <br>"the mostest from the leastest."  <br>Like Ivor Darreg's, their work has produced <br>impressive results with very modest resources, <br>and we could all learn a thing or two from <br>these fine composers.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Sun, 4 Feb 1996 19:47 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id KAA23868; Sun, 4 Feb 1996 10:47:46 -0800<br>Date: Sun, 4 Feb 1996 10:47:46 -0800<br>Message-Id:  <9602041045.aa27022@cyber.cyber.net><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2534 href="#2534">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>2/4/1996 10:47:46 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: miscellany<br>---<br>Congratulations to Steven M. Miller, Harold Fortuin,<br>Matthew Puzan, Enrique Moreno and Neil Haverstick. <br>Even after a month, Neil's amazing MicroStock continues <br>to reverberate in the form of the recordings of the<br>concert.  A first-rate event.  Utterly superb!  <br>Way to go, Neil.<br>Steven M. Miller deserves kudos for reaching outside of <br>academia to solicit tapes for the U. of Santa Fe's upcoming<br>electronic music concert series.  In so doing, he discovered<br>a remarkable fact: some of the best music out there is<br>being done by ordinary schmucks with NO university<br>affiliation, NO resources, and NO predelection for<br>elaborate mathematics.<br>Congrats also to Harold Fortuin both for building a<br>xenharmonic generalized MIDI keyboard (see the Huyghens-<br>Fokkers 1994 Yearbook for more info). Any chance of<br>commercializing the widget?  <br>Good idea also to offer to exchange copies of your<br>music. <br>All too few forum subscribers seem to be interested<br>in making and sharing MUSIC, as opposed to words<br>about numbers about theories about words about<br>numbers about...<br>Especially praiseworthy: the scholarly labors of<br>Mssrs. Moreno and Puzan, whose theses promise a<br>comprehensive survey of xenharmonic incunabula.<br>Speaking of which--<br>Several articles touching on xenharmonics have<br>recently been published.  Of particular interest<br>is Contemporary Music Review, Vol. 10, 1994.<br>The issue is *entirely* devoted to "composition<br>with timbre."   As we all know, composing with<br>timbre is the gateway to non-12..  Thus this issue<br>is of inherent promise to xenharmonists.<br>Also of interest: "Musical Scales In Central Africa <br>and Java: Modelling by Synthesis," by Frederic Voisin,<br>Leonardo Music Journal, Vol. 4, 1994, pp. 85-90.<br>Voisin describes the results of a series of <br>experiments in which indigenous tuning experts<br>were allowed to tune up their own scales on<br>a DX7II: the process was recorded with a MIDI<br>sequencer, and the researchers returned after<br>several days in each case and asked the same<br>tuning expert to evaluate the tuning again (so<br>as to confirm the reliability of the results).<br>When the DX7II was tuned correctly, the researchers<br>report that the tuning expert and a group of<br>bystanders would spontaneously perform a piece<br>from their repertory.  <br>This methodology sounds like a significant advance<br>in ethnomusicology.  It's orders of magnitude<br>beyond the relatively useless previous practice<br>of asking the indigenous tuning expert a series<br>of questions--if the questions are phrased in<br>terms of Western European musical assumptions,<br>what possible use can the answers be?  It's as<br>though a bunch of Javanese music theorists came to<br>the U.S. and asked Western symphony orchestra<br>musicians: "What bem do you use?  And how<br>do you arrive at your rasa?"  The answers could<br>not possibly make sense.<br>And the previous practice of simply measuring<br>tunings in terms of cents and trying to fit them<br>into Western equal-tempered or ji tuning models<br>was also less than satisfactory. After all, a set of<br>measurements of native instruments does not<br>*by itself* tell us what the local tuning experts<br>were trying to achieve...while a digital record of the<br>tuning process *might just do that*<br>"Applying Psychoacoustics in Composition: 'Harmonic'<br>Progressions of 'Nonharmonic' Sonorities," by Richard<br>Parncutt and Hans Strasburger, in Perspectives of New<br>Music, Vol. 32, No. 1, 1995, is also likely to prove<br>interesting to the prospective xenharmonic composer.<br>Finally--finally!--music theorists are beginning to wake<br>up to the reality Plomp and Levelt revealed in 1965:<br>--An INharmonic series of vertical partials will sound<br>entirely transparent and consonant as long as the distance<br>between each successive partial is greater than the<br>critical bandwidth at that frequency.<br>While visionary composers like Jean-Claude Risset,<br>John Chowning, James Dashow and Jonathan Harvey<br>have long taken advantage of this psychoacoustic fact, <br>for just as many decades the music theorists have <br>ignored this reality.  <br>Parncutt & Strasberg's paper is thus a welcome addition<br>to the literature.  By basing their compositional theories<br>on Ernst Terhardt's model of hearing, they've gone<br>back to basics--to the way the human ear hears, rather<br>than abstract set theory, or partition functions, or<br>abstract algebra, or combinatorics, or matrix operations, <br>none of which has any necessary connection to what <br>the ear actually HEARS.<br>Among other praiseworthy ideas, P & S suggest:<br>"(i) the model takes as its starting point the spectrum of<br>a sonority, rather than its musical notation."  This is<br>a VITAL advance in music theory.  Now that arbitrarily<br>complex and inharmonic timbres can be generated by<br>computer, the composer needs to consider the implications<br>of timbre as well as such familiar concepts as root note,<br>voice-leading, the relationship twixt harmony and melody,<br>etc.<br>Moreover, P & S insure that "The model is not octave <br>generalized; it is based on pitch height...rather than pitch<br>class."  Another extremely important point.  Octaves<br>certainly have their uses, but many of us compose in<br>tunings without octaves.  Why ought we to be hamstrung<br>by  600-year-old dogmas obsessed with subdividing a<br>2:1 interval...which interval does not exist in many of <br>the tunings we happen to use?<br>P & S also point out many subtleties often unrecognized<br>by music theorists: for instance, the  psychoacoustic<br>effects produced by mistuned harmonics, etc. Listeners<br>still perceive substantially mistuned harmonics as<br>making a contribution to the formant--and so on.<br>P & S offer C code for an algorithm to evaluate vertical<br>sonorities according to their theory--something sure to<br>be useful to many xenharmonists who compose with timbre.<br>Alas, the article also suffers from a number of <br>omissions and oversights.<br>First and most important, P & S base their compositional<br>theory solely on Ernst Terhardt's theory of hearing.<br>Terhardt is a well-known psychoacoustician who's done<br>excellent work in the field.  However, Terhardt's theory<br>of hearing is merely one among many.  More: Tehardt is<br>a dyed-in-the-wool place theorist, and this tends to<br>bias some of his conclusions.  There is, for<br>example, *no* discussion in any of Terhardt's papers<br>of the contradictions and paradoxes bedeviling place<br>theory--for example, that measured jnd's substantially<br>exceed those predicted by the physics of the place<br>theory of hearing.  <br>Thus there is good reason to believe that the model of<br>hearing on which Parncutt & Strasberg have based their<br>compositional theory is incomplete, and does not explain<br>many important aspects of the human auditory system.<br>P & S also make statements which tend to mislead<br>the unwary reader: "The perception of the pitch of a <br>complex tone such as a musical tone (piano, violin, voice, <br>and so on) involves pattern recognition (Goldstein<br>1973, Terhardt 1972 and 1974)."  <br>In fact there is no consensus, nor yet any convincing<br>body of evidence, as to the exact processes  involved in <br>the perception of the pitch of a complex tone. While<br>Parncutt & Strasberg claim that musical perception<br>is a matter of "pattern recognition," in actual fact<br>this is merely one of three competing theories of<br>the way the ear/brains system operates.<br>The other theories are that the inner ear performs<br>a mechanical Fourier transform, and that the<br>auditory nerve running from the inner ear to the<br>brain extracts & encodes the underlying periodicity<br>of sound waves detected by the inner ear.<br>While there is some evidence in support of the<br>pattern recognition of hearing (first advanced<br>by Wightman, by the way--not Goldstein!),<br>there is also some evidence AGAINST the<br>pattern recognition theory of hearing.  There is<br>also a great deal of evidence FOR the other two<br>theories of hearing, none of which Parncutt &<br>Strsberg seem to be aware of.<br>On top of these lacunae, P & S proceed to collapse<br>their model down to 12 pitch-classes.  This is a<br>pretty low blow.  After much fine talk about freeing<br>the composer from octave equivalence, etc., they<br>wind up giving another recipe for producing pretty<br>sounds in 12-equal.<br>File that one under the category "The beatings were<br>scientifically designed to enhance creativity."<br>Lastly, P & S betray a profound lack of familiarity<br>with the microtonal and psychoacoustics literature.<br>Their bibliography is full of extremely glaring<br>gaps and omissions:  for instance, they omit completely<br>most of the CLASSIC articles on composing with inharmonic<br>sonorities:   John R. Pierce's letter "Attaining Consonance<br>in Arbitrary Scales," In JASA, 1966; Mathews' and Pierce's<br>"Control of Consonance and Dissonance With Nonharmonic<br>Overtones"  in "Music by Computers," ed. Beauchamp & Von <br>Foerster, 1969; Jean-Claude Risset's "Digital Experiments: <br>1964...." in Computer Music Journal, 1984; James Dashow's <br>"Spectra As Chords" in Comptuer Music Journal, 1980; <br>William Sethares' "Local Consonance and..."  in JASA, September<br>1992, my own "The Uses and Characterisics of Non-Just<br>Non-Equal-Tempered Scales" in Xenharmonikon 15, 1993,<br>and last (but not least!) Slaymaker, "Chords From Tones<br>Having Stretched Partials," JASA, 1970 and Geary, J. R., <br>"Consonance of Pairs of Inharmonic Tones," JASA, 1980.<br>If a nudnik like myself can rattle off this many obvious<br>references from memory, shouldn't Parncutt & Strasberg<br>have been able to do the half an hour or so of research <br>required by minimal standards of scholarships?  Ought <br>not these two distinguished researchers to have been able <br>to dredge up adequate citations for their article?<br>Such negligence bespeaks more than mere laziness; it<br>augurs a total lack of interest in looking outside their own<br>narrow little sphere of interest--namely, the theories<br>developed "by Ernst Terhardt and his colleauges at the <br>Institute of Electroacoustics, Technical University of <br>Munich."<br>Thus, while Parncutt & Strasberg's article is a promising<br>start, it falls short on many counts.  <br>Withal, still a worthwhile and useful article.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Mon, 5 Feb 1996 00:17 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id PAA29226; Sun, 4 Feb 1996 15:16:58 -0800<br>Date: Sun, 4 Feb 1996 15:16:58 -0800<br>Message-Id: <960204231257_71670.2576_HHB69-6@CompuServe.COM><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=3026 href="#3026">ðŸ”—</a>emoon@netvoyage.net (Eric Moon)</h3><span>6/7/1996 10:50:23 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>>>>>>This attitude is the natural consequence of a causal relationship<br>>>>>>where the great works are first and the theoretical interest<br>>afterwards.<br>>        It would seem equally natural, then, that there is no interest for<br>>a generalized practice of educating music students in<br>>the *how-to*s of some "exotic" intonation systems for which there is no<br>>significant corpus of real masterpieces.<<<<<<<br><br><br>To the extent that this is tru, it certainly underscores the irrelevance of<br>academia to the creative process.<br><br>However, I was "turned on to", if not educated in, microtonalism through my<br>university composition teacher.<br><br>Even in a purely historical context, it would be nice to see a broader<br>understanding  of the nature and use of pre-ET in the rennaissance and<br>baroque.  I am amazed at how few music students are aware of the existence<br>of anything but ET.<br><br><br><br><br>Eric Moon<br>Temiqui Music<br><br><br><br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Fri, 7 Jun 1996 21:13 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id MAA16266; Fri, 7 Jun 1996 12:13:20 -0700<br>Date: Fri, 7 Jun 1996 12:13:20 -0700<br>Message-Id: <v01520d00addc9d3a3b2b@[199.212.63.117]><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=3829 href="#3829">ðŸ”—</a>&#x22;Jonathan M. Szanto&#x22; &#x3C;jszanto@adnc.com&#x3E;</h3><span>10/25/1996 12:28:10 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>Buddies,<br><br>Since I have been lurking, a couple of comments came together to get me<br>babbling again, and they be:<br><br>>and boy, this list is sort of dull lately...too much polite math<br>>talk...we need a good controversy to get things rolling...Hstick<br><br>.. followed closely by ...<br><br>>Or perhaps people don't use ANY notation if they can avoid it. Those of <br>>us who use non-realtime instruments might need some sort of chart or <br>>table to help in making a piece, but a detailed score seems superfluous. <br>>Of course, the situation may be different where performers are involved <br>>but I find it a tremendous relief not to have to bother with it.<br>><br>>Paul Turner <br><br>Seems to me that the last few weeks have been looking as if sponsored by the<br>old HP Calculators.  Question in general: being that most all involved here<br>are interested in tuning alternatives to 12TET, and sounds like most wish<br>that more people could experience the lovely/ugly/amazing worlds that these<br>intonations open up, wouldn't we all be forwarding the cause if more music<br>were created that *involved* people, rather than spanking the<br>software-monkey another time?<br><br>I know the pleasures myself of having the control of every note and nuance,<br>or letting an algorithm do it's thing.  Nonetheless, and cognizant of the<br>wonderful pieces that have been done in 'non-realtime', does any of it<br>compare to the community experience of, say, playing in a gamelan?  And<br>doesn't Paul's last bit, "the situation may be different where performers<br>are involved but I find it a tremendous relief not to have to bother with<br>it" read almost like "bother with them" (i.e., live musicians performing the<br>work)?<br><br>[NOTE: apparently the PC police have been attempting to control the terms<br>here on the tuning list, too: is it non-12TET? allotonal? microtonal?<br>xenharmonic? what???]<br><br>Given the choice of *doing* intonational music or *having it done to me*, I<br>know which I would choose, and it is the same one that I propose would be<br>most, um, beneficially nurturing to a larger audience and/or new performers.<br><br>..or something like that.  Gad, it's true: Neil H. and I are twin<br>love-children of Elvis and Nadia Boulanger!<br><br>Cheers,<br>Jon<br><br>PS: What I find lacking in the list of late are the laconic and luxurious<br>linguistics of G. Taylor, but maybe that's just me...<br>*--------------------------------------------------------------------*<br>   Jonathan M. Szanto   | If spirits can live online . . . . . . . . .<br> Backbeats & Interrupts |  . . . then Harry lives in Corporeal Meadows<br>   jszanto@adnc.com     | http://www.adnc.com/web/jszanto/welcome.html<br>*--------------------------------------------------------------------*<br><br><br>Received: from ns.ezh.nl [137.174.112.59] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Fri, 25 Oct 1996 14:56 +0200<br>Received: by ns.ezh.nl; (5.65v3.2/1.3/10May95) id AA08319; Fri, 25 Oct 1996 14:57:58 +0200<br>Received: from eartha.mills.edu by ns (smtpxd); id XA08303<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <manuel.op.de.coul@ezh.nl> id FAA06190; Fri, 25 Oct 1996 05:57:55 -0700<br>Date: Fri, 25 Oct 1996 05:57:55 -0700<br>Message-Id: <Pine.SOL.3.91.961025084918.13216A-100000@minerva.cis.yale.edu><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=3925 href="#3925">ðŸ”—</a>bte@MIT.EDU</h3><span>11/4/1996 10:15:39 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>i'm looking for a chinese musical scale in cents,<br>if anyone knows one :)<br><br>thanks.<br><br>Ben Erwin<br><br><br><br><br>--<-@--<-@--<-@--<-@--<-@--<-@--<-@--<-@--<-@--<-@<br>it is then unconditional positive regard or love which releases<br>the infinite potential of creativity.<br>					- Paul W. Dixon<br><br><br><br><br>Received: from ns.ezh.nl [137.174.112.59] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Tue, 5 Nov 1996 07:16 +0100<br>Received: by ns.ezh.nl; (5.65v3.2/1.3/10May95) id AA00495; Mon, 4 Nov 1996 03:27:31 +0100<br>Received: from eartha.mills.edu by ns (smtpxd); id XA00493<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <manuel.op.de.coul@ezh.nl> id SAA15377; Sun, 3 Nov 1996 18:27:29 -0800<br>Date: Sun, 3 Nov 1996 18:27:29 -0800<br>Message-Id: <v03007800aea30e5fd6fc@[130.132.159.42]><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=4467 href="#4467">ðŸ”—</a>Manuel.Op.de.Coul@ezh.nl (Manuel Op de Coul)</h3><span>1/2/1997 9:08:17 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>Gary says:<br>>    Manuel refuted my claim that there is not historical precedent for<br>> "pure" being synonymous with "just", refering to small-whole-number-ratio<br>> (SWNR) pitch relationships.  (Or more specifically, I claimed only that I<br>> did not no of any such precedent.)  <br><br>Ok, I was merely saying that the connotation of "pure" has a meaning in<br>tuning theory. Maybe I misread your statement in that.<br><br>> Adding a new definition to the synonym stew only risks novices thinking<br>> that the two mean two subtly different things.  <br><br>Hmm, I don't see that. Many words have an inherently vague meaning, <br>including "pure". If you take every word literally, life would become<br>difficult.<br><br>>    So I personally think that we ought to accept the hand of vocabulary<br>> cards the English language deals us whenever possible.  <br><br>Languages are constantly changing. It happens all the time that words get<br>new meanings, sometimes they even get the opposite meaning of what they had.<br><br>Manuel Op de Coul    coul@ezh.nl<br><br>Received: from ns.ezh.nl [137.174.112.59] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Thu, 2 Jan 1997 18:36 +0100<br>Received: by ns.ezh.nl; (5.65v3.2/1.3/10May95) id AA00768; Thu, 2 Jan 1997 18:38:59 +0100<br>Received: from eartha.mills.edu by ns (smtpxd); id XA00766<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <manuel.op.de.coul@ezh.nl> id JAA07064; Thu, 2 Jan 1997 09:38:56 -0800<br>Date: Thu, 2 Jan 1997 09:38:56 -0800<br>Message-Id: <62970102173726/0005695065PK2EM@MCIMAIL.COM><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=4555 href="#4555">ðŸ”—</a>Heikki Jamsa &#x3C;hjamsa@raita.oulu.fi&#x3E;</h3><span>1/7/1997 2:12:07 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>>From: William Sethares <sethares@eceserv0.ece.wisc.edu><br>>To: tuning<br>>Subject: stretching of strings<br><br>>A couple of days ago, someone asked <br>>how close to harmonic real strings are.<br>>One early article that addressed this is<br><br>>Young shows that the partials of piano wire are <br>>``stretched" by a factor of about 1.0013, which is <br>>about 2 cents per octave. <br><br>>-Bill Sethares<br><br>Mathematical formula is in small amplitudes<br><br>   f a ( n + k n^2 ) / ( 1 + k )<br><br>where<br>f is frequenz of n:th partial,<br>a is frequenz of grundtone, i.e 1:st partial,<br>n is integer, number of partial,<br>k is small constant, it depends from stiffness, tension and mass of<br>the string.<br><br>Heikki Jamsa<br><br><br><br><br>Received: from ns.ezh.nl [137.174.112.59] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Wed, 8 Jan 1997 02:39 +0100<br>Received: by ns.ezh.nl; (5.65v3.2/1.3/10May95) id AA19476; Wed, 8 Jan 1997 02:42:04 +0100<br>Received: from eartha.mills.edu by ns (smtpxd); id XA19474<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <manuel.op.de.coul@ezh.nl> id RAA23110; Tue, 7 Jan 1997 17:42:00 -0800<br>Date: Tue, 7 Jan 1997 17:42:00 -0800<br>Message-Id: <199701072039_MC1-E45-7C84@compuserve.com><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=4563 href="#4563">ðŸ”—</a>Heikki Jamsa &#x3C;hjamsa@raita.oulu.fi&#x3E;</h3><span>1/8/1997 12:56:36 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>>From: Gary Morrison <71670.2576@compuserve.com><br><br>>> Yes, 41 is simplest, but 53 system is much better. Fifts are even better,<br>>> and thirds are much better than in 41 system.<br><br>>   That's certainly true for the traditional thirds, but 41 fits 9:7 and<br>>7:6 better, although only slightly better.  41 is however significantly<br>>better at the 11:9 neutral third.  Then again, 11:9 isn't 9-limit of<br>>course.  <br><br>So we see, that in 9-limit 53 system is better.<br><br>Heikki Jamsa<br><br><br><br><br><br><br>Received: from ns.ezh.nl [137.174.112.59] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Thu, 9 Jan 1997 18:05 +0100<br>Received: by ns.ezh.nl; (5.65v3.2/1.3/10May95) id AA12433; Thu, 9 Jan 1997 18:08:45 +0100<br>Received: from eartha.mills.edu by ns (smtpxd); id XA12436<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <manuel.op.de.coul@ezh.nl> id JAA03966; Thu, 9 Jan 1997 09:08:42 -0800<br>Date: Thu, 9 Jan 1997 09:08:42 -0800<br>Message-Id: <32970109170523/0005695065PK2EM@MCIMAIL.COM><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=4617 href="#4617">ðŸ”—</a>Judith.Parkinson@anu.edu.au (Judith Parkinson)</h3><span>1/15/1997 4:22:35 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>I would like to unsubscribe. How do I do it?<br><br><br><br>Received: from ns.ezh.nl [137.174.112.59] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Thu, 16 Jan 1997 16:48 +0100<br>Received: by ns.ezh.nl; (5.65v3.2/1.3/10May95) id AA12870; Thu, 16 Jan 1997 16:51:54 +0100<br>Received: from eartha.mills.edu by ns (smtpxd); id XA12932<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <manuel.op.de.coul@ezh.nl> id HAA26757; Thu, 16 Jan 1997 07:51:52 -0800<br>Date: Thu, 16 Jan 1997 07:51:52 -0800<br>Message-Id: <52970116154525/0005695065PK1EM@MCIMAIL.COM><br>Errors-To: madole@mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=8982 href="#8982">ðŸ”—</a>From:&#x9;iann@inch.com (Ian Nagoski)</h3><span>12/30/1996 9:03:39 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>Hey, David - Would you do me a big favor and post this to the tuning list?<br>Thanks!<br><br>MELA Foundation Inc.    275 Church Street New York, NY 10013      <br>212-925-8270<br><br>January 1997<br><br>Mela Foundation is seeking interns for unpaid volunteer positions <br>of Monitor for Dream House exhibition.<br><br>Dream House: Seven Years of Sound and Light, a collaborative <br>Sound and Light Environment by composer La Monte Young and <br>visual artist Marian Zazeela, is presented in an extended exhibition <br>at MELA Foundation, 275 Church Street, 3rd Floor.  Young and <br>Zazeela characterize the Sound and Light Environment<br>as a "time installation measured by a setting of continuous <br>frequencies in sound and light."<br><br>POSITION: MONITOR for DREAM HOUSE exhibition <br>(Volunteer Interns)<br><br>Hours:  Exhibition is open Thursdays and Saturdays from 2:00 <br>PM to Midnight. Time slots of four to six hours need to be filled <br>on those days.<br><br>Description:  Monitor will open or close exhibition; turn on <br>electronic sound equiptment and turn up light environment; <br>make sure all technical equiptment is running properly; greet <br>visitors; distribute information; answer questions concerning <br>the environment; sell books and recordings.<br><br>Contact:  Call Ian Nagoski, MELA Foundation, 212-925-8270, <br>or email at iann@inch.com.  If you call, leave a message on the <br>answering machine with your phone number and times we can <br>reach you.  Or come to 275 Church Street, 3rd Floor, Thursdays <br>and Saturdays, 2:00 PM to Midnight, and experience the environment <br>and speak to the monitor on duty.<br><br>Press Commentary on Exhibition:<br><br>"... the multifaceted form of the 35-frequency construction of Young's<br>current installation is the principal reason it changes hallucinogenically<br>with every shift in perspective and why the tones freeze in place as long as<br>one is perfectly still while the slightest gesture will startle forth<br>unnamable, wildly plumed melodies from the luxuriant harmonic foliage.<br>Zazeela's light sculptures have invariably, teasingly refused to surrender<br>their entire secret to photographic reprodution, so much do they depend on<br>the retinal impact of activated photons in real time and so much do they<br>exploit, in ways analagous to Young's techniques, the creation of visual<br>combination tones and an accumulation of after-images."<br>            -- Sandy McCroskey, 1/1, The Journal of the Just Intonation<br>Network<br><br>"Young's newest sine-tone sculpture shimmers and swirls as you walk <br>around the room and, amazingly, when you freeze, it does too.  <br>Stay at least long enough to stare at Zazeela's Imagic Light and <br>Ruine Window, which will imprint your retina with blues and <br>purples you haven't felt before."<br>                                                -- Kyle Gann, The Village<br>Voice<br><br>"The visitor with an acute ear can actually 'play' the room like an<br>instrument: explore the sound close to the wall, close to the floor, <br>in the corner, or just standing still.  Or lie on the floor and allow <br>the sound to float you into heaven, slide you into hell, or transport <br>you wherever you want to go.  See if you agree with those who <br>call Young's sound sculpture a precursor of ambient music.<br>Zazeela's light installation, "Imagic Light," offers an intriuging<br>complement to the sound, even though it is equally effective when <br>viewed in silence.  Using pairs of colored lights and suspended <br>aluminum mobiles cut out in calligraphic shapes, Zazeela explores <br>the relationship between object and shadow, making the tangible <br>intangible, and vice versa.  Enjoy the installation for its <br>mesmerizing beauty, or try to analyze how the different colors <br>are achieved, how the mobiles create the resulting shadows, or<br>perspective the infinite number of symmetrical patterns in the room."<br>                                                    -- David Farneth,<br>Metrobeat<br><br>Music                  Eternal                    Light<br>Art <br><br>-------------------------------------------<END>------------------------------<br>--------<br><br>Received: from ns.ezh.nl [137.174.112.59] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Wed, 1 Jan 1997 05:55 +0100<br>Received: by ns.ezh.nl; (5.65v3.2/1.3/10May95) id AA06186; Wed, 1 Jan 1997 05:58:17 +0100<br>Received: from eartha.mills.edu by ns (smtpxd); id XA06079<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <manuel.op.de.coul@ezh.nl> id UAA21343; Tue, 31 Dec 1996 20:58:06 -0800<br>Date: Tue, 31 Dec 1996 20:58:06 -0800<br>Message-Id: <970101045521_75023.2426_GHJ56-1@CompuServe.COM><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><a href="/old-tuning-list">back to list</a><h1>Posts from Brian McLaren</h1><h3><a id=2036 href="#2036">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>9/23/1995 8:36:56 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>I will be uploading one of a new set of messages from<br>Brian McLaren per day for the next few weeks. At his request, I will <br>not title them in the Subject line. (My own posts will have titles<br>so they can be distinguished from his, though I imagine content and <br>tone will be sufficient indications of authorship. )<br>	Also, I do not have time at the present to edit or reformat<br>them. So, read'em at your own risk. :-).<br>	 As Brian does not have a telephone or email, any comments or<br>questions that need a quick answer should be sent to him by US mail, <br>though I do send him the accumulated Tuning Digests on a disk about <br>once a month. His US mail address is the following:<br> <br>	Brian McLaren  <br>	2462 S.E. Micah Place<br>	Corvallis, OR 97333-1966-17 <br>	USA <br> <br>(Note the non-standard ZIP code. OR is the state of Oregon.)<br> <br>--John<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Sat, 23 Sep 1995 17:40 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id IAA02819; Sat, 23 Sep 1995 08:39:53 -0700<br>Date: Sat, 23 Sep 1995 08:39:53 -0700<br>Message-Id:  <9509230839.aa04145@cyber.cyber.net><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2038 href="#2038">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>9/24/1995 9:55:13 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Tuning & Psychoacoustics - Post 1 of 25<br>---<br>The rules of Western harmony, to paraphrase<br>Voltaire, are a lie commonly agreed upon.<br>Ultimately, the music we choose to make <br>is limited (or liberated) by our understanding <br>of what our ears hear, and how. <br>Over the course of more than a year various<br>forum subscribers  have treated us to<br>a Mount Everest of misinformation about<br>what the ear hears, how the brain interprets it,<br>and how sounds change during the complex and<br>surprising process we call listening.<br>These fairy tales and "just so" stories about hearing<br>and the ear are common currency.  They are<br>the misinformation about the ear/brain system<br>that "everyone knows."   And, like giant<br>alligators in the sewers and detectives<br>photographing an image of a murderer in a <br>corpse's pupils, these  tall tales  never seem <br>to go away.<br>This post is the first of a series which <br>will examine the evidence about what<br>the ear actually hears and how.  These posts<br>will discuss some of the *facts* of the <br>ear/brain system, as opposed to the <br>fantasies and  canards that<br>"everyone knows are true."<br>---<br>First, it's important to understand that<br>some subscribers will react violently to this<br>series of posts.  <br>Many composers, musicians and<br>performers will angrily attempt to refute the<br>facts listed here. These violent reactions <br>will arise partly out of surprise, partly from<br>an unwillingness to relinquish long-held <br>beliefs, and partly because the facts of the <br>ear/brain system are not yet widely known <br>outside the realm of psychoacoustics and <br>psychophysics.  In fact, the majority of<br>today's composers and music theorists <br>exist in a blissful state of ignorance<br>about the ear/brain system--a state similar<br>to that which characterized clerics in the days<br>when Galileo first pointed his telescope<br>at the moon.  Back then, "everyone knew"<br>that the stars were fixed in Aristotle's<br>crystal spheres; "everyone knew" that the<br>moon and sun belonged to a celestial<br>sphere unchanging and perfect; "everyone<br>knew" that the planets rotated around the<br>earth, and that no satellites circled (say)<br>Jupiter or Saturn; "everyone knew" that<br>Aristotle was the beginning and the end<br>of all knowledge, and "everyone knew"<br>that there remained only the tiniest <br>crumbs of knowledge yet to be gleaned <br>about a universe which was perfectly<br>ordered, perfectly simple, and--<br>by and large--perfectly understood.<br>---<br>When Galileo turned his lens to the <br>moon and discovered that it had<br>mountains, and when he observed<br>satellites around Jupiter, and when<br>he saw new stars in the sky, <br>he was called, alternately, "ignorant,"<br>"a charlatan," "an imposter,"  "well-<br>meaning but ignorant of Aristotle's<br>teachings," "too stupid to properly<br>interperet what he saw through<br>his telescope," and so on.<br>Many of the best-educated men and<br>women of Galileo's time refused<br>to look through his telescope at the<br>sky, because they *knew* that <br>his claims could not possibly be<br>true.<br>It's sadly easy to deduce that all of<br>the above antics will be duplicated<br>in the course of this or that subscriber's<br>reaction to this series of posts.<br>---<br>This sounds shocking.  It is.  In saying<br>this, I assert that most musicians and<br>composers today are ignorant of how<br>the ear hears and how the brain interprets<br>sound.  More: I assert that they are not<br>only ignorant, but actively and perversely<br>misinformed.  Lastly, I assert that much<br>of this misinformation hampers the<br>progress of music and interferes with<br>our ability even to conceive new<br>universes of harmony and melody.  <br>What we cannot perceive, we cannot<br>explore; and when we cannot explore,<br>we stagnate.  <br>Much of the myth and fantasy which fills<br>musicians' heads is promulgated by<br>so-called "modern" academia using<br>so-called "modern" music theory<br>textbooks (the content of which actually<br>hails from the 17th, 18th and 19th<br>centuries).<br>The next post will present some of<br>the surprising  characteristics of the ear/<br>brain system, and some recommendations<br>for references.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Mon, 25 Sep 1995 01:56 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id QAA13589; Sun, 24 Sep 1995 16:56:38 -0700<br>Date: Sun, 24 Sep 1995 16:56:38 -0700<br>Message-Id: <950924235355_71670.2576_HHB53-1@CompuServe.COM><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2046 href="#2046">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>9/25/1995 8:19:24 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Tuning & psychoacoustics - post 2 of 25<br>---<br>Many and strange are the myths which<br>afflict so-called "modern" music theory,<br>particularly when it comes to the operation<br>of the human ear.<br>Most of these tall tales have been handed<br>down to present-day musicians from the 19th<br>century, although some of the myths date <br>from much earlier--as early as the number<br>mysticism of Pythagoras, the Babylonians,<br>the Egyptians, and of Hindu astrology.<br>Shockingly, typical "modern" music theory<br>texts cite Helmholtz, Rameau and Mersenne<br>as the sole authorities on acoustics and <br>psychoacoustics--or they cite other <br>"modern" music theory texts which cite<br>only these musty & antique sources.  <br>This is comparable to a "modern" science<br>text citing Lagrange, Hamilton and<br>Newton as authorities on the nature of<br>subatomic physics.   A physics professor<br>who wrote such a book would be laughed <br>out the profession--but for some reason<br>this practice is acceptable in music.<br>Together, this antique trove of musical<br>old wives' tales and acoustic "just-so stories" <br>constitutes a body of misinformation<br>which has been handed down through <br>textbooks which thoughtlessly draw on<br>older textbooks, until the chain of<br>errors reaches back through 3 centuries<br>or more.<br>Partch has illuminated a few links in this<br>monumental chain of fabulation and<br>compounded error, but the amount of<br>misinformation is far larger than<br>even he could ever have suspected.<br>---<br>Every statement presented in this series <br>of posts as fact will be supported<br>as far as possible by references from <br>the scientific literature.  When subscribers<br>to this forum violently attack these<br>posts--as no doubt they will--the interested reader <br>is  advised not to rely on *my* bare assertions<br>*or* the unsupported claims of those <br>who say "it's [a lie/ignorant/wrong, etc]"<br>Rather, the interested reader is<br>advised to go to the original reference<br>sources. Read them. Search out the audio<br>tapes & CDs specified below. Listen to them. <br>And finally: perform your<br>own experiments with Csound or a<br>synthesizer, using your own ears and<br>a computer.<br>This last point is *crucial.*<br>You will need to perform true double-<br>blind tests on your own hearing to<br>obtain valid conclusions.  If you concoct<br>a set of test tones and listen to them<br>*knowing* what they are, your ears<br>will lie to you and you will literally<br>not be able to hear the test tones<br>and acoustic examples objectively.<br>Only by using a true double-blind<br>procedure can you reliably ascertain<br>what your ears *actually* hear, as opposed<br>to what you *think* you're hearing.<br>This is why the most common<br>objection to the facts of modern<br>psychoacoustics--"I don't hear it that <br>way!"--is utterly meaningless.  Without<br>A-B-X double-blind tests, none of you<br>can tell what intervals you prefer (nor <br>can I) because the knowledge of what you<br>*think* you're listening to and what<br>you *expect* to hear  contaminates<br>and alters what you hear.  <br>---<br>This point is so important that it is<br>worth an example: <br>"The extent to which observers can persist<br>in the same error of observation was shown<br>to me by the following experiment. High-fidelity<br>fans complained about the nonlinear distortion<br>in a certain sound-transmission system. To test<br>the maximal distortion these listeners would<br>tolerate, an induction coil was made with an iron<br>core that was highly overloaded and produced<br>nonlinear hysteresis distortion.  A second coil<br>containing no iron was combined with the first<br>in such a way that only the pure distortion remained.<br>Musicians were delighed with this system, which<br>made tenors' voices sound metallic and heightened <br>the dynamics of the orchestra.  Their adjustments of<br>the system to optimal sound had about 70% pure iron<br>distortion." [von Bekesy, G., "Hearing Theories and <br>Complex Sounds," Journ. Acoust. Soc. Am, 35(4), <br>April 1963, pg. 589]<br>Without an objective reference and<br>an independent means of measurement,<br>*we do not know what we hear.*<br>Over the course of this series of posts,<br>it will become clear that the ear sometimes<br>adds to, sometimes subtracts from, and<br>always changes the information that<br>enters  our auditory system as <br>sound waves.  <br>For example: <br>[1] Highly trained symphony orchestra<br>musicians reglarly perform intervals as <br>small as 683 cents and as wide as 725 cents,<br>yet hear them  as "perfect fifths;"<br>["Some Aspects of Perception - I," Shackford,<br>Journ. Mus. Theory, Vol. 5, 1961, pp. 13-26]<br>[2] So-called "perfect" intervals, including<br>the octave and 3/2, can sound dissonant<br>or consonant depending on the range in<br>which they sound, even if they use<br>harmonic-series timbres; ["The Science<br>of Musical Sound," Sundberg, 1992, pg. 73]<br>[3] Pitches transposed up an octave can<br>be heard by musically trained listeners<br>as dropping slightly in pitch; ["The Science<br>Of Musical Sounds," Pierce, 1992, pg.  214]<br>[4] Tones of specific pitch can be heard<br>by musically trained listeners when in<br>fact no tones are physically present; and<br>tones can disappear and become inaudible<br>to the ear/brain system even though <br>they're presented to the ear at high<br>amplitude; ["Psychoacoustics: Facts and<br>Models," Zwicker & Fastl, 1993, pp. 91-135;<br>"The Perception of Musical Tones," Rasch<br>and Plomp, pp. 1-21, in "The Psychology<br>of Music," ed. Diana Deutsch, 1982; "The<br>Science of Musical Sounds," Sundberg,<br>pp. 48-86.]<br>[5] The ear/brain system can generate<br>audible illusions which convince the<br>listener that s/he is hearing paradoxical <br>and impossible sounds--sounds which<br>simultaneously speed up and slow down,<br>for instance, or sounds which simultaneously<br>rise and fall in pitch; or sounds which<br>rise endlessly in pitch, or fall endlessly<br>in pitch; ["The Science of Musical Sounds,"<br>Pierce, pg. 215; "Structural Representations<br>of Musical Pitch," Shepard, in "The <br>Psychology of Music," Ed. Diana Deutsch,<br>1982, pp. 334-373.]<br>[6] There is a universal human craving for<br>stretched intervals, which leads highly<br>trained musicians to perform so-called<br>"perfect" intervals consistently wider<br>than the ratios by which "everyone knows" <br>these intervals are defined; ["The Science<br>of Musical Sound," Sundberg, pp. 104-105,<br>"Introduction to The Physics and <br>Psychophyics of Music," Roederer, pg. 155]<br>[7] The ear/brain system detects pitch<br>in a complex way still not fully understood, <br>with the result that the pitch of a complex<br>sounds is perceived to change with<br>the loudness of the sound, the amount<br>and onset of noise masking the sound,<br>the type other harmonic sound played<br>simultaneously, the degree of harmonicity<br>of the partials in the sound, the length<br>of the sound being played, the spectral<br>centroid of the sound, and the suddeness<br>of onset of the sound; ["Experiments<br>On Tone Sensation," Plomp, pp. 127-129;<br>"Introduction to the Physics and <br>Psychophyics of Music," Roederer, pg.<br>135; "Perception of Timbral Analogies,"<br>Wessel & Ehresman, Rapports IRCAM 1978,<br>pp. 1-29, Pickles, James O., "An Introduction<br>to the Physiology of Hearing," Academic Press,<br>1988, pp. 270 ff., etc.]<br>[8] Many of the inner workings of the<br>ear/brain system are still unknown, and<br>each of the conflicting theories of how<br>the ear/brain system hears is supported<br>by some psychoacoustic evidence, but<br>contradicted by the rest.<br>["Experiments On Tones Sensation," Plomp,<br>pp. 49-52; "The Science of Musical<br>Sound," Sundberg, pp. 100, 186; "The Science<br>of Musical Sounds," Pierce, pp. 101, 113-114;<br>"Rapports IRCAM - Musical Acoustics,"<br>Risset, 1978, pg. 8; "Introduction To the<br>Physics and Psychophysics of Music,"<br>Roederer, 1973, pp. 130-133]<br>---<br>All of which points to the conclusion that<br> the ear/brain system is *complex.*<br>There is no simple explanation for how we<br>hear.  The ear/brain system generates<br>false information, destroys some of<br>what comes into our ears, and transforms<br>all of it, either subtly or grossly.<br>Yet the single common thread that will run<br>through all the so-called "rebuttals" and<br>attacks on this series of posts will be:<br>THE EAR IS SIMPLE. "Helmholtz explained it<br>all," one person will yelp, while others will<br>screech "Terhardt explained it all," or "Backus'<br>book tells you everything you need to know!"<br>The interested reader is advised, again,<br>not to believe me *or* to believe those who<br>attempt to rebut me.  Rather, the interested<br>reader is advised to *study the psychoacoustic<br>literature,* excerpts of which and references<br>from which will be listed extensively in every<br>post.<br>Only by doing this can the objective reader<br>get a real sense of the extraordinary complexity<br>of human hearing, and the self-evident <br>falsity of claims that "the ear is simple"<br>and "Helmholtz explained it all in 1863,"<br>and "my 1939-vintage references don't say that."<br>Do not lend your credence thoughtlessly to<br>*any* statement without *testing for yourself*<br>the evidence (or lack thereof) for that<br>statement. Wisdom does not arise from<br>credulity, but from doubt.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Mon, 25 Sep 1995 17:21 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id IAA21245; Mon, 25 Sep 1995 08:21:28 -0700<br>Date: Mon, 25 Sep 1995 08:21:28 -0700<br>Message-Id: <Pine.3.89.9509251025.A18905-0100000@styx.ios.com><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2054 href="#2054">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>9/26/1995 10:34:05 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Tuning & psychoacoustics - Post 3 of 25<br>---<br>The psychoacoustic literature overwhelmingly points to the conclusion that, <br>first and foremost, the ear/brain system is *complex.*<br>There is no one simple explanation for how we hear.  The ear/brain system <br>generates false information, throws away some of the sound waves <br>physically received by the ear, and transforms the rest, either subtly or <br>grossly, in the process first of encoding the physical rarefactions and <br>compressions of air into neural impulses, and subsequently processing the <br>neural information in higher brain centers.<br>While the physical process by which the organ of Corti responds to incoming <br>sound waves and the impulses produced in the auditory nerve are known facts,  the arguments among various investigators arise from the *interpretations* of these facts. Some psychoacoustic <br>researchers claim a primary role for the physical acoustic transduction of <br> others claim that the operation of higher brain functions on the encoded nerve impulses is most important (the theory of tuning as a  learned response). <br>Because of the extraordinary variation in reliability and competence among <br>the various authors of psychoacoustic texts over the last century, and <br>because of the rapid progress in the field (which has rendered many earlier <br>texts obsolete), the interested reader is advised *not* to unquestioningly <br>believe *any* references dated earlier than 1970.<br>Rather, the reader is advised to *study as much of the <br>psychoacoustic literature as possible*, excerpts of which and references to <br>which are listen extensively in this article.<br>Only in this way can the objective reader get a real sense of the <br>extraordinary complexity of human hearing, and the provable falsity of <br>claims that "the ear is simple," "Helmholtz explained it all," or "so-and-so's <br>book on musical acoustics written in the 1950s tells us everything we need <br>to know about human hearing."<br>Reading is not enough.  Since the subject is what we hear and how, the <br>reader must also listen and make up hi/r own mind.<br>After perusing this post, the reader is strongly advised to listen to the <br>following tapes/CDs and study the following references: <br>[1] "Auditory Perception: An Audio Training Course," by F. Alton Everest. This <br>is the best single audio-tape set of examples of classic experiments  <br>demonstrating the complexity of the hearing process. At $159 this 104-page <br>manual and 4 audio cassette set isn't cheap. However, if you read the manual <br>and listen to the tapes, you'll quickly learn the basics of how we *actually* <br>hear (as opposed to how most musical theory textbooks and all too many <br>outdated acoustics and psychology texts *claim* we hear).<br>[2] "The Science of Musical Sound," by John R. Pierce, 2nd edition, 1992, with <br>accompanying audio cassette, covers the simplest elements of <br>psychoacoustics.<br>The cassette is useful for elementary phenomena--binaural beats, <br>"streaming," the critical band, consonance of simple vs. complex tones, etc., <br>but it cannot subsitute for Everest's far more complete set of <br>demonstrations.<br>[3] Houstma, Rossing and Wagenaars, 1987, "Auditory Demonstrations," <br>Philips 1126-061. An 80-track CD compendium of psychoacoustic <br>demonstrations of many psychoacoustic phenomena.<br>[4] Mathews, ed., "Sound Examples: Current Directions In Computer Music," <br>MIT Press, 1989.  A disc with a wider range of synthesized psychoacoustic <br>examples than the original cassette companion [2] above. <br>[5]  "Introduction To the Physics and Psychophysics of Music," 2nd ed. 1973 <br>and 3rd ed. 1995 by Juan Roederer contains one of the best general <br>discussions of the psychoacoustic literature up to that time (1973).  <br>Roederer covers a wide range of surprising characteristics of the ear/brain <br>system which are entirely ignored by less complete, and sometimes <br>completely misinformed or out-of-date texts published around the same <br>period.  <br>[6] "The Science of Music Sounds" by Johan Sundberg (1992) is one of the <br>best general references on modern psychoacoustics to date. It contains more <br>up-to-date citations than any text other than Zwicker and Fastl, and it <br>quotes a wider ranger range of sources than any other text but Sundberg <br>(1992) and Deutsch (1982).<br>[7] "The Psychology of Music," ed. Diana Deutsch, 1982, contains an excellent <br>cross-section of definitive summaries of various psychoacoustic phenomena <br>by the leaders in the field.<br>[8] "Psychoacoustics: Facts and Models," by Zwicker and Fastly, 1993, is the <br>best in-depth discussion of experimental psychoacoustics. It does not <br>discuss the various theoretical models of the ear/brain system and does not <br>cover streaming, nor does it consider the musical implications of <br>psychoacoustics.  Within its limits, however, it's the best reference on the <br>experimental side of the field for the specialist.<br>[9] "Audition" by Pierre Buser and Michael Imbert (translated by R.H. Kay), <br>1995, is the most detailed book on the physical structure of the ear/brain <br>system to date.  It also offers the most complete picture to date of the <br>neural structure of the ear/brain pathway, along with a micrometric<br>discussion of the various kinds of neurons which repond to<br>different frequencies, amplitudes, frequency differences, etc. passed along <br>the auditory nerve.  This book also does not discuss large-scale theoretical <br>models of the ear/brain system, nor does it concern itself with such high-<br>level phenomena as categorical perception or auditory illusions; but on the <br>level of the physical neural structure of the ear/brain pathway it is <br>unmatched.<br>Lastly, readers should *avoid* the statements about psychoacoustics <br>contained in many of the following well-meaning but outdated or simply <br>erroneous texts:<br>"The Acoustical Foundations of Music" by Backus, 1969, contains accurate <br>information on acoustics and the physics of some musical instruments.  <br>Unfortunately, almost all of Backus' statements about psychoacoustics had <br>been proven incomplete or incorrect by the time of publication of his book <br>(1969).<br>For example:<br>"The sense of pitch (related to vibration frequency) is thus partly <br>determined by the place along the basilar membrane where the vibration <br>amplitude is largest. There must be other factors also, since for sounds <br>close together in frequency, especially at low frequencies, the difference in <br>motion of the basilar membrane does not appear great enough to account for <br>the pitch discrimination of a good musician." [Backus, 1969, pg. 81]<br>This statement is correct but incomplete: the periodicity theory of hearing <br>can explain pitch discrimination at low fundamental frequencies but Backus <br>never mentions it. In fact the word "periodicity" does not appear in the index <br>of his book.<br>Again:<br>"Complex tones may also be built up out of harmonics but with the <br>fundamental omitted. The ear generally hears such tones as having the <br>fundamental frequency, even though there is no actual vibration of that <br>frequency present in the sound.  This missing fundamental effect is <br>explained on the basis of difference tones, since any two adjacent <br>harmonics will have a difference tones of the fundamental frequency." <br>[Backus, 1969, pg. 106]<br>This explanation dates from Helmholtz's time (1860s) and is known to be <br>incorrect. "One of the experimental results in Chapter 3 was that the <br>detectability threshold for combination tones is significantly lower for <br>small than for large frequency differences between the primary tones.  From <br>this, the conclusion was drawn that the ear's distortion cannot be <br>represented by a frequnecy-independent nonlinear characteristic." [Plomp, <br>1966, pg. 121]<br>"Helmholtz's belief that summation tones and difference tones are the most <br>prominent aural combination tones has become very widespread. However, <br>recent psychophysical and physiological experiments have revealed that this <br>belief is unjustified (Zwicker, 1955; Holdstein, 1970). Evidence for aural <br>summation tones has never been found, and difference tones arise only for <br>stimuli of relatively high intensity." [Houtsma, Adrian, "What Determines <br>Musical Pitch?" Journal of Music Theory, Vol. 17, No. 1, 1973, pp. 139-158] <br>Clearly Backus is misinformed and is passing that misinformation along to <br>his readers.<br>Other inaccuraies abound in Backus' text.<br>Jean-Claude Risset and Max Mathews, two of the most important pioneers in <br>analyzing real-world musical timbres, found in 1969 that instrument sounds <br>synthesized using fixed harmonic overtones sounded lifeless and artificial. <br>"Attempts of synthesis show how grossly inadequate it is to describe the <br>tone quality by a simple frequency spectrum."  [Pierce, J.R. , Mathews, M.  <br>and Risset J-C., "Further Experiments on the Use of the Computer in <br>Connection with Music," Grasvener Blaetter, no. 27/28, pg. 93, 1965] <br>In 1963--when Backus was still writing his text--Max Mathews pointed out: <br>"Our experience has shown how little we now know about relation of the <br>quality of sound to various features of waveform." [Mathews, M., "The Digital <br>Computer As a Musical Instrument," Science, Vol., 142, November, 1963, pg. <br>554]<br>Risset describes the state of ignorance which prevailed in the field of <br>musical acoustics through 1969 (the year in which Backus' text was <br>published): "Despite the considerable skill and ingenuity of scientists such <br>as Hermann Helmholtz or Dayton C. Miller, early analyses of musical-<br>instrument tones have not given satisfactory results. (...)  For a long time <br>physicists have performed analyses of musical-instrument tones, to find <br>out the physical correlates of their tone quality.  Many results of such <br>analyses have been published. (...) Computer sound synthesis makes it <br>possible to synthesize virtually any sound from a physical description of <br>that sound.<br>"This technique provides a way to check sound analyses: a successful <br>analysis should yield a physical description of the sound from which one <br>could synthesizer a sound that, to a listener, is nearly indistinguishable <br>from the original.<br>"We have tried to use the results of analyses of musical-instrument tones <br>that are to be found in musical-acoustic treatises as input data for <br>computer sound synthesis.  In most cases we have obtained sounds that bear <br>very little resemblance to the actual tones produced by the instrument <br>chosen; in almost all cases the available descriptions of musical-<br>instrument tones fail the fool-proof synthesis test.  Hence the descriptions <br>must be considered inadequate." [Risset, J.C. and Mathews, Max, "Analysis of <br>Musical-Instrument Tones," Physics Today, Volo. 22, No. 2, February 1969, <br>pp. 23-24.]<br>By Backus' own admission, his text was based on a series of lectures <br>developed over 10 years--which means that his psychoacoustic references <br>date from the 1930s, 1940s and 1950s during a critical period of upheaval <br>in psychoacoustics caused by the application of computers to music. <br>Backus does not mention computer analysis of sound: "The mechanical <br>method of analyzing sounds was cumbersome, slow and inaccurate; much <br>better equipment is available now for this kind of work.  This equipment is <br>electronically operated and therefore much faster; an oscillogram can be <br>obtained in one cycle of sound and analysis of the sound wave can be made in <br>one second or less." [Backus, 1969, pg. 101]<br>As Risset points out, the use the oscillograms prevents researchers from <br>following the evolution of a sound's spectrum throughout a long time period.  <br>Thus Backus' techniques are by definition inadequate and out of date.<br>None of Backus' references hint at the then-unpublished results of <br>Guttman, Shepard, Risset and Mathews, which changed the entire field of psychoacoustics.<br>Thus Backus' book is full of errors and misconceptions about the ear/brain system and should be ignored. <br>"Genesis of a Music" by Harry Partch, (1947, 2nd ed. 1974) contains much <br>valuable information about just intonation, acoustic instrument-building <br>and the fundamentals of musical acoustics.  Alas, virtually all of Partch's <br>statements about consonance, dissonance, human hearing and the ear/brain <br>system are claptrap.  He cites no psychoacoustic literature dated later than <br>1945: Partch was simply unfamiliar with modern experimental evidence <br>about the ear/brain system.<br>"Musical Engineering," by Harry F. Olson is an excellent introduction to the <br>physics of sound production in musical  instruments.  The statements about <br>musical timbre, the ear/brain system and consonance/dissonance embodied <br>the best knowledge up to that time (1957).  Unfortunately, most of what <br>Olson says about musical timbre, consonance,  hearing, etc., was disproven <br>by the experiments of Wessel, Risset, Ward, and many others in the 1960s <br>and early 70s.<br>""[On] my arrival in the States in 1964...I elected to focus on timbre.  The <br>palette  of computer sound, potentially boundless, was in fact quite <br>restricted, and one did not know how to generate certain sounds. In <br>particular, brassy sounds resisted synthesis efforts. I had to convince <br>myself that the recipes of respected acoustics treatises (like H. F. Olson's) <br>did not work.  As one may judge, from tones synthesized from such recipes, <br>they did not." [Risset, Jean-Claude, "Computer Music Experiments 1964...", <br>Computer Music Journal, Vol. 9, No. 1, Spring 1985, pg. 11]<br>"Fundamentals of Musical Acoustics," by Arthur Benade (1976) contains <br>reliable details on acoustics, but some of  Benade's information on sound <br>production in various instruments has now been proven incorrect--<br>particularly, Benade's theory of "regimes of oscillation" for brass <br>instruments. <br>Benade's text, like Backus, does not contain the word "periodicity" in its <br>index. And many of Benade's statements on psychoacoustics contradict the <br>results of modern research,  although to his credit Benade himself admits <br>this: "The foregoing remarks disagree somewhat with the conclusions drawn <br>by the authors of the following thoughtfully written papers:<br>J.E. F. Sundberg & J. Lindqvist, "Musical Octaves and Pitch," JASA, Vol. 54, <br>1973, pp. 922-929," and so on.   <br>Benade's references on psychoacoustics show strange gaps and a peculiar <br>selectivity.  Ohm, Stumpf, Seebeck, Schouten, Plomp, von Bekesy, Sundberg, <br>Ward and Burns are not cited in the biolography at the end of the chapter <br>"The Acoutical phenomena governing the musical relationships of pitch," <br>while Pierce, Mathews, Shepard, Risset, Sundberg, Ward and Burns are not cited in the chapter "Successive Tones: Reverberation, Melodic Relationships, and Musical Scales." <br>Instead an article by Steven and Volkman dating from 1940 is cited, <br>along with Helmholtz--whose work dates from the 1860s--and "The <br>Collected papers of Wallace Sabine," another 19th-century figure. <br>For a researcher in the 1970s to write a text whose primary psychoacoustic <br>citations hail from the 1860s-1880s is peculiar, to say the least. Like Hall, <br>Benade is a physical acoustician whose bibliography and reference lists <br>betrays a scanty knowledge of modern psychoacoustics, and an unsavory <br>penchant for discarding results with which his simplistic mathematical <br>models disagree.<br>Rossing, "The Physics of Music," 1993, is a comprehensive discussion of the <br>physical basis of acoustic instrument timbre, but it contains very little <br>information about psychoacoustics.  To be fair, that was not Rossing's focus.  <br>Still, the text contains nary a mention of Wessel's streaming phenomenon, <br>no reference to Ward, Corso, Pikler, Sundberg and Terhardt's findings  on the <br>universal preference for stretched octaves, fifths and thirds; no information <br>on how pitch perception is affected by masking, context, tone length, etc.; <br>no distinction twixt physical and perceptual pitch or physical and <br>perceptual loudness, etc.<br>Other texts may prove popular.  Before believing any reference on <br>psychoacoustics, be sure to check its date. Many pre-1970 acoustics text <br>either lack important psychoacoustic data, are outdated, or contain a wealth <br>of outright misinformation parrotted from Rameau, Mersenne and Helmholtz.<br>Check the bibliographies of these suspect texts--notice how few post-1945 <br>papers are cited, and how often the authors take issue with well-known and <br>accepted results from the 60s, 70s, 80s and 90s verified independently by <br>many reserachers in psychoacoustics on 4 continents.  Lastly, simply <br>compare what you hear on F. Alton Everest's tapes and the Houtsma, Rossing <br>and Wagenaars disc and the Mathews "Sound Examples: Current Directions in <br>Computer Music" disc with claims made by the author in question.<br>--mclaren <br> <br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Tue, 26 Sep 1995 21:23 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id MAA17646; Tue, 26 Sep 1995 12:22:26 -0700<br>Date: Tue, 26 Sep 1995 12:22:26 -0700<br>Message-Id: <199509261918.AA04185@net4you.co.at><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2061 href="#2061">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>9/27/1995 8:13:43 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Psychoacoustics - post 4 of 25<br>---<br>The ear itself is the gateway to new kinds<br>of harmony and new forms of music.  The<br>more we learn about the subtleties of the<br>ear/brain system, the wider the range of<br>xenharmonic musics we can make.<br>---<br>MYTH: EVERYONE KNOWS HOW THE EAR PERCEIVES<br>  PITCH. HELMHOLTZ EXPLAINED IT IN 1863.<br>FACT: Since 1841 there have been 3 competing theories<br>of how the ear operates. <br>Some evidence supports, while other evidence <br>contradicts, each hypothesis about <br>how the ear perceives sound.<br>---<br>Ohm (1843) is the founder of modern hearing<br>theory.  "Ohm introduced the view that the<br>analyzing power of the hearing organ may be <br>compared to the way in which periodic <br>functions can be analyzed mathematically<br>by applying Fourier's theorem (Ohm 1843).<br>Helmholtz fully recognized the significance<br>of this hypothesis and based his theory on<br>it..." ["Experiments On Tone Perception,"<br>Plomp, R., 1967, pg. 102]<br>In effect both Ohm and Helmholtz viewed<br>the ear as a frequency analyzer. Ohm's First<br>Law states that the ear detects a pitch<br>only if there is significant acoustic<br>energy at the fundamental frequency of<br>that pitch, which (as we all know) consists<br>of a set of sine wave harmonics added<br>together.<br>---<br>Everyone knows this, and it's wrong.<br>Ohm's hypothesis was dealt a series of<br>blows by experimental evidence.<br>Researchers using crude light microscopes<br>from the 17th through the early 19th centuries<br>examined the cochlea and found what appeared<br>to be rods.  This naturally suggested a set of<br>tuned resonators--an idea which Helmholtz<br>picked up in the 1840s and elaborated into<br>the first (resonance) version of his theory of <br>hearing.<br>"The principle of resonance, based on early work<br>of Galileo, was proposed as a way for low and high<br>tones to have different effects on the ear. For example,<br>in 1683 du Verney, in his `Traite de l'organe de<br>l'ourie,' suggested that a ribbon-like structure<br>along the length of the cochlea vibrates in different<br>places to different frequencies through resonance<br>by noting that the width of the ribbon changed from<br>one end of the cochlea to the other. (..) In 1851 Corti<br>described a number of the finer structures inside the <br>cochlea, the most prominent of which he called teeth,<br>while others called them rods.  The inverted V is <br>now called the "arch of Corti," but his vantage point<br>was from above, so that the arches appeared as extended<br>rods...  He described the rods as delicate, free, and flexible,<br>and he supposed that their movements stimulated acoustic<br>nerve fibers which, at the time, were believed to end <br>in the vicinity of the rods." [Gulick, W. Lawrence, <br>George A. Geschneider and Robert D. Frisina, "Hearing:<br>Physiological Acoustics, neural coding and Psychoacoustics,"<br>Oxford University Press, 1989, pg. 59]<br>The mistaken picture of the arches of Corti as resonating rods<br>was the one used by Helmholtz to support his earliest<br>"resonance" theory of hearing.<br>However, successive improvement in the resolution of<br>available light microscopes--due largely to the work<br>of the mathematician Abel--dealt a serious blow to<br>Helmholtz's 1863 "Tonemfindungen," in which he stated<br>in detail a theory of hearing he had presented in a lecture in<br>Bonn during the winter of 1857.<br>"In his public lecture in 1857, Helmholtz proposed that<br>sounds reaching the cochlea would set certain of the rods<br>of Corti in motion by sympathetic vibration.  He envisaged <br>the rods as a set of tuned resonators, so that only those with<br>a natural frequency equal to that of the stimulus would vibrate<br>and thus stimulate only those acoustic fibers that served them."<br>[Gulick, W. Lawrence,  George A. Geschneider and Robert D. <br>Frisina, "Hearing: Physiological Acoustics, neural coding and Psychoacoustics," Oxford University Press, 1989, pg. 60]<br>The subsequent microscopic "...discoveries of Deiters in <br>1860 made it clear that the rods of Corti were unsuitable as <br>resonators because they were arches rather than independent <br>rods. So, in `Empfindungen,' Helmholtz revised his theory by<br>shifting the resonators to the transverse fibers of the basilar<br>membrane, a membrane "stretched" across the cochlear tube."<br>[Gulick, W. Lawrence,  George A. Geschneider and Robert D. <br>Frisina, "Hearing: Physiological Acoustics, neural coding and Psychoacoustics," Oxford University Press, 1989, pg. 61]<br>In keeping with the ancient principle of likeness, according<br>to which features of the nervous system symbolzed the external<br>world, Helmholtz adopted the doctrine of "specific nerve energies," <br>which stated that each nerve responded to a unique stimulus<br>and only to that stimulus.  This doctrine was proposed by Helmholtz's<br>teacher Johannes Mueller in 1838 in Mueller's `Handbuch der <br>Physiologie,' but it was first stated by Herophilus and Eristratus <br>in 490 B.C. and subsequently expounded by Aristotle in 344 B.C.<br>"By extending Mueller's doctrine, Helmholtz claimed that each <br>acoustic nerve fiber had its own `quality,' so that, when activated, <br>it always led to the perception of a particular pitch. (..) Accordingly,<br>frequency was coded by the place of stimulation along the longitudinal<br>axis of the cochlea." [Gulick, W. Lawrence,  George A. Geschneider and <br>Robert D. Frisina, "Hearing: Physiological Acoustics, neural coding and Psychoacoustics," Oxford University Press, 1989, pg. 61]<br>This did not solve the problems with Helmholtz's theory of<br>hearing.  Instead, more and more dififculties began to appear<br>after its publication in 1863:<br>"First, the transverse fibers of the basilar membrane are <br>neither under tension nor independent. Therefore, they are<br>ill-suited to serve the function ascribed to them in theory.<br>(..) Second, even if the transverse fibers were under tension<br>and independent suspended, the variation in fiber length and<br>mass is so restrictive as to limit resonance to a frequency<br>range that is only a small fraction of the total to which we<br>respond. (..)<br>"Third, there is a serious difficulty with the principle of <br>resonance as a means to account for frequency discrimination.<br>(..) Fourth, since no resonance is wholly specific, Helmholtz's<br>theory also was criticized because a tone of a given frequency<br>would produce resonance not only in the tuned resonator but also<br>in those that are slightly mistuned.  Accordingly, one tone would<br>signal a number of places, and therefore, a number of pitches.<br>In 1900 Gray offered his hypothesis of maximum stimulation to<br>counter this objection. He proposed that the exactly tuned<br>resonator would also show maximum resonance, and it was this<br>trasnverse fiber that singaled the place for that tone. However,<br>he claimed that with intense stimulation many resonators would<br>be responding at the practical maxima, and since the precision of<br>the place would thereby be lost, he predicted that differential<br>pitch sensitivity would worsen as a function of increasing<br>intensity.  Psychophysical data show the opposite to be true.<br>(..) Fifth, Helmholtz assumed that changes in stimulus intensity<br>produced changes in stimulus magnitude.  However, by 1914, the<br>work of Adrian on the all-or-none property of neural action seemed <br>emphatically to deny this requirement of the Helmholtz theory.<br>As the current century began, the resonance-place theory of hearing <br>was in some trouble."  [Gulick, W. Lawrence,  George A. Geschneider and <br>Robert D. Frisina, "Hearing: Physiological Acoustics, neural coding and Psychoacoustics," Oxford University Press, 1989, pg. 63]<br>Other strong doubts about the Helmholtz or "place" theory of hearing <br>arose as a result of Seebeck's experiments in 1843.<br>"He constructed a siren from a forced air system, in front of which<br>he placed a rotating disk with small holes separated by specific <br>distances so as to produceshort sound pulses separated by<br>precisely specified time intervals. (..) The pitch of this periodic<br>pulse was the same as that of a 500-Hz tone.  This is not surprising,<br>since the pulse train delivered 500 pulses/sec. A more surprising<br>result occurred when pulses alternated between two slightly<br>different values. Although the timing between pulses<br>had been changed only slightly...the perceived pitch dropped<br>dramatically from that of a 500-Hz tone to that of a 250-Hz tone<br>despite the fac that most of the energy in this slightly<br>modified stimulus was still at 500 hz.  The physical property<br>that was clearly altered by ths light change in pulse timing was the<br>period. (..) This change in pitch was attributed to the change in<br>the period of repeating sound pressure wave and eventually became<br>known as periodicity pitch." [Gulick, W. Lawrence, George A.<br>Geschneider and Robert D. Frisina, "Hearing: Physiological Acoustics,<br>Neural Coding, and Psychoacoustics," Oxford University Press, <br>1989, pg. 257]<br>As Gulick et alii point out, "Seebeck's work was important because it<br>led investigators to consider the timing of neural impulses as a <br>possible neural code for pitch perception. The place and neural synchrony<br>[periodicity] theories represent two very different views on how the<br>nervous system codes pitch.  For the place theorist it is the frequency<br>spectrum of the stimulus that is important, whereas for the neural<br>synchrony theorist it is some aspect of the time waveform, such as <br>the period, that is important. (..) The controversy between proponents<br>of two viewpoint gained momentum in the 1940s with the work of<br> Schouten." [Gulick, et al., 1989, pg. 258]<br>Pierce describes hearing Schouten's effect first-hand: "He had constructed<br>a sort of optical siren (Figure 6-4) by means of which he could produce sounds with various waveforms.  Using this, he produced sounds with harmonically related partials... Then, by proper  adjustments, he <br>could cancel out the fundamental frequency... I could hear<br>this fundamental frequency come and go, but the pitch of the sound <br>did not change at all.  In some way, my ear inferred the proper pitch <br>from the harmonics..." ["The Science of Musical Sound," Pierce,<br>2nd ed., 1992, pg. 92;  also see Ohm, G.S., "Ueber die Definition des <br>Tones, nebst daran geknuepfer Theorie der Sirene und aehnlicher <br>tonbildener Vorrichtungen," Ann. Phys. Chem, Vol. 59, ppg. 513-565,<br>also see  Schouten, "The Perception of subjective tones," Proceedings <br>of the Koninklijke Nederlandse Akademie van Wetenschappen, 1938, <br>vol. 41, pp.  1083-1093.]<br>While most of the details of Helmholtz's theory of hearing are now<br>known to be inaccurate, parts of the underlying idea  were adopted <br>in the "place" theory of hearing.  According to this theory, just intonation<br>is the ideal musical tuning and the 4:5:6 chord which stands at the<br>center of traditional Western harmony is a necessary outcome of<br>the physical structure of the human auditory system.<br>As will be seen, however, all of the objections to Helmholtz's<br>theory remain troublesome even to modern-day place theories. <br> The modern place theory cannot explain the simultaneously fine <br>frequency discrimination  of the ear and its broad range of frequency response; the modern place theory cannot explain the missing fundamental;<br>nor can it  explain how the relatively wide travelling waves on the<br>basilar membrane give rise to delicate pitch judgments.  The<br>modern place theory cannot explain how the ear can detect<br>the pitch of tones whose fundamental lies below  rougly 150 Hz.  <br>The modern place theory cannot explain how only 3000 hair cells<br>account for the measured jnd of the average subject; the modern<br>place theory cannot explain why louder sounds are more<br>accurately judged in frequency when the opposite is predicted<br>from conventional frequency; and the modern place theory cannot<br>explain categorical perception, the encoding of pitch and<br>amplitude in the auditory nerve, the universal human preference<br>for stretched intervals and beat rates between 4 and 6 Hz, and<br>so on.<br>Thus there is substantial reason to doubt that either small integer<br>ratios or 4:5:6 chords consitute either a privileged or even a<br>necessary outcome of the human ear/brain system. <br>On the other hand, some aspects of the auditory system are<br>convincingly explained by the modern place theory.  The cocktail<br>party effect, the ability to perceive the pitch of tones with<br>a high-pitched fundamental. "Furthermore, support for the view<br>that perception ohte pitch of them issing fundamental is not due <br>to the excitation of low freuqency-sensitive neurons responding<br>to low freuqnecy distortion products of a complex tone comes<br>from observatiosn that a low frequency masking noise presented <br>with the high freuqnecy complex tone does not eliminate the<br>perception of the missing fundamental." [Gulick, et al., 1989, pg. 259] <br>The next post will examine in greater detail the place theory<br>of hearing, and the psychoacoustic evidence for and against it,<br>along with the implications for tuning and music.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Wed, 27 Sep 1995 19:26 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id KAA06522; Wed, 27 Sep 1995 10:26:35 -0700<br>Date: Wed, 27 Sep 1995 10:26:35 -0700<br>Message-Id: <199509271725.KAA19263@osiris.ac.hmc.edu><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2073 href="#2073">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>9/28/1995 10:31:12 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Tuning & Psychoacoustics - post 5 of 25<br>--<br>As mentioned in the previous post,<br>the elements of the modern place<br>theory of hearing are found in Helmholtz's<br>19th-century model of the ear.  Thus it's<br>worth taking some time to examine<br>the implications of that model:<br>"Helmholtz's hearing theory can be<br>considered as an elaboration of three<br>hypotheses. In general terms, the first<br>one is:<br>"Hypothesis I. The analysis of sound is<br>accomplished in the inner ear by means<br>of a large number of resonators tuned<br>to different frequencies from low to <br>high." ["Experiments On Tone Perception,"<br>Plomp, pg. 102, 1966]<br>Helmholtz originally ascribed the<br>"resonator" function to the arches<br>of Corti but (as mentioned in the <br>last post) when he put his ideas down<br>in his book he changed his mind<br>and proposed that the transverse <br>fibres of the basilar membrane act<br>as resonators. His arguments were:<br>[1] In the cochlea of birds, no arches<br>of Corti are found (Hasse, 1867); [2] <br>the width of the basilar membrane<br>varies from about 0.04 mm at its <br>base up to 0.5 mm at the helicotrema<br>(Hansen, 1863); [3] the membrane is<br>much more tightly stretched transversely<br>than longitudinally.<br>"On the basis of these measurements,<br>Helmholtz estimated the selectivity<br>of the resonators, amounting to about<br>4% of the resonance frequency, with<br>bandwidth proportional to logarithmic<br>frequency.<br>"Hypothesis II. A particular tone-pitch<br>corresponds to each of the numerous<br>nerve fibers in such a way that pitch<br>decreases gradually from the basal to<br>the apical end of the organ of Corti."<br>["Experiments On Tone Perception," <br>Plomp, R., pg. 103, 1966]<br>While Helmholtz's hypotheses explained<br>some aspects of human hearing, it<br>did not explain others.   In particular,<br>these hypotheses did not explain how <br>combination tones or beats<br>of mistuned consonances occur.<br>Thus Helmholtz proposed a third<br>hypothesis:<br>"Hypothesis III. The sound transmission<br>of the ear is characterized by nonlinear<br>distortion." ["Experiments On Tone<br>Perception," Plomp, R., pg. 103, 1966]<br>By means of these 3 hypotheses <br>Helmholtz was able to explain much<br>of the experimental data available<br>to him in 1863.  <br>Other aspects of human hearing remained<br>unexplained.  As Plomp points out, "The<br>Achilles' heel of his conception was<br>why periodic sound waves are always<br>characterized by a pitch corresponding<br>to the fundamental. ...  Even so, Helmholtz's<br>theory became widely accepted soon<br>after its publication under the names<br>of resonance theory and place theory."<br>[Plomp, R., 1966, pg. 104]<br>There were other problems with<br>Helmholtz's theory.  Whether in modern<br>form as the "place" theory or in terms<br>of Helmholtz's original conception, the<br>pitch sensitivity of the human ear is<br>significantly greater than the predictions<br>made on the basis of the place theory.<br>Moreover, if the ear is primarily  a Fourier <br>analyzer, why did it respond to the irregularly-<br>spaced holes of Seebeck's siren (Seebeck,<br>1846) with a sensation of definite<br>pitch not present in any of  the<br>Fourier components of the waveform<br>generated when the siren rotated?  <br>Stumpf, one of the proponents of a<br>competing theory of hearing, pointed<br>out these flaws in the original<br>place theory:<br>"The view that fibres of 0.5 mm length <br>should be tuned to low frequencies did <br>not sound very credible and we may<br>suppose that many agreed with Stumpf's<br>statement: `It remains wonderful,<br>however, that so small particles can<br>resonate even on the lowest tones<br>that we produce by strings of enormous<br>size and by which we can bring into<br>resonance only strings of the same<br>size.'" [Plomp, 1966, pg. 107; see also<br>Stumpf, C., "Tonpsychologie," Vol. 2,<br>Verlag S. Hirzel, Leipzig, 1890, pg. 92]<br>Plomp points out: "Some investigators<br>tried to save the resonance hypothesis<br>by supposing that the resonators<br>must be sought in other structures of<br>the cochlea: the hair cells (Baer, 1872;<br>Hermann, 1894; Myers, 1904; Specht,<br>1926) or the tectorial membrane (Kishi,<br>1907; Shambaugh, 1907, 1909, 1911; <br>Leiri, 1932). Others, however, rejected<br>the resonance hypothesis entirely, <br>proposing new hearing theories in which<br>the frequency-analyzing power of the<br>hearing organ was approached in quite<br>a different way (Meyer, 1896, 1898,<br>1899, 1907; Ewald, 1899, 1903,<br>Wrightson, 1918, and many others)."<br>[Plomp, 1966, pp. 107-108]<br>Because of the failure of Helmholtz's<br>original hypothesis to explain many <br>auditory phenomena, many researchers<br>cast about during the period from the<br>1840s to the 1860s for another model<br>of human hearing.  Many researchers<br>seized upon Seebeck's 1843 proposal<br>as the answer.<br>Namely, that "Tones give rise to<br>synchronous nerve impulses whose<br>rate determines pitch.  Wundt tried<br>to evade the difficulty that according<br>to this hypothesis Bernstein's findings<br>would suggest a pitch limit at about<br>1600 cps. He explained that not the<br>total duration of the nerve impulses<br>but the much shorter duration of their<br>peaks might determine the highest<br>pitch audible..." [Plomp, 1966, pg. 105]<br>In favor of this competing hypothesis,<br>called the periodicity theory of hearing, <br>two pieces of early evidence were advanced<br>by Seebeck, Wundt, Stumpf and others:<br>"1. Binaural beats. Dove (1839) had<br>pointed for the first time to the fact<br>that stimulating the ears separately <br>with tones of slightly different frequencies<br>gives rise to slow "binaural beats." Usually,<br>they were explained as resulting from<br>bone conduction between the ears (Seebeck,<br>1846; Mach, 1875; Stumpf, 1890, p. 458;<br>Schaefer, 1891). Thompson, who discovered<br>the beats independently, found that they do<br>not change over into a difference tone when<br>the frequency difference is increased (1877,<br>1878, 1881). Therefore, he suggested that<br>binaural beats are caused by interference in<br>a higher centre of the auditory pathway."<br>[Plomp, 1966, pg. 105]<br>This latter was the first suggestion that the brain was<br>directly involved in the processing of musical<br>sounds. Previous theories, like Helmholtz's, <br>assumed that the ear did all the processing<br>required and that the auditory nerve simply<br>acted as a conduit through which the preprocessed<br>nerve impulses travelled.   Wundt's and Stumpf's<br>observations made it clear, however, that the<br>brain was *part* of the auditory system which<br>determined pitch, spectral content, etc.--perhaps<br>*the* crucial part (as subsequent late-20th-century<br>"pattern transformation" hypotheses of hearing have<br>stressed).<br>The second piece of evidence supporting<br>the Seebeck/Stumpf/Wundt periodicty theory was:<br>"2. Direct stimulation of the auditory nerve.<br>The sensational conclusion that the cochlea<br>is not essential for obtaining an auditory<br>sensation was drawn independently by<br>Fano and Massini (1891) and by Ewald (1892).<br>They based their opinion on the positive<br>reactions on sound by pigeons with removed<br>hearing organs. The conclusion was severely<br>crticized by Matte (1894), Bernstein (1895),<br>Strehl (1895), and Kuttner (1896), and<br>defended by Ewald (1895) and Wundt (1895)"<br>[Plomp, 1966, pg. 106]<br>Plomp points out that although this second<br>competing hearing theory could explain<br>interruption tones and beats of mistuned<br>consonances much better than Helmholtz's<br>theory did, its influence was small, perhaps<br>because Wundt did not work the theory out<br>in nearly as much detail as did Helmholtz<br>in the 2nd edition of "On The Sensation of Tone." <br>The whole later development of physiological<br>acoustics can be regarded as an elaboration<br>of these two competing and contradictory<br>hypotheses, along with Fetis' 1843 learned-<br>response theory of hearing. Like Seebeck's<br>and Stumpf's periodcity theory--which was<br>largely ignored until Schouten in 1935 performed<br>a convincing series of experiments which clearly<br>demonstrated the inadequacy of the place theory<br>of hearing--Fetis' 1843 theory of learned response<br>was likewise ignored for many years.  Starting in<br>the 1950s,  Ward, Burns, Corso, Licklider, and others<br>performed a series of experiments which cast profound<br>doubt on many aspects of both the periodicity and<br>place theory and strongly supported Fetis' 1843 <br>hypothesis. <br>Recently, the auditory artifacts produced by <br>cochlear implants have provided strong evidence against<br>the periodicity theory:  "If we believe the <br>extreme position that at low frequencies information is<br>carried purely by the temporal pattern of nerve impulses,<br>then periodic electrical stimulation should produce<br>faithful auditory sensations and good discrimination<br>of frequencies. The results of electrical stimulation have <br>on the whole been disappointing for such a prediction.<br>In only a few cases to electrical stimuli seem to produce<br>clear tonal sensations. A typical report is that tones<br>sound like "comb and paper" (e.g., Fourcin et al., 1979).<br>[Pickles, James. O., "An Introduction to the Physiology<br>of Hearing," Academic Press, 2nd ed., 1988, pg. 316]<br>On the other hand, the place theory also conflicts with<br>experiment: "In a quasi-linear spectral analyzer such<br>as the cochlea the physical limits of frequency resolution<br>are limited by the duration of the stimulus, as a result<br>of spectral splatter: stimulus duration x spectral line<br>width = 1.  (..) Temporal theories are not so limited...<br>(..) On the hypothesis that place and not temporal cues are<br>used, we can calculate a lower limit for the frequency<br>difference limen as a function of the length of the<br>stimulus.  Moore (1973) showed that below 5 khz frequency<br>discrimination for short stimulus was up to an order of<br>magnitude better than expected on a place basis. " <br>Pickles, James. O., "An Introduction to the Physiology<br>of Hearing," Academic Press, 2nd ed., 1988, pg. 273]<br>As a result, "At the moment pattern hypotheses are<br>dominant..." Pickles, James. O., "An Introduction to the Physiology<br>of Hearing," Academic Press, 2nd ed., 1988, pg. 273]<br>The phenomenon of forward and backward masking<br>also directly contradicts the place theory.  In forward<br>masking, a masking tone precedes the test tone by a<br>small time period--in backward masking, the masking<br>tone occurs *after* the test tone.  If Fourier analysis<br>is occurring mechanically in the ear, it's difficult to<br>explain how a second tone appearing *after* the test<br>tone can interfere with the Fourier analysis.  And in<br>any case, the fact that masking occurs is a fundamental<br>problem for Fourier models of hearing. <br>"Masking is an example of limitations of the<br>auditory system's ability to analyze individual frequency<br>composnents in a complex sound. If the ear were a perfect <br>frequency analyzer, then one sound would never mask<br>the detecability of another sound.  Instead, simultaneously<br>presented sounds would be independently processed, and the<br>perpcetion of one would not affect the perception of others.<br>Masking demnstrates that this ideal state does not exist.<br>Whenever masking occurs, frequency analysis fails.  When<br>the presence of a sound of a particular frequency makes it<br>difficult or impossible to hear another sound of a different<br>frequency, the ear has failed to analyze and detect the<br>individual frequency components of the complex sound<br>created by simultaneous presentation of the two sounds."<br>[Gulick, W. Lawrence and George A. Geschneider and<br>Robert D. Frisina, "Hearing: Physiological Acoustics, Neural<br>Coding, and Psychoacoustics," Oxford University Press,<br>1988, pg. 300] <br>As a result of these pervasive problems with both the<br>place and periodicity theories of hearing,<br> Fetis' model of the ear/brain system<br>as a feedback path controlled primarily by software (viz.,<br>learned response) has now gained great currency. <br>in part because of the inadequacy of current evidence<br>In part this is also probably due to increasing use of computers <br>and  software in the congitive sciences and their consequent<br>popularity as a conceptual model for neural systems.<br>(As will be seen in a future post, a researcher's tools <br>exert a potent influence on the mental models he forms.)<br>If accurate, the "pattern transformation" model of hearing<br>implies that many different tuning systems and musical<br>syntaxes are appropriate.  According to this theory of hearing,<br>no particular complex of overtones has a privleged status<br>in the ear, and no specific musical tuning is implied as<br>superior on the basis of the structure of the ear.<br>Because of the importance of this question for tuning and<br>music, the next post will examine detailed evidence<br>for and against the periodicity and place models of <br>pitch perception.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Fri, 29 Sep 1995 07:12 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id WAA06397; Thu, 28 Sep 1995 22:12:35 -0700<br>Date: Thu, 28 Sep 1995 22:12:35 -0700<br>Message-Id: <Pine.SOL.3.91.950929001046.2688C-100000@library><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2079 href="#2079">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>9/29/1995 9:24:03 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Tuning & Psychoacoustics - Post 6 of 25<br>---<br>MYTH: THE OPERATION OF THE EAR CAN BE<br>EXPLAINED AS THAT OF A FOURIER ANALYZER,<br>WITH SOME SLIGHT MODIFICATIONS.<br>FACT:  Today there are 3 competing models which<br>explain how the ear/brain system operates, and <br>some experimental data supports each hypothesis<br>and contradicts the others.  Each theory has enjoyed<br>proponents for more than 100 years, primarily<br>because many aspects of the ear's behaviour cannot <br>be explained by means of Fourier analysis.<br>---<br>During the late 19th and early 20th<br>century, rapid advances in technology allowed<br>scientists to subject both the place theory<br>and the periodicity theory of hearing<br>to ever-more-sophisticated tests.<br>"On the basis of these different methods,<br>the fact is now well established that the<br>stimulated region of the basilar membrane<br>shifts for decreasing frequency from the<br>basal to the apical end." [Plomp, 1966,<br>pg. 108; see also Cioco, 1934; Crow et al,<br>1934, Oda, 1938; Stevens et al., 1935;<br>Walzl and Bordley, 1942; Schuknecht,<br>1960; Kemp, 1935, 1936, Smith, 1947,<br>Smith and Wever, 1949; Davis et al.<br>1953; Culler, 1935, Culler et al. 1937,<br>1943; and particularly von Bekesy,<br>1944, 1955, 1957.]  von Bekesy<br>constructed a large and simplified<br>physical replica of the cochlea which used<br>the tactile sense of the arm to <br>stimulate the organ of Corti and the <br>auditory pathway.  He proved that<br>even in the case of a very broad<br>maximum of the pattern of vibration,<br>only a small section was felt<br>subjectively to vibrate. This lent<br>strong suport to the view that<br>the place of maximal stimulation<br>along  the basilar membrane <br>corresponds to pitch.  (That is,<br>to Helmholtz's theory, with a good<br>deal of updating; Helmholtz's idea<br>of "resonators" had to be abandoned,<br>and many of the details of his theory<br>modified, to explain experimental<br>results, as we've seen.)<br>While von Bekesy's experiments <br>provided strong confirmation for<br>some of the place theory's prediction,<br>they contradicted other aspects <br>of the place theory.   There<br>remained unresolved, for instance,<br>the question of how to account<br>for the ear's extraordinary<br>sensitivity to tuning differences<br>of individual partials and of<br>the fundamental frequency of<br>the sound wave itself.  WIth only<br>3000 hair cells each spaced 9 microns apart,<br>this was difficult to explain. Known pitch<br>discrimination would demand sensitivity to<br>stimulation on the basilar membrane measured<br>in fractions of a micron,  even though the measured<br>width of the travelling wave on the basilar membrane<br>is many times that width. (This objection<br>was originally raised to Helmholtz's <br>now-obsolete hypotheses of the<br>1860s, and it still bedevils advocates<br>of the modern place theory.) Moreover,<br>if pitch sensitivity were due solely to the hairs<br> lining the basilar membrane, and not to neural<br>processing, there would have to be far more<br>hairs than the known 3000 inner hair cells <br>(electron microscopy has shown that<br>the remaining 12,000 outer hair cells serve <br>an ancillary function, rather than a direct <br>freqency-detection role.  This is also supported<br>by data from the action potentials of the<br>two classes of stereocilia as obtained by<br>microelectrodes.) "The two types of coupling can<br>therefore be associated with the different<br>roles of the two types of hair cell in cochlear<br>function, inner hair cells detecting the movement<br>of the [basilar] membrane, and the outer hair cells<br>helping to generate it." [Pickles, James O., "An<br>Introduction to the Physiology of Hearing," Academic<br>Press, 1988, 2nd ed., pp. 158-159] <br>It is also difficult to explain pitch perception of<br>sounds with low but missing fundamentals: <br>"Suppose high harmonics generate the low pitch.<br>They wil be relatively closely spaced and will not<br>be resolved by the auditory stytem. Recognition of<br>the psectral pattern will not therefore be possible,<br>but hte harmonics wil eb able to interact in the<br>nervous system to produce periodically varying<br>activity.  Temporal theories are therefore supported."<br>[Pickles, James O., "An Introduction to the Physiology<br>of Hearing," Academic Press, 1988, pg. 273]<br>However, Pickles points out that "This is again an<br>area which is controversial, and over the years<br>opinions have swayed in favour of one hypothesis<br>or the other." (I.e., periodicity or place theory.)<br>Both theories suffer from the limits imposed <br>mathematically by their proposed mechanisms<br>of action, which are in each case  different<br>from those observewd: "The lower limit for the place <br>principle is believed to be about 150 Hz becuase <br>the excitation pattern on the basilar membrane does <br>not change with frequencies lower than this limit.<br>Some investigators think that the temporal principle<br>codes ptich for the very low frequencies and supplements<br>the place principle over the midrange frequencies. The<br>upper frequency limit of the applicability of the temporal<br>principle is uncertain. Some investigators put this limit<br>as low as 300 to 400 hz, and others put it as high as<br>4000 to 5000 Hz." [Gulick, W. Lawrence,<br>George A. Geschneider and Robert D. Frisina, "Hearing:<br>Phsyiological Acoustics, Neural Coding, and<br>Psychoacoustics," Oxford University Press,<br>1989, pg. 261]<br>Equally troubling for advocates of the place<br>theory is the fact when sine tones are used,<br>the ear displays a completely different consonance/<br>dissonance curve than that produced by complex<br>tones--instead of a series of peaks and troughs, a<br>smooth shifted-bell-curve-like response is seen <br>for sine tones.  The Ohm/Helmholtz Fourier theory <br>of hearing fails to explain this result.<br>Moreover, von Bekesy found that<br>contrary to Helmholtz's presumption,<br>"it appeared that combination tones<br>are not due to nonlinear vibration of <br>[the timpanic] membrane. Furthermore<br>he discovered that the introduction<br>of a negative or positive static<br>pressure into the external meatus<br>changed the loudness of difference<br>tones. This would imply that these tones<br>are produced in the middle ear." [Plomp,<br>1966, pg. 111]<br>"However Wever et al, 1941, conducted<br>experiments which contradicted von<br>Bekesy's findings just mentioned. ...<br>Further investigations...suggested that<br>the main source of combination tones<br>must be sought in the sensory <br>processes, where the microphonic<br>potential is evoked, and not in the<br>mechanical part of the inner ear (Wever<br>and Lawrence, 1954)" [ Plomp, 1966, <br>pg. 111] <br>In addition, the experiments of von Bekesy,<br>who did more than any other researcher to<br>put the place theory of hearing on a modern<br>scientific basis, were also open to considerable<br>doubt. " Von Bekesy's observations<br>have been questioned on two grounds. Visual<br>observations mean that the vibration amplitude<br>had to tbe at least of the order of the wavelength<br>of light, and the high intensities (130 dB SPL) <br>necesssary make extrapolation to a more <br>physiological range unjustified. Secondly, his<br>measurements were performed on cadavers. It is<br>now known that not only does the experimental<br>animal have to be alive, but the cochlea has to be<br>in extremely good phisological condition, to<br>show a satisfactory mechanical response."<br>[Pickles, James O., "An Introduction to the <br>Physiology of Hearing," Academic Press, 1988,<br>end ed., pg. 40]<br>In short, investigations began<br>to suggest that many important <br>auditory phenomena could only be<br>explained by the software, not the<br>hardware, of the ear/brain system--<br>that is, by the brain itself. "[For] the<br>phenomenon...once called "periodicity<br>pitch" [there are] alternative explanations...<br>known as "pattern" theories.  They suppose that<br>the auditory system, by recognizing that the tones<br>sounded are the upper harmonics of a low tones, <br>supplies the missing fundamental that would have<br>generated them. This is again an area which is<br>controversial, and over the years opinions have swayed<br>in favor of one hypothesis or the other." [Pickles, James<br>O., "An Introduction to the Physiology of Hearing," <br>Academic Press, 1988, 2nd. ed., 1988, pg. 273]<br>Clearly by the 1980s much of the  support for the<br>place  theory of hearing had crumbled.  In 1984 Pierce<br>writes: "Helmholtz accomplished a great deal despite the <br>limitations of the technology available to him.<br>Yet he reached false conclusions. He believed the perception <br>of musical pitch depends on the presence of the fundamental <br>frequency. This is not true for low keys on the piano keyboard,<br> or for orchestra chimes, or for bells. HIs other false conclusion<br>was that the relative phases of sinusoidal components do not <br>affect the timbre of  a sound." ["The Science of Musical Sound,"<br>Pierce, J.R. , 1992, pg. 185; see also "Tone Segregation by Phase: <br>On the Phase  Sensitivity of the single ear," Kubovy and<br>Jordan, JASA, Vol. 66, No. 1, 1979, pp.  100-106]<br>Still, the place hypothesis accounts very convincingly for <br>at least a few  characteristics of the ear/brain <br>system: it explains how the ear can resolve complex sounds into<br>separate pitches, explains the function and structure of some<br>of the mechanical components of the inner ear, it explains <br>elegantly the near-logarithmic nature of pitch, and it explains why<br>very close tones are heard as being identical in pitch.<br>On the other hand, the place theory does *not* explain why stretched <br>intervals significantly larger than those predicted<br>by the small whole number ratios (or numerological, essentially<br>Kabalistic) theory of  consonance are universally preferred to <br>so-called "pure" intervals (which in psychoacoustic tests<br>are consistently heard as "flat" or "too narrow").  Nor does the modern <br>place theory explain combination tones, (as mentioned above), or <br>the fact that two inharmonic-series tones matched to an inharmonic-<br>series scale sound strongly consonant (Risset, 1978, 1984, 1985; <br>Sethares, 1992; Geary, 1980; Pierce, 1966; Carlos, 1987; Plomp and<br>Levelt, 1965, Kameoka and Kuriyagawa, 1969); nor does the <br>place theory explain (or predict)  modern auditory illusions--<br>Shephard's tones,  Risset's tone containing ten 1180-cent<br>intervals which when transposed UP an octave DROPS <br>in audible pitch by a perceived 20 cents, etc.<br>All of these phenomena *can* be explained by the periodicity <br>theory of hearing as emergent  properties of an autocorrelation<br>system.<br>However, the periodicity theory itself has a number of problems.<br>It does not explain the universal human preference for stretched<br>octaves, fifths and thirds, a preference found in the earliest<br>experiments performed on measured intervals and in all <br>double-blind psychoacoustic tests performed for 150 years <br>since;  the periodicity theory of hearing cannot account for the <br>fact that pitches very close together create a "chorus" effect <br>instead of massive dissonance. By contrast, the broad region<br>of general stimulation of the basilar membrane around the<br>much narrow region of maximal stimulation--one of the hallmarks<br>of the place theory--explains this effect simply and clearly.<br>The phenomenon of combination tones is poorly explained by *both*<br>competing hypotheses. As Plomp points out, "This problem applies<br>both to place pitch and periodicity pitch. If pitch is based on the place<br>of maximal vibration, it is essential for hearing a combination tone that<br>the corresonding place of the basilar membrane is stimulated. Then the<br>question may be asked of how this can be accomplished by sensory<br>processes of hair cells at a distant place of the cochlea. The ascertainment<br>of Six (1956) that cochlear microphonics correponding to combinationg tones have their maximum at the same place as the primary tones, contradicts this possibility.<br>If, on the other hand, pitch is based on the periodicity of nerve impulses, <br>the problem arises how impulses that  are synchronous with the frequency of combination tones can be initiated when the waveform of cochlear<br>michrophonics is flattened (the common form of distortion)" [Plomp, 1966, pg. 121]<br>Summing up, James Pickles points out that "Frequency difference limens<br>are very much smaller than cirtical bands. Two mechanisms are possible.<br>For instance, the subject may detect shifts in the place of excitation<br>in the cochlea. This is called the "place theory." Or he may used temporal<br>information.  We know that the firing int he auditory nerve is phase-locked<br>to the stimulus waveform up to about 5 khz. In this theory, called the<br>"temporal" [or "periodicity] theory, the subject discriminates the<br> two tones by using the tme interval between the neural firings. It is not<br>clear which of the two mechanisms is used.  Indeed the controversy has been<br>active for more than 100 years, and the fact that it is not yet settled shows<br>that we still do not have adequate evidence.  Auditory physiolgoists divide<br>into three groups, namely those that think only temporal information is used, those that think only place information is used, and an eclectic<br>group, who suppose that temporal information is used at low frequencies,<br>and only place information at high." [Pickles, James O., "An Introduction<br>To the Physiology of Hearing," Academic Press, 2nd ed., 1988, pg. 271]<br>The implications for musical tuning are mixed.  Because no clear evidence<br>has emerged in favor of any of the three major theories of hearing, <br>no single tuning can be considered to "privileged" or uniquely suited<br>to the human ear.  On the other hand, because of the mixed results<br>from pscyhoacoustic experiments, the data examined so far would<br>tend to support the use of any of the major categories of musical<br>tuning: namely, just intonation, equal temperament, or non-just non-<br>equal-tempered scales.<br>The next post will discuss several modern experiments which provide<br>evidence for the third "pattern recognition" hypothesis of hearing,<br> and the implications of all 3 of these hypothetical auditory mechanisms <br>for music & tuning.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Fri, 29 Sep 1995 19:07 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id KAA23266; Fri, 29 Sep 1995 10:07:19 -0700<br>Date: Fri, 29 Sep 1995 10:07:19 -0700<br>Message-Id:  <9509291007.aa21406@cyber.cyber.net><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2083 href="#2083">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>9/30/1995 9:09:50 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Tuning & Psychoacoustics - post 7 of 25<br>---<br>We've seen that three competing theories<br>of pitch perception have tried to explain<br>the ear-brain system since the middle<br>of the 1840s.  No one model accounts<br>for all the ear's behaviour, and some evidence<br>contradicts each hypothesis.<br>"Protagonists of both place and time theories<br>point out how small the detectable limits are<br>when translated into the terms of the other theory.<br>Temporal [i.e., periodicity] theorists point out that a frequency<br>discrimination limen of 3 Hz at 1 Khz corresponds<br>to a shift in the pattern of excitation on the basilar<br>membrane of 18 microns, or the width of 2 hair cells.<br>Place theorists point out the that the same limen<br>corresponds to a time discrimination of 3 microseconds,<br>as against some 1000 microseconds for the width of a<br>nerve action potential, and a variability of some hundreds<br>in its intiation.  (..) There are several lines of evidence<br>for and against these two theories, none of which is<br>conclusive." [Pickles, James O., "An Introduction to<br>the Physiology of Hearing," Academic Press, 2nd.<br>ed., 1988, pp. 271-272.]<br>At this point it's instructive to step back<br>and recall that all cultures are conceptually<br>limited by their experience.  The Cargo Cult<br>of the South Seas Islands during WW II arose<br>because the islanders fitted B-17s into<br>their experience as godlike birds from<br>a supernatural realm.<br>In the same way,  the most sophisticated<br>means of frequency analysis available to<br>Helmholtz was a set of tuned glass resonators.<br>By putting his ear to these globes, he could hear<br>a particular resonant frequency amplified out<br>of a complex harmonic timbre.  So it was<br>natural for Helmholz to model the ear/brain<br>system as a set of millions of tuned<br>resonators.<br>As technology advanced during the late 19th<br>and early 20th century,  high-precision machine<br>tools became available.  So it was natural for<br>von Bekesy & others to model the ear/brain system as<br>a precision machine for performing mechanical<br>Fourier transforms of complex harmonic sounds.<br>[For more details on these hypotheses, see:<br>Helmholtz, "On the Senations of Tone," 1863;<br>Plomp, R. "The ear as a frequency analyzer," JASA,<br>1964, vol. 36, pp. 1628-1636;  Boomsliter & Creel,<br>"The Long Pattern Hypothesis of Pitch and Harmony,"<br>Journ. Mus. Theory, Vol. 5, 1961, p. 1-12; von<br>Bekesy, G. "Concerning the Fundamental Component<br>of Periodic Pulse Patterns and Modulated Vibrations<br>Observed on the Cohlaer Model with nerve Supply,<br>JASA, Vol. 33, 1961, ppg. 888-896; von Bekesy,<br>"Three Experiments Concerned with Pitch<br>Perception," JASA, Vol. 35, pp. 602-606, 1963;<br>von Bekesy, G. "Hearing Theories and Complex<br>Sounds," JASA, Vol. 35, pp. 588-601, 1963;<br>Licklider, J.C. R. : "Periodicity Pitch and Related<br>Auditory Process Models," Intern. Audiol. Vol. 1,<br>pp. 11-36, 1962.]<br> Then  in the 1940s and 1950s computers became<br>available, and with them software.<br>So it became natural for modern researchers to<br>model the ear/brain system as a combination<br>of hardware and software, with software<br>performing the crucial functions of pitch<br>detection, perception of consonance, dissonance,<br>etc.  Thus we now see papers like: Goldstein, J.R.<br> "An optimum  processor theory for the central formation of the<br>pitch of complex tones," JASA, 1973, Vol. 54, pp.<br>1496-1616; Wightman, F. I. "The pattern-<br>transformation model of pitch," JASA, 1973,<br>vol. 54, pp. 407-416.<br>So what do we have?<br>Quite possibly, a series of cargo cults.<br> The ear/brain system is viewed<br>by each era in terms of the most convenient<br>available paradigms, regardless of whether<br>those paradigms are actually appropriate.<br>In an interview with Curtis Roads, Max Mathews<br>summarized all 3 theories of hearing with<br>typical elegance and pith: "In a book first published<br>in 1863, Helmholtz proposed that dissonance<br>arises from unpleasant beats between partials<br>whose drequencies are too close together. [4] The<br>octave is the most consonant of intervals because<br>all of the partials of the upper coincide in frequency<br>with partials of the lower tone. (...) Rameau had<br>another view of harmony. [6] He observed that<br>in a major triad all frequencies present are integer<br>multiples of a basse fundamentale or fundamental<br>bass which, in the root position of the chord (C, E, G)<br>lies two octaves below the root of the chord. (...)<br>But, one might hold that musical harmony is merely<br>a matter of brainwashing; that we accept combinations<br>of tones that we have been taught are correct, and<br>reject those that we have been taught are incorrect.<br>We have some experimental evidence that bears on<br>this." [Mathews, M. and Pierce, J.R. "Harmony and<br>Non-Harmonic Partials," Rapports IRCAM, 1980, pp. 3<br>-5]<br>The above passage describes clearly the 3<br>different competing hypotheses of hearing<br>still competing even today: namely,  [1] that<br>the ear is a frequency-domain Fourier analyzer;<br>[2] that the ear is a time-domain autocorrelator;<br>[3] that the ear/brain system uses a learned<br>neural net system of pitch/interval recognition<br>and consonance/dissonance classificiation.<br>The contradictory results of experiments on<br>pitch sensation lead to the conclusion that<br>some aspects of all of these 3 models of human<br>hearing bear some relation to the ear/brain<br>system's actual operation.  However, because<br>some of the experimental results are contradicted<br>by each of these 3 models of hearings,  it<br>is inescapably clear that under various<br>circumstances one or more of these ear/brain<br>hearing systems becomes dominant, and in<br>some cases (particularly in the case of<br>auditory illusions) all 3 of the ear/brain<br>systems can clash and yield conflicting<br>results.<br>These  3 separate hypothetical mechanisms<br>for processing  both vertical and horizontal<br>(sequential) pitch are: [1] a frequency-based or<br>Fourier analysis system; [2] a time-based or<br>autocorrelative system; [3] ear/brain "wetware"<br>that includes a strong learned component,<br>and which is capable of actively filtering<br>out auditory information, creating illusory<br>auditory information, and transforming some<br>or all of the information conveyed from the<br>basilar membrane and the hair cells  to the auditory<br>nerve, and from there into the Sylvian fissure,<br>the superior medial olive and the geniculate<br>nucleus--all areas in the brain responsible<br>for dealing with aspects of auditory perception.<br>This last point is important, because it is now<br>known that musicians and non-musicians use<br>different brain centers when hearing the same<br>music.  Musicians show glucose metabolism<br>primarily in the left brain when listening to<br>music, while non-musicians show glucose<br>metabolism both brain hemispheres.<br>These PET scan results offer strong<br>confirmation of the third model of hearing--<br>what Mathews and Pierce call the "brainwashing"<br>hypothesis, the model of hearing as molded by<br>learned response (first put forward by Fetis and<br>Alexander J. Ellis in the middle of the 19th century).<br>While the Fourier analysis model of the ear/brain and<br>the autocorrelative (or periodicity pitch) model<br>have been extensively documented, what<br>about experiments documenting the "wetware"<br>component of the ear/brain system?<br>Auditory illusions provide strong evidence<br>for this hypothesis of the ear/brain<br>system: Shepard, R. N., "Circularity in<br>judgments of relative pitch," JASA, 1964,<br>vol. 36, pp. 2346-2353; McAdams, S.<br>and Bregman, A. "Hearing Musical Streams,"<br>Computer Music Journal, 1979, Vol. 3,<br>pp. 26-44; Locke, S. and Kellar, L., "Categorical<br>percpetion in a non-linguistic mode," Cortex,<br>Vol. 9, 1973, pp. 355-369; Cohen, A. "Inferred<br>sets of pitches in melodic perception,"<br>In R. Shepard, Cognitive structure of musical<br>pitch," symposium presented at the meeting<br>of the Western Psychological Association, San<br>Francisco, CA, April 1978; Burns, E. M. and<br>Word, W. I., "Categorical perception--phenoneon<br>or eiphenomenon: Evidence from experiments<br>int ehperception of melodic musical intervals,"<br>JASA, 1978, vol. 63, pp. 456-468; Blcehner,<br>M.J. "Musical Skill and categorical perception<br>of harmonic mode," Status Report on Speech<br>Perception, SR-51/52. New Maven, Connecticut,<br>Haskins Laboratories, 1977, pp. 139-174;<br>Balzano, G. J., "Musical versus psychoacoustical<br>variables and their influence on the perception<br>of musical intervals," Bulletin of the Council<br>for Research in Music Education, 1981; Bachem,<br>A. "Tone Height and tone Chroma as two different<br>pitch qualities," Acta psychogica, 1950, vol.<br>7, pp. 80-88; Moreno, E., "Expanded Tunings in<br>Contemporary Music: Theoretical Innovations and<br>Practical Applications," Vol. 30, Studies in the<br>History and Interpretation of Music, The Edwin<br>Meller Press, Lewiston: 1992; Moreno, E. "The<br>Existence of Unexplored Dimensions of Pitch:<br>Expanded Chroma," Proc. ICMA, 1992, pp. 404-405;<br>Pierce, J.R. "Attaining Consonance in Arbitrary<br>Scales," JASA, 1966, pg. 249;  Butler, J. W. and<br>Daston, P. G., "Music Consonance as Musical<br>Preference: A Cross-Cultural Sutdy," Journ. of Gen.<br>Spcyh.., 1968, vol. 79, pp. 129-142; Hutchinson,<br>W. and Knopoff, L., "The Acoustic Component of<br>Western Consonance," Interface, Vol. 7, 1978,,<br>pp. 1-29; Watkins, A. J., "Perceptual Aspects of<br>synthesized approximations to Melody," JASA,<br>Vol. 78 No. 4, 1985, pp. 1177-1186; Pikler, A. G.,<br>Mels and Musical Intervals," Journ. Mus. Theory,<br>Vol. 10, 1966, pp. 288-298; Risset, J-C., "Musical<br>Acoustics,"  Rapports IRCAM 1978, pp. 7-8.<br>Why are these 3 models of ear/brain function<br>important to musicians in the real world?<br>They're of crucial concern to microtonalists because<br>if the place theory is right, then just intonation is<br>the ideal tuning.  If the periodicity theory is the<br>correct description of how the ear hears, then<br>many tunings are acceptable provided that the<br>interval between the fundamental and the first<br>partial, and twix each subsequent pair of partials,<br>is larger than the critical band at that frequency.<br>As Pickles points out, the periodicity theory does<br>*not* offer support for conventional Western<br>musical practice: "It might be thought that the<br>pleasant consonance of simple musical intervals<br>depends on the simple relations between their periods,<br>resulting in synchronous nerve firing.  However,<br>once it is realized that most musical notes are<br>rich in overtones, and that consonance might depend<br>on a lack of beats between the harmonics, the<br>argument cannot be used to support the importance<br>of time information." [Pickles, James O., "An Introduction<br>To the Physiology of Hearing," Academic Press, 2nd ed.,<br>1988, pg. 274]<br>On the other hand, if Fetis/Ward/Burns' "pattern<br>recognition" hypothesis of the ear as a pliable active<br>feedback system molded by learned response is the true<br>picture of human hearing, then *any* type of tuning is<br>acceptable.  After a while, the listeners will<br>become acculturated and learn to accept *any*<br>arbitrary interval as "consonant" or "dissonant."<br>And what if elements of all three models are<br>at work in the ear/brain system?<br>In that case, the implications for musical tuning<br>are more complex--a situation which will be<br>considered in the next post.<br>--mclaren<br>&<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Sun, 1 Oct 1995 02:44 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id RAA20743; Sat, 30 Sep 1995 17:43:51 -0700<br>Date: Sat, 30 Sep 1995 17:43:51 -0700<br>Message-Id: <9510010034.AA17220@us2rmc.zko.dec.com><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2085 href="#2085">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/1/1995 9:31:39 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Tuning & Psychoacoustics - post 8 of 25<br>---<br>As xenharmonists, it's of some interest to us<br>exactly how the ear/brain system works.  If the<br>human ear favors one tuning system over another,<br>we want to know about it. <br>Alas, the evidence is far from clear, and there are<br>problems with all three hypotheses of ear/brain<br>function.<br>Concerning the place and periodicity hypotheses<br>of hearing, "On current evidence, it is not possible<br>to decide betwene the temporal and place theories<br>of frequency distribution. (..) In any case the best<br>support for the eclectic [pattern recognition] view<br>is the rather negative one that the evidence in favour<br>of either of the other two theories is not conclusive,<br>and this may be a function of the quality of evidence<br>available, rather than of the actual operation of the<br>auditory system." [Pickles, James O., "An<br>Introduction to the Physiology of Hearing," Academic<br>Press,  2nd ed., 1988, pg. 277]<br>Risset summarizes the evidence for and problems<br>with all 3 proposed ear/brain mechanisms in<br>his 1978 IRCAM report: "Numerological theories of<br>consonance suffer difficulties. Because of the<br>ear's tolerance, intervals corresponding to 3:2 (a<br>simple ratio) and 300,001/200,000 (a complex <br>ratio) are not discriminated. Also psychophysiological<br>evidence indicates that numerical ratios should not<br>be taken for granted. The subjective octave corresponds<br>to a frequency ratio a little larger than 2, and is<br>reliably different for different individuals (Ward,<br>1954; Sundberg and Lindqvist, 1973); this effect<br>is increased by sleep-deprivation (Elfner, 1964).<br>There are also physical theories of consonance. <br>Helmholtz (1877) links the degree of dissonance<br>to the audibility of beats between the the partials<br>of the tones.  This theory is hardly tenable, <br>because the pattern of beats, for a given interval,<br>depends very much on the placement of the<br>interval within the audible frequency range. Recent<br>observations (Plomp, 1966) suggest an improved<br>physical explanation of consonance: listeners find<br>that the dissonance of a pair of pure tones is maximum<br>when the tones are about a quarter of a critical<br>bandwidth apart; the tones are judged consonant<br>when they are more than one critical bandwidth<br>apart. Based on this premise, Pierce (1966, also<br>in von Foerster and Beuachamp, 1969, pp. 129-132)<br>has used tones made up on non-harmonic partials, <br>so taht the ratios of fundamnetal leading to<br>consonance are not the conventional ones:<br>Kameoka et al. (1969). have developed an <br>involved method to calculate the magnitude<br>of disonance...<br>"Whereas the explanation put forth by Plomp<br>can be useful to evalutate the "smoothnesss"<br>or "roughness" of a combination of tones, it<br>is certainly insufficient to account for<br>musical consonance. In a laboratory study,<br>Van de Geer et al., (1962) found that intervals <br>judged the most consonant<br>by laymen do not correspondent to the ones<br>usually term consonant. This result is<br>elaborated by recent work by Fuda and Wessel (1977).<br>The term consonance seems ambiguous, since it <br>refers at the same time ot an elemental level,<br>where "smoothness" and "roughness" are<br>revaluated, and to a higher esthetic level,<br>where consonance can be functional in a given<br>style. The two levels are related in a culture-<br>bound fashion. In music, one does not judge only<br>the consonance of isolated tones: as Cazden (1945)<br>states, "context is the determining factor. (...) the<br>resoution of intervals does not have a natural<br>basis; it is a common response acquired by all<br>individuals within a culture area (cf. also Lundin,<br>1947)." Musical consonance is relative to a musical<br>style ( Guernesey, 1928); ninth chords, dissonant<br>in Mozart's music, are treated as consonant by<br>Debussy (Chailley, 1951; Cazden, 1962, 1968, 1972).<br>The cultural and contextual aspects of musical<br>consonance are so important that, despite nativists'<br>claims to the contrary, purely mathematical and/or<br>physical explanations can only be part of the story.<br>cf. Costere, 1962)." [Risset, J-C., "Musical Acoustics,"<br>Rapports IRCAM, 1978 pp. 7-8]<br>In short, all 3 hypotheses of hearing explain different<br>aspects of the  ear/brain system.  Depending on the<br>acoustic stimulus, different systems appear to  operate<br>to process sound. This is most powerfully evidenced by Sethares,<br>W., "Local Consonance and the Interaction between<br>Timbre and Tuning," JASA, vol. 94 No. 3, 1993, pp. 1218-1219,<br>Slaymaker, J., "Inharmonic Tones," JASA         1970, and <br> Roads, C. "An Interview with Max Mathews," Computer Music<br>Journal, 1980.  <br>In the latter, Mathews points out: <br>"Our initial experiments were aimed at finding <br>out what properties of normal harmonic music<br>carried over to music that was made with<br>stretched overtones. We found some things<br>carried over and some things did not. The<br>sense of "key" carried over better than we<br>expected.<br>ROADS: So you can actually detect "keys" in<br>sequences of completely inharmonic sounds.<br>MATHEWS: That's right. You play two samples<br>and a person can reliably say whether they're<br>in the same or a different key.<br>Other properties do not carry over. The sense<br>of finality in a traditional cadence does<br>not carry over. A person who hears a cadence<br>with unstretched tones says, "That sounds<br>very final to me." When he hears the same<br>cadence played with stretched tones, he'll<br>say "That doesn't sound especially final." But<br>we have been able to make other inharmonic<br>materials which do convey a sense of cadence.<br>(...)<br>ROADS: If we can detect "keys" and some form<br>of finality within a cadence or progressions<br>within inharmonic tones, then some of the <br>theories of harmony in the past must not have<br>been as cogent as some of their proponents<br>have thought them to be.<br>MATHEWS: Our results are contradictory. We<br>loked at two theories. One was the Rameau<br>theory of the fundamental bass, and the other<br>was the Helmholtz and Plomp theory of the<br>consonance and dissonance of overtones. The<br>destruction of the cadence would support<br>the Rameau theory and the persistence of<br>the sense of key would support the Helmholtz<br>and Plomp theory. So we have one result which<br>supports one theory and one which supports the <br>other, with the overall conclusion that the world <br>a more complicated place than we had perhaps<br>hoped it was. We will have to dig deeper<br>before we can say which is causing<br>the various perceptions we find meaningful<br>to music" [Roads. C, "An Interview With Max<br>Mathews, Comp. Mus. Journ., Vol 4 No. 4, 1980,<br>pp. 21-22]<br>MYTH: PITCH PERCEPTION IS SIMPLE, AND<br>CONSONANCE, DISSONANCE AND HARMONY<br>CAN BE EXPLAINED BY EITHER RAMEAU'S<br>OR HELMHOLTZ'S MODELS<br>FACT: Musical phenomena are a complex<br>interaction of at least 3 ear/brain mechanisms<br>for recognizing and assigned pitch, and<br>each ear/brain system can conflict with<br>the other 2, leading to paradoxical results,<br>auditory illusions and a great deal of learned<br>behaviour on the part of the listener as to<br>what "consonance," "dissonance," and even what<br>"pitch" is.<br>This latter will prompt the usual screams<br>of protest from those into whose brainpans<br>little information about modern psychoacoustics<br>has dripped; thus it is important to<br>make clear that even something as purportedly<br>"elementary" and "innate" as the pitch sense<br>displays extremely complex behaviour. <br>The next post will examine the meaning(s)<br>of the term "pitch," the psychophysical<br>factors which influence its perception, and<br>the implications for tuning & music.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Sun, 1 Oct 1995 20:53 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id LAA27839; Sun, 1 Oct 1995 11:52:54 -0700<br>Date: Sun, 1 Oct 1995 11:52:54 -0700<br>Message-Id: <199510011852.AA24025@net4you.co.at><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2090 href="#2090">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/2/1995 9:12:35 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Tuning & Psychoacoustics - Post 9 of 25<br>---<br>"A theory should as simple as possible--<br>but not simpler." -- Albert Einstein<br>---<br>MYTH: PITCH IS THE LOGARITHMIC FREQUENCY<br>HEIGHT OF A MUSICAL TONE, AND ITS<br>PERCEPTION IS AUTOMATIC AND INNATE.<br>Fact: There are 3 kinds of pitch: physical,<br>mel and perceptual pitch.  The 3 differ<br>significantly. Perceptual pitch is never<br>identical to the log of the frequency of<br>the fundamental of the perceived tone,<br>and mel pitch differs radically from both.<br>The perception of all 3 kinds of pitch is<br>strongly influenced by both context and<br>learned experience.<br>---<br>The perceived pitch of sine tones depends<br>on their duration and their loudness. "A<br>150-Hz tone increasing from 45 to 90 dB<br>drops in pitch to an extent corresponding<br>to a 12% frequency shift. This is close<br>to 2 semitones in the diatonic scale. The<br>sensitivity to this effect varies considerably<br>between individuals. (...) A funny consequence<br>of this is that a soft sine tone at 300 Hz<br>may sound as a pure octave of a loud sine<br>tone at 168 Hz. The mathematically pure<br>octave, however, has the frequency of 150<br>Hz. The tone that sounds as a pure octave<br>is 12% too high. This means that mathematically<br>it is a minor seventh! This is a good argument<br>for avoiding confusion of perceptual and physical<br>entities." ["The Science of Musical Sounds,"<br>Sundberg, 1992, pg. 46]<br>Pierce explains that "By asking naive subjects<br>to relate frequency changes of sine waves to<br> a halving of pitch, psychologists found a mel<br>scale of pitch (for sine waves). In the mel scale<br>there is no simple relation between frequency<br>and pitch; nothing like the octave shows up. (...)<br>The sounds of orchestral bells are not periodic,<br>and these sounds do not have all the properties<br>of periodic musical sounds. One can play tunes<br>with bells, and the pitches that are assigned<br>to bells can be explained largely in terms<br>of the frequencies of prominent almost-<br>harmonic partials.<br>"Clucking sounds and shushing sounds (bands<br>of noise) have  brightness, but no<br>periodicity. Oddly, *we can play a <br>recognizable tune with these sounds,<br>even though they cannot be heard as <br>combining into chords or harmony.* <br>Apparently, in the absence of a clear pitch,<br>brightness can suggest pitch.' ["The Science<br>of Musical Sound," Pierce, J.R. 1992, <br>pg. 37]<br>"Systematical series of experiments have been<br>carried out in which listeners have been <br>asked to adjust the frequency of a variable<br>tone so that it sounds "twice as high"<br>or "half as high" as a reference tone. (...)<br>The mel scale is constructed such that<br>a halving of the number of mels corresponds<br>to a halving of the pitch perceived. As<br>shown in the figure, a tone with the pitch<br>of 1,000 mel sounds twice as high as<br>another tone with the pitch of 500 mel.<br>Examination of the figure tells us this<br>corresponds to a frequency shift from<br>approximately 1,000 to 380 Hz." ["The<br>Scinece of Musical Sounds," Sundberg,<br>1992, pg. 47]<br>The mel scale of pitch measures what<br>is also sometimes called "ratio pitch."<br>This is drastically different from the<br>ordinary scale of perceptual musical<br>pitch, since the mel scale applies only<br>to sine tones.  <br>However, the plot thickens as soon as<br>we realize that *many musical timbres<br>can be modelled as sums of sine waves.*<br>Thus the conceptual basis for <br>conventional harmonic-series models<br>of consonance, as well as for the <br>purported acoustic superiority of<br>small whole-number ratios,<br>comes into doubt as soon as we<br>begin to examine the psychoacoustic<br>evidence in detail.  If perceptual<br>pitch is always different from <br>physical logarithmic pitch, how <br>can either equal-tempered or<br>just intonation tunings offer a<br>valid model for musical harmony<br>and musical melody?<br>To make matters even more complex,<br>"In certain cases the amplitude <br>dependence of the pitch of complex<br>tones is the opposite of that shown<br>in Figure 3.4. If the loudness of a <br>complex tone of about 100 Hz <br>fundamental frequency is increased,<br>its pitch may rise rather than drop."<br>["The Science of Musical Sounds,"<br>Sundberg, 1992, Pg. 46]<br>"The pitch of pure tones depends not <br>only on frequency, but also on other<br>parameters such as sound pressure<br>level. (...) Pitch shifts of pure<br>tones can also occur if additional<br>sounds that produce partial masking<br>are presented.  Pitch shifts produced<br>by a broad-band noise masker are<br>shown in Fig 5.4, and are given as<br>a function of both frequency and<br>critical-band rate of the pure tones,<br>the level of which is 50 dB. (...)<br>The results display in Fig 5.5 show pitch<br>shifts up to 8% at low frequencies<br>near 300 Hz, and a pitch shift<br>of only 1% at higher frequencies<br>between 1 and 4 kHz, due to the octave<br>ratio of partial-masking tone<br>and test tone." ["Psychoacoustics: <br>Facts and Models," Zwicker<br>and Fastl, 1993, pp. 105-107]<br>The pitch of pure tones is also<br>dependent on their duration. <br>Doughty and Garner (1948) found<br>that pitch is unchanging for tones of <br>25 msec and longer, but that<br>12-msec and 6-msec tones have<br>a lower pitch. [See Doughty, J. M and<br>Garner, W.R. "Pitch Characteristics<br>of short tones. II: Pitch as a function<br>of tonal duration," J. Exp. Psychol.,<br>Vol. 38, pp. 478-494, 1948]<br>Corso summed up the situation when<br>he concluded that "the pitch of musical<br>sounds is not directly proportional to<br>the logarithm of the frequency and is<br>probably complexly conditioned." [Corso,<br>J.F., "Scale Position and Performed Musical<br>Octaves," Journal of Psychology, Vol. 37,<br>1954]<br>In short, most of what musicians<br>"know" about pitch is untrue,<br>at least as far as pure sine tones<br>are concerned.   This casts strong<br>doubt on tuning theories which ascribe<br>to various pitch relationships "special"<br>characteristics--in particular, the<br>data adduced in this post casts strong<br>doubt on both just and equal-tempered<br>tuning systems, and would tend instead<br>to favor non-just non-equal-tempered<br>tunings.<br>What about complex tones made<br>up of many sinusoidal components<br>and the influence of learning and<br>context?  What are the implications<br>for tuning and for music?<br>That's the topic of the next post.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Mon, 2 Oct 1995 19:10 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id KAA17686; Mon, 2 Oct 1995 10:10:07 -0700<br>Date: Mon, 2 Oct 1995 10:10:07 -0700<br>Message-Id: <Pine.A32.3.91.951002110443.55513A-100000@tiger.cudenver.edu><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2095 href="#2095">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/3/1995 8:22:15 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Tuning & psychoacoustics - post 10 of 25<br>---<br>So far we have seen the complexity of the ear's response to pitch; not a <br>quantity linearly proportional to the logarithm of frequency, pitch appears <br>to be influenced by many aspects of timbre--amplitude, masking tones, <br>overtone harmonicity, and range of the note played.  <br>The ear's perception of complex sounds is equally complicated.<br>"Both von Helmholtz and Wundt based the development of harmony and <br>melody on the coinciding harmonics for consonant intervals." [Plomp, R. and <br>Levelt, W.J.M., "Tonal Consonance and Critical Bandwidth," Journ. Acoust. <br>Soc. Am., Vol. 6, No.1, April 1965, pg. 549]<br>Simple experiments, conducted in the 1960s, showed this not to be the case.<br>"On the basis of more recent and more sophisticated experiments (Plomp and <br>Levelt, 1965) on consonance judgment involving pairs of pure tones and <br>inharmonic complex tones, it became apparent that the beats between <br>harmonics may not be the major detemrining factor in the perception of <br>consonance. Two pure tones an octave or less apart were presented to a <br>number of musically naive (untrained) subjects who were supposed to give a <br>qualification as to the "consonance" or "pleasantness" of the superposition. <br>A *continuous pattern* was obtained, that did not reveal preferences for <br>any partuclar musical interval. Whenever pure tones are less than about a <br>minor third apart, they were judged "dissonant" (except for the unison); <br>intervals equal orlarger than minor third were judged as more or less <br>consonant, irrespective of the actual frequency ratios.  The shape of the <br>curve really depends on the absolute frequency of the fixed tone." [Roederer, <br>J., "The Physics and Psychophysics of Music," 1973, Pg. 142] <br>Plomp and Levelt called this interval, somewhat smaller than a minor third, <br>"the critical bandwidth."  It changes size slightly at lower frequencies.  <br>"...maximal tonal dissonance is produced by intervals subtending 25% of the <br>critical bandwidth, and maximal tonal consonance is reached for interval <br>width of 100% of the critical bandwidth." [Plomp, R. and Levelt, W.J.M., <br>"Tonal Consonance and Critical Bandwidth," Journ. Acoust. Soc. Am., Vol. 6, <br>No.1, April 1965, pg. 549]<br>"An interesting consequence of the significance of the critical bandwidth is <br>that the degree of dissonance of a dyad depends on many factors other than <br>the frequency ratio.  If the tones have many strong overtones, the <br>consonance quality is reduced.  A consonant dyad becomes increasingly <br>dissoannt when it is transposed downward on the frequency scale, just as <br>for sine tones. For example, a major third sounds reasonably consonant <br>around A4, but if played close to C2 it sounds quite dissonant on most <br>instruments.  The relation between consonance and frequency ratios is also <br>entirely dependent on whether the tones have harmonic spectra.<br>"Consonance is apparently a highly conditioned phenomenon. It is stimulating <br>to realize that the dissonance/consonance concept in music theory would <br>have been entire different if our musical instruments had not provided us <br>with harmonic spectra!" [Sundberg, J., "The Science of Musical Sounds,"1992, <br>pg. 85]<br>This finding lends support to all three tunings (just, equal tempered, non-<br>just non-equal) provided that the partials of the musical notes are changed <br>so as to fit the tuning.<br>As mentioned above, Plomp's and Levelt's findings (extended and refined by <br>Kameoka and Kuriyagawa's formula for calculating the consonance of <br>complex tones) also casts doubt on many conventional "rules" of harmony <br>and melody--even if just intervals and perfectly harmonic overtones are <br>used: "As an application of the consonance theory, effects of harmonic <br>structure on the consonance characterisc are discussed. (...) <br>(...) It became clear that the fifth was not always a consonant interval.  A <br>chord of two tones that consists of only odd harmonics, for example, shows <br>muchworse cosnonance at the fifth (2:3) than at the major sixth (3:5) or <br>some other frequency ratios.  This was proved true  by psychological <br>experiments carried out in another institute (sensory Inspection Committe <br>in the Japan Union of Scientists and Engineers) with a different method of <br>scaling. Thus, the fact warns against making a mistake in applying the <br>conventional theory of harmony to synthetic musical tones that can take <br>variety in the harmonic structure." [Kameoka, A., and Kurigawa, M., <br>"Consonance Theory Part II: Consonance of Complex Tones and Its <br>Calculation Method," Journ. Aoucst. Soc. Am., Vol. 45, No. 6, 1969, pg. 1460]<br>Because consonance and dissonance depend not on the harmonicity of two <br>complex tones, but on the coincidence (or lack thereof) of their component <br>partials within the critical bandwidth for that frequency range, "...these <br>examples refer to a vast domain opened up by digital synthesis, namely that <br>of inharmonic tones.  Most sustained instrumental tones are equasi-<br>periodic, and their frequency components are harmonically related, which <br>stresses certain intervals like the octave and the fifth.  With the freedom of <br>constructing tones from arbtirary frequency components, one can break the <br>relationship between consonance-dissonance aspects and fixed, privileged <br>intervals (Pierce 1966). In his piece Stria (1977), Chowning has thus been <br>able to make rich textures permeate each other without dissonance or <br>roughness, by controlling the frequencies constituting these textures. This <br>is also a case where spectra not only play a coloristic role (see Roads 1985) <br>but actually peform a quasi-harmonic function." [Risset, J.C., "Digital <br>Techniques and Sound Structure in Music," in "The Music Machine," ed. Curtis <br>Roads, 1985, pg. 122]<br>"By using a digital computer, musical tones with an arbitrary distribution of <br>partials can be generated.  Experience shows that, in accord with Plomp's <br>and Levelt's experiments with pairs of sinusoidal tones, when no two <br>successive partials are too close toegher such tones are consonant rather <br>than dissonant, even though the partials are harmonics of the fundamental.  <br>For such tones, the conditions for consnance of two tones will not in general <br>be the traditional ratios of the frequencies of the fundamentals. (...)  It <br>appears that, by providing music with tones that have accurately specified <br>but nonharmonic partial structures, the digital computer can release music <br>from the tyranny of 12 tones without throwing consonance overbarod." <br>[Pierce, J.R., Journ. Acoust. Soc. Am., Vol. 6, No. 12, 1966, pg. 249]<br>"I suggest that the nonharmonic domain of frequency relationships may in <br>some way contain a necessary system of hierarchical structural functions."  <br>[Dashow, J.,  "Spectra As Chords," Computer Music Journal, 1980]" <br>"The hypothesis has been made that perceived  effects similar to the <br>consonance and dissonance experienced with harmonic tones  should exist <br>for inharmonic tones. Clearly, it cannot be claimed that the perceptions are <br>exactly the same, since inharmonic and harmonic tones themselves sound <br>different to the ear. However, the experiments do establish a similarity <br>between the consonance dissonance phenomenon in harmonic and inharmonic <br>sounds." [Geary, J.M., "Consonance and Dissonance of Pairs of Inharmonic <br>Tones,"  J.Acoust. Soc. Am, 67 (5), May 1980]<br>"The chords sounded smooth and nondissonant but strange and somewhat <br>eerie. The effect was so different from the tempered scale that there was <br>no tendency to judge in-tuneness or out-of-tuneness. It seemed like a peek <br>into a new and unfamiliar  musical world, in which none of the old rules <br>applied, and the new ones, if any, were yet undiscovered." [Slaymaker, F. H, <br>"Chords From Tones Having Stretched Partials," J. Acoust. Soc. Am., Vol. 47, pp. 1469-1471, 1970]<br>"We have to compose real music of many kinds within all and any of our new <br>tuning schemes, if this work is to have any lasting value at all, or be taken <br>seriously by the music community..."[Carlos, W., "Tuning: At the Crossroads," <br>Computer Music Journal, 1987] <br>In short, "Experiments with inharmonic partials (Slaymaker, 1970; Pierce, <br>1966) have shown that consonance or dissonace is indeed dependent on the <br>coincidence of partials and not necessarily on the simple frequency ratio <br>between the fundamnetal frequencies..." [Rasch, R.A. and Plomp, R., "The <br>Perception of Musical Tones," in "The Psychology of Music," ed. Diana <br>Deutsch, 1982, pg. 21]. Thus all three tuning systems appear equally viable <br>on the basis of the evidence considered in this post, given a digital or acoustic instrument whose partials are matched to the  tuning system <br>in question.<br>The next post will discuss the important phenomenon of categorical<br>perception, and its implications for tuning and music.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Tue, 3 Oct 1995 19:30 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id KAA04880; Tue, 3 Oct 1995 10:30:18 -0700<br>Date: Tue, 3 Oct 1995 10:30:18 -0700<br>Message-Id: <m0t0B81-000FwjC@frollo.fa.disney.com><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2097 href="#2097">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/4/1995 10:18:47 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Tuning & Psychoacoustics - Post 11 of 25<br>---<br>MYTH: "I KNOW WHAT MY EARS HEAR AND<br>I KNOW WHAT A 'PURE' OCTAVE, A 'PURE'<br>FIFTH, AND A 'PURE' THIRD IS."<br>FACT: Because of the phenomenon of<br>categorical perception, none of us know<br>we actually hear--as opposed to what<br>our ear/brain system brainwashes us<br>into *believing* we hear.  The only way to<br>actually *determine* what you're<br>hearing (rather than what you *think*<br>you're hearing) is to use double-blind<br>psychoacoustic tests.<br>Until 1969, such tests were seldom<br>used.  Computers were unheard-of;<br>and prior to computer-generated<br>psychoacoustic test tones, the only<br>available readily controllable test<br>tones were those generated by analog<br>circuits whose frequency drifted <br>by significant amounts as the temperature<br>of the sound-generating circuit changed.<br>As a result, ignorance of the<br>ear/brain system's behaviour was<br>near-absolute prior to Max Mathews'<br>creation of the acoustic compiler in 1959.<br>As a result of Mathews' innovation, many<br>surprising properties were discovered in<br>the ear/brain system.<br>One of the most surprising of these properties<br>is known as "categorical perception."<br>---<br>The phenomenon of categorical perception<br>is familiar to linguists.  <br>Everyone pronounces phonemes,<br>vowels, and consonants slightly differently--<br>and in different regional dialects the <br>sound of a word may be entirely<br>transformed.  In New England, "pahk my cah,"<br>in the MidWest, "park my car," down south,<br>"purk m' cuhr."  The ear/brain system <br>has a learned mechanism for dealing with<br>these differences--different sounds are<br>heard as the same semantic unit.  This<br>ear/brain system of learned categorization<br>is known as categorical perception, and it<br>operates so efficiently that people in a given<br>region of the country cannot even "hear" their<br>own accent.  As far as they can tell, they're<br>speaking "standard English"--everyone else is<br>slurring or pinching or warping their words "with<br> some strange kind of accent."<br>Categorical perception has been proven to <br>operate in the perception of musical sounds, <br>and it gives rise to many of the same distortions<br> of the auditory system.<br>In the paper "Categorical Perception--Phenomenon<br>or Epiphenomenon: Evidence from experiments in<br>the perception of melodic musical intervals,"<br>by E. M. Burns and W. D. Ward [JASA, vol. 63, No. 2, <br>1978, pp. 456-468], the authors point out:<br>"An experiment on the perception of melodic<br>intervals by musically untrained observers<br>showed no evidence for the existence of<br>"natural" categories for musical intervals."<br>The authors also found that for trained<br>musicians "musical intervals are also<br>rather unique in that musicians are able to<br>perfectly identify more than 30 categories<br>of musical intervals..."  These results<br>strongly contradict both the standard 12-tone<br>dogma that only the intervals of the 12-TET<br>scale are recognizable or musically <br>significant; and the standard "natural<br>interval" dogma which holds that some<br>musical intervals are [fill in your own<br>preferred propaganda] "natural," "pure," <br>"preferred," "rational," etc.  <br>Among other interesting conclusions, Ward<br>and Burns found that "The average difference<br>limen (based on the 75% correct<br>points from the psychometric functions)<br>for three subjects at the physical octave<br>was 16 cents. The DL's at other ratios in the<br>civicinity of the octave were not <br>significantly different. A DL of 16 cents is in<br>good agreement with the DL estimated from the <br>from the standard deviation of repeated<br>adjustments of sequential octaves (about 10<br>cents) in the same frequency region found by<br>Ward (1954). (...) As in Moran and Pratt's<br>experiment, large differences were found for<br>DL's at different ratios, but the range of <br>DL's (14-25 cents) was in good agreement<br>with their results." [Burns, E. M. and Ward,<br>W.D.,  JASA, 63(2), Feb. 1978, pg. 456]<br>This preference for stretched as<br>opposed to purportedly "natural" intervals<br>is not a new discovery.  As will be seen<br>in the post after this one, the preference<br>for stretched vertical intervals--and for <br>significantly *wider* melodic than<br>vertical intervals--was discovered by<br>the very first researchers who <br>investigated the operation of the<br>ear/brain system.<br>What are the implications of these particular<br>psychoacoustic data for tuning and music?<br>First, these data explain clearly and convincingly<br>why there are so many different tunings systems<br>and timbres used in the various musics of cultures<br>throughout the world.  Because of the influence of<br>categorical perception and the implied importance<br>of learned response on the ear/brain system, any<br>system of pitches can be learned as "preferred"<br>by the ear.  Thus a Mongolian Buddhist using the r-gynd-stad<br>tuning can with equal justification claim that the pitches<br>of his musical system enjoy a privileged status in the<br>ear/brain sytem as can Javanese gamelan performer.<br>According to the psychoacoustic results adduced above,<br>both musicians are correct--because the cultures in<br>which their pitch preferences were formed characterize<br>those particular pitches as "special."  And because of the<br>known effects of learned response and categorical perception,<br>a wide variety of pitches can equally be perceived as<br>"special" or "uniquely privileged."<br>These psychoacoustic data would also tend to support current<br>Western musical practices, at least to the extent that the Western<br>12-tone tuning system is acculturated into Wesern musicians<br>and composers, and to which Western performers and audiences<br>perceive departures from those pitches as falling within the <br>range of variability which (as Moran and Pratt point out) characterize <br>all pitches.<br>Categorical perception strongly favors all three classes of tuning--<br>just intonation, equal temperament and non-just non-equal tunings--<br>since once the pitches are learned and perceived as "special" or<br>"privileged" both audience and performers strongly tend to<br>perceive departures from those pitches as "ornamental," if<br>indeed the departures are heard as different pitches at all. If<br>these psychoacoustic results are accurate, all tuning systems<br>are self-reinforcing feedback systems, with "errors" heard as<br>slight variations of base pitches (as in the case of Jaipongan,<br>where slendro or pelog are used as base scales for ornamental<br>extra-scalar variations, or as in the various sruti of East Indian<br>practice, where the remaining 22 pitches are used as ornamental<br>extra-modal variational pitches, or as in the vocal inflexions  of <br>Sinead O'Conner, Louis Armstrong or Ella Fitzgerlad, all of whom consistently range microtonally outside the 12-tone equal tempered <br>scale in which their song purports to reside).<br>The next post will consider the effects of possible interactions<br>between the various ear/brain processes discussed to date,<br>and the evidence for such interactions, along with the implications<br>for tuning and music.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Thu, 5 Oct 1995 21:58 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id MAA22353; Thu, 5 Oct 1995 12:58:04 -0700<br>Date: Thu, 5 Oct 1995 12:58:04 -0700<br>Message-Id:  <9510051256.aa03198@cyber.cyber.net><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2098 href="#2098">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/5/1995 12:58:04 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Tuning & psychoacoustics - post 12 of 25<br>---<br>The psychoacoustic evidence for the periodicity and Fourier-analysis-based <br>models of hearing has now been examined. <br>But what about interaction between these two ear/brain systems?<br>Evidence for this comes from David Wessel's examination of a psychoacoustic effect known as "streaming" in the mid-70s: <br>"Consider a melodic line of eleven tones where the even-numbered tones and <br>the odd-numbered tones are separated in register. As shown...at a rate of 5 <br>or 6 tones per second, a listener would hear the sequence as a coherent <br>succession.  At a faster tempo--10 to 12 tones per second--the high tones <br>group together to form a separate stream from the low tones. At an <br>odge, C., Jerse, T. "Computer Music: Synthesis, Composition and Performance," 1985, pg. 47]<br>Time is a crucial factor in pitch perception, implying further feedback <br>between the periodicity and Fourier-analysis systems of pitch detection: <br>"The data...show that the just-noticeable relative frequency difference <br>increases with decreasing test-tone duration. (...) At long durations (around <br>500 ms) a critical-band rate difference of 0.01 Bark represents the just-<br>noticeable difference for pitch.  At a duration  of 10 ms, the JNDF amounts <br>on average to 0.2 Bark.  For a decrease of the test-tone duration by a factor <br>of 10 ms, the magnitude of the JNDF, expressed in critical-band rate, <br>increases by a factor of 10.  Thus pitch differences which are easily <br>detected at logn durations are no longer distinguishable at short durations.  <br>This effect is well known to musicians: inaccuracies in intonation, easily <br>detected in sustained tones, almost disappear if the tones are considerably <br>shortened in duration, for example by playing `spiccato.'" [Zwicker, W. and H. <br>Fastl, Psychoacoustics: Facts and Models, 1990, pg. 116]<br>Other results make it clear that the perception of pitch is dependent on the <br>temporal order of tones:<br>"When presented witha group of spectral components, a listener may or may <br>not fuse them into the percept of a single sound.  One of the determining <br>factors is the "onset asynchrony" of the spectrum which refers to the <br>difference in entrance times among the components. (...)  Rudolf Rasch has <br>noticed a related phenomenon with regard to the synchronization of tones in <br>chords in polyphonic music.  He has found that the amount of asynchrony in <br>starting times of chord tones actually improves our ability to perceive the <br>individual tones while we continue to perceive the chord as a whole. <br>Rasch has shown that the effect obtains best when the attacks of the tones <br>are spread out over a time span of 30 to 50 msec." [Dodge, C., and Jerse., T. <br>"Computer Music:  Synthesis, Composition and Performance," 1985, pg. 59]<br>Because of this unexpected interdependence of time with freqeuncy <br>perception, it seems likely that all 3 of the ear's mechanisms for processing <br>sound interact to some degree. There is further evidence for this interaction <br>between all 3 ear/brain systems in the form of auditory paradoxes:<br>"Paradoxical effects can be obtained thanks to the precision and flexibility <br>inherent in computer synthesis.  Shepard produced a sequence of 12 tones in <br>chromatic succession which seem to rise indefinitely in pitch when they are <br>repeated.  I extended this  paradox and generated, e.g., ever-ascending or <br>descending glissandi, and sounds going down the scale and at the same time <br>getting shriller. These paradoxes are not merely "truquages"--artificial <br>curiosities: they reflect the structure of our pitch judgments.  Pitch appears <br>to comprise a focalized aspect, related to pitch class, and a distributed <br>ascpect, related with spectrum, hence with timbre--and the paradoxes are <br>obtained by controlling independently the physical counterpart of these<br>attributes, which are normally correlated. I have even manufactrured a <br>sound which does down in pitch for most listeners when its frequencies are <br>doubled--i.e., when one doubles the speed of the tape recorder on which it is <br>played; this shows how misleading mere intuition can be in predicting the <br>effect of simple transformations on unusual sounds." [Risset, J.C., "The <br>development of Digital Techniques: A Turning Point for Electronic Music?"  <br>Rapports IRCAM No. 9, 1978, pg. 7]<br>These effects make clear the importance of context and the subtlety of <br>interaction among the ear's various methods of sound processing. <br>This would tend to militate against tuning theories which stress absolutes <br>like beats or the convenience of easy modulation, and would support instead <br>the use of non-just non-equal-tempered tunings whose context-driven <br>character mirrors  this aspect of the ear/brain system.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Fri, 6 Oct 1995 07:40 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id WAA01139; Thu, 5 Oct 1995 22:40:25 -0700<br>Date: Thu, 5 Oct 1995 22:40:25 -0700<br>Message-Id: <951006053855_71670.2576_HHB33-5@CompuServe.COM><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2101 href="#2101">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/6/1995 11:06:52 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Tuning & psychoacoustics - post 13 of 25<br>---<br>One of the oldest of old wives' tales about the ear/brain<br>system is the fairy tale that the ear/brain system responds<br>with in some special (viz., magical) way to intervals described <br>by small whole numbers.  Sometimes the supersitition is overt, <br>betraying clearly its occult origins in Cabbalism, gematria,<br>Hindu astrology and Babylonian extispicy--as in  Zarlino's choice of <br>the senario (small whole numbers less than 6) as the<br>basis for tuning because of the  Medieval system of number<br>mysticism, according to which 6 was "a perfect number" because<br>its prime factors add up to the number itself.<br>Or as in the case of Johannes Avianius' view of the 4:5:6 triad <br>as "Unitrisona omnis Harmoniae," a mystical "three in one" <br>musical trinity deriving its supernatural potency from <br> the Christian Father, Son and Holy Ghost.<br>In other cases the superstitition is gussied up with references<br>to Fourier analysis--the mathematics of which (as has been seen)<br>do not explain many properties of the ear/brain system.<br>Contrary to this long-running musical myth,  psychoacoustic<br>evidence shows that listeners hear stretched intervals as<br>"pure" and intervals with the small whole number ratios<br> predicted by numerological theories of consonance as "too<br>flat" and "impure."  <br>The evidence is extensive:<br>In his 1976 thesis for the Dept. of Speech Communciation and Music <br>Acoustics at the Royal Institute of Technology at Stockholm, K. Agren found <br>the average size of the major second to be 199 cents; the major third 402 <br>cents; the purportedly "perfect" fifth 704 cents; and the octave 1204 cents.  <br>The standard deviation for all subjects was 14 cents for the M2nd, 9 cents <br>for M3rd, P5 10 cents, and octave 10 cents.  In accord with all other <br>experiments on perception of musical intervals, Agren found that subjects <br>uniformly preferred *stretched* intervals on average 5-8 cents wider than <br>their purportedly "natural"  counterparts.<br>This preference for stretched as opposed to purportedly "natural" intervals <br>is not a new discovery.  The preference for stretched vertical intervals--<br>and for significantly *wider* melodic than vertical intervals--was <br>discovered by the very first researchers who investigated the operation of <br>the ear/brain system.<br>C. J. Delezenne, in "Memoires sur les valeurs numeriques des  notes de la <br>gamme," Recueil des travaux de la Societe des  Sciences de Lille,  1826-<br>1827,  was the first researcher to  identify the preference for thirds wider <br>than the purportedly  "natural" 5:4. Delezenne's data also showed a <br>preference for stretched octaves:  "In fact, it is a daily experience that in <br>climbing to the  octave from the tonic, the musical ear demands  the octave  <br>so strongly that in order to get away from the leading tone,  and to arrive <br>more  quickly at the octave, the latter is raised  involuntarily."  Pg. 24, <br>Ibid.)  Delezenne used an adjustable  monochord and gave his values in <br>fractions of a Pythagorean  comma rather than in cents.  <br>His results are especially striking  because when starting the experiment he <br>explicitly rejected the Pythagorean system, but was eventually forced to <br>admit the now-universally-recognized preference for stretched intervals <br>wider than the so-called "natural" intervals.  <br>In 1869 Cornu and Mercadier built a phonautograph, an early method of <br>recording waveforms.  Mssrs. C. & M.  directed the  sound waves with a <br>parabolic dish toward a membrane, which in turn engraved the waveform on <br>a smoked drum of camphorated cellulose by means of a needle.  <br>Simultaneously an electric chronometer marked the drum the drum at <br>intervals of 1 second.  By measuring the wavelength, Cornu and Mercadier <br>could precisely determine pitch--as opposed to the usual wild guess about <br>what pitch was actually played, or heard (the "wild guess" method is still <br>used by many contemporary music theorists).  Many musicians assert on the <br>basis of nothing other than some undefined extrasensory perception that <br>they "can tell a Pythagorean third when they hear it," etc.  <br>As these experiments unmistakably prove, this is not so. <br>Again, to make the point clear, categorical perception leads us to recognize <br>as "perfect" or "natural" intervals which differ greatly from small-whole-<br>number ratios; moreover, there is at work a universal human craving for <br>stretched intervals.)<br>The amount of evidence for human preference for stretched octaves is so <br>voluminous that no digressions can be afforded.  The subject will be dealt <br>with later in this series. Thus, to return to the early  scientific record: <br>Cornu & Mercadier found that the mean intonation for a vertical dyad  <br>yielded the ratio  1.251, close to but sharper than the 5/4;   however, a <br>consecutive-tone test yielded 1.2666 as the mean value.  <br>Notice that this shows a marked preference not only for stretched vertical <br>intervals, but for even more widely stretched melodic intervals.  <br>The Pythagorean third is 1.256, so the experiment showed that in the <br>successive intonation of 2 tones, the subjects preferred a sharped <br>Pythagorean third.  Cornu and Mercadier interpreted their results to mean <br>that musicians customarily use 2 different thirds for vertical and <br>successive intervals, and that they also prefer intervals somewhat sharper <br>than would be expected by contemporary models of human hearing. [Cornu & <br>Mercadier, "Sur les intervalles musicaux," Comptes Rendus de l'Academie  <br>Royale des Sciences, 1869a, pp. 301-308.]<br>The evidence for a preference for wider-than-"rational" intervals doesn't <br>end in 1869, however.  It scarcely begins there:<br>In 1876 Preyer found that what he called the "index of sensitivity" for the <br>major thirds was 158; this corresponds to 11 cents.  So intervals as large <br>as 397 cents were still identified as major thirds.  This is midway between <br>the 5/4  and the 81/64 (12 cents short of the 407-cent Pythagorean major <br>third). [Preyer, W. T., "Ueber die Grezen der Tonwahremung," Jena, 1876]<br>In 1897-8 Carl Stumpf studied both the minor third and the major third in 3 <br>forms: ascending, descending and simultaneous intervals. His results showed <br>a marked asymmetry in the  spread of sharp vs. flat errors. For the minor <br>third, the listeners  were more inclined to accept considerable flatting than <br>slight  sharping.  Stumpf stated that the "point of subjective purity" shifted <br>toward flat minor thirds. Analysis of data from his second experiment with <br>major thirds showed exactly the opposite tendency. In this case, the point of <br>subjective purity shifted to sharp thirds.  [Stumpf, C. and H. F. Meyer, <br>"Massbestimmungen ueber die Reinheit consonanter Intervale," in Beitraege <br>zur Akustik und Musikwissenschaft, Vol. 2, 1898]<br>Moran and Pratt's investigations in 1926 found an average error of 18 cents <br>for the intervals of the 12-TET scale. "There is a range of about half an <br>equal semitone midway between each musical interval, within which an <br>interval should be recognized by D as neither of the familiar intervals, next <br>above or below it."  This meant that major thirds sharped by as much as 25 <br>cents were still recognized by their subjects as  pure thirds. [Moran, H. and <br>C. C. Pratt, "Variability of Judgements on Musical Intervals," Journal of <br>Experimental Psychology, Vol. 9, 1926]<br>Comprehensive statistics showing a preference for melodic Ptyhagorean <br>thirds  were first compiled by P.C. Greene in 1937. [Green, P.C. "Violin <br>Performance with Reference to Tempered, natural and Pythagorean <br>Intonation," Iowa Studies Music 4, pp. 232-251, 1937]<br>Bolt was the first to use pure sine waves and electronic instrumentation. In <br>1947 he observed mistuned major thirds and found  the same results--<br>although his main interest was in spectral cues for identifying mistuned <br>intervals.  [Bolt, R.H., "Masked Differential Pitch Sensitivity of the Ear  for <br>Musical Intervals, " JASA, vol. 19, 1947]<br>In 1948 Nickerson observed the same melodic preference for widely <br>stretched (viz., near-Pythagorean) thirds. [Nickerson, J.F., "A Comparison of <br>Performance of the  Same Melody in Solo and in Ensemble with Reference to <br>Equi-Tempered, Just, and Pythagorean Intonation," Ph.D. thesis, Univ. Minn., <br>1948]<br>Ward studied the octave sense along with preferred values  for thirds and <br>fifths starting in 1954.  <br>Ward's 1970 chapter in "Music Perception" lends further  support to the <br>preference for wider-than-5:4 thirds, both vertically and melodically. <br>Additional papers which amass evidence for this universal human preference <br>include: Ward, W.D., "Music Perception," In  "Foundations of Modern  Auditory <br>Theory," Ed. J. V. Tobias, 1970 see also Ward, W.D. "Subjective Musical <br>Pitch," JASA, Vol. 25, 1954.]  Corso and Pikler & Harris reproduced these <br>results in the late 50s-early 60s. [Corso, J.F. "Scale Position and Performed <br>Musical Octaves," J. Pysch., Vol. 37, 1954; Pikler, A. G.  & J.D. Harris, <br>"Measurement of the Musical Interval Sense," JASA, Vol. 33, pg. 862, 1961.]  <br>Pikler's article "History of Experiments on the Musical Interval Sense," <br>Journal of Music Theory, 1966, pp. 55-95,  summarizes these results at <br>length.<br>During the late 60s and throughout the 70s Johan Sundberg used computer <br>analysis of recordings of live performances to determine performers' <br>intonational preference.  His difficult-to-obtain report STL-QOSR- 2-3, <br>Speech Transm. Lab., Stockholm 1970, "Statistical computer measurement <br>of the tone-scale in played music," by Fransoon, F., Sundberg, J.  and <br>Tjernlund P. is summarized in Sundberg's 1992 text as confirming <br>Delezenne's, Voos', Corso's, Ward's, Lichte's,  Pikler & Harris', et al.'s <br>results; Sundberg, J. "The  Science of Musical Sounds," 1992, pg. 105. <br>Roederer's 1973 text quotes Ward's confirming data for Pythagorean thirds.  <br>Roederer ascribes the preference to Terhardt's hypothesis of universally <br>stretched intervals rather than Pythagorean intonation as such.  <br>In 1975 Terhardt and Zick published a paper showing that  for tone <br>sequences emphasizing melody over accompaniment, subjects preferred all <br>intervals stretched. [Terhardt, E. & Zick, M. "Evaluation of the Tempered Tone <br>Scale in Normal, Stretched and Contracted Intonation," Acustica, Vol. 32, <br>1975, pp. 268-274.]<br>The most recent paper supporting the stretched-third preference appears to <br>be Voos, "Quality Ratings of Tempered 5ths and Major 3rds," Music <br>Perception, Vol. 3 No. 3, 1986.]<br>By this point it should be clear that the evidence for musicians  preferring <br>intervals *wider* than the 81:64  as a "major third" goes back at least 125 <br>years.   <br>What about the octave?<br>This subject is so enormous and so important that the purported "perfect" <br>octave of 2:1 will be dealt with separately in the next two posts.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Fri, 6 Oct 1995 22:52 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id NAA12599; Fri, 6 Oct 1995 13:52:09 -0700<br>Date: Fri, 6 Oct 1995 13:52:09 -0700<br>Message-Id: <009977C6B6BABBDC.42AF@ezh.nl><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2104 href="#2104">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/7/1995 7:42:06 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Tuning & psychoacoustics - post 14 of 25<br>---<br>"In the case of the octave, the craving for stretching has been noticed for <br>both dyads and melodic intervals. The amount of stretching preferred <br>depends on the mid frequency of the interval, among other things. The <br>average for synthetic, vibrato-free octave tones has been found to be about <br>15 cents.  Thus, subjects found a just octave too flat but an octave of 1215 <br>cents just." [Sundberg, J. "The Science of Musical Sounds," 1992, pg. 104]<br>MYTH: "The interval is just or not at all." [Harrison, "Lou Harrison's Music <br>Primer," 1971, pg. 48]<br>FACT: "For centuries, musical folklore has held that the simplest ratios are <br>the best  ratios, in musical intonation.  Thus the interval betwen two <br>frequencies having a ratio of 3:2 is the "perfect" fifth; 4:3 gives a "perfect" <br>fourth, etc. (...) These philosophical and a priori views of temperament, <br>however, are hardly supported by empirical evidence." [Ward, W.D. and <br>Martin, W.D., "Psychophysical Comparison of Just Tuning and Equal <br>Temperament in Sequences of Individual Tones," JASA, Vol. 33, No. 50, 1961, <br>pg. 586]<br>MYTH: "This 2 to 1 relationship is a constant one...the fact is that nature <br>does not offer one tone and its doubling (200 to 400) as a given quality of <br>relationship, and the same quality of relationship in two tones which are <br>not a ratio of doubling (200 to 600, for example)" [Harry Partch, "Genesis of <br>a Music,"  2nd. Ed., 1974, pg. 77.]<br>FACT: "If a frequency of 8 kHz is chosen for f1, subjects produce for the <br>sensation of `half pitch' not at a frequency of 4 kHz, but a frequency of about <br>1300 Hz." [E. Zwicker and H. Fastl, "Psychoacoustics: Facts and Models," <br>1993, pg. 103.] <br>MYTH: "If, through some terrestrial disaster, our [equal-tempered] musical <br>system were completely lost, it would sooner or later be inevitably <br>redicsovered, just as it exists today, after having passed through <br>transformations identical or similar those those it has undergone." [Ducup <br>de Saint-Paul, quoted in Matthys Vermeulen, "Hic et Nunc, Jacobe," Djawa, <br>Vol. 12, 1932, pp. 146-149]<br>FACT: "It is quite remarkable that musicians seem to prefer too wide or <br>"stretched" intervals." [Johan Sundberg, "The Science of Musical Sounds," <br>1992, pg. 103.]<br>MYTH: "Notice that these frequency clumps are arranged in a harmonic series <br>based on a fundamental frequency half that of tone M, and also that any lack <br>of accuracy in setting an exact 3/2 frequency ratio will be called to our <br>attention... " [Benade, A. H., Fundamentals of Musical Acoustics, 1975, pg. <br>272]<br>FACT: "The experimental results very convincingly show that, on the <br>average, singers and string players perform the upper notes of the major <br>third and the major sixth with sharp intonation (Ward 1970)...The same <br>experiments revealed that also fifths and fourths and even the almighty <br>octave were played or sung sharp, on the average! (A reciprocal effect <br>exists. Pure octaves are consistently judged by musicians to sound flat!) <br>Rather than revealing a preference for a given scale (the Pythagorean), these <br>experiments point ot the existence of a previously unexpected *universal <br>tendency to play or sing sharp all musical intervals.* (italics in original <br>text)" [Juan Roederer, "Introduction to The Physics and Psychophysics of <br>Music," 1973, pg. 155.]<br>MYTH: "Consequently, these statements can be conclusively made; the ear <br>consciously or unconsciously classifies intervals according to their <br>comparative consonance or comparative dissonance; this faculty in turn <br>stems directly form the comparative smallnesss or comparative largeness <br>of the numbers of the vibrational ratio..." [Harry Partch, "Genesis of a Music,"  <br>2nd. Ed., 1974, pg. 87.]<br>FACT: "Therefore it must be concluded that even just or pythagorean <br>intonation cannot be considered as ideal.  Rather, optimum intonation of a <br>diatonic scale probably depends on the structure of the actual sound in the <br>same manner as has been previously discussed with respect to tempered <br>scales." [E. Terhard and S. Zick, "Evaluation of the Tempered Tone Scale In <br>Normal, Stretched, and Contracted Intonation," Acustica, Vol. 32, 1975, pg. <br>273.]<br>MYTH:"The reason that the ratio does not change is simply and wholly because  physiogically the ear does not change excpet over a period of thousands and  millions of years." [Partch, Genesis of a Music, 2nd ed.,<br> 1974, pg. 97]<br>FACT: "The degree of consonance depends on the quality or  spectrum of the <br>component tones, i.e., the relative intensity of dissonant vs. consonant upper <br>harmonics." [Juan Roederer, "The Physics and Psychoacoustics of Music," pg. <br>143.]<br>MYTH: "Long experience in tuning reeds on the Chromelodeon convinces me <br>that it is preferable to ignore partials as a source of musical materials.  <br>The ear is not impressed by partials as such.  The faculty--the prime <br>faculty--of the ear is the perception of small-number intervals, 2/1, 3/2, <br>4/3, etc., etc., and the ear cares not a whit whether these intervals are in or <br>out of the overtone series." [Harry Partch, "Genesis of a Music,"  2nd. Ed., <br>1974, pg. 87.]<br>FACT: "In 1987 IPO issued a wonderful disc by Houtsma, Rossing and <br>Wagenaars...illustrating the effects of a moderate stretching...of scale <br>frequencies and/or partial spacings. Part of a Bach chorale is played with <br>synthesized tones. When neither scale nor partial frequencies are stretched, <br>we hear the intended harmonic effect.  When the scale is unstretched but the <br>partial frequencies are stretched, the music sounds awful. Clearly, intervals <br>in the ratio of small whole numbers are in themselves insufficient to give <br>Western harmonic effects." [John R. Pierce, "The Science of Musical Sound," <br>2nd Ed., pp. 91-92.]<br>MYTH: "In the previous section of this chapter, I made a definition: we would <br>henceforth reserve the word  *tone* to refer to sounds having harmonic <br>partials. For emphasis, I will often refer to such sounds as musical    <br>tones...to underline the fact that harmonically related complexes of partials <br>have a very    special    perceptual    status    that happens also to make <br>them useful in music." [Benade, A.H., Fundamentals of Musical Acoustics, <br>1975, pg. 264]<br>FACT: "Clearly the timbre of an instrument strongly affects what tuning and <br>scale sound best on that instrument." [Wendy Carlos, "Tuning: At the <br>Crossroads," Computer Music Journal, 1987.]<br>"Most instruments in our music culture produce harmonic spectra,  as <br>mentioned.  However, in the contemporary computer-aided electroacoustic <br>music studios, is not a necessary constraint any longer.  One would then ask <br>if this does not open up quite new possibilities also with respect to <br>harmony.  If one decides to use one particular kind of inharmonic sepctra for <br>all tones, it should be possible to tailor a new scale and a new harmony to <br>this inharmonicity." - Johan Sundberg, "The Science of Musical Sounds," pg. <br>100.<br>"By using a digital computer, musical tones with an arbitrary distribution of <br>partials can be generated.  Experience shows that, in accord with Plomp's <br>and Levelt's experiments with pairs of sinusoidal tones, when no two <br>successive partials are too close together such tones are consonant rather <br>than dissonant, even though the partials are not harmonics of the <br>fundamental.  For such tones, the conditions for consonance of two tones <br>will not in general be the traditional ratios of the frequencies of the <br>fundamentals...  [The 8-TET scale] is, of course, only one example of many <br>possible scales made up of tones whose upper partials are not harmonics of <br>the fundamental and having unconventional intervals, which nonetheless can <br>exhibit consonance and dissonance comparable to that obtained with <br>conventional musical intstruments (which have harmonic partials) and the <br>diatonic scale.  It appears that, by providing music with tones that have <br>accurately specific but nonharmonic partial structures, the digital comptuer <br>can release music from the constraint of 12 tones without throwing <br>consonance overboard."  [John R. Pierce, "Attaining Consonance in Arbitrary <br>Scales," Journal of the Acoustical Society of America, 1966, p. 249.]<br>"The physical correlate of an interval is not a ratio, anymore than the <br>physical correlate of a pitch is a frequency.  Intervals and pitches both have <br>thresholds, ranges of variability," [Moran, H. and C. C. Pratt, "Variability of <br>Judgments on Musical Intervals," Journal of Experimental Psychology, Vol. 9, <br>1926] <br>Evidence for this conclusion is so voluminous and so detailed that it <br>cannot be contained in a single series of 22 posts. However, the next post <br>scratches the surface of this body of evidence, and hints at the enormous<br> extent of the experimental data showing a universal human preference for <br>stretched octaves, fifths, thirds, etc.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Sun, 8 Oct 1995 03:26 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id SAA22621; Sat, 7 Oct 1995 18:25:50 -0700<br>Date: Sat, 7 Oct 1995 18:25:50 -0700<br>Message-Id: <951008012346_71670.2576_HHB23-1@CompuServe.COM><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2107 href="#2107">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/8/1995 8:12:29 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Tuning & psychoacoustics - post 15 of 25<br>---<br>MYTH:"In any given range of pitch the comparative consonance of an interval <br>is determined by the relative frequency of the wave  period in the sounding <br>of the interval." [Harry Partch, "Genesis of a Music,"  2nd. Ed., pg. 151.]<br>FACT: "Systematic measurements show that people tend to find that an <br>interval traditionally classified as "consonant" sounds  progressively <br>dissonant the farther down in the bass it is  played...In the very low bass, <br>even the octave sounds dissonant!" [Johan Sundberg, "The Science of Musical <br>Sounds," pg. 73.] <br>"Even the *order* in which two instruments define a musical interval is <br>relevant.  For instance, if a clarinet and a violin sound a major third, with <br>the clarinet playing the lower note, the first dissonant pair of harmonics <br>will be the 7th harmonicof  the clarinet with the 6th harmonic of the violin <br>(because only  odd harmonics of the clarinet are present).  This interval <br>sounds smooth.  If, on the other hand, the clarinet is playing the upper tone, <br>the 3rd harmonic of the latter will collide with the 4th harmonic of the <br>violin tone, and the interval will sound  `harsh.'" [Roederer, J., "Introduction <br>to The Physics and  Psychophysics of Music," 1973, pg. 143.]<br>In his 3-part article, "Some Aspects of Perception," Shackford reveals how <br>widely so-called "perfect" intervals can deviate when performed by trained <br>symphony-caliber performers from major orchestras--yet these intervals <br>are still heard as "perfect." Because Shackford's measurements offer such <br>remarkable proof of the ear/brain's categorical perception mechanism at <br>work, the article deserves an extended quote:<br>"Mean Values (MV) and quartile deviations (QD) of interval sizes measured in <br>a string trio [composed of members of the New York Philharmonic] as <br>compared with just, equally tempered and Pythagorean tunings (J,ET and P):<br>--------------------------------------<br>          Dyads           <br>Interval  	MV (cents)  QD (cents)<br>Major 2nd    204              197-211<br>minor 3rd    305              287-318<br>Major 3rd    410              402-418<br>Fifth        	707              699-714<br>---------------------------------------<br>          Melodic           <br>Interval  	MV (cents)  QD (cents)<br>Minor 2nd     93               86-101<br>Major 2nd     204             199-209<br>Fourth           501             408-510<br>Fifth             701             692-708<br>---------------------------------------<br>[Shackford, "Some Aspects of Perceptions," Journ. Mus. Theory, Vol. 6, 1961]<br>"Fifths and twelfths are shown in Examples 17 and 18; and then a statistical <br>analysis of the sizes of these intervals in performance is represented in <br>Example 19. The spread of 50 cents, a quarter tone, between the largest and <br>smallest fifths played is surprisingly large for the interval that is supposed <br>to be the most sensitive to inaccuracies of intonation." [Shackford, C. "Some <br>Aspects of Perception - I," Journ. Mus. Theory, Vol. 6, 1961, pg. 185]<br>"Thirds and tenths are shown in Example 20 and are then analyzed in <br>Example 21. Major thirds and tenths have about the same spread [50 cents] <br>but the median and mean is larger for thirds. (...)  As with fifths, long-held <br>thirds and tenths show a narrower spread than those used in passing. Though <br>sizes approaching the "natural" value of 386 cents were used, the <br>Pythagorean interval of 408 cents appears to be the most representative of <br>actual practice." [Shackford, C., "Some Aspects of Perception - I," Journ. Mus. <br>Theory, Vol. 6, 1961, pg. 189]<br>"For barbershop quartets, a Major 3rd of 403 cents was preferred, while a <br>fourth of 493 cents and a fifths of 705 cents was preferred." [Sundberg, J. <br>"The Science of Musical Sounds," 1992, pg. 100]<br>"It is quite remarkable that musicians seem to prefer too wide or 'stretched' <br>invervals in many cases. Above we have seen several examples of interval <br>stretching: the barbershop singers' fifth and just minor seventh; string trio <br>players' melodic  major and minor thirds and fifths; music listeners <br>preferred sizes of fifth and octave; and a professional musician's settings <br>of melodic intervals that contain  ascending fifths. In the case of octaves, <br>the craving for stretching has been noticed for both dyads and melodic <br>intervals. The amount of stretching preferred depends on the mid frequency <br>of the interval, among other things. The average for synthetic, vibrato-free <br>octave tones has been found to be about 15 cents. Thus, subjects found a <br>just octave too flat but an octave of 1215 cents just. (...) A German <br>acoustician, Ernst Terhardt, developed an interesting theory that proposes <br>an explanation for why  we are so eager to stretch octaves. He departed <br>from the fact that the pitch of a sine tone is changed if another sine tone <br>starts to sound simuntaneously. The net result is that both tones push the <br>pitch of the other tone away from its own pitch to increase the distance <br>between the two. In this way, the pitch interval between the first partials <br>in a harmonic stpectrum becomes a bit stretched. (...) Terhardt believes that <br>this stretched octave follows us from cradle to casketand that is is this <br>octave that musicians model when they play." [Sundberg, J. "The Science of <br>Musical Sounds," 1992, pp. 103-105]<br>Additional papers which adduce evidence for the universal preference for <br>stretched octaves include Terhardt, E., "Pitch, Consonance and harmony," <br>JASA, Vol. 55, 1970, pg. 410. He didn't cite Terhardt, E., "On the perception <br>of periodic sound fluctuations (roughness)." Acustica, Voll. 30, 1974, pg. <br>201. Nor does he cite Terhardt, E. and Zick, M., "Evaluation of the Tempered <br>Tone Scale in Normal, Stretched and Contracted Intonation," Acustica, Vol. <br>32, 1975, pp. 269-276, in which Terhardt points out: "Therefore it must be <br>concluded that even just or Pythagorean intoantion cannot be considered as <br>ideal. Rather, optimum intonation of a diatonic scale probably depends on <br>the structure of the actual sound in the same manner as has been previously <br>discussed with respect to tempered pianos." [Terhardt, E. and Zick, M., op <br>cit.]<br>Terhardt goes on to conclude: "It is remarkable, however, that stretched <br>intonation is distinctly preferred to contracted intonation. Probably, the <br>pitch interval established by the simultaneous complex tones fits better <br>with the mentally stored octave interval in stretched intonation than in <br>contracted intonation.  This is well in line with the psychoacoustic <br>phenomenon of octave enlargement." [Terhardt, E. and Zick, M. , op cit.]<br>Various musicians who find these results inconvenient have claimed that <br>the preference for stretched intervals occurs not because Western <br>musicians "prefer" non-just sharp intervals, but because they learn to play <br>them; a wealth of evidence disproves this claim.  <br>In "Octave adjustment by non-western musicians," Edward M. Burns <br>states "The results were essentially the same as found with Western<br> musicians, that is, small intrasubject variability, large intersubject<br> variability, and a small but statistically signficant frequency-dependent<br> "stretch" of the physical octave when adjusting the subjective octave. <br>(...) As suggested by Terhardt, they do seem to rule out the explanation <br>that this stretched is learned from the "stretched" tuning of the piano <br>to which Western musicians are universally exposed. This stretched <br>tuning of the piano is due to certain physical characteristics of the <br>piano strings and is not found in most instruments to which the Indian<br> musicians are exposed." [Burns. E. M, op cit., Session M: Musical acoustics,<br> 88th meeting of the  Acoustical Society of America; in JASA, vol. 56,<br> Supplement, pg. S 26]<br>In the same session, Burns' paper "In Search of the Shruti," cites evidence <br>from Indian musicians confirming "earlier experiments [which] indicate <br>that the phenomenon of "categorical perception" is present in the <br>perception  of musical intervals." [Burns, op cit, in JASA, Vol. 56, Supplement, pg. S 26]<br>This explains why various just intonation fans hear the perceptually <br>non-octave 2:1 ratio as being a "pure" octave while listeners not indoctrinated by constant exposure to just intonation accurately<br>perceive the distorted 2:1 ratio  as smaller than the perceptual octave.<br>  Exactly the same effect is at work among Javanese musicians who <br>hear many different gamelan as being tuned to "pelog" even though "the majority of large Balinese gamelan are tuned with five pitches to the octave, having some intervals larger than others, in a general pattern <br>that has come to be called pelog: but no two gamelan have exactly the <br>same pattern of intervallic structure.  This is not for want of skill.  <br>It is because the tuning pattern has been composed." [Erickson, Robert,  "Timbre and the Tuning of the Balinese Gamelan," Soundings, pg. 98, 1984]<br>Categorical perception also explains why equal tempered intervals are <br>accepted with such equanimity by listeners; a wide variety of different <br>intervals are perceived as "thirds" and "fifths" and "fourths" and "sixths" <br>in an actual musical peformance setting:  a psychological mechanism is <br>at work whereby listeners unconsiously process the sounds they hear <br>and fit unfamiliar intervals into familiar categories.  Listeners <br>literally *hear what they expect to hear*--regardless of what is <br>*actually played.* <br>More evidence for this phenomenon comes from "Categorical Perception--<br>Phenomenon or epiphenomenon: Evidence from experiments in the perception <br>of melodic musical intervals," Burns, E. M. and Ward, W.D., JASA vol. 63, No. <br>2, Feb. 1978, pg. 456.<br>"In marked contrast to the extreme accuracy of musical-interval judgments <br>in the experimental situations cited above is the large variability found in <br>measurements of intonation in musical performance.  The results of several <br>studies on intonation in performance of western classical music have been <br>summarized by Ward (1970). They show large variations in the tuning of <br>individual intervals (ranges of almost a semitone) in a given performance.  <br>Similar variability has been found in measurements of intonation in <br>nonclassical western music (Stauffer, 1954; Fransson, Sundberg and <br>Tjernland, 1970; Owens, 1974) and in nonwestern music (Jhairazbhoy and <br>Stone, 1963; Callow and Shepherd, 1972; Spector, 1966).  Of course this <br>large variability is not in itself surprising since variability in production of <br>tones is involved. The important point, however, is that in the above-cited <br>studies, all listeners, including the performing musicians, agreed that the <br>compositions were performed correctly and the large variability in <br>intontion was not detected. <br>"This apparent inability to detect large variations in interval size in certain <br>situations suggests that a phenomenon associated with the perception of <br>speech tokens, "categorical perception," may be involved." [Burns, E., and <br>Ward, W.D., "Categorical Perception--Phenomenon or epiphenomenon: <br>Evidence from experiments in the perception of melodic musical intervals," <br>JASA vol. 63, No. 2, Feb. 1978, pg. 456.]<br>Again, in "Categorical Perception of Musical Intervals," Burns and Ward point <br>out "A body of evidence indicates that certain speech units are perceived in <br>in a special mode called `categorical perception,' the characteristics of <br>which are (1) the existence of well-defined identification functions and (2) <br>the ability to predict precisely the discrimination functions from the <br>identification functions, based on the  assumption that the subjects can <br>discriminate two stimuli better than they can differentially identify them.  <br>(...) A study of the perception of musical intervals by experienced musicians <br>was performed using the procedures associated with categorical perception <br>experiments;...the results show that the musicians exhibit categorical <br>perception, some to a degree approaching that shown in the perception of <br>stop consonants." [Burns, E. and Ward W., "Categorical Preception of Musical <br>Intervals," JASA, Vol. 55, No. 2, Feb. 1974]<br>The powerful evidence for categorical perception in listeners and <br>performers alike lends equal support to just, equal-tempered and non-just <br>non-equal-tempered  tunings.  Because listeners unwittingly brainwash <br>themselves to hear the intervals they expect regardless of what intervals <br>are actually performed,  all three tunings should prove equally acceptable to <br>listeners.<br>Of course there is more evidence for a difference between the stretched<br>intervals heard as "pure" and the perceptually-distorted intervals<br>characterized by small whole numbers, and universally heard as<br>"too narrow" and "flat."  The next post will examine some more<br>of this enormous body of evidence.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Sun, 8 Oct 1995 20:46 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id LAA28440; Sun, 8 Oct 1995 11:45:50 -0700<br>Date: Sun, 8 Oct 1995 11:45:50 -0700<br>Message-Id: <951008184423_71670.2576_HHB28-1@CompuServe.COM><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2111 href="#2111">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/9/1995 7:52:48 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Tuning & psychoacoustics - post 16 of 25<br>---<br>The evidence for a universal human preference for stretched intervals is<br>so overwhelming that it appears throughout the length and breadth<br>o`e psychoacoustic literature, both with Western and non-Western<br>musicians:<br>"Dowland has reported that measurements of Western and non-Western fixed <br>pitch instruments suppprt Ward's conclusion that the perceptual octave is <br>some 15 cents larger than the  physical or mathematical octave.  Western <br>musical practice supports these conlusions (play sharp in higher octave). <br>Balinese gamelan tunings take advantage of this apparently widespready <br>characteristic of pitch perception to create a multi-octave beating ocmplex <br>in their fixed pitch instruments."  [Erickson, Robert, "Timbre and the Tuning <br>of the Balinese Gamelan," Soundings, pg. 100, 1984]<br>Particularly revealing is "The 1215-Cent Octave: Convergence of Western and Non-Western  Data on Pitch Scaling,"  W. J. Dowling, Abstract QQ5, 84th meeting of the Acoustical Society of America, Friday, December 1, 1972, p. 101 of program.<br>Yet more evidence for a universal preference for stretched octaves comes<br>from Sundberg, who found that the octave was as a rule played <br>significantly sharp by performing musicians, and was also preferred sharp <br>of the 2:1 in adjustment tests:<br>"Evidently the octave intervals in such stretched scales will exceed a 2:1 <br>frequency ratio slightly. Thus, it is necessary to distinguish between the <br>*physical octave * (PO) which is defined as a 2:1 frequency ratio, and the <br>*subjective (musical) octave * (MO) that is perceived as pure.  (...) As a rule, <br>the perceptual octave corresponds to a fundamental frequency ratio <br>exceeding 2:1." [Sundberg, J. and Lindqvist, J., "Musical Octaves and Pitch," <br>JASA, 54(4), 1973, pp. 973-929]<br>Among the many implausible arguments which attempt to explain away this <br>mountain of experimental evidence for a preference for an octave interval <br>larger than the purportedly "pure" 2:1, most prevalent is the claim that <br>these "laboratory experiments do not represent real musical practice."  <br>If this objection is correct, why does computer analysis of the frequencies <br>of pitches played during actual performances which show a uniform stretch <br>of the octave also show the same results as the laboratory psychoacoustic <br>experiments?  And why do psychoacoustic measurements and experiments <br>stretching back over 150 years uniformly produce the same results?<br>"This disparity between the physical and subjective octaves is not a new <br>discovery.  Stumpf and Meyer, using the method of constant stimuli, had 18 <br>subjects judge pairs of successive tones as greater than, less than, or equal <br>to an octave.  They lower tone was 300 cps and the upper tone was varied <br>around 600 cps.  They found that 602 cps (the higher upper tone used) <br>received 52 percent "less," 43 precent "equal," and 5 percent "greater" <br>responses from the group, indicating that the mean subjective octave of 300 <br>cps was somewhere above 602 cps (the present Fig. 4 gives about 605 cps). <br>Later von Maltzew, in an investigation on the identification of intervals in <br>the upper frequency range, found that a physical octave was more often <br>called a major seventh or below than a minor ninth or above. See C. Stumpf <br>and M. Meyer, Beit. Akust. Musikw., Vol. 2 ppg. 84-167, 1898. C. v. Malzew, Z. <br>Psychol. Vol. 64, pp. 16-257, 1913. [Ward., W.D., "Subjective Musical Pitch," <br>Journ. Acoust. Soc. Am. , Vol. 26, No. 3, May 1954, pg. 374]<br>"The average standard deviation of repeated adjustments of sequential or <br>simultaneous octaves composed of sinusoids is on the order of 10 cents <br>(Ward, 1953, 1954; Terhardt, 1969; Sundberg & Lindquist, 1973).  A range of <br>average deviations from 4 to 22 cents for adjustments of the other <br>intervals of the chromatic scale (simultaneous presentation) has been <br>reported by Moran and Pratt (1926). Rakowski (1976) reports variability--in <br>interquartile ranges--of 20 to 40 cents for both ascending and descending <br>melodic versions of the 12  chromatic intervals. Other general trends <br>evident from the results of adjustment experiments are...a tendency to <br>'compress' smaller intervals (adjust narrower than equal-tempered <br>intervals) and "stretch" wider intervals (adjust wider)."  [Burns, E. M., and <br>Ward, W.D., "Intervals, Scales and Tuning," in The Psychology of Music, ed. <br>Diana Deutsch, 1982, pg. 250.]<br>"A number of measurements have been made of the intonation of musicians <br>playing variable-tuning instruments under actual performance conditions <br>(e.g., Greene, 1937; Nickerson, 1948; Mason, 1960; Shackford, 1961, 1962, a, <br>b). The results of these measurements have been summarized by Ward <br>(1970). They show a fairly large variability for the tuning of a given <br>interval in a given performance--ranged of up to 78 cents, interquartile <br>values of up to 38 cents. The mean values of interval tunings, in general, <br>show no consistent tendency to either just intonation or Pythagorean <br>intonation in either melodic or harmonic situations.  The general tenedency  <br>seems to be to contract the semitone and slightly expand all other intervals <br>relative to equal temperament.  There is also some evidence of context-<br>dependent effecst (e.g., to play F# sharper than Gb (Shackford, 1962 a,b)]. <br>Those results mirror, to a certain extent, the results of the adjustment and <br>identification experiments using isolated intervals (discussed in Sections <br>III A and III B) which showed a tendency to compress the scale for small <br>intervals and stretch the scale for large intervals, in both ascending and <br>descending modes of  presentation. <br>"The above measurements were obtained for Western classical music, but <br>the same general tendencies are evident in intonation form a military band <br>(Stauffer, 1954),  Swedish folk musicians (Fransson, Sundberg & Tjernland, <br>1970), and jazz daxophonists (Owes, 1974). Measurements of intonation <br>inperformance for Indian (Hindustani) classical music (jairazbhoy & Stone, <br>1963; Callow and Shepard, 1972) show similar variability." [Burns, E. M., and <br>Ward, W.D., "Intervals, Scales and Tuning," in The Psychology of Music, ed., <br>Diana Deutsch, 1982, pg. 258.]<br>"Even the ubiquitous 5th itself is played, on the average, sharper than the <br>702 cents predicted; indeed, in Shackford's study, it is played sharpest in a <br>harmonic context, where the minimization-of-beat forces would be <br>expected to be the most active." (...) Thus evidence indicates strongly that in <br>musical performances the target pitch for frequencies actually produced in <br>response to a given notation is one that is just a shade sharper than that <br>called for by Et.  In the 500 and 1000 Hz regions, even the subjective octave <br>(sacrosanct 2:1 in all theoretical systems) is about 1210 cents for pure <br>tones (Ward, 1954). In his studies, Shackford (1962 a,b) measured harmonic <br>10th, 11th and 12th and found that they were sharped to about the same <br>extent as 3rd, 4tha nd 5th.<br>"Boomsliter and Creel (1963) too have provided striking confirmation of this <br>theory. (...) ...it is clear from the sample dat they present aththe preferred <br>scale almost always is composed of tones consistently higher in frequency <br>than those of ET. For example, in three classical numbers (the Marseillaise, <br>a Bartok dance, and Mozart's Serenta Notturna), all notes above "do" are <br>preferred 4 to 23 cents sharp." [Ward, W.D., "Musical Perception," in <br>"Foundations of Modern Auditory Theory," ed. J.V. Tobias, Vol. 1,  pp. 420-<br>421]<br>cent 2:1.<br>The next post will examine data bearing on the third theory of hearing--<br>a model of the ear so far not dealt with as extensively as the other two.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Tue, 10 Oct 1995 02:20 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id RAA12768; Mon, 9 Oct 1995 17:20:34 -0700<br>Date: Mon, 9 Oct 1995 17:20:34 -0700<br>Message-Id: <951010001440_71670.2576_HHB24-3@CompuServe.COM><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2122 href="#2122">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/11/1995 2:29:05 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Tuning & psychoacoustics - post 17 of 25<br>---<br>While Ohm's/Helmholtz's view of the ear as Fourier  analyzer has staggered<br>under the blows of psychoacoustic research, so has the<br>Seebeck/Stumpf/Schouten model of the ear as a neural periodicity pitch<br>detector.<br>True, 50 years of research has unearthed many results which cannot be<br>explained by the frequency-domain model or "place theory" of hearing... But the<br>periodicity model of hearing has *also  *shown many shortcomings.<br>In particular, both models of the ear/brain system fail to explain or predict<br>the important phenomenon of categorical perception.  Neither model of hearing ex<br>plains the existence or pitch of the Zwicker Tone, or Risset's and<br>Shepherd's auditory paradoxes (sounds which when transposed upward by an<br>octave, drop in perceived pitch; sounds which appear to rise or fall<br>indefinitely in pitch yet whose fundamental frequency never changes;<br>sounds which are heard as speeding up/slowing down constantly yet whose<br>rate never changes).<br>Moreover, if the structure of the human ear is responsible for the music we<br>make and the tunings we use and the harmonies we prefer, how is it possible<br>to explain the fact that different cultures make entirely different kinds of<br>music?<br>If the ear is either a Fourier analyzer or a time-based autocorrelator which<br>responds most powerfully to either small-integer ratios played on<br>instruments with integer harmonics (the Fourier analysis model of hearing)<br>or fixed pitches played on instruments whose partials are matched to the<br>tuning--for example, the Railsback stretch of the grand piano matched to<br>the stretch of the partials of the piano strings--(this is the autocorrelation<br>model of hearing in which tuning & timbral partials, even if stretched, will<br>autocorrelate so as to yield uniform time-domain periodicities and thus a<br>sense of definite pitch with fundamental)...<br>If either of these models of hearing is accurate, why do the Javanese play<br>inharmonic instruments using stretched octaves and non-just non-equal-<br>tempered tunings?<br>Are other cultures deranged?  Are their ears physically different from ours?<br>Musicologists of the 19th century dismissed the Javanese, the Balinese, and<br>other non-western music with references to "the degree of aural<br>development among races as well as individuals."<br>The variability in Javanese and Balinese tunings was dismissed by De Lange<br>and Snelleman in 1992 with the memorable phrase: "for those whose ears<br>are insufficiently developed, the perfect fourth is not divided into two<br>whole tones and a semitone, but rather as the sixth, eventh and eighth<br>harmonic partials." [DeLange, Daniel and Snellman, J.F, "La Musique et les<br>instruments de musique dans les Indes Orientales neerlandaises," in<br>Lavignac, "Encylopedie de la musique et dictionnaire du COnservatoire:<br>Histoire de la musique, premiere partie (Paris, 1922," Vol. 5, pg. 3148.]<br>Such racism has become less fashionable over the last three quarters of a<br>century, but much of the debate over psychoacoustics and tuning takes place<br>in a cultural vacuum: only western music is considered, and psychoacoustic<br>arguments for or against this or that tuning are often made only in the<br>context of western equal temperament or just intonation tuning systems.<br>However, such enthocentrism is slowly changing.<br>"One of the revelations of modern psychoacoustic and etnomusicological<br>reserach has been the extraordinary complexity of intonation as used by<br>Western and non-Western musicians." [Perlman, Marc, "American Gamelan in<br>the Garden of Eden: Intonation in a Cross-Cultural Encounter," Musical<br>Quarterly, 1995, pg. 532]<br>"There are...a number of musical cultures that apparently employ<br>approximately equally tempered 5- and 7-interval scales (i.e., 240 and 171<br>cent step-sizes, respectively) in which the fourths and fifths are<br>significantly mistuned form their natural values.  Seven-interval scales are<br>usually associated with Southeast Asian cultures (Malm, 1967). For<br>example, Morton (1974) reports measurements (with a Stroboconn) of the<br>tuning of a Thai xylophone that "varied only + or - 5 cents" from an equally<br>tempered 7-interval tuning. (In ethnomusicological studies measurement<br>variability, if reported at all, is generally reported without definition.)<br>Haddon reported (1952) another example of a xylophone tuned in 171-cent<br>steps from the Chopi tribe in Uganda.  The 240-cent step-size, 5-interval<br>scales are typically associated with the "gamelan" (tuned gongs and<br>xylophone-type instruments) orchestras of Java and Bali (e., Kunst, 1949).<br>However, mreasurements of gamelan tuning byHood (1966) and McPhee (1966)  show e<br>xtremely large variations, so much so that McPhee states: "Deviations  in what i<br>s considered the same scale are so large that<br>one might with  reason state that there are as many scales as there<br>are gamelans." Another example of a 5-interval, 24--cent step tuning<br> (measured by a  stroboconn,  "variations" of 15 cents) was reported by<br> Wachsmann (1950) for a Ugandan harp.  Other examples of equally tempered scales<br> are often reported for pre-instrumental cultures...<br>For example, Boiles (1969) reports measurements (with a Stroboconn,<br>"+ or - 5 cents accuracy") of a South American Indian scale with equal<br>intervals of 175 cents, which results in a progressive octave stretch.<br>Ellis (1963), in extensive measurements in Australian<br>aboriginal pre-instrumental cultures, reports pitch distirbutions that<br>apparently follow arithmetic scales (i.e., equal separation in Hz).<br>Thus there seems to be a propensity for scales that do not utilize perfect<br>consonances and that are in many cases highly variable, in cultures that<br>either are pre-instrumental or whose main instruments are of the xylophone<br>type. Instruments of this type produce tones who partials are largely<br>inharmonic (see Rossing, 1976) and whose pitches are often ambiguous (see<br>de Boer, 1976)." [Burns, E. M. and Ward, W. D., "Intervals, Scales and Tuning,"<br>in The Psychology of Music, 1982, ed. Diana Deutsch, pg. 258]<br>These empirical data would seem to indicate that  of the three tunings (equal te<br>mpered,  just intonation, and non-just non-equal-tempered)<br>non-just non-equal-tempered and equal temperament are most widely<br>used by other cultures.  This is a conclusion directly opposite to that<br>implied by the idea of small whole numbers as uniquely preferred by<br>the ear/brain system.<br>The next post will examine in detail the third theory of hearing, first<br>proposed by Fetis in 1843, and in later life espoused by Helhmoltz: namely,<br>the view that the ear prefers a set of intervals determined by learning<br>and culture.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Thu, 12 Oct 1995 03:16 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id SAA00081; Wed, 11 Oct 1995 18:15:55 -0700<br>Date: Wed, 11 Oct 1995 18:15:55 -0700<br>Message-Id: <951012011313_71670.2576_HHB40-2@CompuServe.COM><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2124 href="#2124">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/12/1995 6:33:22 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Tuning & psychoacoustics - post 18 of 25<br>---<br>So far little has been said about the third theory of hearing, first proposed <br>by Fetis in 1841 and supported by Helmholtz and Ellis, as well as by vast amounts of psychoacoustic data from Ward, Dixon, Terhardt, et alii. <br>Fetis ascribed musical intervals and msuical conventions to "education" <br>rather than to "nature," mathematics, or the structure of the ear.<br>Although few of the proponents of equal temperament or just intonation who <br>quote him will admit it, Helmholtz echoed this sentiment when he wrote <br>that the Western musical system "does not rest solely upon inalterable <br>natural laws, but is also, at least partly, the result of esthetical principles, <br>which have already changed, and will still further change, with the <br>progressive development of humanity." [Helmholtz, Hermann, "On the <br>Sensation of Tone," 2nd. Dover ed., 1863, pg. 235]<br>As  previously noted, after exhaustive study of the musics of many cultures, <br>Alexander James Ellis concluded that "the Musical Scale is not one, not <br>`natural,' nor even founded necessarily on the laws of the constitution of <br>musical sound, so beautifully worked out by  Helmholtz, but very diverse, <br>very artificial, and very capricious." [Ellis, A. J., "On the Musical Scales Of <br>Various Nations," Journal of the Royal Society of the Arts, Vol. 3, 1885, pg. <br>536]<br>"The evidence presented thus far implies that musical-interval categories <br>are learned rather than are the direct result of characteristics of the <br>auditory system. This evidence includes: (1) the variability found in <br>measured scales and intonation, even when possible contextual effects are <br>taken into account; (2) the intrasubject variability, large intersubject <br>variability, and consistent deviations from small-integer-ratio categories <br>found in category-scaling and adjustment expeirments; (3) the absence of <br>small-integer-ratio ssingularities in frequency-ratio-JND functions and <br>absence of small-integer- ratio confusions in absolute-identification <br>experiments; and (4) the relative inability ofmusically untrained subjects to <br>perform musical interval identification or discrimination exeriments. <br>[Burns, E.M., and Ward, W.D, "Intervals, Scales, and Tuning," in The Psychology <br>of Music, ed. Diana Deutsch, 1982, pg. 261]<br>Moreover "since stimulus uncertainty in `real world' perception is, in <br>general, high, it might be expected that categorical preception of musical <br>pitchwould be the normal situation. This conclusion is supported by the <br>results of the various investigations of intonation in performance. Second, <br>the lack of evidence for the existence of natural categories for musical <br>intervals implies that individuals in a given culture learn the scales of their <br>culture from experience, not because of any innate propensity of the <br>auditory system for specific intervals." [Burns, E. M., and Ward., W.D., <br>"Categorical Perception," Journ. Acoust. Soc. Am., Vol. 63, No. 2, February <br>1978, pg. 466.]<br>"To the casual glance, the range and variability figures of Table III may <br>suggest that the performers were not very proficient, which is not at all <br>true.  Even when tuning an instrument to the *same* pitch as a standard, <br>the typical musician will show a standard deviation, in repeated settings, of <br>about 10 cents (Corso, 1954)." [Ward, W.D., "Musical Perception," in <br>"Foundations of Modern Auditory Theory," ed. J.V. Tobias, 1970, Vol. 1, pg. <br>418]<br>Again, these psychoacoustic results provide equal support for all three <br>major systems of tuning: equal-tempered, just intonation, and non-just non-<br>equal-tempered, inasmuch as the evidence strongly suggests that once the ear learns to accept any given set of musical intervals they are quickly<br>learned and categorized as "pure," "preferred," "natural," etc.<br>--mclaren<br> <br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Thu, 12 Oct 1995 15:58 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id GAA08250; Thu, 12 Oct 1995 06:58:00 -0700<br>Date: Thu, 12 Oct 1995 06:58:00 -0700<br>Message-Id: <00997C43D9CD945A.4CBC@ezh.nl><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2133 href="#2133">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/13/1995 8:00:23 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Tuning & psychoacoustics - post 19 of 25<br>---<br>We return to the parable of the three blind men and the elephant. Because of <br>the powerful prejudicial effect of mathematical and  physical models on <br>our perceptions and preconceptions, it's vital to understand some of the <br>drawbacks of those mathematical models--in particular, the Fourier <br>transform, far and away the most popular analysis technique for dealing <br>with sounds.  <br>As it turns out, the complexity of the ear's behavior is mirrored by the <br>complexities and limitations which beset the Fourier transform. <br>"The measurement of sound spectra is complicated by the fact that the <br>spectra of almost all sounds change both rapidly and drastically as time <br>goes by.  This situation is worsened by the fact that the accuracy with <br>which we can measure a spectrum inherently decreases as we attempt to <br>measure it over smaller and smaller intervals of time.<br>"The spectral content of any instant during the temporal evolution of a <br>waveform does not even exist; for example, we could scarcely tell anything <br>at all about the frequency comopnents of a digital signal by examining a <br>single sample!  We can measure what happens to the spectrum only on the <br>average over a short interval of a sound--perhaps a millisecond or so.  The <br>longer the interval, the more accurate our measurement of the average <br>spectral content during that interval, but the less we know of the variations <br>that occurred during that  interval.  Thus the problem of spectral <br>measurement may be see to be one of finding the best compromise between <br>the opposing goals.  Just how much accuracy is needed is still an open <br>question in the realm of musical psychoacoustics: in some cases  our ears <br>seem to be more toleraant of approximations than in others.  The historical <br>model of spectra as measured by Hermann Helmholtz (see References) is <br>clearly inadequate for believable resynthesis..." [Moore, F. R., "An <br>Introduction tothe Mathematics of Digital Signal Processing," Part II, <br>Computer Music Journal, Vol. 2, No. 2, pg. 43] <br>Claims of "perfect  reconstruction of the input signal" are often made for <br>Fourier transform analysis.   These claims are true only insofar as the <br>continuous Fourier transform is involved, a mathematical operation demanding  infinite amounts of data and infinite numbers of frequency<br> components. <br>Claims of "perfect reconstruction of the input signal" are *untrue* for the  discrete short-time Fourier transform applied to real-world signals.<br>"The test of any analysis/synthesis system is how little it distorts the <br>signal.  The phase vocoder, or short-term Fourier system, as it is also <br>called, is capable of zero distortion. (...) Consequently, what comes out of <br>each channel is a pure sinusoid.  We can measure its frequency, phase, and <br>amplitude. Thus, we can recreate the signal exactly by producing a new <br>sunsoid of that frequency, phase, and amplitude.<br>"In the electronic music literature this is called additive synthesis.  <br>Needless to say, when the assumption is violated, and the input signal is <br>something like white noise, the output of each channel is not a sinusoid and <br>cannot be represented with only phase, frequency, and magnitude data. You <br>must use a different representation. But for harmonic sounds in which the <br>pitch and amplitude are not changing, categorizing the signal by these three <br>numbers yields a system which is an identity."[Moorer, J.A., "A Conversation <br>with James A. Moorer," Roads, C. in "The Music Machine," 1989, pg. 14]<br>In the real world all sounds contain noise.  And not just one kind<br>of noise: many different kinds of noise are present. There is <br>always some white noise, and always some 1/f noise represented by jitter <br>in the fundamental frequency, there is always a stochastic component in the <br>individual harmonic envelopes, and there is always some band-limited noise, <br>as for instance from the scrape of a violin bow or the background breath-<br>noise in a flute. Thus the claim of "perfect reconstruction of the input <br>signal" is untrue for real-world Fourier analysis applied to real-world <br>sounds.   The exact amount of distortion introduced and the precise <br>amount of data lost by doing a real-world short-time Fourier analysis of a <br>real-world sound varies with the sound. <br>In some cases, the distortion and data loss is negligible, while in other <br>cases the short-time Fourier analysis renders the sound unrecognizable.<br>So why do many people continue to act as though the Fourier perspective<br>is the only valid one for dealing with acoustics?<br>Because engineering courses are saturated with the Fourier perspective, it <br>is often assumed that frequency/time duality (or in optics, <br>contrast/periodicity) is the only possible way of looking at any physical <br>phenomenon--particularly acoustics.  <br>This is often true, but by no means always.<br>In fact multiple methods of sound analysis have long been suggested: in <br>1947 Denis Gabor suggested an alternative to the Fourier method of analysis <br>of sounds in his paper "Acoustical Quanta and the theory of hearing." [Gabor, <br>D, "Nature," Vol. 159, 1947, pg. 303.]<br>Both Morlet and Daubechies wavelets have offered new paradigms for <br>analyzing sounds: see Kronland-Martinet et alii, "Grossman, A. and Kronalnd-<br>Martinet, R., "Time-and-scale representation obtained through continuous <br>wavelet transforms," 1988, Signal Processing IV: theories and Applications, <br>Amsterdam: Elsevier Science Publishers. <br>The Fourier transform viewpoint is a linear parametric method of analysis.  <br>Thus it is strictly limited by the assumptions inherent in parametrized <br>analysis, and by the assumption that input functions will obey the <br>superposition principle.<br>Other non-linear non-parametric models for signal processing exist. See <br>Maragos, P., "Slope Transforms: Theory and Application to Nonlinear Signal <br>Processing," IEEE Trans.Sig. Proc., Vol. 43, No. 4, April 1995, pp. 864-877.<br>Each of these mathematical analysis methods has its own unique drawbacks: <br>"Even though the Morlet wavelet analysis seems to compact information in a <br>way that is well suited to the characteristics of hearing, it does not work <br>as easily as the use of Gabor grains for altering independently frequency and <br>speed.  Hence the value of this or that method is contingent on the music <br>purpose. Indeed to realize various types of intimate sonic modification, one <br>may have to go out of the general framework and resort to more specific <br>methods." [Risset, J.C., "Timbre Analysis by Synthesis," in "The Music <br>Machine," 1992, pg. 37]<br>Frequency-based mathematical models of analysis are not the only kind <br>possible: time-based autocorrelation methods of pitch detection have long <br>been implemented in computers. Both the Average-Mangitude Difference Function (a time-based autocorrelation) and the zero-crossing detection function (another time-based period-detection method) are typically used<br>to extract a fundamental frequency track from a digitized  waveform prior to employing a Fourier transform to dissect the sound into sinusoids. <br>Thus, ironically, the best-known frequency-domain algorithm for analyzing <br>musical sounds is crucially dependent on a *prior    time-domain    <br>autocorrelation    algorithm * when we want to apply it in the real <br>world. Given this incestuous connection between frequency- and time-<br>domain methods of analysis in the real world, it is not clear why one <br>viewpoint (the Fourier transform) ought to dominate the discourse of signal <br>processing.<br>The progressive discovery of the many limitations of the Fourier transform <br>as a tool for analyzing real-world sounds has led to a search for alternative <br>methods of analysis: Jean-Claude Risset, the pioneer of analysis-by-<br>synthesis in 1965 on mainframe computers at Bell Labs, states: "From these <br>studies I draw two conclusions: first, there does not seem to be any general <br>and optimal paradigm to either analyze or synthesize any type of sound.  One <br>has to scrutinize the structure of the sound--quasiperiodic, sum of <br>inharmonic components, noisy, quickly or slowly evolving--and also <br>investigate to find out which features of sound are relevant to the ear." <br>[Risset, Jean-Claude, "Timbre Analysis by Synthesis," in "The Psychology of <br>Music," ed. Diana Deutsch, 1982, pg. 18]<br>Because the Fourier mindset dominates and shapes so much<br>of the discourse of Western music, it's important to point<br>out *all* of its limitations and inaccuracies.  Thus the<br>next post will continue the discussion of the many conditions<br>under which the Fourier viewpoint is inappropriate for<br>real music in the real world.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Fri, 13 Oct 1995 17:07 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id IAA05441; Fri, 13 Oct 1995 08:07:19 -0700<br>Date: Fri, 13 Oct 1995 08:07:19 -0700<br>Message-Id: <Pine.SOL.3.91.951013095946.18776B-100000@library><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2140 href="#2140">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/14/1995 7:39:20 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Tuning & psychoacoustics - post 20 of 25<br>---<br>As is now evident, the Fourier transform is at best poorly suited<br>to the analysis of real-world sounds.<br>Noise, inharmonic partials and radical phase changes insure that<br>many real-world instrument tones are poorly modelled as a<br>sum of pure sinusoids near-constant in magnitude and phase.<br>This is complicated by the fact that "...much of the characteristic sound of <br>an instrument is in its transient regions, such as the attack portion of its <br>tone." [Moorer, J. A., "Signal Processing Aspects of Computer Music - A <br>Survey," Computer Music Journal, Vol. 2, No. 2, pg. 7]<br>To date, the aperiodic and chaotic attack portions of instrumental notes <br>have consistently resisted analysis, as have the residual stochastic <br>portions of the sound which cannot be analyzed successfully by current <br>techniques: a variety of work-arounds are  generally used to "smooth-over" <br>the radical phase and magnitude discontinuities generated by Fourier <br>analysis of the attack transients, or to parametrize the chaotic-attractor <br>"residual" and mimic it with some kind of bandlimited noise generator added <br>to the resynthesized signal.<br>"Each...spectrogram tells how amplitude and phase vary as a function of <br>frequency.  This process of analysis and resynthesis has been called a phase <br>vocoder.  Serra made use of the process to his ends, taking successive <br>spectra at intervals of around 10 milliseconds.<br>"Such successive spectra do not in themselves give a deep insight into <br>musical sounds.  Serra's innovation was to use successive spectra in <br>dividing the signal into two parts--and deterministic, or predictable part, <br>and a stochastic, or unpredictable, noisy part.  The deterministic part Serra <br>took to be clear peaks which in several successive spectra change just a <br>little in apmlitude and phase.  This part of the spectrum Serra resynthesized <br>by generating the individual sinusoidal compoennts whose amplitudes, <br>frequencies, and phases changed with time in the fashion indicated by the <br>successive spectra. (...) [Serra] replaced this [non-deterministic] part of the <br>spectrum with a noise that had roughly the  same overall spectrum as his <br>stonachastic part but that didn't match it in waveform.<br>"Serra tested this division of the signal into a deterministic and stochastic <br>part...by listening separately to the deterministic and stochastic parts, and <br>then adding them and listening to their sum. A piano sound reconstructed <br>from the deterministic spectra alone didn't sound like a piano.  With the <br>stochastic or noise portions added, it sounded just like a piano.  The same <br>was true of a guitar, a flute, a drum, even the human voice." [Pierce, J.R., <br>"The Science of Musical Sound," 2nd ed., 1992, pg. 106] <br>Moreover, Fourier techniques work even to a rough  approximation only with <br>a small class of harmonic-series instruments (Western brass instruments, <br>double reeds and strings, the harp). <br>"Most percussion instruments (drums, bells) are inharmonic. This means that <br>to describe them with sinusoids aften requires a large number of such. <br>There are some synthesis techniques for creating what often turn out to be <br>quite convincing drum-like or gong-like sounds, but to date there are few <br>analysis techniques that can be used with inharmonic sounds."  [Moorer, J. A., <br>"Signal Processing Aspects of Computer Music - A  Survey," Computer Music <br>Journal, Vol. 2, No. 2, pg. 7]<br>Bearing in mind that this puts all of Javanese and Bainese and Thai and most <br>African and South American music off-limits to Fourier analysis (because <br>these cultures  use mainly inharmonc instruments), the value of <br>Fourier analysis becomes questionable in the context of world music.<br>The net result is that conventional FFT  analysis *sometimes* tells us <br>*something* about what is going on in *portions* of *a few notes* played  by *a few instruments.*  <br>However, the Fourier transform is far from the universal mathematical <br>Swiss Army Knife it has been touted as being.<br>For example, suppose we try to increase frequency resolution by taking an <br>FFT of tens of thousands of points--we have only 2 ways of doing this.  [1] <br>Add tens of thousand of zeroes padded at the end of each wavecycle, which <br>merely refines the accuracy with each bin's frequency is specified but does <br>not tell us anything about what's going on between the frequency bins <br>(where most of the interesting and complex behavior of real-world <br>intstruments takes place); or [2] we can extend our FFT over multiple <br>wavecycles, which does give us some information about what's going on <br>between frequency bins because the fundamental of the wavecycle is apt to <br>change over the couse of several period--but this dodge lumps all the <br>spectral changes in 2, 3, or more wavecycles into a single analysis frame <br>and thus "smears out" the spectral changes of the sound in time. <br>If this sounds like "Catch-22," guess what? <br>It is. <br>Heisenberg's Uncertainty Principle is actually an outgrowth of the basic <br>characteristic of wave motion:  to wit, you can accurately measure <br>*either*  the frequency *or *  the period of a changing waveform, but you <br>cannot measure *both * precisely at the *same    time. * And when you <br>increase the precision with which you measure the wavetrain's period, you <br>consequently decrease the precision with you measure the wavetrain's <br>frequency.<br>This has profoundly important consequences for the FFT.<br>[1] Increasing your time resolution (that is, making the FFT snapshots closer <br>together in time) deceases your frequency resolution (because you must <br>therefore take smaller FFTs over those smaller time-lengths). <br>[2] Increasing your frequency resolution (that is, taking the FFT snapshot <br>over a bunch of different spectrally-evolving wavecycles) decreases your <br>time resolution (because all the spectral changes in each frequency line are <br>lumped into a single frequency and averaged over the number of wavecycles <br>you're looking at).<br>[3] Increasing the number of phase points, to give you a more precise <br>measurement of the exact amount by which partial is detuned from the <br>others, also increases the number of frequency bins--and to do this you <br>must extend the FFT over a longer time-period, which in turn means you're <br>lumping your phase changes together and averaging them out, which entirely <br>defeats your purpose.<br>[4] Decreasing the number of frequency points, to narrow down the time <br>window over which you take the FFT "snapshot," also decreases the number <br>of phase points--which divides the fundamental frequency in a smaller <br>number of divisions and defeats your purpose by making the measured <br>frequency changes coarser in the time domain.<br>Because the discrete Fourier transform is cyclic and imposes an infinite <br>periodicity (both supersonic and subsonic) on your spectrum, you must use a <br>limited fixed sampling rate and band-limit your input samples to avoid <br>aliasing (that is, to avoid the lowest supersonic and the highest subsonic <br>frequency bins from bleeding into your audible frequency bins and <br>contaminating them with inharmonic-sounding spurious garbage). <br>But once you fix your samling rate, you've thrown out all information <br>between samples. This means that there's no way to  reconstruct the detail <br>in the waveform "between" the samples because it's gone.  You've dumped it <br>out.  You've thrown out the baby with the bathwater.  The price you pay for <br>perfect reconstruction of a signal is that the signal that spews out of your <br>mathematical analysis algorithm is sometimes quite different from the real <br>analog signal that came in.<br>"Sometimes" because if there's very little noise and the partials are almost <br>perfectly harmonic,  you get good results with the Fourier transform even in <br>its discrete version.<br>Alas, most sounds are *not*  noise-free and perfectly harmonic.<br>"If you have a hammer, everything in the world looks like a nail."  This is <br>nowhere more true than of the Fourier transform.<br>Many writers have begun articles on tuning or acoustics with statements <br>along the lines of: "Musical sounds are made up of sinusoidal frequency  and <br>phase components..."  <br>No!<br>Wrong!<br>Completely false!<br>Classic error.<br>These people have mistaken the *map*  for the *territory.*<br>They have confused the *mathematical  model * of the  physical <br>phenomenon with the *physical phenomenon * itself.<br>*Sounds * are displacements of air molecules.   <br>*Sinusoids * are ideal mathematical entities infinite in temporal extent <br>and perfectly periodic.    <br>Sometimes one or another mathematical model works well in analyzing <br>acoustical phenomena; other times they all work well, sometimes *none * <br>yield useful results. <br>Different mathematical techniques and different conceptual models are <br>required for different acoustical phenomena, as Risset points out.<br>There is no "one size fits all."  Yet this this is exactly what the Fourier <br>tykes would have us believe.<br>The universe exhibits what the mathematicians call "the inexhaustibility of <br>the real."  Goedel proved this in 1930: the universe is ultimately more <br>complex than any statements we can make about it mathematically.<br>Or, to put in another way, there are an infinite number of true but <br>unprovable propositions.<br>Clearly proponentsn of this or that tuning system who write circularly-<br>reasoned arguments a la "that's the beauty of mathematics--it has an <br>inescapable logic" haven't collided with the real world in the form of a <br>sound that turns to junk when you Fourier analyze it.  <br>For example, breathy vocal sounds. Or flute multiphonics, or a cymbal clash, <br>or gamelan bar note.<br>It's worth remembering Fourier never came up with his transform to solve <br>the problem of frequency analysis. He used it as a clever dodge to solve the <br>problem of heat comduction in a  metal bar.  <br>It worked well on that problem, but it has since been greatly extended--in <br>some cases, overextended.<br>The wavelet transform, a probably superior mathematical method for <br>analyzing acoustic phenomena, dates from only 1987.<br>Since then we've had very few useful & powerful transforms.  <br>Mathematical progress has been slow.  The Walsh Transform is no big help--<br>it is acoustically "brittle" and is too few Walsh components are used in a <br>reconstructing a sound, the output is intolerably buzzy and distorted-<br>sounding.  Bart Kosko's fuzzy Kalman filter promises some insight into <br>acoustic transformations but the amount of  ground gained has been <br>small...and the rate of progress slow.<br>In the end, the real world is very *very*  VERY complex.  <br>Our linear parametric mathematical models models apply with accuracy only <br>to an tiny class of physical phenomena.  <br>It has become increasingly (distressingly!) clear over the last few years <br>that sounds are not "infinite harmonic wavetrains containing perfectly <br>harmonic overtones with a few stochastic ergodic noise components mixed <br>in."<br>Rather, real computer analysis of actual instrument timbres shows with <br>brutal clarity that real-world sounds run the entire gamut from chaotic <br>strange attractors to pure noise to semi-noise/semi-pitched to strongly <br>pitched narrowband noise to mostly harmonic sounds with a rock-steady <br>fundamental.<br>No one mathematical analysis technique is adequate to model all these <br>ranges of behavior.  And when you realize that something as simple as the <br>flute can exhibit the entire range (overblown multiphonics, semi-pitch <br>"breathy" whispery notes, flutter-tongued notes, strongly pitched notes in <br>the lower registers with a steady fundamental) you start to realize  that <br>the FFT is useful for only a very limited class of musical sounds. Thus it is <br>hardly surprising that the to-date largely FFT-obsessed model of the ear as <br>frequency analyzer has had extremely limited success in explaining real-<br>world musical preferences, the effects of real-world intervals on listeners, <br>and the real-world propensity of composers, performers and audiences to <br>prefer intervals not well defined by the integer eingenvalue vocabulary  of <br>the Fourier transform.<br>--mclaren<br> <br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Sat, 14 Oct 1995 17:30 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id IAA19603; Sat, 14 Oct 1995 08:30:29 -0700<br>Date: Sat, 14 Oct 1995 08:30:29 -0700<br>Message-Id:  <9510140829.aa01987@cyber.cyber.net><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2144 href="#2144">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/15/1995 7:59:42 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Tuning and psychoacoustics - post 21 of 25<br>---<br>Throughout this series of posts, we have seen that the ear/brain system is not simple.<br> Tones," in "The Psychology of Music," ed. Diana Deutsch, 1982, pg. 21]<br>But the behavior of the ear/brain system is also different from that predicted by Seebeck, Stumpf and Schouten: <br>e away the fundamental 440 cps and the second harmonic 880 cps? <br>l. 1, No.1, 1955, pg. 55 (English edition, 1957)]<br>This is the simplest and most compelling example of the contradictory behavior of the ear/brain system.<br>s. (...) The fundamental neural message is given by the rate and the distribution in time with which individual impulses are fired along the axon." [Roederer, Juan, "The Physics and Psychophysics of Music," 1973, pg. 45]<br>des the information on repetition rate or periodicity pitch (see below)."  [Roederer, Juan, "The Physics and Psychophysics of Music," 1973, pg. 45]<br>main and the Seebeck/Stumpf time-domain model of the ear, and instead supports the Fetis/Burns/Ward model of the ear as an adaptive system molded by learned responses.<br>Thus in one simple experiment we have compelling evidence both for and against all 3 major theories of hearing.<br>Other compelling evidence for the "contextual" behaviour of the ear/brain system abounds. <br> influencing is effected by the following vowel (regressive dissimilation) as well as by the preceding." [Werner Meyer-Eppler, "Statistic and Psychologic Problems of Sound,"  Die Reihe, Vol. 1, No.1, 1955, pg. 55 (English edition, 1957)]<br>and Synthesis," in "The Psychology of Music," ed. Diana Deutsch, 1982, pg. 36]<br> 429.]<br> 1, pg. 429.]<br>greater than 2 milliseconds." [Pierce, J.R., "The Science of Musical Sound," 2nd ed., 1992, pg. 149]<br>"On the hypothesis that critical band filters can be identified with<br>auditory nerve filters, the model of Zwicker and Scharf was tested by<br>Pickles (1983). (...) The results agreed with the psychophysical darta, in<br>that the summed activity increased with stimulus bandwidth, for wider<br>timulus bandwidths. (Fig. 9.13 B).  However, there was no clear sign<br>of a flat portion in the function at narrow bandwidths. The reason for<br>this is not known..." [Pickles, James O., "An Introduction to the Physiology<br>of Hearing," Academic Press, 2nd ed., 1988, pg. 283]<br>. <br>he listener is based on learned experience..." [Roderer, Juan, "The Physics and Psychophysics of Music," 1973, pg. 134] <br>But by far the most striking gaps in current knowledge of the ear/brain system involve the  question of how the human auditory performs 3-dimensional sound localization. <br>TF, or the location of a specific sound using that mathematically-modelled HRTF.<br><br>Human Subjects," J. Audio Eng. Soc., 43(5), 1995 May, pp. 300-321; also<br>see Appleton, J., "Machine Songs III: Music In the Service of Science--<br>Science in the Service of Music," Computer Music Journal, 16(3), 1992,<br>pp. 17-21]<br>Clearly, there remain many unexplained aspects in the behavior of the ear/brain system.<br>The next post examines the mass of evidence gleaned from<br>the many psychoacoustics results confirmed and supported<br>by a wealth of modern.  Although the modern psychoacoustic<br>data is complex, it does support some conclusions.  These will<br>be given in the next post, after which the various biases and<br>prejudices of the psychoacoustic researchers themselves will<br>be examined...with an eye to determining how much or how little<br>their prejudices affected the conclusions each major researcher<br>drew from hi/r research.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Sun, 15 Oct 1995 19:43 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id KAA28157; Sun, 15 Oct 1995 10:42:44 -0700<br>Date: Sun, 15 Oct 1995 10:42:44 -0700<br>Message-Id: <951015174059_71670.2576_HHB28-1@CompuServe.COM><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2151 href="#2151">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/16/1995 8:42:42 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Tuning and psychoacoustics - post 21 of 25<br>---<br>Throughout this series of posts, we have seen that the ear/brain system <br>is not simple.<br>As is now clear, the behavior of the auditory system when presented <br>with complex tones is different than that predicted by Ohm/Helmholtz: <br>"Helmholtz's working hypothesis has  been put aside by later <br>investigators, both those who worked in music and those who worked <br>in psychoacoustics.  Several reasons for this can be given.  First, <br>before the introduction of electroacoustic means of tone production <br>and control in the 1920s, it was not possible to carry out the <br>necessary psychoacuostical experiemnts, while Helmholtz's observations <br>proved insufficient in many ways. Second, it turned out that musical <br>theory has its own rules apart formm the perceptual relevance of the<br> characteristics of the sounds it makes." [Rasch, R. A., and Plomp, R.,<br> "The Perception of Musical Tones," in "The Psychology of Music," ed. <br>Diana Deutsch, 1982, pg. 21]<br>But the behavior of the ear/brain system is also different from that <br>predicted by Seebeck, Stumpf and Schouten: <br>"It sounds obvious if we say that we hear a note a' if the fundamental <br>of the frequency is 440 c.p.s. But what happens if we remove this <br>fundamental by electrical means, leaving on ly the harmonics with <br>frequencies of 880, 1320, 1760 cps, etc?  Or if we take away the <br>fundamental 440 cps and the second harmonic 880 cps? <br>We learn from experiments that the perceived pitch level remains the <br>same: a'.  One may take away many of the lower harmonics without <br>altering this.  If this `mutilated' note is interrupted for only an <br>interval of a second, the sensation is completely altered. Instead of <br>the `residual tone' on a' we now hear another pitch which lies <br>approximately in the region of the strongest remaining harmonics and <br>is called `formant pitch.'" [Werner Meyer-Eppler, "Statistic and <br>Psychologic Problems of Sound," Die Reihe, Vol. 1, No.1, 1955, pg. 55 <br>(English edition, 1957)]<br>This is the simplest and most compelling example of the contradictory <br>behavior of the ear/brain system.<br>The ability of the ear to extract an unambiguous fundamental frequency <br>from a complex tone argues strongly in favor of the Ohm/Helmholtz <br>hypothesis of the ear as a Fourier analyzer; but the ability of the <br>ear to still hear a "residual" fundamental even after the fundamental <br>and lower harmonics have been removed electronically cannot be <br>explained by the ear-as-Fourier-analyzer model of hearing. Instead, <br>"beats of mistuned consonances and periodicity pitch can be perceived <br>even if each component tone is fed dichotically to a different ear.  <br>In such a case, of course, the complete vibration pattern never <br>arises--what must arise is a superposition or interaction of the <br>neural signals from both cochleas after they have been combined at <br>the medullar or midbrain levels. (...) The fundamental neural message <br>is given by the rate and the distribution in time with which <br>individual impulses are fired along the axon." [Roederer, Juan,<br>"The Physics and Psychophysics of Music," 1973, pg. 45]<br>Thus the ability to hear such residual pitch argues against the<br> Ohm/Helmholtz Fourier analyzer model of hearing, and for the <br>Seebeck/Stumpf model of the ear as time-domain autocorrelator in <br>which "the actual time distribution of [auditory nerve] impulses <br>codes the information on repetition rate or periodicity pitch (see <br>below)."  [Roederer, Juan, "The Physics and Psychophysics of <br>Music," 1973, pg. 45]<br>However, the fact that after a brief interruption the ear hears <br>exactly the same tone from which fundamental and lower harmonics <br>have been electronically removed as having an entirely different <br>pitch argues strongly against BOTH the Ohm/Seebeck frequency-domain <br>and the Seebeck/Stumpf time-domain model of the ear, and instead <br>supports the Fetis/Burns/Ward model of the ear as an adaptive <br>system molded by learned responses.<br>Thus in one simple experiment we have compelling evidence both <br>for and against all 3 major theories of hearing.<br>Other compelling evidence for the "contextual" behaviour of the <br>ear/brain system abounds. <br>"...it is to be emphasized that sound elements which are juxtaposed <br>in time can have the effect that identical physical vibration <br>procedures give rise to totally different sensations.  The phenomenon <br>has been particularly observed in the case of synthetic explosive <br>sounds such as `p',`t', `k' which may be perceived in a totally <br>different manner, depending on the vowels which are juxtaposed <br>to them (3).  To explain this one cannot attribute it to masking <br>which has already been known for a long time becuase the <br>influencing is effected by the following vowel (regressive <br>dissimilation) as well as by the preceding." [Werner Meyer-Eppler, "<br>Statistic and Psychologic Problems of Sound,"  Die Reihe, Vol. 1, <br>No.1, 1955, pg. 55 (English edition, 1957)]<br>Further evidence of complex phenomena possibly produced by <br>interaction between the ear's frequency-domain and its <br>time-domain processing functions was brought forward by <br>Strong and Clark. "...in order to evaluate the  relative significance <br>of spectral and temporal envelopes, [they] resorted to an <br>interesting process: they exchanged the spectral and temporal <br>envelopes among the wind instruments and asked listeners to <br>attempt to identify these hybrid tones.  The results indicated <br>that the spectral envelope was dominant if it existed in a unique <br>way (as in the oboe, clarinet, bassoon, tube and trumpet); otherwise <br>(as in the flute, trombone, and French horn), the temporal envelope <br>was at least as important." [Risset, Jean-Claude, "Exploration of <br>Timbre by Analysis and Synthesis," in "The Psychology of Music," <br>ed. Diana Deutsch, 1982, pg. 36]<br>Some results are simply inexlicable by any of the above models: <br>"Doughty and Garner (1948)...concluded that pitch was unchanging <br>for tones of 25 msec and longer, but that 12-msec and 6-msec <br>tones have a lower pitch.  However, Boomsliter et al., (1964) <br>emphasize that the transition from "click" to "tone" depends on <br>the intensity. Swigart (1964) has reported a perhaps related <br>phenomneon for repeated short bursts of tone.  If one presents <br>successive 8-msec bursts of 1000-Hz tone with 1-msec pauses  <br>between (i.e., if one cuts out every ninth cycle), the pitch is <br>significantly lower than that of a continuous 1000-Hz tone.  <br>Just why, however, is still unclear." [Ward, W.D., "Musical <br>Perception," in "Foundations of Modern Auditory Theory," ed. J.V. <br>Tobias, Vol. 1, pg. 429.]<br>"An aspect of pitch perception that is still regarded as <br>somewhat mysterious despite a goodly amount of experimentation <br>is "aboslute" (or "perfect") pitch." [Ward, W.D., "Musical Perception," <br>in "Foundations of Modern Auditory Theory," ed. J.V. Tobias, Vol. 1, <br>pg. 429.]<br>"In 1973 David M. Green published some interesting results on <br>temporal acuity. He measured the ear's ability to discriminate <br>between two signals that have different waveforms but the same <br>energy spectrum.  An example of such signals is any short waveform <br>and the same waveform reversed in time, such as those in figure <br>10-5.  Here Part A is a sound of decreasing frequency, Part B is a <br>sound of increasing frequency. Green found that the ear can tell the <br>difference between two such waveforms if their duration is greater <br>than 2 milliseconds." [Pierce, J.R., "The Science of Musical Sound," <br>2nd ed., 1992, pg. 149]<br>"On the hypothesis that critical band filters can be identified with<br>auditory nerve filters, the model of Zwicker and Scharf was tested by<br>Pickles (1983). (...) The results agreed with the psychophysical data, in<br>that the summed activity increased with stimulus bandwidth, for wider<br>timulus bandwidths. (Fig. 9.13 B).  However, there was no clear sign<br>of a flat portion in the function at narrow bandwidths. The reason for<br>this is not known..." [Pickles, James O., "An Introduction to the <br>Physiology of Hearing," Academic Press, 2nd ed., 1988, pg. 283]<br>No model of the ear/brain system convincingly explains any of <br>the above results, or for that matter one of the best-known <br>quirks in musical perception: perfect pitch. Musical aesthics is <br>yet another abyss which has swallowed many a psychoacoustic <br>researcher. <br>"Why some vibration patterns appear more "beautiful" than others <br>is not known.  A great deal of research (good and bad) has been <br>attempted, for instance, to find out what physical characteristics <br>make a Stradivarius violin a great instrument.  Many of these <br>characteristics are dynamic in character, and most of them seem <br>more related to the major or minor facility with which the player <br>can control the wanted tone "color" (timbre), than to a "passive" <br>effect on a listener.  To a large extent the impression on the listener <br>is based on learned experience..." [Roderer, Juan, "The Physics and <br>Psychophysics of Music," 1973, pg. 134] <br>But by far the most striking gaps in current knowledge of the <br>ear/brain system involve the  question of how the human auditory <br>performs 3-dimensional sound localization. <br>A Head-Related Transfer Function can be measured empircially for <br>each individual by means of microphones placed in the ear canals  <br>and an extremely high-speed computing engine, but to date no one <br>has offered a general mathemtical model which predicts the HRTF, <br>or the location of a specific sound using that mathematically-<br>modelled  HRTF.<br>The best example of this complete gap in our psychoacoustic <br>knowledge is the inadequacy of current stereo speakers.  Even a <br>6-year-old child easily detects the difference between a recording <br>reproduced from digital media on high-quality stereo speakers, and <br>a live performance: but to date no one has succeeded in <br>formulating a mathematical model of hearing which details the <br>difference in hard numbers. [See Moeller, H. K., Soerenson, M. F.,<br> Hammershoei, D., and Jensen, C. B, "Head Related Transfer Functions <br>of Human Subjects," J. Audio Eng. Soc., 43(5), 1995 May, pp. <br>300-321; also see Appleton, J., "Machine Songs III: Music In the <br>Service of Science-- Science in the Service of Music," Computer <br>Music Journal, 16(3), 1992,pp. 17-21]<br>Clearly, there remain many unexplained aspects in the behavior of <br>the ear/brain system.<br>The next post examines the mass of evidence gleaned from<br>the many psychoacoustics results confirmed and supported<br>by a wealth of modern.  Although the modern psychoacoustic<br>data is complex, it does support some conclusions.  These will<br>be given in the next post, after which the various biases and<br>prejudices of the psychoacoustic researchers themselves will<br>be examined...with an eye to determining how much or how little<br>their prejudices affected the conclusions each major researcher<br>drew from hi/r research.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Tue, 17 Oct 1995 01:35 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id QAA13399; Mon, 16 Oct 1995 16:34:38 -0700<br>Date: Mon, 16 Oct 1995 16:34:38 -0700<br>Message-Id: <199510162332.AA046446328@athena.ptp.hp.com><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2156 href="#2156">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/17/1995 8:40:51 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Tuning & psychoacoustics - post 22 of 25<br> <br>---<br>In the course of this series of posts much experimental evidence has been <br>reviewed.  Forum subscribers open-minded enough to have read the original <br>references now understand the degree of contradiction and complexity <br>which attends the human auditory system.<br>As we've seen, the evidence offered by psychoacoustic research is not <br>simple and straightforward.  Some results conflict,  and others support <br>none of the three accepted models of human hearing.<br>There is, however, a preponderance of evidence to support a number of basic <br>conclusions about the ear/brain system:<br>The fact that different aspects of the ear/brain's sound processing function <br>are evoked by different experiments opens up the likelihood that at least 3 <br>different ear/brain systems operate to process sound.  Wever (1964) was <br>the first to suggest that more than one mechanism exists to process sound; <br>von Bekesy strongly implies this conclusion in his 1966 paper. Plomp (1967) <br>strongly disagrees, but gives no basis for his objection. Pickles (1989) <br>points out that "the best support for [this] view is the rather negative<br>one that the evidence in favour of either of the other two [place and<br>periodicity] theories is not conclusive, and this may be a function of<br>the quality of the evidence available, rather than of the acutal operation<br>of the auditory system." [Pickles, James O., "An Introduction to the<br>Phsyiology of Hearing," Academic Press, 2nd ed., 1988, pg. 277]<br>The leading candidates for different mechanisms for detecting pitch and <br>processing sounds, they are: [1] the Fourier analyzer action of the <br>basilar membrane; [2] the  encoding of pitch and spectral content by <br>repetition rate of neurons firing  along the auditory nerve; [3] the <br>combination of received neural impulses in medullar and higher brain <br>areas and the consequent active feedback pathway between the Sylvian <br>fissure, the superior medial nucleus, and the different classes of neurons <br>in the primary, secondary and third- and fourth-order nerve fibers of <br>the auditory nerve.<br>What does this imply?<br>First, the role of learning and the possible conflict twixt periodicity and <br>Fourier analysis makes it clear that "the pitch of musical sounds is not <br>directly proportional to the logarithm of the frequency and is probably <br>complexly conditioned."  [Corso, J.F. "Scale Position and Performed Musical <br>Octaves," Journal of Psychology, Vol. 37, 1954] This renders suspect tuning <br>theories which ascribe absolute and invariant qualities to this or that <br>scale  degree or interval.  Instead, pitch and  intervallic quality appear <br>to be  storngly influenced by musical context, as well as by the overtone <br>content of the intervals.<br>This conclusion would tend to support all three tunings equally, depending <br>on musical context, and learning: just intonation, equal temperament, and <br>non-just non-equal-tempered tunings are all equally supported by the <br>brain's learned sound processing capacities.<br>With instruments using strictly harmonic spectra, this conclusion weakly <br>supports the use of just intonation tuning--weakly, because of the <br>important role of learned response in the ear/brain system.   For <br>instruments which do not use strictly harmonis spsectra, non-just non-<br>equal-tempered systems are weakly supported: this conclusion does not <br>support use of equal temperament except insofar as education and <br>acculturation can sufficiently indoctrinate listeners into accepting that <br>tuning.<br>Second, from Plomp and Levelt's and Kameoka and Kuriyagawa's work it is <br>clear that the roughness or sharpness of musical intervals is largely <br>determined by proximity of individual overtones with the critical band for <br>that frequency range.<br>It is also clear from Mathews', Pierce's, Geary's, Sethares' and Dashow's <br>work that timbres can be matched to tunings using digital technology so as <br>to precisely control the degree of audible roughness or smoothness within <br>the intervals of the scale.<br>However, it is less clear from the psychoacoustic evidence that audible <br>roughness and sharpness of musical intervals equates with "consonance" and <br>"dissonance," much less with the more sophisticated quality of <br>"concordance" and  "discordance" put forward by Easley Blackwood.<br>Much of the music-theory literature on consonance and dissonance merely <br>redefines those terms to favor the author's chosen list of references. By <br>redefining consonance as "beats," just intonation emerges as the preferred <br>tuning; by redefining consonance as "roughness," the periodicity theory is <br>favored with the proviso that the partials of the overtones be warped to fit <br>the tuning (so that all the partials share sub- and super-multiples of the <br>same periodicity); and if consonance is redefined as "learned preference," or <br>"experimental results of interval preference," non-just non-equal-tempered <br>tuning emerges as the "best" tuning based on the empirical evidence of <br>preference for stretched non-just non-equal-tempered intervals.<br>A good example of this process can be found in the following quote from <br>Plomp:<br>"In conclusion, Helmholtz's theory, stating that the degree of dissonance is <br>determined by the roughness of rapid beats, is confirmed. It appears that <br>maximal and minimal roughness are related to critical bandwidth..." [Plomp, <br>"Experiments on the Tone Sensation," 1967, pg. 58] By discussing only <br>harmonic tones and by defining dissonance as "the roughness of rapid beats," <br>just intonation emerges as the de facto winner.<br>A different set of assumptions produces an entirely different conclusion.  <br>For example, Risset's composition Inharmonique is based on inharmonic <br>tones which also exhibit a lack of "roughness of rapid beats."  Thus Risset's <br>harmonic practices would appear to be equally acceptable according to <br>Plomp's definitions, yet Risset's composition does not employ small-integer <br>ratios--but the compositions still exhibits marked examples of dissonance <br>and consonance.<br>Moreover, musical intervals are often not heard as isolated units: "there is <br>considerable evidence that melodies are perceived as *gestalts * or <br>patterns, rather than as a seuccession of individual intervals, and that <br>interval magnitude is only a small factor in the total percept." [Burns., <br>E.M.,  and Ward, W.D., "Intervals, Scales and Tuning," in "The Psychology <br>of Music," ed. Diana Deutsch, 1982, pg. 264] <br>As Plomp points out, "A clear relationship exists between these data, <br>justifying the conclusion that consonance is closely related to the absence <br>of (rapid) beats, as in Helmholtz's theory.  The critical-bandwidth curve <br>fits the data rather well." [Plomp, "Experiments In the Tone Sensation," <br>1967, pg. 58]<br>Thus, while the psychoacoustic evidence on "roughness" and "smoothness" of <br>musical intervals is clear, the musical imlications are less <br>striaghtforward.  As von Bekesy points out, "...linearity can be assumed of <br>the mechanical part of the [auditory] stimulation; but from a physiological <br>point of view, the question of linearity in the nervous system is still  <br>open to speculation." [von Bekesy, G., "Hearing Theories and Complex <br>Sounds," Journ. Acoust. Soc. Am., Vol. 35, No. 4, 1963, pg. 588]<br>Although "beats" are castigated by one group of theorists and used as the <br>justification for one set of tuning theories, strong evidence exists that a <br>beat rate of 6 to 7 Hz adds to the perceived musicality of a performance.  <br>This is true of both non-Western and Western music:  "Even a cursory <br>acquaintance with the sound of a Balinese gamelan uncovers some puzzling <br>aspects of musical timbre.  The beating complex that is the result of all <br>the beats produced in the gamelan, and especially dependent upon the beats <br>of paired metallophones, resembles in its effect the quality of a string, <br>woodwind or brass section in a Western orchestra.  (...) It appears that <br>some type of pulsation at rates between 6 and 7 times per second -- and <br>slightly irregular -- is musically desirable, both in Bali and in the West, <br>that the effects of beats and the effects of vibrato are similar so far as <br>the quality of richness is concerned, and that the unfiication of hte <br>sound (section sound) can be accomlished with either technique." [Erickson, <br>R., "Timbre and the Tuning of the Balinese Gamelan," Soundings, 1984, <br>pg. 100]<br>In fact the argument for this or that tuning according to beat rate  is not <br>supported by the psychoacoustic data, except insofar as the data strongly <br>support a universal preference for low-level beats in the 6-7 Hz region.<br>The ability of the ear to extract individual components from complex <br>sounds, however, argues strongly in favor of just intonation.<br>JI tunings are the only tunings which accord with the ear's Fourier <br>analysis mechanism.<br>It is, however, clear that Fourier analysis is only one method used by the <br>ear to process sounds, and in many situations it is the least important <br>system. Both Plomp & Levelt's and Kameoka and Kuriyagawa's findings strongly <br>support all three general kinds of tunings, provided that the overtones of <br>the individual partials of the notes are matched to the scale as suggested <br>by Sethares, Risset, Pierce and McLaren.<br>We've seen from Shepard's and Risset's auditory illusions and from Wessel's <br>streaming phenomenon that all 3 ear/brain systems of pitch processing <br>interact; sometimes they conflict.  This provides opportunities for <br>composition using digital media, and tends to support non-just non-equal-<br>tempered tunings (albeit weakly).<br>At first glance, the surprising and universal human preference for stretched <br>intervals, including a stretched octave of between 1210 and 1215 cents on <br>average, strongly favors non-just non-equal-tempered scales. <br>However Terhardt has brought forth convincing evidence that much of this <br>effect is due to learning: and in that case, since any musical tuning can be <br>learned, all three tunings are supported by this body of evidence to the <br>degree that acculturation is involved.<br>The wide variability of interval size in live concerts by expert performers <br>tends to support this concludion; however Terhardt's findings in comparing <br>stretched, compressed and equal-tempered tunings found a differential <br>preference for all three types of tunings--depending on context.<br>This evidence gives superiority to either equal-tempered, stretched or <br>compressed tunings, depending on whether harmony or melody predominates.<br>The body of psychoacoustic evidence as a whole clearly shows a difference <br>between the size of preferred melodic and harmonic intervals called by the <br>same name; this also provides strong evidence for categorical perception of <br>musical intervals, which in turn tends to vitiate the superiority of any <br>given tuning.  If, once learned, an interval can be recogtnized even though <br>significantly altered in size, then many different tunings should prove <br>equally musical and effective provided that Rothenberg's properiety criteria <br>are observed.<br>The experiments also show a clear dichotomy between the preferred size of <br>vertical intervals and sequential intervals. Both preferred interval sizes <br>as measured in adjustment tests are significantly larger than small-integer <br>ratios predicted by conventional Western theory, but the sequential <br>intervals heard as "true thirds," "true fifths," "true octaves," etc. are <br>even wider than the already winder-than-just vertical intervals.  This body <br>of data strongly supports the use of non-just non-equal-tempered tunings, <br>inasmuch as the psychoacoustic data support neither a preference for <br>tempered nor just intervals. <br>Lastly, the limitations on the applicability of the Fourier transform do <br>not argue against just intoantion or for any other tuning, since the FFT is <br>entirely appropriate for strictly harmonic sounds; however an awareness of <br>the limitations of the FFT as a tool for explaining and analyzing musical <br>sounds serves as a warning against generalizing the results of this or that <br>psychoacoustic experiment beyond its proper range.  <br>Thus the data is mixed and, as promised, there exists considerable <br>psychoacoustic evidence to support each major type of tuning, as well as a <br>significant body of findings which tend to *refute * the arguments for each <br>particular tuning.<br>To date, the psychoacoustic data amassed by various researchers has been <br>considered as though it were a perfect array of unbiased results.  However, <br>all the major psychoacoustic researchers have exhibited strong biases <br>toward this or that particular tuning philosophy.  In some cases this <br>muiscal bias  had little effect on the conclusions they chose to draw from <br>their data; in other cases, these researchers deliberately buried or <br>ignored results which did not conform to their tuning prejudices.  <br>The next post will examine in detail the biases of each major reseracher,<br>and the degree to which it warped his conclusions.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Tue, 17 Oct 1995 18:17 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id JAA08685; Tue, 17 Oct 1995 09:16:38 -0700<br>Date: Tue, 17 Oct 1995 09:16:38 -0700<br>Message-Id: <Pine.SOL.3.91.951017110431.9413A-100000@library><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2161 href="#2161">ðŸ”—</a>JOHNSON@SKSOID.dseg.ti.com</h3><span>10/18/1995 5:55:00 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>Greetings!<br><br>I've read with great interest the topics of this list for some time...<br><br>Recently there was mention made of Chinese bells and I remember an excellent<br>article in the April 1987 issue of Scientific American which describes an <br>instrument made of 65 bronze bells recovered by archaeologists in 1978 that<br>dates back to the fifth century B.C.<br><br>An unusual (and rather charming) discovery about these old chime bells is that<br>they were constructed such that each will produce two separate pitches<br>depending upon where they are struck (The interval is always a minor or major <br>third.).  To quote the article, "The design of the bells requires a <br>theoretical grasp of physics and engineering formerly thought to have evolved <br>only in the late 18th century."<br><br><br>Thoughts??? Observations???<br><br>regards,<br><br>dj<br><br>dana-johnson@ti.com<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Wed, 18 Oct 1995 17:09 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id IAA09635; Wed, 18 Oct 1995 08:09:28 -0700<br>Date: Wed, 18 Oct 1995 08:09:28 -0700<br>Message-Id:  <9510180805.aa17347@cyber.cyber.net><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2162 href="#2162">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/18/1995 8:09:28 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Tuning & psychoacoustics - post 23 of 25<br>---<br>Psychoacoustics is an empirical science. Mathematical theories abound, <br>but they are attempts to explain experimental evidence. There are no valid "a priori" theories of hearing.<br>Psychoacoustics uses choice and adjustment methods, along with <br>computer analysis of live performances.  The first methods  involve laboratory  setting, while the second generally does not. <br>Overall results from both settings tend to agree. <br>Psychoacoustic researchers are prone to bias.  The goal of scientific <br>investigation is not to reduce or eliminate the prejudice of the <br>investigator, but to reduce or eliminate its effect on the measured <br>results. All of the psychoacoustic researchers cited so far have tuning <br>preferences. <br>Some of these researchers warp the presentation of results to favor a given <br>tuning system, while others do not.<br>Ohm (1843), Helmholtz (1863) and Pikler (1898) strongly favored  just <br>intonation tunings and the ear-as-Fourier-analyzer model. To explain away <br>the empirical evidence that 19th-century composers and performers <br>universally used equal tempered tunings, Helmholtz claimed that modern <br>performers were incompetent and that "true" (i.e., just) intonation was a <br>lost art, requiring superlative skill. To refute the empirical evidence that <br>most people who listened to music seemed to like equal-tempered intervals, <br>Helmholtz claimed that modern listeners had been brainwashed by equal <br>temperament.<br>In order to determine a listener's "true"  preference among musical <br>intervals, he contended, one needs must find an ear uncomtaminated by <br>debased modern equal-tempered music.  Since ears accustomed to pure just <br>intonation and unsullied by equal temperament were not to be found in 19th <br>century Europe, Helmholtz's hypothesis ran afoul of the first demand on any <br>scientific hypothesis: namely, that it be testable. <br>However, in the second edition of his book "On the Sensations of Tone," <br>Helmholtz modified his original position and wrote that music "does not <br>rest solely upon inalterable natural laws, but is also, at least partly, the <br>result  of esthetical principles, which have already changed, and will still <br>further change, with the progressive development of humanity." [Helmholtz, <br>Hermann, "On the Sensation of Tone," 2nd. Dover ed., 1863, pg. 235]<br>Helmholtz is thus a contradictory figure, on the one hand explaining away <br>empirical evidence with various pieces of circular reasoning, and on the <br>other hand openly suggesting that the third, or learned, model for hearing <br>had a strong influence on the auditory system.<br>Pikler and Ohm proved less open-minded, and they consistently bury results <br>which conflict with just intonation as the "best" tuning. <br>Seebeck (1843), Stumpf (1896) Schouten (1938), Boomsliter & Creel (1965), <br>Plomp (1967) and Roederer (1973) are strongly biased toward the <br>periodicity model of the ear.   Of these, Seebeck, Schouten and Stumpf do not <br>attempt to explain all pitch processing or auditory phenomena on the basis <br>of the periodicity theory: they simply give their results and omit mention of <br>data which would tend to contradict their conclusions. <br>Plomp's approach deserves special mention.  He argues tenaciously and at <br>length against von Bekesy's place theory near the end of his magnum opus, <br>Experiments In the Tone Sensation (1967).  After describing a model of the <br>ear's pitch and spectral-analysis functions as a set of 1/3-octave bandpass <br>filters, Plomp goes on to state: "This model of the ear's frequency-analyzing <br>mechanism must be considered as a simplified representation, since the ear <br>does not containa  limited number of fixed filters but is a continuous <br>system of overlapping filters. Nevertheless, Figure 60 elegantly accounts <br>for both the discrimination of the lower harmonics and the preservation of <br>periodicity.  The way in which these waveforms give rise in the ear to <br>periodic nerve impulses, however, is still rather unknown." [Plomp, <br>"Experiments In the Tone Sensation," pg. 128, 1967]<br>Plomp mentions experiments by de Boer (1956), Schouten (1962), Ritsma <br>and Engel (1964) and Licklider (1956, 1959, 1962)--all staunch advocates <br>of the periodicity theory.  Significantly, Plomp does not mention any of the <br>experiments which tend to contradict the periodicity theory of hearing--in <br>particular, Flanagan and Guttman's 1959 experiments and the removal of the <br>fundamental from the Seebeck click series.  These experiments *are <br>*described by von Bekesy.<br>By neglecting to cite the full range of experimental results, Plomp creates a <br>false impression that all psychoacoustic data support the periodoicity <br>theory.  Moreover, he neglects to mention that the Fourier-analysis (or <br>place) theory of hearing could equally well account for the fact that pitch is <br>primarily determined by the lower harmonics of a sound, and that even when <br>those lower harmonics are masked by noise the ear still detects a definite <br>pitch.  "Apart from the question of how a model spanning only two octaves <br>can throw any light on the perception of a complex tone, we may ask how <br>this observation can explain why the pitch of a complex tone is not altered <br>when the lower harmonics are masked completely by noise... In that case, <br>thecontribution fo the place corresonding to the fundamental is eliminated." <br>[Plomp, "Experiments In the Tone Sensation," 1967, pg. 130]<br>Oddly, Plomp neglects to mention the obvious place-theory explanation of <br>this effect. This phenomenon is well known from the perception of definite <br>pitch ascribed to bells: the ear operates as a Fourier analyzer and fits the <br>partials of the bell into the higher members of a harmonic series, then <br>assigns the bell a perceived pitch given by the assumed fundamental.  If the <br>ear's Fourier analysis can assign a nonexistant fundamental to a bell, why <br>not to a strictly harnonic sound whose lower harmonics are masked by <br>noise?<br>Houtsma summarizes this explanation concisely: "De Boer (1956) reported <br>pitch matches in which inharmonic complex tones comprising five or seven <br>partials with uniform frequency spacing were aurally matched to periodic <br>complex tones with a fundamental that differed systematically from the <br>spectral spacing of the inharmonic sound. Schouten, Ritsma and Cardozo <br>(1962) produced similar data for AM complexes (three partials)...and <br>smoorenburg (1970) found essentially the same results using complexes <br>consisting of only two tones. [Houstma, A.J.M., and Goldstein, J.L., "The <br>Central Origin of the Pitch of Complex Tones: Evidence from Musical Interval <br>Recognition," Journ. Acoust. Soc. Am., Vol 51, No. 2, 1971, pg. 525]<br>Moreover, Plomp glosses over the most serious objection to the periodicity <br>theory--namely, that because of the duration imposed on the impulses from <br>nerve fibers in the inner ear, pitches above 1600 Hz should not be <br>perceptible. "The physiological process which sets an upper limit to the <br>frequency of impulses in each fiber is the refractory period. For a brief <br>interval of approximately 1 msec after each impulse the nerve-fiber is not <br>excitable and cannot transmit another impulse." [Boring, E. G. and A. Forbes, <br>Hearing: Its Psychology and Physiology, 1983, 2nd ed., pg. 401]  Plomp's <br>response to these objections is worth noting:  <br>"The hypothesis that hte pitch of a tone is based on the period of the sound <br>waves may be criticized ont eh ground that this periodicity is preserved up <br>to 3000-4000 cps, whereas we are able to distinguish tones up to about <br>16000 cps. This discrepancy is one of the most serious arguments against <br>periodicity pitch. It is obviated by Wever's assumption (Chapter 7) that the <br>ear is provided with two ptich-detecting mechanisms: one, based on <br>periodicity, for low frequency and one, based on place of maximal <br>stimulation along the basilar membrane, for high frequencies.  This <br>conception is not very attractive, however." [Plomp, "Experiments In the <br>Tone Sensation, 1967, pg. 130]<br>This is a remarkable statement. Plomp saves the periodicity model of pitch <br>by dragging in another model of ear/brain function, then criticizing his own <br>conclusion!<br>Plomp never explains why the idea of multiple auditory pitch detection <br>mechansisms is "not very attractive."  Moreover, his arguments for the <br>periodicity theory lose much of their power because he's forced to appeal to <br>the very theory he's arguing against (the place theory) in order to save the <br>periodicity theory for notes with high fundamentals.<br>In several cases where both the periodicty and place theories offer equal <br>explanatory power, Plomp consistently comes down on the side of the <br>periodicity theory.  Consider the following example:<br>"Upon presenting tone intervals with the same freuqnecy ratios to the ear, <br>for instance the mistuned interval 200 + 601 cps, the same phenomena were <br>observed as with (von Bekesy's) model. This corresondence was considered <br>by von Bekesy as an affirmation that in both cases the same mehcanism is <br>involved.  In his opinion, it seems clear that the periodicity of the nerve <br>impulses does not play an important part in the production of beats.<br>Although this reasoning appears rather attractive, I prefer an alternative <br>explanation of the beats which is based on the assumption that pitch is <br>related to the periodicity of nerve impulses." [Plomp, "Experiments In the <br>Tone Sensation," 1967, pg. 125]<br>Perhaps even the most diligent researchers become confused when <br>attempting to explain away their own biases.  At least Plomp admits his <br>prejudice: "In the writer's opinion, this explanation of pitch perception in <br>terms of periodicity is more satifactory than those based on the palce <br>principle. If the pitch of complex tones is derived from periodicity, it is <br>difficult to see why this should not be the case for simple tones, too." <br>[Plomp, "Experiments In the Tone Sensation," 1967, pg. 129]  <br>Aside from the fact that many of his objections to the place theory are <br>easily answered, and that he neglects to point out some of the most serious <br>problems with the periodicity theory, Plomp is reasonably straightforward <br>about his leanings toward the periodicity theory.<br>Boomsliter & Creel, in "The Long Pattern Hypothesis in Music," Journ. Mus. <br>Theory, 1965, are not so forthcoming.<br>They are strongly prejudiced toward just intonation, and their article does <br>not cite results which tend to contradict either periodicity or JI tunings <br>(viz., combination tones, the universal preference for stretched intervals, <br>etc.) and they explicitly attempt to derive all of the ear's functions from the <br>periodicity theory.  For example, there's no mention of the body of <br>psychoacoustic evidence for a universal preference for stretched intervals, <br>and Boomsliter and Creel explain away their own data showing a general <br>preference for just intervals on their "search organ" singificantly larger <br>than those predicted by the just intonation theory of small whole numbers. <br>The same is true of Roederer in his book's section on the physical makeup of <br>the ear/brain system: there is a great deal of discussion of neurons and <br>neural firing pattern, none at all on the processing of medullar and higher <br>brain areas nor any detailed discussion of von Bekesy's experiments, the <br>physical action of the organ of Corti, etc.  However to his credit Roederer <br>does cite extensively the results of Ward, Corso, Terhardt, Sundberg and <br>Lindqvist for the unviersal preference of stretched invtervals.  <br>Thus Roederer, like Helmholtz, is a contradictory figure--deliberately <br>overemphaszing some of the evidence, while remaining open-minded about <br>other contradictory results. Fetis (1943), Ellis (1885) Corso (1954), Ward <br>(1970),  Burns (1970), Hood (1975) and Erickson (1983) are all strongly <br>biased toward the ear-as-controlled-by-learned-preference model of <br>hearing.  Terhardt and Ward/Burns tend to bury evidence which does not <br>favor their view by dumping a superflux of additional results on top of the <br>relevant data; this has the same effect as squirelling the relevant data <br>away in a bibliograhy at the back of the article, but it achieves the same end <br>by opposite means. Fetis, Hood, Ellis, tend to stress the  multiplicity of <br>results and musical cultures, rather than concentrating on empirical data <br>from specific experiments.<br>Von Bekesy demonstrates a bias toward the place theory but his bias does <br>not appear to affect his willingness to bring forward contradictory results. <br>In particular, he cites both the periodicity and place theories as worthy of <br>additional investigation in his 1966 article "Hearing Theories and Complex <br>Sounds," Journal of the Acoustic Society of America. <br>Terhardt & Zick, Kameoka & Kuriyaga, Pierce, Mathews, Green, Wessel, <br>Risset  and Sundberg do not exhibit a bias toward any specific theory of <br>hearing.  These authors all cite competing hypotheses and suggest lines of <br>further experimental inquiry into all 3 ear/brain models.<br>Throughout this article the intent has been to present psychoacoustics data <br>as clearly as possible.<br>In many cases this meant extracting experimental results from layers of <br>refutation or from citations buried in bibliographies because this or that <br>psychoacoustician preferred not to bring the inconventient result out into <br>the body of the text, where it might raise embarassing questions.<br>In other cases, viz., Risset or von Bekesy or Pierce, extensive direct quotes <br>of secondary sources were used because these sources offered the most <br>detailed survey of the evidence.<br>Thus the casual reader must be wary of Roederer, Helmholtz, Plomp and <br>other sources widely cited because of the covert (sometimes overt) bias <br>toward this or that tuning or theory or hearing.<br>As mentioned at the outset, acousticians have fared far worse than <br>psychoacoustics researchers in this regard.  <br>Backus (1969), like von Bekesy, is biased toward just intonation--but unlike <br>von Bekesy he neglects to mention any of the psychoacoustic experiments <br>which cast doubt on either just intonation as the ideal tuning system or the <br>place theory as the sole explanation of hearing.  In the chapter ""Intervals, <br>Scales, Tuning, and Temperament," Backus lavishes 3 pages on just <br>intonation and 2 pages on Pythagorean intonation but only 1 page on equal <br>temperament. No tunings are mentioned  other than Pythagorean, meantone, <br>just intonation and equal temperament: there is, for example, no reference <br>to pelog, slendro, the Indian srutis, or any other non-European tuning..<br>Moreover, Backus buries or is not aware of many psychoucstic data which <br>contradict his view of the ear as simple Fourier analyzer.  In part (as <br>mentioned earlier) this is because Backus had the bad luck to publish his <br>book "The Science of Musical Acoustics" just before computers introduced <br>an immense unpheaval into acoustic and auditory research. In part the <br>problem appears to be overt prejudice against acoustic results which do not <br>favor just intonation.  As mentioned earlier, texts by Rossing and Hall <br>supersede the acoustics in Backus and the psychoacoustics  (where Backus <br>refers to them at all) are incorrect as well as out of date. Thus Backus' <br>entire text should be ignored.<br>Benade (1975) cannot excuse his lapses on the basis of bad timing. In the <br>period 1970-1974 much of the data cited throughout this series of posts <br>was already well known; Benade chooses not only to ignore it, but actually <br>to argue with a number of independently-confirmed results, particularly the <br>universal preference for stretched musical intervals and the accumulated <br>evidence for the periodicity theory.   <br>For example: "Experiments by Paul Boomsliter and Warren Creel give us very <br>important information on what a musician actually does about tuning.  My <br>discussion in this capter is strongly influenced by these data, although I do <br>not completely accept their published interpretatiojn.  Paul C. Boomsliter <br>and Warren Creel, "The Long Pattern Hypothesis in harmony and hearing," J. <br>Mus. Theory, Vol. 5, No. 2, 1961, pp. 2-30, and Paul C. Boomsliter and Warren <br>Creel, "Extended Reference: AN Unrecognized Dynamic in Melody," J. Mus. <br>Theory, vol. 7, No. 2, 1963: pp. 2-22. " [Benade, A., "Fundamentals of Musical <br>Acoustics, 1975, pg. 303]<br>In short, Benade agrees with Boomsliter and Creel's claim for "small-<br>integer-ratio" detectors in the ear, but rejects the evidence they provide for <br>the periodicity theory of hearing.   Benade's commentary is notable because <br>[1] it is hidden away in a  footnote and [2] it ignores the fact that a wealth <br>of additional evidence supports the periodicity theory of hearing--evidence <br>which cannot be easily explained by the place theory, which Benade <br>espouses.<br>Again: "Everywhere in our experiments we have found indications that our <br>nervous system processes complex sounds coming to it by seeking out <br>whetever subsets of almost harmonically related components it can find." <br>[Benade, A., "Fundamentals of Musical Acoustics," 1975, pg. 68]<br>This statement is as deceptive as it is true.  The accuracy of Benade's claim <br>depends on experiments he chooses to perform: and by failing to perform <br>auditory experiments which would cast doubt on the place theory of hearing, <br>Benade creates the impression that no such doubt exists.  As has been seen <br>throughout this article, there is ample evidence both to support and <br>contradict the place theory of hearing (and to support and contradict the <br>other two models of hearing as well). By omitting mention of any of this <br>additional evidence, Benade creates a profoundly misleading impression in <br>the unwary reader.  The implication of Benade's statement is that all <br>psychoacoustic experiments support the place theory of hearing--entirely <br>untrue, as we have seen.<br>Again: "The situation with tones having harmonic partials is much more <br>straightforward.  We have already learned that pitch-matchings between <br>usccessive and superposed tones are in agreement the tones consist of a <br>few strong partials." [Benade, A., "Fundamentals of Musical Acoustics," <br>1975, pg. 302]<br>The psychoacoustic data do not support this claim.  On the contrary: every <br>psychoacoustic experiment since the 1830s shows a distinct and <br>measurable difference betwen intervals heard as "perfect" when played <br>successively and when played simultaneously, with a strong tendency for <br>successive tones to be played wider than simultaneous tones, and a <br>consistent tendency for both categories of tones to be played wider than <br>small-integer ratios.  Clearly in this case Benade is unware of (or has <br>chosen to ignore) 150 years of  psychouacoustic data.<br>For these reasons Benade's text is unreliable insofar as it bears on <br>psychoacoustics.  Some of Benade's acoustic results remain valid, others <br>have been disproven--particularly Benade's discussion of oscillation <br>patterns in woodwinds and his theory of regimes of oscillation for brass <br>instruments.  On balance the entire text should be ignored in favor of more <br>detailed and far more accurate treatments by Rossing, Fletcher, Askill and <br>Lord Rayleigh.<br>Rossing and Fletcher's "The Physics of Musical Instruments," and Askill's <br>"The Physics of Musical Sound" remain excellent surveys of the state of the <br>art in musical acoustics.  As mentioned, however, little information on <br>psychoacoustics can be gleaned from these texts because psychoacoustics is <br>not their concern.  These texts do not cite appreciable amounts of <br>psychoacoustic data and should not be quoted to support this or that tuning <br>or theory of hearing.<br>"Musical Acoustics: An Introduction," by Donald Hall, 1980, contains an <br>accurate precis of acoustics of piano strings, metallohpohnes and <br>woodwinds, as well as good survey of brass instruments, et alii. Hall is <br>strongly biased toward just intonation and he buries or calls into question <br>psychoacoustic data which do not accord with his prejudices. The acoustic <br>portion of Hall's text is impeccable and worth reading, while the section of <br>the book which bears on tuning systems and psychocoustics is incomplete, <br>outdated, full of errors of omission, and should be ignored.<br>The single best overall survey of psychoacoustic experiments peformed up <br>to the 1960s is Plomp's 1966 text "Experiments In the Tone Sensation." It <br>contains an exhaustive bibliography unmatched anywhere else, and <br>constantly uses extensive direct quotes from the original sources.  Plomp <br>exhibits a constant and strong bias toward the periodicity theory; however, <br>he readily admits his prejudice.<br>He is also conscientious in pointing out behaviours of the human ear which <br>are not well explained.<br>Georg von Bekesy is biased toward the place theory; not surprising, <br>inasmuch as his work put the place (Fourier) theory of hearing on a firm <br>foundation. He cites both the periodicity and place theories as deserving <br>further study, however,  and (like Plomp) also cites results which <br>contradict all three  models of the ear/brain system.  <br>"Experiments in Hearing," New York: Robert E. Krieger, 1960 and republished <br>in 1980, is the single best source of references for the place theory of <br>hearing. <br>Harvey Fletcher's "Speech and Hearing in Communication," 1953, is dated but <br>unlike Backus and Benade it is not rendered worthless by overt bias.  Better <br>texts now exist (Sundberg, Rossing, Pierce, Terhardt & Zick) but the results <br>Fletcher cites tend to be accurate.<br>Diana Deutsch's 1982 "The Psychology of Music"  summarizes key  <br>psychoacoustic results by many of reserachers who made the original <br>findings.   Most of the  contributors are biased toward one or another tuning <br>and the reader must take care to separate experimental results from the <br>conclusions drawn by the various authors.  As has been seen, the conclusions <br>of various researchers are on occasion mere opinions, unsupported by the <br>facts.  The data cited in Deutsch's compilation are extensive and accurate, <br>although the bibliogpraphies for each section prove distinctly selective.<br>"Psychological Acoustics," edited by E.D. Herbert, is a collection of the <br>original papers in psychocoustics from the 1870s to the 1970s. This is the <br>only text which amasses all the original results in the original authors' own <br>words.  Much of the material is now dated, however, and therefore provides <br>an incomplete picture of the ear/brain system.<br>"Auditory Scene Analysis," by Albert S. Bregman, 1990, is a disappointment. <br>It is vague on crucial points and does not cite enough psychoacoustic <br>references.  While Bregman does not exhibit major biases toward any <br>specific tuning system, he appears to gloss over many difficult areas of <br>psychoacoustics; viz., the contradictory evidence for various theories of <br>hearing, unexplained ear/brain phenomena, the role of musical illusions in <br>the auditory path, etc. <br>On the whole Bregman's text is useful as a quick overview but should not be <br>cited as a primary source.<br>The next and last post of this series will discuss the higher-level <br>ineraction of tuning, timbre and structural tonality as considered by<br>Rothenberg, Keislar, Douthett and as examined in the work of Pierce, Risset, Sethares, Carlos, et al.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Wed, 18 Oct 1995 18:02 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id JAA13167; Wed, 18 Oct 1995 09:01:51 -0700<br>Date: Wed, 18 Oct 1995 09:01:51 -0700<br>Message-Id: <Pine.A32.3.91.951011123529.42758B-100000@freenet2.freenet.ufl.edu><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2168 href="#2168">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/19/1995 9:37:24 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Tuning & psychoacoustics - post 24 of 25<br>---<br>Juan Roederer is one of the more influential psychoacoustic researchers.  <br>Like many others in the field, he is biased toward a particular model of<br>the ear.Roederer is strongly biased toward the periodicity theory of hearing.<br>In "Introduction to Physics and Psychophysics of Music," the section on the<br> physical makeup of the ear/brain system shows this bias clearly.<br>In this section there is a great deal of discussion of neurons and <br>neural firing pattern, none at all on the processing of medullar and higher <br>brain areas nor any detailed discussion of von Bekesy's experiments, the <br>physical action of the organ of Corti, etc.  However to his credit Roederer <br>does cite extensively the results of Ward, Corso, Terhardt, Sundberg and <br>Lindqvist for the universal preference of stretched invtervals.  <br>Thus Roederer, like Helmholtz, is a contradictory figure--deliberately <br>overemphaszing some of the evidence, while remaining open-minded about <br>other contradictory results. Fetis (1943), Ellis (1885) Corso (1954), Ward <br>(1970),  Burns (1970), Hood (1975) and Erickson (1983) are all strongly <br>biased toward the ear-as-controlled-by-learned-preference model of <br>hearing.  Terhardt and Ward/Burns tend to bury evidence which does not <br>favor their view by dumping a superflux of additional results on top of the <br>relevant data; this has the same effect as squirelling the relevant data <br>away in a bibliograhy at the back of the article, but it achieves the same <br>end by opposite means. Fetis, Hood, Ellis, tend to stress the  multiplicity of <br>results and musical cultures, rather than concentrating on empirical data <br>from specific experiments.<br>Von Bekesy demonstrates a bias toward the place theory but his bias does <br>not appear to affect his willingness to bring forward contradictory results. <br>In particular, he cites both the periodicity and place theories as worthy of <br>additional investigation in his 1966 article "Hearing Theories and Complex <br>Sounds," Journal of the Acoustic Society of America. <br>Terhardt & Zick, Kameoka & Kuriyaga, Pierce, Mathews, Green, Wessel, <br>Risset  and Sundberg do not exhibit a bias toward any specific theory of <br>hearing.  These authors all cite competing hypotheses and suggest lines of <br>further experimental inquiry into all 3 ear/brain models.<br>Throughout this article the intent has been to present psychoacoustics <br>data as clearly as possible.<br>In many cases this meant extracting experimental results from layers of <br>refutation or from citations buried in bibliographies because this or that <br>psychoacoustician preferred not to bring the inconventient result out into <br>the body of the text, where it might raise embarassing questions.<br>In other cases, viz., Risset or von Bekesy or Pierce, extensive direct quotes <br>of secondary sources were used because these sources offered the most <br>detailed survey of the evidence.<br>Thus the casual reader must be wary of Roederer, Helmholtz, Plomp and <br>other sources widely cited because of the covert (sometimes overt) bias <br>toward this or that tuning or theory or hearing.<br>As mentioned at the outset, acousticians have fared far worse than <br>psychoacoustics researchers in this regard.  <br>Backus (1969), like von Bekesy, is biased toward just intonation--but <br>unlike von Bekesy he neglects to mention any of the psychoacoustic experiments<br> which cast doubt on either just intonation as the ideal tuning<br>system or the place theory as the sole explanation of hearing.  In the <br>chapter ""Intervals, Scales, Tuning, and Temperament," Backus lavishes 3 <br>pages on just intonation and 2 pages on Pythagorean intonation but only 1 <br>page on equal temperament. No tunings are mentioned  other than<br>Pythagorean, meantone, just intonation and equal temperament: there is, <br>for example, no reference to pelog, slendro, the Indian srutis, or any other <br>non-European tuning..<br>Moreover, Backus buries or is not aware of many psychoucstic data which <br>contradict his view of the ear as simple Fourier analyzer.  In part (as <br>mentioned earlier) this is because Backus had the bad luck to publish his <br>book "The Science of Musical Acoustics" just before computers introduced <br>an immense unpheaval into acoustic and auditory research. In part the <br>problem appears to be overt prejudice against acoustic results which do <br>not favor just intonation.  As mentioned earlier, texts by Rossing and Hall <br>supersede the acoustics in Backus and the psychoacoustics  (where Backus <br>refers to them at all) are incorrect as well as out of date. Thus Backus' <br>entire text should be ignored.<br>Benade (1975) cannot excuse his lapses on the basis of bad timing. In the <br>period 1970-1974 much of the data cited throughout this series of posts <br>was already well known; Benade chooses not only to ignore it, but actually <br>to argue with a number of independently-confirmed results, particularly the <br>universal preference for stretched musical intervals and the accumulated <br>evidence for the periodicity theory.   <br>For example: "Experiments by Paul Boomsliter and Warren Creel give us very <br>important information on what a musician actually does about tuning.  My <br>discussion in this capter is strongly influenced by these data, although I do <br>not completely accept their published interpretatiojn.  Paul C. Boomsliter <br>and Warren Creel, "The Long Pattern Hypothesis in harmony and hearing," J. <br>Mus. Theory, Vol. 5, No. 2, 1961, pp. 2-30, and Paul C. Boomsliter and Warren <br>Creel, "Extended Reference: An Unrecognized Dynamic in Melody," J. Mus. <br>Theory, vol. 7, No. 2, 1963: pp. 2-22. " [Benade, A., "Fundamentals of Musical <br>Acoustics, 1975, pg. 303]<br>In short, Benade agrees with Boomsliter and Creel's claim for "small-<br>integer-ratio" detectors in the ear, but rejects the evidence they provide <br>for the periodicity theory of hearing.   Benade's commentary is notable <br>because [1] it is hidden away in a  footnote and [2] it ignores the fact that <br>a wealth of additional evidence supports the periodicity theory of hearing--<br>evidence which cannot be easily explained by the place theory, which Benade <br>espouses.<br>Again: "Everywhere in our experiments we have found indications that our <br>nervous system processes complex sounds coming to it by seeking out <br>whetever subsets of almost harmonically related components it can find." <br>[Benade, A., "Fundamentals of Musical Acoustics," 1975, pg. 68]<br>This statement is as deceptive as it is true.  The accuracy of Benade's claim <br>depends on experiments he chooses to perform: and by failing to perform <br>auditory experiments which would cast doubt on the place theory of hearing, <br>Benade creates the impression that no such doubt exists.  As has been seen <br>throughout this article, there is ample evidence both to support and <br>contradict the place theory of hearing (and to support and contradict the <br>other two models of hearing as well). By omitting mention of any of this <br>additional evidence, Benade creates a profoundly misleading impression in <br>the unwary reader.  The implication of Benade's statement is that all <br>psychoacoustic experiments support the place theory of hearing--entirely <br>untrue, as we have seen.<br>Again: "The situation with tones having harmonic partials is much more <br>straightforward.  We have already learned that pitch-matchings between <br>usccessive and superposed tones are in agreement the tones consist of a <br>few strong partials." [Benade, A., "Fundamentals of Musical Acoustics," <br>1975, pg. 302]<br>The psychoacoustic data do not support this claim.  On the contrary: every <br>psychoacoustic experiment since the 1830s shows a distinct and <br>measurable difference betwen intervals heard as "perfect" when played <br>successively and when played simultaneously, with a strong tendency for <br>successive tones to be played wider than simultaneous tones, and a <br>consistent tendency for both categories of tones to be played wider than <br>small-integer ratios.  Clearly in this case Benade is unware of (or has <br>chosen to ignore) 150 years of  psychouacoustic data.<br>For these reasons Benade's text is unreliable insofar as it bears on <br>psychoacoustics.  Some of Benade's acoustic results remain valid, others <br>have been disproven--particularly Benade's discussion of oscillation <br>patterns in woodwinds and his theory of regimes of oscillation for brass <br>instruments.  On balance the entire text should be ignored in favor of more <br>detailed and far more accurate treatments by Rossing, Fletcher, Askill and <br>Lord Rayleigh.<br>Rossing and Fletcher's "The Physics of Musical Instruments," and Askill's <br>"The Physics of Musical Sound" remain excellent surveys of the state of the <br>art in musical acoustics.  As mentioned, however, little information on <br>psychoacoustics can be gleaned from these texts because psychoacoustics <br>is not their concern.  These texts do not cite appreciable amounts of <br>psychoacoustic data and should not be quoted to support this or that tuning <br>or theory of hearing.<br>"Musical Acoustics: An Introduction," by Donald Hall, 1980, contains an <br>accurate precis of acoustics of piano strings, metallohpohnes and <br>woodwinds, as well as good survey of brass instruments, et alii. Hall is <br>strongly biased toward just intonation and he buries or calls into question <br>psychoacoustic data which do not accord with his prejudices. The acoustic <br>portion of Hall's text is impeccable and worth reading, while the section of <br>the book which bears on tuning systems and psychoacoustics is incomplete, <br>outdated, full of errors of omission, and should be ignored.<br>The single best overall survey of psychoacoustic experiments peformed up <br>to the 1960s is Plomp's 1966 text "Experiments In the Tone Sensation." It <br>contains an exhaustive bibliography unmatched anywhere else, and <br>constantly uses extensive direct quotes from the original sources.  Plomp <br>exhibits a constant and strong bias toward the periodicity theory; however, <br>he readily admits his prejudice.<br>He is also conscientious in pointing out behaviours of the human ear which <br>are not well explained.<br>Georg von Bekesy is biased toward the place theory; not surprising, <br>inasmuch as his work put the place (Fourier) theory of hearing on a firm <br>foundation. He cites both the periodicity and place theories as deserving <br>further study, however,  and (like Plomp) also cites results which <br>contradict all three  models of the ear/brain system.  <br>"Experiments in Hearing," New York: Robert E. Krieger, 1960 and republished <br>in 1980, is the single best source of references for the place theory of <br>hearing. <br>Harvey Fletcher's "Speech and Hearing in Communication," 1953, is dated <br>but unlike Backus and Benade it is not rendered worthless by overt bias.<br>Better texts now exist (Sundberg, Rossing, Pierce, Terhardt & Zick) but the<br> results Fletcher cites tend to be accurate.<br>Diana Deutsch's 1982 "The Psychology of Music"  summarizes key  <br>psychoacoustic results by many of reserachers who made the original <br>findings.   Most of the  contributors are biased toward one or another tuning <br>and the reader must take care to separate experimental results from the <br>conclusions drawn by the various authors.  As has been seen, the <br>conclusions of various researchers are on occasion mere opinions, <br>unsupported by the facts.  The data cited in Deutsch's compilation are <br>extensive and accurate, although the bibliogpraphies for each section prove <br>distinctly selective.<br>"Psychological Acoustics," edited by E.D. Herbert, is a collection of the <br>original papers in psychocoustics from the 1870s to the 1970s. This is the <br>only text which amasses all the original results in the original authors' <br>own words.  Much of the material is now dated, however, and therefore <br>provides an incomplete picture of the ear/brain system.<br>"Auditory Scene Analysis," by Albert S. Bregman, 1990, is a disappointment. <br>It is vague on crucial points and does not cite enough psychoacoustic <br>references.  While Bregman does not exhibit major biases toward any <br>specific tuning system, he appears to gloss over many difficult areas of <br>psychoacoustics; viz., the contradictory evidence for various theories of <br>hearing, unexplained ear/brain phenomena, the role of musical illusions in <br>the auditory path, etc. <br>On the whole Bregman's text is useful as a quick overview but should not be <br>cited as a primary source.<br>The next and last post of this series will discuss the higher-level <br>ineraction of tuning, timbre and structural tonality as considered by<br>Rothenberg, Keislar, Douthett and as examined in the work of Pierce, <br>Risset, Sethares, Carlos, et al.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Thu, 19 Oct 1995 19:38 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id KAA07308; Thu, 19 Oct 1995 10:37:43 -0700<br>Date: Thu, 19 Oct 1995 10:37:43 -0700<br>Message-Id: <009981E2B053B9DF.5D10@ezh.nl><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2175 href="#2175">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/20/1995 7:57:41 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Tuning & psychoacoustics - post 25 of 25<br>---<br>As an empirical science, psychoacoustics is largely concerned with <br>measuring the reactions of the ear/brain system to specific acoustic <br>stimuli. However, human hearing is a hierarchical process made up of many <br>layers of abstraction.  <br>Small acoustic stimuli shade imperceptibly into larger ones, leading <br>inexorably to such large-scale percepts as "key center," "cadence," and<br> "discordance" and "concordance." As Eberhard Zwicker points <br>out, "It is clear that psychoacoustics plays an important role in musical <br>acoustics.  There are many basic aspects of musical sounds that are <br>correlated with the sensations already discussed in psycoacoustics.  <br>Examples may be different pitch qualities of pure tones and complex sounds, <br>perception of duration, loudness and partially-masked loudness, sharpness <br>as a an aspect of timbre, perception of sound impulses as events within the <br>temporal patterns leading to rhythm, roughness, and the equivalence of <br>sensational intervals.  For this reason it can be stated that most of this <br>book's contents are also of interest in musical acoustics. At this point we <br>can concentrate on two aspects that have not been discussed so far: musical <br>consonance and the Gestalt principle." [Zwicker, E. and H. Fastl, <br>Psychoacoustics: Facts and Models, 1990, pg. 312]<br>Zwicker characterizes the hierarchical perception of musical tones by <br>drawing a distinction between sensory consonance (perceived roughness, <br>sharpness, and noisiness of the tone) and harmony, (perceived tonal <br>affinity, tolerability, and root relationship of tones or sequences of tones <br>to a scale).  <br>So doing, he posits that both modes of perception are hierarchically involved<br> in the sensation of musical consonance.<br>Both experience and experiment tell us that the process of listening to <br>music involves levels of neural organization above the purely physical <br>acoustic operation of the inner ear.  While the point of maximal stimulation <br>on the basilar membrane indicates a simple mechanical Fourier analysis of <br>sounds entering the ear, the firing pattern of neural fibers in the auditory <br>nerve encodes pitch and spectral information in the nerve system in a <br>complex way.<br>The path between primary auditory nerve and cerebral cortex is not a simple <br>one.  Many feedback loops control the processing of auditory information, <br>and there are many opportunities for higher brain centers to alter the raw <br>input travelling up the auditory nerve--and vice versa.<br>The anatomy of the pathway between the auditiory nerve and   the cerebral <br>cortex is complex: the cells of the primary neurons (that is, those in the <br>auditory nerve) are located within the modiolus of the cochlea; these <br>primary nurons terminate in the cochlear nucleus, a mass of gray matter <br>located in the dorsal and lateral portion of the medulla oblongata. Here the <br>physical nerve connection breaks. From this point there is a synpatic <br>connection (mediated by neurotransmitters) to the neurons of the inferior <br>colliculus.  After another synpatic gap in the neural pathway, the third-<br>order neurons converge on the medial geniculate body, the final relay station<br> on the auditory path to the cerebral cortex. It's worth nothing that the <br>medial geniculate body not only collates fibers from the audtiory nerve, but <br>also from other sensory systems and from the cerebral cortex as well. Thus <br>the geniculate body serves not as a passive relay station so much as an <br>active filtering and integrating locus.<br>>From the geniculate body, the fourth-order auditory neurons connect with <br>the cerebral conrtex by way of a thin sheet of radiating nerve fibers.  These <br>radiations include corticofugal fibers running from the cortex back to the <br>medial geniculate body.<br>Thus the auditory neural pathway contains a complex feedback loop, <br>controlled by several sets of higher brain loci, running between the auditory <br>nerve and the cerebral cortex.  <br>Most of the fourth-order neurons enter a small region ofthe posterial half <br>of the horizontal wall of the Sylvian fissure, which acts as a focal zone for <br>the entire auditory cortex. The complexity of the auditory region of the <br>Sylvian fissure is daunting: each cochlear fiber makes connections with <br>thousands of other neurons grouped in at least thirteen regions, and <br>populated by many different types of neurons. To make the process even <br>more complex, not all of these neurons respond identically. Some produce <br>strong signals when presented with tones in a <br>particular frequency range but do not respond to tones in other frequency <br>ranges. A small fraction of neurons emit strong signals when two different <br>frequencies are sounded together, but these same neurons produce little or <br>no response when either frequency sounds alone. Some neurons are most <br>strongly stimulated by sounds at specific amplitudes: sounds outside this <br>narrow amplitude window cause no resopnse from suchneurons. For yet other<br> auditory nerve fibers, the higher the sound's amplitude, the stronger the <br>response, until a satuation point is reached. Some neurons respond best toe <br>amplitude-moedulated tones, others to frequency-modulated tones. Some <br>neurons respond with paritcular vehemence to sounds coming from a <br>particular region of space, and some neurons respond best to sounds that <br>are moving in space.<br>Because these cortical loci consist of neural pathways, they are formed by <br>learned response and can be changed.  Thus, the impact of culture and <br>experience on musical perception is at least as great as the physical <br>sensory correlates of musical tone--if not greater.<br>"I once attended...a concert in Bangkok that was totally mystifying. I could <br>see that the audience was utterly enraptured, swooning at moments of <br>apparently overwhelming emotional beauty that made no impression on me <br>whatsoever; not only that, I couldn't distinguish them from any other <br>moments in the piece." [Eno, Brian, "Resonant Complexity," Whole Earth <br>Review, May 1995, pg. 42]<br>This points to a important caveat.  While the results adduced so far provide <br>evidence for this or that musical tuning system ont he basis of sensory <br>consonance, psychoacoustics cannot describe or validate the higher levels <br>of musical organization implicit in a tuning system.<br>Thus the internal structure of a tuning is different from the sensory <br>consonance produced by intervals within that tuning.  For example: Risset's, <br>Pierce's and Sethares' timbral mapping procedure, following the <br>implications of research by Plomp and Levelt and Kameoka and Kuriyagawa, <br>allow a composer to control the level of *sensory consonance * in a given <br>tuning, but mapping the component partials of a sound into a given <br>maximally consonant set for a specific scale does *not * change the <br>inherent tonality of the scale, its Rothenberg propriety, the Barlow <br>harmonicity or the Wilson efficiency of the scale.<br>In short, by changing timbre, note duration, and compositional style one can <br>change the surface affect of music produced in a given tuning: but the <br>deeper structural elements of the tuning remain invariant. <br>Ivor Darreg described one of the deeper structural invariants in a given <br>tuning as its "mood:" "In my opinion, the striking and characteristic moods <br>of many tuning-systems will become the most powerful and compelling <br>reason for exploring beyond 12-tone equal temperament. It is necessary to <br>have more than one non-twelve-tone system before these moods can be <br>heard and their significance appreciated." [Darreg, Ivor, "Xenharmonic <br>Bulletin No. 5, 1975, pg. 1]<br>David Rothenberg proposed that the Rothenberg propriety of a scale <br>explains some aspects of the scale's deep structure; Clouth and Douthett <br>duplicated some of this work in their article "On Well-Formed Scales."  <br>John Chalmers has speculated that Rothenberg propriety explains the sense <br>of tension in such tunings as Ptolemy's intense diatonic.<br>In addition to the "mood" or overall "sound" of a given tuning, Darreg and <br>McLaren (1991) pointed out that each tuning exhibits some degree of <br>inherent bias toward melody or harmony.  The Pythagorean intonation and <br>13-tone equal temperament, for example, are both strongly biased toward <br>melody, while 31-tone equal temperament and 13-limit just intonation are <br>strongly biased toward harmony.<br>Douglas Keislar made this same point in his 1992 doctoral thesis.  In it, <br>Keislar describes research which demonstrates that altering the surface <br>characteristics of the music--timbre, tempo, spatialization--does not <br>change the deeper structural characteristics of the tuning. Thus, while <br>mapped overtones will make a comopsition in 13-tone equal temperament <br>sound more acoustically smooth, it does not change the essentially atonal <br>character of the 13-tone scale, nor does it materially affect the scale <br>"mood." Similarly, changing the timbres of a composition in Ptolemy's <br>intense diatonic tuning will alter the degree of sensory roughness or <br>smoothness; adding reverberation will mask to greater or lesser degree <br>some of the overall "sound" of the composition.  But the sense of aesthetic <br>tension created by scale intervals which are, in Rothenberg's usage, <br>improper, will remain unchanged.<br>Thus the implications for tuning suggested by psychoacoustic research <br>must be viewed as separate from larger musical and perceptual questions. <br>Because current psychoacoustic experiments focus on questions of sensory <br>perception, there remains a dichotomy between what Easley Blackwood has <br>called "concordance and discordance" and sensory consonance and <br>dissonance. In fact sensory consonance is a misnomer: the effects are more <br>accurately described as sensations of auditory roughness or smoothness.<br>Depending on the tuning or the composition, intervals which are perceived <br>as rough may prove concordant, while intervals which prdouce the auditory <br>sensation of smoothness may strike the listener as discordant--that is, out <br>of place musically.  In Western music, the best example of this phenomenon <br>is the perfect fourth, which sounds acoutically smoother than the major <br>third but which by itself generally constitutes an unstable and  musically <br>discordant interval.<br>In Balinese and Javanese music, the best example is the stretched 1215-<br>cent octave, which sounds acoustically rough but which produces as sense <br>of musical concordance when performed by a gamelan.<br>The most striking example in my own experience was a 1990 concert by <br>the Women's National Chorus of Bulgaria. One of the duets (a folk song <br>from the Thracian plains) ended on a large major just second (9/8).  The <br>Western audience sat without moving forwhat seemed a long time: only <br>when the  singers bowed did the audience realize the duet was over, and <br> applaud.  In  this case the contradiction between learned perceptions of <br>concordance and cadence, and the sensory perception of roughness in the <br>cadential intervals, prevented the audience from correctly perceiving the <br>cadence. <br>It is important not to confuse sensory roughness or smoothness, as <br>measured by psychoacoustical experiments, with higher-level perceptions <br>of musical consonance and dissonance. Many advocates of just intonation <br>have baselessly conflated the two categories, while advocates of Fetis' <br>model (viz., all auditory responses are predominately learned responses) <br>excessively emphasize the abstract levels of hierarchical auditory <br>perception while unjustifiably discounting the purely physical processes at <br>work in the human ear/brain system--in particular the frequency-analysis <br>operations of the basilar membrane and the periodicity-extraction <br>mechanism of the neurons in the auditory nerve. <br>Ultimately, what Zwicker calls Gestalt musical perception is mediated not <br>only by the physics and acoustics of the inner ear, but also by primary, <br>secondary, third-order and fourth-order neurons, a variety of different <br>brain locations, and the operant conditioning imposed by experience, culture <br>and  musical tradition.  The conclusions of this series of posts must be <br>taken in that context, and understood in that larger framework.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Sat, 21 Oct 1995 01:16 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id QAA08509; Fri, 20 Oct 1995 16:16:08 -0700<br>Date: Fri, 20 Oct 1995 16:16:08 -0700<br>Message-Id: <Pine.3.89.9510201934.A16496-0100000@email.ir.miami.edu><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2179 href="#2179">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/21/1995 7:38:10 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: large numbers of tones/oct on<br>   sample-playback MIDI modules<br>---<br>It came to my attention recently that<br>a professor at the University of <br>Mississippi teaches a college course<br>about Elvis' Hawaiian films. <br>This was a relief to me.  It proved that<br>no matter how bizarre and nonsensical<br>the posts of certain folks on this forum,<br>they're actually quite rational compared <br>to the *truly*  looney denizens of the <br>so-called "real world."<br>Speaking of the real world, the yakademics<br>have now returned from sabbatical and are<br>no longer giving "special tutoring" to those<br>special coeds.<br>Since this forum is still largely an academic reserve,<br>it empties out during the summer, leaving only<br>the lone desultory student or two burned out <br>by a McJob at 2 am but not yet ready to lobotomize<br>hi/rself with The Weather Channel.<br>Thus there was little point in my posting anything<br>during the summer months.  <br>Now that the rich white PhDs and the dirt-poor<br>overworked students are both back from summer<br>hiatus, there's an audience capable of hoisting<br>torches & pitchforks and screaming "Somebody get a rope!"<br>In short, an audience fully up to the high standards<br>of academic open-mindedness and insight we've<br>all come to respect so deeply.<br>Various claims to the contrary, it is in fact possible<br>to use sample-playback MIDI modules with only 1 pitch <br>table for either equal-tempered multiple divisions of the <br>octave or high-limit just intonation *without* the dreaded<br>"chipmunking" effect.<br>As you'll recall, "chipmunking" occurs when a sample<br>recorded at one pitch is played back at a drastically<br>different pitch.  At first glance, you'd think this<br>unavoidable when dealing, say, with one of Erv Wilson's<br>70-pitch hebdomekontanies.<br>Chipmunking typically occurs on the Proteus modules<br>the VFX, and all the other xied-wavetable synths.<br>Whence arises chipmunking?   <br>Consider:  starting with some 1/1 pitch--say, A 440 Hz--<br>the pitch table of the MIDI module will contain a progressively <br>lower playback pitch than the frequency at which the sound was <br>originally recorded.<br>Take the following Wilson 70-note [1,17,41,67,97,127,157,191]<br>hebdomekontany (4 out of 8 CPS):<br>Scale degree 1: C + 0.000 cents<br>Scale degree 2: C + 14.9691 cents<br>Scale degree 3: C + 28.5475 cents<br>Scale degree 4: C + 32.3370 cents<br>Scale degree 5: C + 57.9854 cents<br>Scale degree 6: C# + 7.8545 cents<br>Scale degree 7: C# + 33.5029 cents<br>Scale degree 8: C# + 45.3184 cents<br>Scale degree 9: C# + 55.7040 cents<br>Scale degree 10: C# + 70.9667 cents<br>Scale degree 11: C# + 72.2992 cents<br>Scale degree 12: C# + 97.9476 cents<br>Scale degree 13: D + 35.0111 cents<br>Scale degree 14: D + 48.5894 cents<br>Scale degree 15: D + 50.2738 cents<br>Scale degree 16: D + 60.6594 cents<br>Scale degree 17: D + 63.8521 cents<br>Scale degree 18: D + 74.2378 cents<br>Scale degree 19: D + 77.2546 cents<br>Scale degree 20: D + 90.8330 cents<br>Scale degree 21: D# + 53.5448 cents<br>Scale degree 22: D# + 82.0924 cents<br>Scale degree 23: E + 19.5562 cents<br>Scale degree 24: E + 46.5370 cents<br>Scale degree 25: E + 95.0737 cents<br>Scale degree 26: E + 98.8633 cents<br>Scale degree 27: F + 12.4416 cents<br>Scale degree 28: F + 22.0545 cents<br>Scale degree 29: F + 24.5116 cents<br>Scale degree 30: F + 25.8441 cents<br>Scale degree 31: F + 38.0900 cents<br>Scale degree 32: F + 39.4224 cents<br>Scale degree 33: F + 51.4924 cents<br>Scale degree 34: F + 65.0708 cents<br>Scale degree 35: F + 74.3808 cents<br>Scale degree 36: F + 87.9591 cents<br>Scale degree 37: F# + 0.0291 cents<br>Scale degree 38: F# + 1.3616 cents<br>Scale degree 39: F# + 13.6075 cents<br>Scale degree 40: F# + 14.9400 cents<br>Scale degree 41: F# + 17.3970 cents<br>Scale degree 42: F# + 27.0100 cents<br>Scale degree 43: F# + 40.5883 cents<br>Scale degree 44: F# + 44.3779 cents<br>Scale degree 45: F# + 92.9145 cents<br>Scale degree 46: G + 19.8954 cents<br>Scale degree 47: G + 57.3592 cents<br>Scale degree 48: G + 85.9067 cents<br>Scale degree 49: G# + 48.6186 cents<br>Scale degree 50: G# + 62.1970 cents<br>Scale degree 51: G# + 65.2138 cents<br>Scale degree 52: G# + 75.5994 cents<br>Scale degree 53: G# + 78.7921 cents<br>Scale degree 54: G# + 89.1778 cents<br>Scale degree 55: G# + 90.8621 cents<br>Scale degree 56: A + 4.4405 cents<br>Scale degree 57: A + 41.5040 cents<br>Scale degree 58: A + 67.1524 cents<br>Scale degree 59: A + 68.4848 cents<br>Scale degree 60: A + 83.7475 cents<br>Scale degree 61: A + 94.1332 cents<br>Scale degree 62: A# + 5.9487 cents<br>Scale degree 63: A# + 31.5970 cents<br>Scale degree 64: A# + 81.4662 cents<br>Scale degree 65: B + 7.1145 cents<br>Scale degree 66: B + 10.9041 cents<br>Scale degree 67: B + 24.4824 cents<br>Scale degree 68: B + 39.4516 cents<br>Scale degree 69: B + 53.0300 cents<br>Scale degree 70: B + 86.4216 cents<br>(Those of you unfamiliar with a Wilson CPS<br>or the hebdomekontany will want to review<br>topic 2 of Tuning Digest 17 from 17 February<br>1994, also topics 1 and 2 of Tuning Digest<br>30 from 3 March 1994.  The latter, by Paul<br>Rapoport, comprise perhaps the finest into<br>to the subject yet written.)<br>As you can see, entering the above 70-note<br>just array into an EMu proteus synth, <br> starting with 1/1 = 440.0 Hz + 0 cents,<br>produces a progressive transposition of sounded<br>pitch vs. originally-sampled pitch as the<br>scale rises.  By the time we reach pitch 70,<br>the synth is playing a note at 440 Hz + 1186.4 cents<br>which was originally sampled playing at <br>440 Hz + 7000 cents!    In other words note<br>70 of the just array is being played almost 5.5 <br>octaves *lower* than its original pitch.  This<br>produces wildly bizarre sonic artifacts--growls,<br>wah-wah-wah effects, low- or high-pitched<br>background noise, etc., collectively known<br>as "chipmunking."   <br>Is there any way to avoid these weird sonic artifacts<br>when playing either just arrays with a lot of different<br>notes, or small just arrays which modulate extensively,<br>or equal temperaments with lots of notes per octave?<br>Yes, there is.<br>The solution is twofold:<br>[1] Use a SMPTE-locked MIDI interface with a multitrack<br>tape deck *OR* any ordinary MIDI interface with a<br>hard disk recorder; and...<br>[2] Write a program which re-maps the MIDI notes in<br>your composition to different MIDI channels depending<br>on their MIDI note number.<br>Using this combination, you can now lay down just arrays<br>or equal tempered scales up to 127 notes per octave without<br>any significant chipmunking.<br>To see how this works, let's take a concrete example.  First<br>we write a program--perhaps using MAX to re-map the notes<br>in real time, or using the Cal portion of Cakewalk on IBM<br>machines, or even using the MIDI file routines available <br>for $40.00 from Sound Quest to write your own C or BASIC<br>or PASCAL program--that reads in the MIDI notes of our<br>composition.  Note X is remapped as note X on channel 1,<br>note X +1 is remapped as note X on channel 2, note<br>X + 3 is remapped as note X on channel 3, note X + 4 is<br>remapped as note X on channel 4, note X + 5 is remapped as<br>note X on channel 5, and note X + 6 is remapped as note<br>X in channel 6.  Then note X + 7 is remapped as note X+1 on<br>channel 1, note x + 8 is remapped as note X + 1 on channel 2...<br>and so on.  You get the idea. <br>Next, make up 6 different tuning tables for, say, <br>your Proteus II module.  All 6 tuning tables use 12<br>notes per octave out of the hebdomekontany.  Tuning<br>table 1, for instance, would be:<br>Scale degree 1: C + 0.0000 cents<br>Scale degree 2: C# + 7.8545 cents<br>Scale degree 3: C# + 97.9467 cents<br>Scale degree 4: D + 90.8330 cents<br>Scale degree 5: D# + 82.0924 cents<br>Scale degree 6: E + 98.8633 cents<br>Scale degree 7: F# + 0.0291 cents<br>Scale degree 8: F# + 92.9145 cents<br>Scale degree 9: G + 85.9067 cents<br>Scale degree 10: G# + 48.6187 cents<br>Scale degree 11: A + 4.4405 cents<br>Scale degree 12: A# + 5.9487 cents<br>The second tuning table would be:<br>Scale degree 1: C + 14.9691 cents<br>Scale degree 2: C# + 33.5029 cents<br>Scale degree 3: D + 35.0111 cents<br>Scale degree 4: D# + 53.5448 cents<br>Scale degree 5: E + 46.5370 cents<br>Scale degree 6: F + 12.4416 cents<br>Scale degree 7: F# + 1.3616 cents<br>Scale degree 8: G + 19.8954 cents<br>Scale degree 9: G# + 62.1970 cents<br>Scale degree 10: A + 41.5040 cents<br>Scale degree 11: A# 31.5970 cents<br>Scale degree 12: B + 10.9041 cents<br>and so on.<br>Now copy your remapped MIDI file to 5 different<br>files with similar names; then delete<br>all notes on channels 2-6 for file 1,<br>delete all notes on channels 1 & 3-6 for<br>file 2, etc.   If you're dealing with an<br>orchestration using multiple MIDI files<br>you may want to write into a program a<br>routine which automatically deletes all<br>but the 12 transposed notes/oct in each of<br>the channels you need for that MIDI file.<br>Now lock your sequencer via SMPTE to<br>your multitrack tape recorder and lay<br>down channel 1 using pitch table 1.<br>Run the tape recorder back and<br>lay down channel 2 using pitch table 2,<br>and so on until you've laid down all 6<br>channels using all 6 pitch tables.<br>If you don't have an Alesis ADAT or<br>a Tascam DA-88, don't despair--my<br>experience shows that for compositions<br>of less than 15 minutes or so you can<br>lock WITHOUT SMPTE to a hard disk<br>recorder and still maintain perfect sync<br>with prerecorded parts, provided your<br>hard disk recorder has a "trigger playback<br>on MIDI" feature (most do).   Since hard<br>disk recorders boast unmeasurably low<br>wow and flutter, you can actually lock multiple<br>recorded parts in sync *without* using SMPTE<br>sync.  I've done this with 3 different stereo<br>tracks, equivalent to 6 mono tracks, so there's<br>absolutely no reason why you can't do it with as<br>many tracks as your hard disk recorder will allow.<br>Of course the different parts will eventually <br>drift apart if they last long enough...20, 30,<br>40 minutes or so.  But for pieces less than about<br>15 minutes my experience is that the parts<br>remain in perfect sync.  And since hard disk<br>recorders are getting dirt cheap, this is good<br>news for all of us.<br>As you can see, this process is laborious--but it<br>produces excellent sonic results.  The worst<br>chipmunking you'll get with a 70-note hebdomekontany<br>is a note transposed about 85 cents up or down from<br>the pitch it was originally recorded at: this is<br>a stretch or compression or less than 5%, and produces<br>virtually no sonic artifacts.  And 70 notes is an acid<br>test!  Very few just arrays use that many notes!<br>One further refinement you might want to consider<br>is to compose a piece with lots of notes per octave<br>using a "sketch" set of timbres generated by a synth<br>which doesn't suffer from chipmunking--say, a<br>TX81Z or a VL-1.  Once you've got the skeleton of<br>the composition laid down using these approximate<br>timbres, orchestrate the final version with a box<br>like one of the E-Mu Protei or even one of the Korg<br>synths limited to retuning within 12 tones per octave.<br>Then lay down multiple tracks with the final timbres<br>for a full version of the composition. <br>Although it's more trouble than merely entering a simple<br>pitch table and playing all the MIDI notes with a single<br>sequencer track, this method has the advantage of<br>allowing you to make full use of the high-quality samples<br>available in contemporary MIDI boxes.  And as we all<br>know, synthesizer technology lurched to a grinding halt<br>sometime around 1989 and the synthesizer industry<br>decided to commit financial suicide. As a result virtually all<br>modern synths are nothing but sample-playback boxes.<br>Thus the method described here is the only really<br>effective way to deal with modern so-called synths<br>(which aren't really synthesizers any more, they're all<br>just fancy effects boxes with prerecorded sounds burned<br>into ROM) when using large number of tones (just or equal <br>tempered) per octave.<br>JI composers, take special note--by using the above process<br>with one channel for each key into which you want to module,<br>you can modulate to a virtually unlimited number of different<br>just 1/1s by laying down different tracks with SMPTE sync<br>or via hard disk recorder playback-on-MIDI-note sync.  (Number<br>of keys is virtually unlimited because remember--there's no<br>limit to the number of different pitch tables you can load<br>into your synth *sequentially.* Using this method you could<br>modulate into 300 successive 1/1s if you were so inclined!) This<br>completely obviates the purported "difficulty" of modulation<br>when using just intonation, and renders utterly moot all the<br>various "practical" objections to just intonation raised <br>throughout the 19th and early 20th century on the basis of the<br>"impossibility" of modulating between just key centers.<br>Best of all, as hard disk recorders drop in price and hard disks<br>grow bigger and cheaper, you'll have more and more capability<br>on hand as time goes on.  God I love the 90s!<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Sat, 21 Oct 1995 19:32 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id KAA17301; Sat, 21 Oct 1995 10:32:29 -0700<br>Date: Sat, 21 Oct 1995 10:32:29 -0700<br>Message-Id: <199510211731.KAA17136@eartha.mills.edu><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2182 href="#2182">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/22/1995 7:42:36 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: custom MIDI controller<br>---<br>One of the biggest stumbling blocks in<br>the path of the microtonal revolution is<br>the lack of a generalized MIDI keyboard.<br>If MIDI users could buy a keyboard like<br>the one on the Secor generalized <br>Scalatron, microtonality would take<br>an enormous step forward.  Suddenly,<br>it would become simple and easy to perform<br>keyboard music in 31, 19, Partch 43, Wilson<br>41, Secor 17, or Helmholtz 24-note tunings.<br>Well, guess what?<br>Now you can build your own generalized MIDI<br>keyboard--and for less than $275!<br>PAVO, 10. S. Front St., Philadelphia PA 19106,<br>makes a black box to which you can hook 64<br>momentary normally-open switches and get<br>MIDI notes out.<br>What kind of switches can you use?<br>The sky's the limit: light switches, doorbell<br>switches, reed switches, infrared or cadmium<br>selenide photocells, contact switches, touch<br>switches, proximity switches, ultrasound-<br>activated switches, moisture-activated<br>switches, odor-activated switches...you name it.<br>Among the ideas PAVO suggests for novel<br>MIDI controllers: [1] sewing reed switches into<br>your clothing and generating a MIDI composition<br>by your movements; [2] attaching multiple<br>photoelectric switches to various parts of a<br>room and generating MIDI notes by shining a<br>laser; [3] building your own custom MIDI <br>percussion controller or keyboard.<br>Of particular interest for folks on this forum<br>is [3].<br>The PAVO MIDI computer (a black box with a<br>64-lead ribbon cable coming out of it and MIDI<br>IN and MIDI OUT connectors) comes in kit form.<br>The cost is $265 U.S. and with that you get the<br>PROM of your choice.  (PAVO black boxes can do<br>a *lot* of things; the 64-note MIDI controller PROM<br>is only *one* of many PROMS they offer.  You can,<br>for example, turn the black box into a "translating<br>randomizer" merely by substituting another PROM<br>into the ZIF socket inside the black box.  In this<br>mode the PAVO black box selectively translates one <br>type of MIDI message into any other type of MIDI message,<br>randomizing them within user-selected parameters<br>entered into the front panel.  However this post<br>concerns only the 64-note custom MIDI controller<br>EPROM, so if you want more info on the many *other*<br>exotic applications of their MIDI computer black<br>box, write PAVO directly. That address again:<br>PAVO, 10. S. Front St., Philadelphia PA 19106)<br>The limitations of the PAVO box, are to be fair,<br>numerous: first, you're limited to 64 input switches.<br>(If you need a 128-key controller, buy two black<br>boxes and hook their outputs through a MIDI merge<br>box; ditto 192-key controller, etc.  At $250 per<br>black box, this isn't all that expensive--especially<br>compared to the *outrageous* highway-robbery cost<br>of $2000 for a 36-pad MIDI marimba bought <br>commerically!)<br>Second, the switches can't be more than 25 feet from<br>the PAVO black box (and should probably be a lot<br>closer for reliable operation).  Most limiting of all,<br>the black box does not accept velocity information<br>from the switches.  Thus you must set the velocity<br>of the MIDI notes either via a pot on the front panel<br>of the black box, or by means of a MIDI controller<br>foot pedal hooked into the data stream with a MIDI<br>merge box.  (It's possible that you might be able<br>to wire an 8-bit A/D converter to the frame of the<br>MIDI controller and feed it into the front pot of the<br>PAVO black box, but since it's not part of the original<br>design...you'd have to do it at your own risk.)<br>All in all, these limitations are minor compared to<br>the advantages offered by this widget.  For the first<br>time, you can build your own custom MIDI percussion<br>setup.  One of the first and most obvious applications<br>that comes to mind would be to set up a set of plywood<br>or pine squares in the form of a 64-note Bosanquet<br>keyboard and attach the squares to reed or touch<br>switches, then solder the switches to the ribbon<br>cable leads.  Plus in the black box, turn it on, and presto!<br>You've got your own Bosqnquet-style percussion controller.<br>This would be ideal especially for those of us you yearn to<br>work in large JI arrays (say, Wilson 31 or 41 or 43, not<br>to mention D'Alessandro or the hebdomekontany) with<br>a percussion-type controller.  <br>By fitting the switch array with a DB-25 connector, one<br>could easily disconnect one percussion controller and <br>reconnect another one, thus allowing a performer to move<br>within a less than minute from, say, Partch 43 to 53-tone<br>equal temperament.  Since switches are cheap (check the<br>latest JDR MICRODEVICES catalog) and plywood or pine<br>even cheaper, it should be a breeze to build half a dozen<br>different percussion arrays, each suited to a given tuning.<br>(Remember that since we're dealing with MIDI, one need<br>only saw the pieces of wood and glue switches to 'em--<br>all tuning's done in the MIDI synth.)<br>Neoprene coverings on the plywood or wooden percussion<br>pads would help give the percussion pads a more lifelike<br>"feel," and again it's cheap and easy.<br>Building the PAVO black box sounds pretty simple.<br>They offer a videotape showing the complete process (for<br>those of you who haven't dealt with a soldering iron and<br>a volftmeter before), as well as a diagnostic EPROM. Plug<br>in the EPROM and it'll automatically check your solder<br>connections, chips, glue logic, and run a test on the MIDI<br>ins and outs as well as the 64-lead ribbon connector (via<br>loop-through).<br>PAVO claims that assembly of one of their black boxes<br>takes 5-7 hours, and given the apparent simplicity of<br>the circuitry inside their box, that sounds reasonable.<br>It's basically nothing but an antique 6809 8-bit<br>microprocessor with an EPROM, a kilobyte or so of<br>static RAM and some glue logic and hex buffers to<br>keep the inputs and outputs from fricasseeing if you<br>accidentally hook a MIDI out to the black box's MIDI OUT.<br>All told, this is spectacular development for  those of us<br>who burn with the bestial desire to build Bosanquet<br>MIDI controllers!<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Sun, 22 Oct 1995 23:59 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id OAA00139; Sun, 22 Oct 1995 14:58:49 -0700<br>Date: Sun, 22 Oct 1995 14:58:49 -0700<br>Message-Id: <951022215607_71670.2576_HHB46-1@CompuServe.COM><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2187 href="#2187">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/23/1995 7:54:49 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: xenharmonic notation in Finale<br>---<br>The estimable Paul Rapoport has created a<br>microtonal music font for use with Finale.<br>This was a significant advance, hampered by<br>Finale's generally 12-centric mode of operation.<br>Well, times have changed.  The latest version<br>of Finale--rev 3.5--just arrived, and it has<br>features to delight the heart of the most<br>hardened microtonalist.<br>Most notably, the NONSTANDARD KEY SIGNATURE<br>DIALOGUE BOX now contains an enhanced KEY STEP<br>MAP DIALOG BOX.  What, pray tell, does this signify?<br>Buckle up, chromedomes--time for a trip into<br>the bowel of Finale's infinite set of dialog boxes...<br>First, click on the KEY SIGNATURE TOOL.  (It's easy<br>to tell; this is the icon that looks like a rodent<br>having sex with a VCR.  As opposed to the icon<br>that looks like a cyclotron swallowing a squid--<br>that's the Speedy Note Entry tool.)<br>When the Key Signature dialog box appears,<br>choose NONSTANDARD from the dop-down menu.<br>Click NEXT twice, then click the KeyMap icon.<br>Okay.<br>Now you're into a dialog box which allows you to<br>define a microtonal key signature.<br>First, you need to decide whether you want what<br>Finale mystifyingly calls a "Linear Key Format"<br>or "Nonlinear Key Signature."  At this point permit<br>me to quote from the Finale Reference (Vol. 3,<br>ver. 3.0, which also applies to Finale ver. 3.5): <br>"In this dialog box, you specify how many notes<br>will constitute an "octave" (it's twelve notes in the<br>traditional system).  You also sepcify how many of<br>these are "diatonic" (seven in the traditional system),<br>and where the "chromatic" steps occur in the scale. (In<br>the traditional system, the chromatic steps occur between<br>every pair of diatonic steps except steps 3 and 4 and steps<br>7 and 8.<br>"If you're creating a linear key format, note that your work <br>in the Key Step Map dialog box must follow certain rules in <br>order to meep the definition of a lienar key format.  The<br>total diatonic steps, for example, must be an odd number.<br>Furthermore, the bottom and top halves of the scale must<br>contain the identical arrangement of diatonic and <br>chromatic steps.  These principles ensure that there is a<br>progression of keys, although it may not be a circle of fifths<br>as there is in traditional key structures. (Finale will<br>correctly interpret, transcribe, and play back music in<br>a format that hasn't been constructed accordin go these<br>rules.  Theformat, however, won't be technically and<br>musically correct; you may get unexpected results when<br>you transpose--or add chord symbols to--music in such a<br>key system).<br>"You may wonder what the relationship is between your MIDI<br>keyboard and the unusual key maps you can construct in this<br>dialog box.  The principle is simple: each key on your keyboard<br>*always* corresponds to a note in your key map.  If you've<br>established a quarter-tone key system, for example, you'd<br>have to drastically alter your playing style in order to input<br>a simple C scale, because Finale now thinks that the first<br>four notes on your keyboard are C, C-quarter-sharp, C-sharp, <br>and C-three-quarter-sharp.  You'd have to play C, E and G#<br>"keys" on your keyboard to *notate* the C, D and E on the<br>screen."<br>Well, there it is, kiddies.  Just what we've needed lo these<br>many years.  With this upgrade, Finale appears to support <br>most of what's required for notating rationally a wild<br>microtonal piece performed on the MIDI keyboard.<br>The dialog box labelled KEY STEP MAP is fairly straightforward.<br>It includes a control for TOTAL STEPS (the total number of<br>steps in the scale) and DIATONIC STEPS.  The remainder left<br>over by subtracting diatonic steps from total steps is,<br>obviously enough, the number of chromatic steps. <br>This begs the question of what to do in a JI scale when<br>faced with, say, the 11/9, or the 11/8...are these<br>diatonic or chromatic steps?  The question doesn't<br>appear to have much meaning to me, but those of you<br>who've delved into Finale for the purposes of notating<br>high-limit JI may have a different opinion.  Be interested<br>to hear from those of you who've done this!<br>By creating a nonlinear key signature you can generate<br>a notation for a tuning with no circle of fifths, and<br>no sequence of keys.  This is useful both for equal temperaments<br>with no fifths (6,8,9,11,13,16,18,23 equal tones per octave)<br>and for non-just non-equal-tempered scales like the free-free<br>metal bar scale, scales formed from ratios of infinite continued<br>fractions, etc.<br>The ticket to getting Paul Rapoport's nonstandard accidentals<br>to appear next to the correct notes is the ATTRIBUTE dialog<br>box.  <br>To quote the Finale manual again (Volume 3, page 300):<br>"For any such key system you create, you can specify a number of<br>special attributes, such as the symbols you want to use in the key<br>signature (instead of the b and # symbols).<br>*Harmonic Reference.  This number identifies the note that all other <br>dialog boxes in Finale's key system will consider to be the C, or<br>fundamental root tone.  Enter zero for C, 1 for D, 2 for E, and so on.<br>There's little ever to change the default setting in this box (zero,<br>or C.). [Note: Unless you're notating Harry Partch's music, with his<br>1/1 of G!]<br>*Middle Key Number.  This number specific the MIDI key number<br>that corresponds to the Harmonic Reference Number. <br>(..)  You can use this parameter to good advantage if you want<br>to transform your synthesizer into a transposing synthesizer (as <br>far as Finale is concerned). For example, if you set the middle<br>Key Number to 48 (C below middlel C), Finale will interpret<br>every note you play as a note an octave higher (...)<br>*Symbol Font.  This number corresonds to the font from which<br>the symbols you want to use for accidentals are drawn.  To <br>choose a new font, click Symbol Font; Finale displays'<br>the Font dialog box, form which you can choose the new font.<br>*Symbol List ID. This number identifies a symbol list you've created--an <br>array of accidental AMounts (where one sharp has an Amount of 1,<br>one flat has an Amount of -1, and so on) and corresonding chracters you<br>want to appear in the key signature to represent them.  To create a <br>symbol list, click Symbol List ID; the Symbol List gialog box appears,<br>in which you can define the character you want to appear in <br>place of the usual sharp, flat, double-sharp, or other standard symbol.<br>(See SYMBOL LIST DIALOG BOX).<br>*Go to Key Unit.  Enter a number in this text box to specify the<br>number of scale steps Finale should consider to be between <br>each pair of keys on your MIDI keyboard.  In other words, if you've<br>specified a quarter-tone scale, tell Finale that the Key Unit is 2--<br>there are two scale tones, not one, between one synthesizer key and<br>the next.  (If your synthesizer *can* produce quarter tones, however, <br>leave the key unit at 1, so that Finale will correctly play back your<br>quarter-tone score.<br>"If you've specified the correct Key Unit value, Finale will transcribe <br>and play any music perofrmed in the usual way correctly.  If you<br>created  quarter-tone scale without changing the Key Unit, by contrast,<br>you'd have to drastically modify your playing sytle, because Finale would <br>treat your keyboard as show here." [Note--the diagram in the<br>manual shows a quarter-tone keyboard replete with microtonal<br>accidentals]"<br>Hot rats, boys!<br>This is a real breakthrough.  It's what we've needed for years.<br>It's what Lippold Haken's LIME *should* have included, but didn't.<br>One final point: for those you whose wee widdle hearts go pit-a-pat<br>at the thought of a musical staff with more than 5 lines, Finale<br>also allows this.  You can completely redefine the staff, with <br>as many lines (within practical limits) as you like.  Folks like<br>Leo de Vries whose twinline 31-tone notation used more than 5<br>staff lines will jump for joy at this feature in Finale 3.5<br>Yes, Finale is still not quite as simple as quantum <br>electrodynamics.  Those dialog boxes are not easy to find,<br>or easy to use correctly.  But they're there.  And for the first<br>time, they make possible transcription of xenharmonic music <br>via  computer.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Mon, 23 Oct 1995 20:00 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id KAA20043; Mon, 23 Oct 1995 10:59:33 -0700<br>Date: Mon, 23 Oct 1995 10:59:33 -0700<br>Message-Id: <199510231752.NAA26693@freenet5.carleton.ca><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2190 href="#2190">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/24/1995 7:33:51 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: The accuracy of tunable MIDI synthesizers<br>---<br>>From time to time a recurrent gripe surfaces throughout the microtonal <br>community.  It centers on the supposedly "crude" tuning accuracy of <br>the typical synth module.  Ezra Sims is the most  vocal proponent <br>of this notion: he claims that the coarse tuning resolution of modern <br>MIDI synths makes them unusable for just intonation.  <br>Does this claim have any basis in fact?<br>First, a word about tuning tables and synths. Tuning tables on MIDI <br>synths have standardized on two accuracies: 1024 TU per octave and <br>768 TU per octave.  By far the most common tuning table standard is <br>768 TU/oct (64 steps per 12-TET scale step). This is the standard <br>used for tuning tables in the E-Mu Proteus I, Proteus II, Proteus <br>3, UltraProteus and Morpheus synths, along with the Yamaha TX11 and <br>TX81Z and the Waldorf Wave and MicroWave synths. (Dick Lord also  <br>states that a tuning table accuracy of 768/oct is buried inside the <br>Ensoniq VFX, VFX-SQ, TX10, EPS,  EPS-16+ and ASR-10.  Most post-1988 <br>Ensoniq synths are microtunable and let the user input values to the <br>nearest cent, but the tuning tables when entered have a tendency to <br>jump around after you've set 'em.  This would be consistent with a <br>tuning table quantum of 1.5625 cents, or 768 tuning units per octave.)<br>In any case it's clear that the 768 tuning units per octave has become <br>a de facto standard.  So it's worth  discussing in some detail the <br>question of the  purported "crudity" of this TU (tuning unit).<br>The first important point is that there is a big difference between <br>the *SIZE*  of the TU in the synth's tuning table, and the  <br>*ACCURACY* of a specific tuning entered into that tuning table. <br>Everyone knows, for example, that the accuracy of a synth with a tuning <br>table having 768 parts per octave is 1.5625 cents: that is, 1200/768 <br>cents.<br>Everyone knows this, and it's  wrong.<br>In fact, the accuracy of the synth depends on the  particular tuning <br>chosen. For example: if you tune your synth to 12 equal tones per <br>octave, the worst error is zero cents--and the average error is zero <br>cents.  This, because 12 is evenly divisible by 768 (768/12 = 64) <br>so each step of 12/oct falls exactly on a TU in the synth's tuning <br>table.  Thus for 12/oct (every 64 TUs), 24/oct (every 32 TUs), 48/oct <br>(every 16 TUs), 96/oct (every 8 TUs), 192/oct (every 4 TUs), 384/oct <br>(every 2 TUs) and 768/oct, the average error = the worst error of <br>the worst-tuned note...namely, zero cents.  For these scales, you <br>get perfect tuning accuracy within the limits of the jitter of the <br>synth's clock crystal and the sample-and-hold in the D/A converter. <br>---<br>What about *other* tunings than power-of-two multiples of 12?<br>To a first approximation, the *average accuracy*  of  any given <br>tuning should be somewhere around (1.5625/2) cents = 0.78125 cents.  <br>This assumes that in the worst case a scale-step lies no more than 1/2 <br>a tuning unit away...a logical enough assumption, as it turns out. <br>Remember:  if a given note is *more* than 50% of a TU above the <br>one chosen, accuracy could be gained by jumping  up to the next <br>higher tuning unit.  <br>For example: if a desired scale-step were 1.6 tuning units away from, <br>say, 324 TU, we could gain accuracy by setting the synth to 326 TU <br>so that the error would be -40% of a TU instead of +160% of a TU.  The <br>same argument applies if the desired tuning step is more than 50% <br>below the set tuning unit. This cuts our 1st-approximation guesstimate <br>of the average error down to 1/2 of 1.5625 cents, for an average error <br>of 0.78125 cents.  But even this average error is actually too large.<br>A moment's thought tells us that the accuracy is likely to be <br>significantly better than that on average, because it's *highly* unlikely <br>that every single step in our scale will be maxed out at the worst <br>possible 50% error of a TU error.  Thus, at first glance, the average <br>accuracy is likely to be much less than 50% of a TU-- that is, <br><< 0.78125 cents.<br>How likely?<br>Well, at this point I'll diverge into a brief paragraph on the integrals <br>of  Gaussian vs. non-normal distributions over a given region.  The <br>integral of such a statistical distribution within an interval gives <br>the signed probability of an event within those numerical parameters; <br>for a normal or Gaussian distribution this is generally expressed <br>in terms of standard deviations from the mean.  The measurement is <br>non-linear, so that (if memory serves) 2 standard deviations out from <br>the mean excludes nearly 98% of the probable outcomes.<br>Alas, this logic presumes a perfectly  Gaussian distribution of <br>scale-steps.   <br>Clearly no musical tuning follows this distribution; a graph of the step <br>size of equal-tempered scales, for instance, shows a rising line <br>y = mx + b, not a bell curve. Similarly,  a graph of the free-free metal <br>bar scale successive step size is proportional to the square of the  <br>hyperbolic cotangent (see Rossing, 1992, for details), while a graph <br>of the distribution of step-sizes of Harry Partch's 43 tones is a <br>stepped histogram with a bunch of near-equal clumps (since  21/20's <br>84.5 cents - the 33/32's 53.2 cents falls within 0.5 cents of the  <br>81/80's 21.5 cents - the 33/32's 53.2 cents...and so on).  That is, <br>a number of the successive step-sizes in Partch's 43-tone  scale are <br>nearly identical, so their distribution again does not look anything <br>like a bell curve. (Again, it's a shame there are no graphics available<br>on this tuning forum. Since the internet is hurtling us into the future<br>at the speed of light, naturally we're stuck in 1970 with dark ages<br>ASCII-only on-line technology.  Naturally!)<br>Using  back-of-the-envelope guesstimates which would make even the <br>most reckless mathematician cringe, a flat-line ET scale- step <br>distribution by the halfway point would have considerably less area than <br>a Gaussian bell curve, while beyond the halfway  point it'd have lots <br>more area...so call it (1.8 + 0.25), or maybe 2.05 or so times the total<br> Gaussian area, while a hyperbolic cotangent's area over the domain would<br> at a  wild guess come out to perhaps 70% of the area of a bell curve...  <br>So the expected average error in an ET scale should be about twice that <br>of the bell curve average error, while for the free-free metal bar <br>scale it should be perhaps 70% of the (1.5625/2) cents/step average.  <br>(End of digression.  Bet you never thought a discussion of tuning <br>accuracy on synths would involve probability integrals!)<br>What does all this mean?<br>It means that the actual tuning accuracy for a 768 TU/oct synth is <br>likely to be completely different from what we'd expect from our <br>simplistic argument above (which led to the conclusion that the accuracy <br>should be << 0.78125 cents per scale step on average).<br>On reflection, this is obvious.  Most real-world tunings will exhibit <br>a mix of large and small errors, with the largest error being a bit <br>less than 0.78125 and the smallest errors (excluding the always-zero <br>root note or 1/1) probably hovering around 0.01 or so. So to a second <br>approximation the average error should range twixt 0.2 cents and 0.4 <br>cents, depending on the exact shape  of the statistical distribution <br>of step-sizes in the tuning, and the exact location of the mean <br>step-size.<br>This tells us that to get real concrete answers, we'll need to do <br>some actual number-crunching and try a mini-Monte Carlo analysis. <br>So let's see what the actual worst scale-step, best scale-step and <br>average (total cents error divided by total number of scale-steps) <br>is for a number of different tunings:<br> <br>[1] For Partch's Monophonic fabric of 43 just tones the  error for <br>each step of the scale is:<br>SCALE STEP   THEORETICAL   TUNED ON SYNTH    CENTS ERROR<br>NUMBER           IN CENTS	       		IN CENTS<br>0 (1/1)	     	[0.0]	        [0.0]	      	[0.0]<br>1 (81/80)	 21.5062896       21.87		0.368710403<br>2 (33/32)	 53.272943         53.125	 -0.147943229<br>3 (21/20)      	84.4671934       84.375 	-0.092193469<br>4 (16/15)	111.7312853     112.5	       0.768714742<br>5 (12/11)	150.6370585     150.0	     -0.6370585<br>6 (11/10)     	165.0042285    165.625	      0.620771502<br>7 (10/9)	182.4037121    182.8125      0.40878787<br>8 (9/8)		203.9100017    204.6875      0.777498271<br>9 (8/7)         231.1740935    231.25          0.075906482<br>10 (7/6)	266.8709056    267.1875      0.316594408<br>11 (32/27)  	294.1349974     293.75	    -0.384997396<br>12 (6/5)	315.641287      315.625	    -0.016287<br>13 (11/9)	347.4079406   346.875 	    -0.532940629<br>14 (5/4)       386.3137139   385.9375      -0.376213864<br>15 (14/11)	417.5079641   417.1875      -0.320464092<br>16 (9/7)	435.0840953   434.375	    -0.709095252<br>17 (21/16)	470.7809073   470.3125	    -0.468407332<br>18 (4/3)	498.0449991   498.4375	     0.392500873<br>19 (27/20)	519.5512887   520.3125	     0.76121127<br>20 (11/8)	551.3179424   551.5625	     0.244557637<br>21 (7/5)	582.5121926   582.8125	     0.3003074<br>22 (10/7)   	617.4878074   617.1875	    -0.300307392<br>23 (16/11)  	648.6820576   648.4375	    -0.2444557627<br>24 (40/27)  	680.4487113   679.6875	    -0.761211264<br>25 (3/2) 	701.95500	701.562		-0.39250086<br>26 (32/21)  	729.219092    729.6875	     0.468407348<br>27 (14/9)   764.9159047   765.625	     0.709095272<br>28 (11/7)   782.4920359   782.8125	     0.320464118<br>30 (8/5)    813.6862861	  814.0625	     0.376213871<br>31 (18/11)  852.5920594  853.125	     0.53294064<br>32 (5/3)    884.358713	  884.375	     0.016287012<br>33 (27/16)  905.8650026  906.25	     	0.384997406<br>34 (12/7)   933.1290944   932.8125	    -0.316594386<br>35 (7/4)    968.8259065    968.75	    -0.075906467<br>36 (16/9)   996.0899983   995.3125	    -0.777498257<br>37 (9/5)   1017.596288    1017.1875	    -0.40878786<br>38 (20/11) 1034.995771  1034.375	    -0.62077149<br>39 (11/6)  1049.362941	 1050.0	    	 0.63705851<br>40 (15/8)  1088.268715   1087.5	     	0.768175<br>41 (40/21)  1115.532807  1115.625	     0.09219348<br>42 (64/33)  1146.727057  1146.875	     0.14794324<br>43 (160/81) 1178.49371   1178.125       -0.3687104<br> <br>The average error per scale step is 0.40561  cents. The worst error <br>is 0.777 cents--roughly 3/4 of a cent--and the best-tuned scale step<br>has an error of 0.016  or about 1/60 of a cent.  These numbers are <br>well within the  range of our second approximation back-of-the-envelope <br>calculation.<br> <br>[2] For  Wilson's first stellated tetrachordal hexany (Chalmers, "Divisions <br>of the Tetrachord," 1993, pg. 124:<br> <br>THEORETICAL   THEORETICAL 	TUNED ON SYNTH    CENTS ERROR<br>NUMBER         IN CENTS	  	 IN CENTS       	  <br>0 (1/1)	      [0.0]		   [0.0]	   [0.0]<br>1 (28/27)	   62.960903	    62.5	  -0.460903<br>2 (16/15)      111.731285	   112.5	    0.7687147<br>3 (784/729)    125.921807	   126.5625	    0.6406922<br>4 (448/405)    174.692189	   175.0	    0.3078108	   <br>5 (256/225)    223.462570           223.4375	  -0.0250705<br>6 (35/27)      449.274617	   450.0	    0.72538227<br>7 (4/3)	   	498.044999	   498.4375      0.39250087<br>8 (48/35)        546.815380	   546.875	    0.05961948<br>9 (112/81)       561.005903	   560.9375	  -0.068403<br>10 (64/45)       609.776284	   609.375	  -0.40128439<br>11 (1792/1215) 672.737188	   673.4375	    0.70031172<br>12 (224/135)   876.64719	   876.5625	  -0.08469<br>13 (16/9)         996.089998	   995.3125    -0.77749825<br> <br>A median has little meaning for these sets of numbers, since<br>no error appears more than twice and there are many errors<br>in that category.  A median decile might have more significance,<br>but its musical meaning is debatable--at least as debatable<br>as that of the mean or average error.<br>The average error is 0.41635 cents/step, similar to that of the Partch <br>scale.   As before, absolute cents are summed and divided by the total <br>number of scale degrees, and the 1/1 is ignored so as not to artificially <br>lower the average error.<br>[3] Archytas' enharmonic (Mixolydian, B-b)  from Chalmers, "Divisions <br>of the Tetrachord," 1993, pg. 104:<br> <br>THEORETICAL   THEORETICAL 	TUNED ON SYNTH    CENTS ERROR<br>NUMBER             IN CENTS	    IN CENTS     <br>0 (1/1)	      [0.0]		  [0.0]		    	    [0.0]		<br>1 (28/27)     62.960903	   	  62.5		          -0.460903<br>2 (16/15)     111.731285	  112.5	          	0.7687147<br>3 (4/3)		498.044999	  498.4375              0.39250087<br>4 (112/81)    561.005903	  560.9375	         -0.068403<br>5 (64/45)     609.776284	  609.375	         -0.40128439<br>6 (16/9)      996.089998	  995.3125            -0.77749825<br> <br>The average error per scale step is in the same ballpark: 0.47818 cents <br>per step.<br> <br>[4] Ptolemy's intense chromatic (from Chalmers, "Divisions of the  <br>Tetrachord," 1993, pg. 102:<br> <br>THEORETICAL   THEORETICAL 	TUNED ON SYNTH    CENTS ERROR<br>NUMBER              IN CENTS	    IN CENTS       <br>0 (1/1)		[0.0]		   [0.0]	   	  [0.0]<br>1 (28/27)	   62.960903	   62.5	       -0.460903<br>2 (10/9)	  182.403712	   182.8125	        0.4087878	<br>3 (4/3)	  	498.044999	   498.4375           0.39250087<br>4 (3/2)	  	701.955001             701.5625        -0.39250086<br>5 (14/9)	  764.915904	   765.625	        0.70909527<br>6 (16/9)	  996.089998	   995.3125         -0.77749825<br> <br>In this case the error's somewhat higher than previously: average <br>error of 0.523515 cents per step. Withal, still quite small.<br>For all the just intonation scales considered above, the average of  <br>the average errors/scale step is 0.458 cents.  This implies that if <br>you tune an arbitrary JI scale, your average error/step will be around <br>0.4 cents, with the average error increasing slightly as the number <br>of steps in your JI scale decreases.<br>As is readily apparent, 0.4 cents is a far cry from the 1.5625 cents <br>generally quoted.  Clearly for JI scales the tuning *accuracy* <br>(for real-world scales) of a 768 TU/octave synth is *far* better <br>than has been bruited about by microtonalists who don't know their <br>math.<br>So much for the tuning accuracy of a JI scale on a 768 TU/octave  <br>synth.  But what about equal tempered scales?<br>Rather than stupefy you with a recitativo of the error per scale step <br>for various equal temperaments, here's the  output from my simple <br>BASIC program for various ETs:<br> <br>TONES/OCT 	AVERAGE ERROR/STEP  WORST ERROR  BEST ERROR<br>		IN CENTS	     IN CENTS         IN CENTS<br>[5] 5/oct	0.375		   0.625		0.0<br>[6] 13/oct	0.3883115	   0.600952      	0.0<br>[7] 19/oct	0.3895362	   0.65789	 	0.0<br>[8] 31/oct	0.3902204	   0.705688      	0.0<br>[9] 41/oct	0.3040017	   -.7241209    	0.0<br>[10] 53/oct	0.39048162	   -.7370605    	0.0<br>[11] 72/oct	0.34722140	   0.5208282    	0.0<br> <br>Total average error: 0.369 cents, slightly lower than in the JI scales <br>considered above, probably because the ET scales have a fixed step <br>size thus a more even distribution of error sizes.<br>As you can see, the average error per scale step is just about as <br>low for ETs as for the just intonation scales above.  And in  all <br>cases less than 0.4 cents.  Again, a damn small tuning error.<br>To give you an idea of how small: at 100 Hz the ratio twixt two notes <br>using harmonic-series overtones (one note tuned with perfect accuracy <br>in the target scale, one note tuned in the best approximation allowed <br>by the synth) would amount to a whopping 2^[0.3040017/1200]  = 2^<br>[2.833475  exp -4] = 1.0001964 for the 41/oct case.  At a fundamental <br>of 100  Hz this would produce an out-of-tune note of 100.01964 Hz, with <br>a  fundamental beat rate of 1 beat every  50.911 seconds. (Of course, <br>the 2nd harmonic would beat at twice that rate, with additional sum <br>and difference tones...and so on.)<br>Now, come on, people...  Can you *really* hear the difference <br>between 1 beat every 51 seconds and the normal internal beating and <br>vibrato from a real-world acoustic instrument?<br>Is that reasonable?<br>Is an average beat rate of 1 per 51 seconds really something to get <br>all het up about?  Is anyone in your audience going to jump up and <br>shout "I can hear it!  It's out of tune!  There was a full two <br>thousandth of a beat in that sixteenth note at metronome marking 100!"<br>Please.<br>How many notes in the average JI or  xenharmonic equal-tempered  <br>composition would last long enough to hear even *one fourth*  of a full<br> beat-complex?  <br>Even assuming (that is) that your acoustic-instrument performers <br>were exactly, perfectly, precisely 100% in absolute theoretical tune <br>with the ideal frequency of the note required, to a full 6 or 7 digits <br>of precision! <br>Now, let's think about this, people.  This cursory little statistical <br>analysis tells us unequivocally that even with a purportedly "coarse" <br>tuning grid like 768 TU per octave, any audible error when playing <br>a synth with a live ensemble *far* more likely to be caused by <br>the *live  ensemble*  rather than the synth.<br>Bearing in mind that Partch's tuning accuracy (which he required in <br>tuning his acoustic instruments) was "better than 2 cents," how likely <br>do you think it that any of the performers *or* the audience <br>will hear errors in the synth tuning averaging around 1/3 of a cent?  <br>That's a tuning precision 6 times better than the accuracy Partch <br>demanded! The only possible conclusion to be gained from this little <br>investigation into the statistics of tuning accuracy is that concerns <br>about the "coarseness" and "inaccuracy" of a 768 TU synth are wildly <br>overblown. Now, some of you might argue about the significance of an <br>"average" tuning error (isn't the audience likely to hear and remember <br>the  *worst-tuned* notes, rather than some numerical "average"?).<br>Rather than dispute the point, let's grant it.<br>Even so..the worst tuning error in most cases is still likely to be <br>no more than twice the averages cited above.  That is, about 0.68 <br>cents--*WORST CASE*.<br>This means that the absolute worst-tuned note<br> played with a 768 tuning-unit synth would be mistuned by a ratio of<br> 2^[0.68/1200] = 2^[5.66 exp -4] <br>= 1.0003929:1.  For a properly-tuned note of  100H z this would <br>produce an out-of-tune note of 100.03929 Hz, and a fundamental beat <br>rate of 1 beat every 25.45 seconds.<br>Can anyone seriously contend that this kind of so-called "inaccuracy" <br>is anything that even the keenest-eared member of the audience would <br>ever hear in anything but an hour-longLaMonte Young drone composition?<br>>From now on, let's have no more of these preposterous claims that <br>is a very coarse and inadequate grid for [fill in the blank...just <br>intonation, equal temperaments, meantone,whatever]."  The facts do <br>not support such a contention.<br>In fact, if Johnny Reinhard can produce a computer-analyzed solo from <br>of any of his live acoustic performances in which the average note <br>was no farther off than 1/3 of a cent, I'll eat his entire  collection <br>of microtonal manuscripts.  With Worchestershire sauce.  In one sitting!<br>In real-world live acoustic solos, performed notes are generally played <br>*much* farther off than 0.3 to 0.4 cent...especially at rapid tempi <br>above 200 bpm. Sundberg's computer analyses show accuracies for <br>professional musicians in the neighborhood of 10 cents, while Shackford's<br> computer analyses show average accuracies for symphony performers in the<br> neighborhood of 15 cents.  This is *worlds* away from the average 1/3 <br>cent error we've found here, and indeed the coefficients of thermal <br>expansion for wood and metal are such that an acoustic instrument would <br>almost certainly detune by *more* than 0.3 to 0.4 cents simply by <br>being moved from a cold car into a warm concert hall.<br>So let us have no more claims that "768 TU per octave are inadequate <br>for microtonal music."<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Tue, 24 Oct 1995 19:51 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id KAA05819; Tue, 24 Oct 1995 10:50:32 -0700<br>Date: Tue, 24 Oct 1995 10:50:32 -0700<br>Message-Id: <9510241742.AA03583@danhicks.math.nps.navy.mil><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2193 href="#2193">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/25/1995 10:38:45 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Live xenharmonic recording<br>---<br>As more and more of you get together and<br>produce live microtonal music (whether with MIDI<br>instruments, acoustic instruments, or<br>a combination of the two), sooner or <br>later you'll want to record your xenharmonic<br>performances on DAT.<br>Here are the fruits of my experience in<br>recording live to DAT:<br>[1] The first thing to remember is that <br>whenever a "pro" is involved, the recording<br>will be crap.  <br>In my experience "professional sound <br>engineer" is a code phrase that actually<br>means "incompetent toad."  Most of these<br>people are ex-stereo salesmen who wouldn't<br>know a balanced line from their own bum.<br>Among the examples of expertise I've seen<br>demonstrated by "pro recording engineers:"<br>using ordinary drugstore rubbing alcohol to<br>clean the heads of a 16-track tape deck; <br>using a Calrec soundfield microphone to<br>zero in on someone snapping a rubber band<br>while 5 other xenharmonic instruments were<br>playing live; accidentally forgetting to<br>record one of the tracks of a critical stereo<br>master during a live take; and clipping most<br>of a digital recording. <br>This last is worth a mention or two.  One of<br>the hallmarks of a "professional" recording<br>is that the digital audio clips a lot. A WHOLE lot.<br>Fortunately, all these problems can be<br>eliminated very simply: if there's a "pro"<br>involved in the recording process, get rid<br>of him. (It's always a him. Women don't<br>seem to be able to plumb such Stygian<br>depths of ineptitude.)<br>Do the recording yourself.  The results will<br>be *infinitely* superior.<br>[2] The first problem you'll encounter is<br>the ground loop.  This is a pesky 60 Hz hum that<br>can drive you out of your mind.  It's caused<br>by two grounds at slightly different<br>potentials; 60 Hz wall current flows between<br>the 2 grounds, producing an audible buzz.<br>Ground loops can arise at many points in the<br>audio chain.  The 1st and most obvious place is <br>the wall socket.  In this case, 2 different<br>pieces of audio equipment are hooked together <br>electrically (say, a synth plugged into a mixer)<br>but plugged into 2 different wall sockets.<br>A ground loop can occur if the ground<br>on one wall socket is faulty;  in that case<br>current will flow from one wall socket to the<br>other through your equipment (an electrical<br>signal always seeks the lowest level of<br>electrical potential).   <br>Another particularly interesting cause of<br>ground loop is a connection between your<br>computer's MIDI port and your synth.  This<br>is NOT supposed to cause a ground loop<br>because the MIDI's supposed to be optoisolated;<br>my best guess is this sometimes occurs because<br>the metal shell of the MIDI cable is connected <br>both to the digital ground of the computer and<br>the analog and digital grounds of the synth,<br>causing current to flow twixt the analog<br>ground of the synth and the computer's<br>backplane.  In this case you'll also get a<br>distinctive whining noise--clock noise<br>from the computer.   <br>The way to solve all ground problems is with<br>an isolation transformer.  The Ebtech Hum<br>Eliminator handles both balanced and <br>unbalanced lines and does a good job.  It's<br>also dirt cheap: < $60 for 2 stereo<br>channels.  I keep 3 of these on hand at all<br>times whenever I do live recordings, since<br>(as usual) if you ask any "pro" for an<br>isolation transformer, he'll fumble around<br>like a lobotomized trilobite & come up with a<br>single mono balanced line version.  (As<br>always, the "pro" is too inept to realize that<br>in the real world most synths use stereo<br>unbalanced line outs.)<br>If all else fails, you *can* fix ground loop<br>hum in the mix.  Digitize the audio to your<br>hard disk, feed .25 seconds of the hum into<br>the Dolson DNOISE program, then filter<br>it out of the recording on your hard disk<br>by running DNOISEwith the Fourier<br>filter generated by the hum. Warning: this<br>usually adds considerable reverb, since the<br>notch filters generated by DNOISE are usually<br>set at harmonics of 60 Hz, and as we all know<br>running a bunch of different FFT bins at once<br>through a soundfile always & unavoidably adds<br>reverb due to the nature of the short-time FFT.<br>[3] When live instruments are combined<br>with synths, it's important that everyone<br>be able to hear hi/rself.  Often the<br>live instrumentalist will use outboard<br>effects and a small speaker to enhance the<br>sound; thus as a recording engineer you'll<br>often be faced with the problem of recording<br>a live instrument with a speaker nearby.<br>If you feed the output of your recording to<br>reference speakers so that everyone can<br>hear what the mix sounds like, you'll <br>inadvertently recreate Robert Ashley's classic<br>electronic music composition "The Werewolf."<br>The only reliable way to deal with feedback<br>in my experience is with a feedback <br>eliminator.  Turning down the monitor<br>speakers doesn't work because no one<br>can hear the total mix; moving the small<br>speaker back from the mike doesn't work <br>because the live performer can't hear <br>what hi/r output sounds like.<br>The Sabine feedback eliminator is in my<br>experience the best way to deal with the<br>problem.   Because it's a digital widget,<br>it's especially effective in killing screech<br>& howl before it starts.  There are other<br>feedback eliminators on the market, but<br>this one is cheaper and does a better job<br>than anything I've come across.  The cost<br>is about $250.<br>Naturally a "pro's" solution to the problem of<br>feedback is: "Uh, uh, hm, uh, play lower."<br>Typically useless; typically incompetent.<br>[3]  When recording to DAT or ADAT, you'll<br>discover that Robert Fripp's rules of <br>recording apply: <br>*The SPL level of the group during live<br>performance will always be at least<br>twice the level during the sound check.<br>*The percussionist will always hit the<br>microphones at some point during the<br>performance.<br>*If the monitor speakers are placed close<br>enough to the performers that they can<br>hear themselves, there will be feedback;<br>if the monitor speakers are placed far<br>enough away from the performers to<br>avoid feedback, they won't be able to<br>hear themselves.<br>*The tape will always run out during the<br>best part of the performance.<br>To avoid these inevitable problems,<br>try the following:<br>*Set the DAT record level during a<br>sound check, then back it off by half, then<br>drop it by another 3 dB.   Most DATs<br>are actually at -10 dB when they read<br>0 dB, so this will save your bacon during<br>really loud sections.  If the sound levels<br>are generally within recording limits<br>but momentarily rise by extraordinary<br>amounts (this can occur with metallophone-<br>type percussion instruments), add a compressor<br>between the mixer and the DAT. <br>*Place a coincident XY pair of mikes<br>directly above the percussionist.  Very<br>few percussionists will try to play<br>empty air.<br>*Instead of using monitor speakers, use<br>headphones for everyone in the group<br>whenever possible.<br>[4] Placement of microphones is<br>critical for live recording.  It differs<br>with each room, acoustic instrument,<br>and type of mike.<br>You might be surprised to learn that<br>with acoustic instruments, different<br>frequencies radiate in different directions.<br>Thus placing a mike front center and 30 <br>degrees below a cello will pick up one<br>set of low frequencies, while moving <br>the mike to the left or right will pick<br>up another set of mid-frequencies. This<br>is one of the reasons why you'll often<br>need a whole passel of microphones in<br>different locations around one <br>acoustic xenharmonic instrument.<br>Cardioid condenser mikes should be<br>placed as close as possible unless<br>the source is metal bars or tubulongs;<br>in that case they should be placed at<br>least 8 feet to 10 feet away.<br>When miking a guitar, you'll find that<br>you get more realistic sound if you<br>aim the mikes slightly away from the<br>guitar's center hole.  The entire body<br>of the guitar radiates sound, and for<br>best results place one mike up by the<br>fingerboard and another mike down<br>below the center hole, aimed at the<br>instrument's body.<br>The same appears to be true of the cello,<br>the viola and the violin. In those instruments<br>the bridge is one of the "hottest" sources<br>of sound, and a mike moderately distant<br>from the bridge, aimed at the body of<br>the instrument, often needs to be balanced<br>by another close-in mike aimed at another part<br>of the instrument to get a recording that<br>sounds like the live instrument.<br>Again, as noted, to get the "full" sound<br>of the instrument you may have to combine<br>the output from a bunch of different mikes<br>in different positions.  (This is one reason<br>why so many sampling CDs sound different<br>from one another; only 2 mikes were used,<br>and on each CD the mikes were placed in<br>different positions!  Yes, Virginia, mike<br>placement is CRITICAL!)<br>Wind instruments can exhibit sharp<br>transients, so *always* use a puff filter.  <br>This can be something as simple as a clean<br>sock placed over the mike or as elaborate<br>as a $50 screen from the local music<br>store.  The acoustic result tends to be<br>the same.<br>If you're using PZM mikes, you can <br>increase dynamic range by hot-wiring<br>two 9 volt batteries in parallel.  This<br>will increase the apparent noise of the<br>mike, so you'll have to use an additional<br>hiss elminator between the PZM mike<br>and the mixer. (More on hiss elimination<br>in a moment.)<br>PZM mikes operate unlike other mikes--<br>they produce the best results if they're<br>firmly attached to large rigid slabs of wood,<br>metal or glass.  If possible, bolt the PZM<br>mike to the floor or the wall! (Warning: if<br>your recording site is near a street, you'll<br>pick up low frequencies from traffic through<br>the wall. A notable problem on recordings<br>made with PZMs in London, since in London<br>every recording studio is near a street with traffic.)<br>The PZM mike also has a peculiar pickup pattern: <br>totally hemispherical.  Whereas cardioid mikes<br>will do an excellent job of rejecting<br>off-axis sounds, the PZM mike picks up<br>everything indiscriminately within 180<br>degrees of its soundfield.  This means<br>that the PZM mike is suited only<br>for an extremely quiet recording <br>environment.  By contrast, many of<br>my recordings with condenser mike<br>make been made in houses over which<br>jet planes have been flying--yet the<br>jet plane rumble isn't audible in the<br>final recording because of the cardioid<br>condenser's superb rejection of off-<br>axis sound.<br>The PZM mike is apt to overload during<br>high transients.  It should be placed <br>farther away than a condenser mike. <br>While a condenser mike will suffer<br>drastic bass rolloff if it's farther than<br>about 1 foot from the sound source,<br>a PZM mike (firmly attached to a<br>rigid plane of wood or metal)  will<br>exhibit excellent flat frequency <br>response at almost any distance.<br>The Calrec soundfield mike is a special<br>case.  It's noisy, but 4 of 'em output<br>to an ADAT will allow you to "zoom"<br>in after the recording on any of the<br>corners of an imaginary tetrahedron.<br>This can actually let you fix some<br>recording problems in the mix.<br>[5] Different engineers prefer<br>different philosophies of mike <br>placement.<br>The 3 most common are the <br>coincident XY pair, the binaural <br>pair, and the widely separated pair.<br>Coincident XY produces excellent<br>results with a group in which everyone<br>has about the same SPL; the binaural<br>pair produces remarkable stereo<br>versimilitude but only if the listener<br>uses headphones.  The widely separated<br>pair (or quad, or octet) is useful for<br>instruments physically distant and with<br>very different SPLs, but tends to<br>produce a final recording without<br>a convincing soundstage.  <br>In general, the smaller the number of<br>mikes, the more realistic the soundstage<br>of the recording. Some of my CDs are reissues<br>of Mercury Living Presence recordings<br>made with coincident XY pairs in<br>1957-1959 and they sound more true<br>to life than almost any recordings made today.<br>With instruments which exhibit <br>significant sustain (like a psaltery)<br>you may want to place a  mike<br>inside the body of the instrument.  If so,<br>leave the sides open.  Otherwise the<br>transients will blow the top out of<br>your mix and force you to record at<br>such a low level as to produce junk. Mixing<br>the output with the sound picked up<br>from 2 nearby mikes can help to<br>capture the live reverberant sound better<br>than a pure coincident XY or binaural pair.<br>It's important to realize that <br>microphones are acoustic<br>cyclopses: they see *only and perfectly*<br>that tiny bit of the soundfield at<br>which they're aimed.   To get a<br>recording that sounds like what your<br>ears hear at a live performance, you'll<br>often have to jump through hoops and<br>use bizarre and irrational mike placements<br>and mixes.<br>One of the greatest fallacies in dealing<br>with microphones is the old canard: "If<br>your ears can hear it, the mike will<br>pick it up."  This is NEVER true.<br>Sounds which are clearly audible to your<br>ears during a live performance will<br>invariably be ignored by the mikes;<br>sounds which your ears cannot hear<br>during a live performance will be<br>magnified unbearably by the mikes.<br>Small changes in mike placement can<br>produce extreme changes in the <br>recording. <br>Above all, trust your ears by listening<br>to the test recordings on your DAT:<br>if the test recording doesn't sound<br>like the live performance, change<br>things--no matter how conceptually<br>perfect your mike placement or<br>mix levels.<br>[6] All live recordings have hiss.<br>Digital microphones, digital mixers,<br>digital synths, digital recorders--<br>doesn't matter.  There will STILL be<br>hiss.<br>In my experience the biggest source<br>of frying bacon is the effects unit.<br>Even if it's a 24-bit reverb, it will<br>hiss like crazy.  The only solution to<br>this is to put a hiss eliminator on <br>the effects unit BEFORE the stereo<br>returns come back into the mixer.<br>There are a lot of models of hiss<br>eliminator on the market.  They all<br>work on the same principle: a<br>level-sensing circuit activates<br>a voltage-controlled filter which<br>closes down depending on the<br>sensitivity setting.<br>The Hush IIcx is fairly cheap and<br>works well; a used KLH Burwen<br>Dynamic Noise Reduction unit<br>will also work well; dbx makes<br>(or used to make) a single-ended<br>noise reduction unit that worked<br>well; and other companies make<br>similar widgets.  They're all in<br>the range of $150-$200. <br>You'll need at least 2 of these <br>for any recording session. 1 to<br>kill the hiss from the effects<br>unit(s) coming into the mixer,<br>another to kill the hiss after<br>it leaves the mixes and goes<br>into your DAT or ADAT.<br>[7]  Fripp's rule of thumb that<br>the tape always runs out during<br>the best part of the performance<br>can be easily end-run.  I always<br>record with 2 digital recorders--<br>one recording live from mikes,<br>another recording the straight<br>mix output from the mixer.  As<br>Warren Burt can testify, this<br>approach works--what one <br>recording misses, the other<br>gets.  Starting one machine<br>later than the other assures that<br>you'll never be burned by <br>lack of tape.<br>[7] "Pro" engineers will place great<br>stock in balanced vs. unbalanced<br>lines.  In my experience balanced<br>lines are useful mainly in running<br>audio cables from the mixer to<br>the DAT.  As long as your other cable<br>runs are short & you're not recording<br>next to a microwave relay tower or<br>a commercial radio tower, there's<br>no practical advantage in using balanced<br>lines. (Unless the stage is a long ways<br>away from the mixing console! A cable run<br>of more than 15 or 20 feets demands a balanced<br>line, no question.) <br>"Pro" engineers will claim that balanced<br>lines eliminate ground loops.  Naturally,<br>this isn't true.  Balanced lines are just<br>as prone to ground loops as unbalanced<br>lines when the digital grounds of digital<br>synths are involved.  The sad fact is that<br>you'll still need isolation transformers<br>even if you use balanced lines on all<br>of your equipment. One further point:<br>if at any point in the audio chain you<br>introduce an unbalanced line, the whole<br>audio chain might as well be unbalanced.<br>A single unbalanced line can (& usually <br>will) introduce a ground loop.  Bear in<br>mind that the unbalanced part of the<br>audio loop can be inside a wall socket <br>with 3 holes but no true ground!<br>So much for the myth that "balanced lines<br>eliminate ground loops."<br>[8] You should bring along your own<br>speakers, your own preamp, your own<br>surge suppressor, your own power strips<br>and your own line conditioner/backup UPS<br>to any public recording session.  Last year<br>I had the delightful opportunity to handle<br>audio on a live performance in which<br>the "pro" sound engineer in charge thought<br>it would be a real smart idea to let<br>20 people plug coffee machines and hot<br>plates and toaster ovens into the same<br>outlet the performers were using to<br>power their digital synths.<br>The result was  interesting <br>(as in the Chinese curse).<br>[9] Always bring 4 of everything--4<br>3-prong-to-2-prong plugs (because<br>the place where you perform won't <br>have 3-prong plugs), 4 1/4-inch phone<br>jack-to-RCA cables, 4 XLR-to-phone-jack<br>transformers, 4 MIDI mergers, 4 mini-plug-<br>to-headphone adapters, 4 durable<br>equipment bags, 4 everything.  2 are<br>never enough and someone always needs<br>one extra.<br>[10] All these pieces of advice deal<br>with digital recordings rather than<br>analog.  Alas, there's just no comparison<br>twixt DAT and analog reel recordings.<br>The reel recordings don't measure up.<br>Despite the frenzied claims of the<br>LP and reel-to-reel fanatics, DAT<br>offers infinitely superior sound<br>quality to any possible reel recording.<br>--mclaren<br><br>Received: from sun4nl.NL.net [193.78.240.1] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Thu, 26 Oct 1995 09:25 +0100<br>Received: from eartha.mills.edu by sun4nl.NL.net with SMTP<br>	id AA06609 (5.65b/CWI-3.3); Thu, 26 Oct 1995 06:30:36 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id WAA09429; Wed, 25 Oct 1995 22:29:20 -0700<br>Date: Wed, 25 Oct 1995 22:29:20 -0700<br>Message-Id: <199510260528.WAA03929@hopf.dnai.com><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2196 href="#2196">ðŸ”—</a>Allen Strange &#x3C;STRANGE@sjsuvm1.sjsu.edu&#x3E;</h3><span>10/25/1995 11:32:27 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>Folks:<br><br>  In B, Maclaren's last post (when does he find time to write all this stuff)<br>reference is made to Robert Ashley's "The Werewolf" - the analogy is great<br>but I believe the title is "Wolfman"-it was published in one of the wonderful<br>Source Magazines of years-gone-by.<br><br>=========================================================================<br>|                          Allen Strange                                |<br>|             http://cadre.sjsu.edu/music/strange.html                  |<br>|_______________________________________________________________________|<br>| Electro-Acoustic Music     | International Computer Music Association |<br>|        Studios             |        2040 Polk St., Suite 330          |<br>| School of Music            |        San Francisco, CA 94109           |<br>| San Jose State University  |       Telephone + (408) 395-2538         |<br>| 1 Washington Square        |          Fax + (408) 395-2648            |<br>| San Jose, CA 95192-0095    |      Email: icma@sjsuvm1.sjsu.edu        |<br>| Telephone +(408) 924-4646  |                                          |<br>| Fax +(408) 924-4773        |     We hope to see you at the ICMC96     |<br>| <strange@sjsuvm1.sjsu.edu> |         On the Edge in Hong Kong         |<br>|                            |         ICMC96@cs.ust.hk for info        |<br>|=======================================================================<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Thu, 26 Oct 1995 11:12 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id CAA10774; Thu, 26 Oct 1995 02:12:04 -0700<br>Date: Thu, 26 Oct 1995 02:12:04 -0700<br>Message-Id: <199510260253.XAA09265@chasque.apc.org><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2198 href="#2198">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/26/1995 7:01:00 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: New xenharmonic CD<br>---<br>"Ping-Pong Anthropology," by The 13th Tribe, is yet<br>another microtonal CD by yet another world music <br>group well worth hearing.<br>In this case the members of the avant ensemble are:<br>Erik Balke, a Norwegian folk musician and student of<br>African and Balinese music; Werner Durand, a German<br>and Silvia Ocougne, a Brasilena.<br>Balke and Durand perform on harmonic-series PVC pipes<br>while Ocougne uses prepared acoustic guitars whose<br>strings are hammered, plucked and pulled.  Skin drums<br>and plexiglas tubes are also used.<br>The music uses a "call and answer" technique in<br>combination with digital delays, and the result is<br>something like ethnic music for a tribe of children<br>living in the rafters of a geodesic dome.  The first<br>track, "Dream Hunters," along with track 3, "Hazar," and <br>track 7, "Ping-Pong Anthropology," are particularly<br>memorable.  All three performers (along with French<br>guest perfomer Pierre Berthet on tracks 8 & 9) use<br>higher members of the harmonic series to weave<br>extended melodies.  The effect is reminiscent of some<br>of the earlier compositions of Denny Genovese, although<br>with greater rhythmic density and a concommitant use<br>of digital electronics to generate a sleet of ricocheting<br>"ghost" notes.<br>This CD is available for a limited time from Experimental<br>Intermedia.  Not nearly as expensive as you'd expect<br>for an import--about $17.  Highly recommended.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Thu, 26 Oct 1995 16:03 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id HAA15182; Thu, 26 Oct 1995 07:03:28 -0700<br>Date: Thu, 26 Oct 1995 07:03:28 -0700<br>Message-Id:  <9510260700.aa23177@cyber.cyber.net><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2199 href="#2199">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/26/1995 7:03:28 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: trivial errata in the series of psychoacoustics posts<br>---<br>As some of you might have guessed, my series of 25 psychoacoustics<br>posts constitute a distilled and simplified early version of a significantly<br>longer and more detailed  monograph on tuning and psychoacoustics.<br>This paper should appear in Xenharmonikon 18, perhaps in 1997. Until<br>then, it behooves me to point out that some errors crept into<br>the posts--some apparently due to end-of-line word deletions during<br>uploads, etc.<br>Other errors are entirely my own fault.<br>In Topic 8 of Digest 508 a dropped word at the end of a line <br>produced a significant distortion of the intended meaning.  <br>The full and accurate text is:<br>---<br>It is well known that the description of the ear to which Doty,<br>Worrall and Alves (known as the place theory of hearing) refer is<br>incomplete and conflicts with much of the psychoacoustic<br>evidence.  "A second difficulty with the place theory lies in <br>the fact that, in complex sounds, components are often heard<br>that are NOT present in the Fourier analysis.  Or loudness <br>judgments of components may be made which do not agree <br>with the amplitudes obtained for Fourier components.  It is <br>certainly true that there are phenomena which cannot at the <br>present time be explained by the plaheory of hearing." <br>[von Bekesy, Georg, "Hearing Theories and Complex Sounds," <br>Journ. of the Acoust. Soc. Am, 35(4), April<br>1963, pg. 589]  Be it noted that von Bekesy is the researcher <br>most responsible for compiling experimental evidence for <br>the place theory. (In fact he won the Nobel prize for it.)<br>---<br>Leaving out the italicized word "NOT" from the posted text<br>produces a distinctly false impression.  Mea culpa.<br>---<br>Several other  errata appeared in Digest 511, topic 6:<br>The title of the reference listed as [5] should be "The Physics<br>and Psychophysics of Music" by Juan Roederer, 2nd ed., 1973.<br>(There is now a third edition, 1995, same author, same title.)<br>My post incorrectly listed the title as "Introduction to the<br>Physics and Psychophysics of Music," etc.  Important if you<br>try to look up the book in a computerized library system!<br>Under the reference listed as [6]  the sentence should read<br>"...more detailed than any text but Pierce (1992)."  This is my<br>flub.  Because John R. Pierce's "The Science of Musical Sound"<br>from 1992 has a virtually *identical* title to Johan Sundberg's<br>"The Science of Musical SoundS" (S on the end) *ALSO* <br>published in 1992, I confuted them here.  The sense of the<br>paragraph is that Sundberg's 1992 book offers more complete<br>references and a wider consideration of psychoacoustic ear/brain<br>models than any general-reading text other than Pierce's book <br>(also from 1992). <br>--mclaren<br> <br> <br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Thu, 26 Oct 1995 18:33 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id JAA22990; Thu, 26 Oct 1995 09:32:38 -0700<br>Date: Thu, 26 Oct 1995 09:32:38 -0700<br>Message-Id: <Pine.3.89.9510261244.A27249-0100000@mcmail.CIS.McMaster.CA><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2206 href="#2206">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/27/1995 8:21:21 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: A new way of regarding non-octave<br>  scales; Jose Wurschmidt's categorization:<br>  implications for non-octave composition<br>---<br>As Erv Wilson has remarked, "The field of<br>microtonal scales is absolutely infinite."<br>The closer one looks at any given category<br>of tunings, the more detail one sees.<br>This is nowhere more apparent than with<br>non-octave scales: specifically, that subset<br>defined by the Nth root of K.<br>As everyone realizes, non-octave scales are<br>so new and so unfamiliar to Western ears that<br>their properties remain largely unexplored. <br>While Enrique Moreno (1992) and myself (1989,<br>1992, 1993, 1995) have made a start, much<br>theoretical work remains.<br>One of the more striking characteristics of<br>non-octave scales is that they often exhibit<br>a marked disjunction between what Jose <br>Wuerschmidt called the "defining interval"<br>and the "constructing interval."  Indeed, this<br>perceptual dissonance can be so great in <br>non-octave scales as to turn the ordinary rules<br>of harmony and melody upside-down and inside-<br>out, and often leads to puzzlement and frustration<br>among those who hope to compose with Nth roots<br>of K.<br>Gary Morrison has alluded to this problem in posts<br>on his non-octave 13.6363/oct scale (what he <br>calls "88 CET," an appelation which while accurate<br>stresses its defining rather its constructing interval;<br>and in the case of 13.6363/oct the constructing intervals<br>are actually the ones with most musical importance).<br>However I propose to discuss the issue on a more general<br>basis, covering all Nth roots of K.<br>First, a word about the terminology.  Jose Wuerschmidt was<br>a microtonal theorist who did seminal work during the<br>1920s: his article "Die Quinten- und Terzengewebe" ("The<br>Web of Fifths and Thirds") had a huge impact on subsequent<br>thinking about scale generation, and to a large degree <br>underlies Rothenberg's, Wilson's, Fokker's and Lucy's<br>approach to xenharmonics.   (Although they themselves are<br>often not aware of this; W's ideas diffused far & wide, often at<br>2nd- 3rd, and 4th-hand.) Wuerschmidt's essential idea<br>was that tunings are characterized by two kinds of intervals:<br>one, which he called "constructing intervals," which generate<br>the tuning via an implied underlying harmonic root progress<br>and which define the tuning's tonality--and a second kind of<br>interval, which Wuerschmidt called "defining intervals."<br>This is the interval which (in what Erv Wilson calls "logarithmic<br>space," as opposed to "ratio space") linearly defines the melodic<br>modes of the scale.<br>In the case of 12-TET, the constructing interval is clearly 2^[7/12].<br>Underlying this approximation one can reach back to a Pythagorean<br>(one might say archetypal) constructing interval 3/2, which places<br>12-TET firmly in the camp of the positive scales. (I.e., those whose<br>fifths exceed the 3/2 in size. Technically, Bosanquet's positive/negative<br>classification was originally intended to relate scales to the fifth of<br>12-TET, as anal-renentive detail-obsessives  will<br>doubtless point out, but modern usage relates equal tempered<br>scales to the 3/2. )  Other constructing intervals are equally<br>plausible: Erv Wilson has generated JI tunings based on cycles<br>of an interval given by the harmonic mean twixt 4/3 and 11/8,<br>and he has also generated JI tunings based on cycles of 6/5s and <br>5/4s.   One could equally well imagine JI tunings based on cycles<br>of 7-limit, 11-limit, 13-limit and other constructing intervals;<br>Johnny Reinhard has generated a tuning based on the squares of<br>prime numbers.  Other constructing intervals are possible.<br>Returning to equal-tempered scales, clearly harmonic progressions<br>other than the 3/2 have been used in other cultures.  The Javanese and <br>Balinese do not appear to use a 3/2 at all, nor do the East Indian<br>srutis.   Even in this culture, some instruments favor the 5/4<br>rather than the 3/2--as for example vibes. <br>In the realm of the Nth roots of K, subdivisions of the 3:1--most<br>notably the Bohlen-Pierce scale, 13th root of 3--tend to preserve<br>the 3:1 as a constructing interval when the division is a small<br>number of scale-steps, but as the number of steps rises, other<br>constructing intervals can appear (depending on the exact Nth root<br>of K).<br>By constrast, the defining interval of 12-TET is the semitone of <br>100 cents.  This interval defines the melodic structures,  the leading<br>tones and modes possible in 12-TET.  Because of the size of the<br>12-TET defining intervals, many characteristic melodic structures<br>of antiquity cannot be accurately rendered; in 12-TET there is<br>no distinction between the diatonic and the chromatic semitones,<br>for example--nor can the Hellenic enharmonic genus' characteristic<br>plangent near-quartertone be rendered at all accurately.  The sharped<br>leading-tone favored by fretless string players (very well rendered<br>by 17-TET) cannot be faithfully reproduced in 12.  Ditto the string<br>player's flatted II in the root of a typical I-IV-V-II-I progression.<br>In fact, string players will tend to make a consistent pitch distinction<br>twixt II and IIb, while recovering pianists (and other musically<br>challenged individuals) will perceive no difference between the<br>two root notes.<br>However, the defining interval of the 13th root of 3 is the single<br>scale-step of 146.304 cents, very close in melodic size (and effect)<br>to a single scale-step of 8-TET.  Thus, while 12-TET uses a<br>whole-tone very similiar to the familiar tonal 9/8, 13th root<br>of 3 uses a defining interval not close to anything very tonal.<br>In fact the scale-step of 13th of 3 is a good approximation to<br>3 scale-steps of 24-TET, which forms an entirely anti-tonal<br>interval, lying as it does halfway between one 24-tone circle of<br>12 fifths and another; again, 146.304 cents is a reasonable counterfeit<br>of the neutral third formed by the geometric mean between<br>the 6/5 and 5/4, but again this is hardly a tonal interval in <br>the just intonation sense (since 350 cents corresponds to an<br>irrational number 1.224053543).<br>Thus 13th of 3 boasts quite tonal harmonic progressions, especially<br>if one deliberately mis-spells the chords with a 13-scale-steps<br>3:1 on the outside and a 292.608 2-scale-step third on the inside.<br>But the melodic defining intervals and thus the modes of 13th of<br>3 are utterly anti-tonal and inharmonic, and produce an<br>interesting clash with the constructing intervals.<br>In the Nth roots of 2, this kind of war twixt defining and <br>constructing intervals is rare.  Above 48 tones per octave it<br>does not exist; and below there are only a few examples. 35-TET<br>is one example, 26-TET another.  The most notable exemplar is<br>19-TET, in which the 189.47-cent whole-tone defining interval <br>clashes headlong with the very good 694.7368-cent constructing<br>interval of a fifth, unless purely diatonic progressions are used.<br>(That strategy quickly wears out its welcome unless the listeners<br>harbor a particular love for Christmas carols.)<br>Wendy Carlos' alpha and beta scales are characterized by virtually<br>just constructing intervals almost bang-on the just 3:2, but their<br>defining intervals are nothing like the 200-cent approximation of<br>the 9/8 with which we're familiar. <br>Thus the clash twixt defining and constructing intervals must<br>be considered a particular resource of non-octave Nth root of K<br>scales.<br>Moreover, because many Nth roots of K share identical constructing<br>intervals while boasting entirely different defining intervals,<br>the adroit scale designer can fix the constructing interval and<br>generate new scales by searching by alternate Nth roots of K with<br>a different N but the same K.    <br>For example, one might decide one wanted a just 5/4.  In that<br>case one would fix the constructing interval (a chain of 5/4s)<br>and use a successive set of Ns to generate alternate<br>non-octave scales and then explore their characteristics.<br>The most obvious example is of course the set of equal divisions<br>of the 5/4 ordinally greater than and ordinally less than the <br>familiar 4-equal-part division of the approximate 5/4 used<br>in 12-TET.<br>Maintaining a just 5/4 and using 5 divisions gives a scale-step<br>of  [386.31371/5] cents, which yields a non-octave scale of<br>1200/77.26274 tones/oct = 15.5314 tones/oct.  Using 3<br>divisions of the 5/4 (one less than the familiar 4, just as we<br>above explored one more than the familiar 4) we obtain<br>a scale-step of [386.31371/3] cents, for a non-octave scale<br>of 1200/128.77123 tones/oct = 9.31885 tones/oct.  In both<br>cases the constructing interval will be a 5/4, but the defining<br>intervals are quite different.<br>One result of this procedure is to generate a family of harmonically<br>related non-octave scales among which one can "transfer" (to<br>use Ivor Darreg's, and earlier still, Augusto Novaro's, terminology)<br>in a non-octave analogy to traditional tonal modulation.  In the<br>case of standard Western modulation, changing to another key<br>maintains the defining interval while moving by the constructing<br>interval; non-octave "modulation" of the kind described above<br>turns this process on its head by maintaining the constructing<br>interval but often moving by the defining interval.<br>Other obvious elaborations abound, but that must be left for<br>another post.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Sat, 28 Oct 1995 04:08 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id TAA15674; Fri, 27 Oct 1995 19:08:53 -0700<br>Date: Fri, 27 Oct 1995 19:08:53 -0700<br>Message-Id: <951027220824_78406650@mail02.mail.aol.com><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2212 href="#2212">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/28/1995 12:45:59 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: The Glechniszahlen-Reihe Monster<br>---<br>Along with the Sierpinski gasket and the<br>Wierstrass curve, the Gleichniszahlen-Reihe<br>Monster is one of the more interesting<br>number-theoretic constructs.<br>Consider the sequence:<br>1<br>1  1<br>2  1<br>1  2  1  1<br>1  1  1  2  2  1<br>..<br>Is there a pattern here?<br>The answer's embarassingly simple: row 2<br>is "one 1," referring back to the previous<br>row.  Row 3 is "2 ones," referring to row 2.<br>And so on.<br>This "likeness sequence" (a loose translation<br>of the German name) grows quickly.  Row 27,<br>for example, contains 2017 entries.<br>Clearly the Gleichniszahlen-Reihe Monster can<br>be generalized to any two relatively prime<br>numbers.  The monster then takes the form:<br>p  q<br>1  p  1  q<br>1  1  1  p  1  1  1  q<br>3  1  1  p  3   1  1  q<br>1  3  2  1  1  p  1  3  2  1  1  q<br>..<br>What does this have to do with tuning?<br>Well, the Gleichniszahlen-Reihe Monster<br>offers an attractive method of generating<br>modes from a tuning.  It also provides a<br>scheme for traversing ratio space to generate<br>scales (if the units of the sequence are <br>considered as coordinates in ratio space).<br>Lastly, the Gleichniszahlen-Reihe Monster<br>could be used as a melodic engine for algorithmically<br>generating note-sequences in any tuning (if<br>the units of the sequence are considered as indices<br>of an array containing xenharmonic pitches).<br>For more info, see Hilgemeir, M., "Die Gleichniszahlen-<br>Reihe," in Bild der Wissenschaft, vol. 12, 1986,<br>pp. 194-195.<br>--mclaren <br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Sat, 28 Oct 1995 18:53 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id CAA24365; Sat, 28 Oct 1995 02:54:13 -0700<br>Date: Sat, 28 Oct 1995 02:54:13 -0700<br>Message-Id:  <9510280952.aa18004@cyber.cyber.net><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2216 href="#2216">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/29/1995 1:17:07 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subjedt: Xenharmonic uses of FFTs<br>---<br>The FFT (to paraphrase DSP expert F. Gump)<br> is like a box of chocolates: you never<br>know what you're going to get out.<br>Because of the close connection between<br>the micro-level of harmonic or inharmonic<br>partials, and the macro-level of just,<br>equal-tempered and n-j n-e-t tunings,<br>the FFT deserves a more detailed and more<br>knowledgable discussion than it has to<br>date received on this forum.<br>As everyone knows, today's digital <br>time-stretching and pitch-shifting<br>algorithms (exemplified by SoundHack<br>and the Dolson vocoder) have reached a<br>high state of perfection.  This kind of<br>software allows you to reliably change<br>the pitch (or length) of any sound with<br>digital exactitude, under exquisitely<br>precise software control.<br>Everyone knows this, but it isn't true.<br>A number of folks on this forum have gone<br>so far as to claim that the FFT "tells you<br>what's going on inside a sound."<br>Alas, not so.<br>In fact the short-time FFT analysis of<br>a signal changing  in time gives you<br>a series of snapshots.  Each snapshot is<br>an average of what goes on during that<br>time interval.  You get *NO* information<br>whatever about goes on *BETWEEN* spectral<br>snapshots.<br>To get around this severe limitation in our<br>knowledge about the waveform being analyzed,<br>scientists and acousticians use a sophisticated<br>scientific technique.   It's called "a wild guess."<br>Between spectral snapshots spat out by the STFFT<br>analysis, audio analysis programs make a set of<br>arbitrary assumptions.  In effect, guesses.<br>Namely: they guess (arbitrarily) that the frequency<br>components do not change very much, or very fast,<br>and that they remain nearly harmonic all the time.<br>None of these assumptions are true for any sound<br>in the real world, but they are sometimes *almost*<br>true for some sounds, some of the time.<br>Some sounds have nearly harmonic overtones that<br>change relatively slowly except for the initial<br>10 milliseconds of the attack.  Alas, during the<br>first 1/100th of a second of almost every sound, short-<br>time FFT analysis produces garbage output and the<br>results must invariably be fudged with various<br>ad hoc rules of thumb and guesstimates.<br>This occurs because--during the initial attack of<br>a soun--both the frequency and the magnitude<br>of the partials change very rapidly, and the FFT<br>completely falls apart when applied to spectra<br>changing rapidly in both phase and magnitude<br>at the same time.  (This is inherent in the nature<br>of wave phenomena, and is in fact the basis for<br>the Heisenberg Uncertainty Principle when applied<br>to de Broglie matter waves.)<br>The net result is that the FFT in fact does *not*<br>tell you "What's going on inside a sound."  Instead,<br>the FFT *sometimes* gives you a hint under<br>*some* circumstances of *some* of what<br>*might* be going on inside *certain* sounds<br>at the micro-level...part of the time.<br>However,  the short-time FFT also introduces<br>a great many distortions into the information<br>it generates.  The short-time FFT also destroys<br>some of the information being analyzed. <br>Some people have claimed otherwise: memorably,<br>Mark Dolson.  The statement is always incorrect<br>when applied to the short-time FFT, and often<br>incorrect when applied to the simple FFT.<br>Under no circumstances can<br>the output of an FFT be taken as gospel,<br>and in many cases the FFT lies outright.<br>Doubtless many of you will be shocked to<br>learn this.  "But the textbooks say..." <br>Nope. <br>All too many textbooks are written by<br>folks without a lot of hands-on practical<br>experience, and they usually deal with ideal<br>theoretical cases ONLY.  For good reasons, <br>engineering and physics texts are  written<br>to make the subject matter as transparent<br>and comprehensible as possible.  As a result,<br>few introductory texts go so far as to tell<br>you the remarkable number of ways in which<br>today's sophisticated DSP algorithms can<br>turn your input into total trash.<br>Perhaps you've been seduced by the siren sound<br>of that cognomen "digital."  Anything that's<br>"digital" *must* be accurate--right?  It *must*<br>be reliable--right?  After all--the Fourier transform<br>is a classic mathematical technique...how can<br>it *lie* to us?<br>To repeat one of my favorite riffs, all methods<br>of analysis are reliable only insofar as the<br>quantity being analyzed fits the assumptions<br>on which the analysis is based.  Aiming a<br>telescope at a virus doesn't tell you much;<br>using a microscope to study galaxy M31 is<br>futile.<br>In particular, mathematical techniques produce<br>accurate results only when the input honors<br>the boundary conditions of that technique.<br>This is no surprise to those of us on the physics<br>side of the fence, but it seems to come as a <br>constant shock to some other folks.  While <br>physics dudes understand & accept that<br>all mathematical models of reality are merely<br>*approximations* of the extremely complex<br>real world--and usually crude approximations<br>at that--this is a lesson that has yet to percolate<br>into everyone else's consciousness.  Thus one<br>often sees engineers with a mathematical hammer<br>looking at everything in the universe as though<br>it's some kind of nail.<br>The FFT is a classic example.<br>Surprisingly, this can be good thing.  To an engineer,<br>distortion is a no-no...but to a composer, distortion's<br> *dandy.*  If a mathematician puts a sound<br>into the FFT and gets out weird digital glop<br>that strikes the ear as xenharmonic & unspeakably bizarre <br>& nothing like the input...well, that's bad news for<br>a math nerd but great news to a xenharmonist.<br>So rejoice: not only does the FFT often produce<br>utter junk on output, it often spits out sonically<br>*interesting* junk.<br>Think of it as "found art," DSP-style.  <br>This makes DSP pitch-shifting and time-stretch<br>algorithms (like SoundHack) splendid synthesis<br>modules!  Because of the FFT's propensity to<br>act in a highly non-linear and bizarre manner,<br>it can mixmaster even the most mundane inputs<br>into utterly fascinating digital grunge.<br>But don't take my word for it.<br>Instead, let's consider 3 hands-on examples that<br>show just how wildly the FFT can misbehave:<br>[1] Try this one--take a short noisy percussive<br>sound (say, a breaking light bulb, or the thwack<br>of a hammer, or a recorded gunshot) and time-<br>stretch it by a factor of 100.   Surprise!  Although<br>intuition would lead you to suspect that the output<br>would simply be a very long very loud rumble,<br>such is not the case!  Instead, what you get out<br>bears *no sonic relation whatever* to the input:<br>the output is a wild series of rising and falling<br>sine waves, a strange and xenharmonic surf of<br>exotic glissandi and portamenti--1000 violins<br>run amok with tremolo from hell.<br>[2] Now take a short 100-sample burst of noise--<br>say, from an arc welder, or off a radio being <br>tuned--and time-stretch it by a factor of 100, <br>then  another factor of 100 (10,000 all told).<br>Surprise!  The output will be a long digital<br>shriek composed of many sine waves rising<br>and falling.  Surprise #2: the shriek will<br>gradually die away into silence after several<br>minutes.  Yes, even though the input was <br>noise of a constant level, the output is not<br>only a set of pitched gliding sine waves, but<br>one which fades away into *nothing!*<br>[3]  Digitally pitch-shift a perfectly harmonic sound<br>(say, a triangle wave or a square wave) by<br>an irrational factor...say, a 12-TET minor third.<br>Surprise!  The output sound will suffer from<br> periodic "blips" in its amplitude and<br>severe overall phasing--in fact the original<br>boring triangle or square wave will sound as<br>though it's been passed through a Leslie<br>speaker simulator and then a phaser, along<br>with a chopper modulator that makes<br>the sound's envelope flutter audibly.<br>---<br>How can such things happen???<br>Listen up: this may be the only time anyone <br>tells you the whole truth about the FFT.<br>In case [1],  time-stretching a sharp percussive<br>noise produced a series of wild rising<br>and falling sine waves because we tried to<br>use the FFT to analyze and resynthesize a<br>noise impulse as though it were made up of <br>a collection of sine waves.<br>Remember the admonition at the start of this<br>post?  A mathematical technique is *only*<br>useful for analyzing those inputs which<br>adhere to the assumptions underlying that<br>technique.  And in this case, our assumptions<br>were fatally flawed--we tried to model the<br>sound of a light bulb smashing as a set of<br>sine waves.<br>Sorry: this doesn't work in the real world.  <br>As opposed to pie-in-the-sky theoretical<br>inputs made up of perfectly harmonic sinusoids,<br>many common everyday sounds in the<br>real world are not even remotely well<br>modeled as collections of sine waves.  <br>What took place inside the FFT algorithm that's<br>at the heart of SoundHack's time-stretch<br>algorithms is worth examining in detail,<br>because it will demonstrate just how <br>badly such so-called "digitally perfect"<br>algorithms as the FFT can misbehave.<br>To see what happened, think back on the<br>way you got bell sounds out of an<br>old analog synth.  Remember?   First you'd<br>crank up the voltage controlled filter to<br>a whopping big Q, until it was just about<br>to warble into oscillation.  Then you backed the<br>filter's Q knob off just a bit and plugged<br>a short sharp impulse into the filter's<br>input.  On the Arp 2600 a trigger pulse<br>(which is generally *never* used as an<br>audio output--it's meant to trigger an<br>outboard synth or an analog sequencer or<br>envelope generator!)  made a dandy candidate.<br>What happened, of course, is that the<br>short sharp impulse hit the filter with<br>a whole bunch of freqencies. (Remember,<br>the frequency and time domains are inverse<br>to one another: an impulse narrow in the time<br>domain is broad in the frequency domain. <br>Thus a sharp short spike like a trigger<br>pulse contains a wide band of sine<br>waves in the frequency domain) The filter<br>stored those frequencies and smeared<br>them out over time.  Moreover, because<br>the filter had a very high Q it was near<br>the conditions necessary for self-oscillation,<br>and the burst of energy from the trigger<br>pulse pushed the filter over the edge and<br>made it "ring" for a while.<br>So the output was a rich clangy bell sound,<br>with lots of bizarre spurious sine waves<br>generated by the filter itself.  The capacitors<br>in the filter circuit delayed each of the many,<br>many sine waves in the trigger pulse by<br>a different amount, spreading them out<br>over time: and the self-oscillation of the<br>filter added huge numbers of overtones<br>at the natural resonance frequency of the<br>filter itself (a frequency determined by<br>the capacitance, inductance, and resistance<br>of the filter circuit).<br>The end result is that a perfectly ordinary<br>little click, when fed into that analog<br>filter, generated a completely unexpected<br>result: a deep inharmonic bell clang that<br>lasts several seconds.<br>If you'll remember that a filterbank is<br>at the heart of the FFT, you'll now realize<br>what was happening when you fed the poor<br>defenseless FFT that short sharp breaking-<br>light-bulb sound. <br>Extreme values of time-stretch are analogous<br>to raising the Q of an analog filter.  In this<br>case, the energy from each time-slice of<br>the FFT was carried out into many, many<br>other frames because the extreme<br>time-stretch cranked down drastically<br>the rate at which the short-time FFT was <br>permitted to change its output.<br>The net result is that the energy from<br>each FFT frame built up and built up,<br>until finally it sent the individual filters<br>of which the FFT is made into a brief<br>period of self-oscillation.<br>At the same time, the digital filterbank<br>which lies at the heart of the FFT<br>spread those sine waves out in time.<br>This explains the wild rising and falling<br>sine waves--whose amplitudes rise<br>and fall as their phases coincide<br>constructively or destructively.<br>This last phenomenon is the clue<br>to case [2], in which a noise burst<br>of constant level is changed into a<br>shriek which decays into silence.<br>Because of the extreme time-<br>stretch (here, a factor of 10,000!)<br>the many sine waves generated<br>by the FFT's filterbank bled<br>away at a rate controlled by the<br>internal "circuitry" of the FFTs<br>digital filters--in this case, the<br>various constants used inside <br>the FFT itself, which correspond<br>to delay times and filter gains and<br>tap coefficients. In effect, we<br>"whacked" the FFT with a<br>100-sample impulse and it<br>reverberated for a while, then<br>died away.  This is in fact a<br>classic example of the impulse<br>response of an FIR filterbank at <br>the heart of a real-world FFT.<br>In case [3] the filter tried to<br>approximate an irrational<br>quantity with the ratio of 2<br>integers.  In this case, the<br>attempt failed because the length<br>of the FFT wasn't very large, and so<br>we tried to approximate an irrational<br>number with 2 *small* integers.  <br>Remember:  an FFT algorithm<br>does pitch-shifting by changing the<br>decimation factor of the input FFT<br>of the sound and then changing the<br>output sample rate conversion filter<br>so that the ratio of the two quantities<br>is as close as possible to the desired<br>pitch shift ratio.  However, in the<br>case of a ratio as irrational as 2^(4/12),<br>the FFT algorithm falls apart--because<br>ultimately it's limited by the fundamental<br>frequency of the sound itself.  If the<br>sound's fundamental is, say, 100 samples<br>in length, then the FFT *must* use a 128-point<br>window to preserve the fundamental of<br>the input sound.  This limits the granularity<br>by which the decimation factor/sample rate<br>conversion filter  can be changed.  And thus<br>(as usual with the FFT) we get a trade-off:<br>to pitch-shift a sound with extreme precision,<br>we must reduce the window size of our<br>FFT--but this amounts to throwing away most of<br>the frequency information in the original sound. <br>Conversly, the more precise our frequency analysis<br>of the input, the more coarse and granular the<br>amount by which we can ratchet the pitch<br>up or down via DSP methods.<br>---<br>Now that you've more insight into just how<br>bizarrely the FFT can behave, you might want to<br>try your hand at using the FFT to make microtonal<br>music.  This is a happy hunting ground for<br>the imaginative xenharmonist!  Talk about "found<br>scales..."  With a sound tool like SoundHack or<br>the Dolson vocoder, you can obtain "found scales"<br>from almost any kind of percussive sound--nor <br>do you need access to a digital audio workstation<br>or a mainframe!  You can do  impressive and <br>wildly microtonal-sounding compositions with the FFT<br>right on your home Mac or PC.<br>Here are some suggestions for ways to produce<br>*highly* xenharmonic music using the FFT:<br>[1] Try ring modulating a harmonic-timbre sound<br> & then  pitch-shifting or time-stretching it.<br>(To ring modulate a sound, just multiply it by <br>a fixed sine wave or set of sine waves.  Most<br>DSP tools allow the user to generate a fixed<br>signal with an arbitrary set of frequencies<br>and amplitudes, and also allow you to multiply<br>any signal by any other signal.)  <br>You'll discover that the more inharmonic a<br>sound, the wilder the output from the FFT--<br>regardless of the particular technique you<br>use.<br>[2] Try extreme time-stretching or pitch-<br>shifting of conversations.  Only a small part <br>of any given vocalisation consists of pitched<br>material: the rest is made up of glottals,<br>fricatives, plosives, labials, and the like.<br>Because these are *wildly* inharmonic<br>impulses, they're superb candidates <br>for teasing wacky microtonal goobidge from the<br>FFT.<br>[3] Try pitch-shifting or time-stretching<br>a sound by some large amount, then<br>save the sound in reverse order and<br>repeat the process.  As long as the<br>time-stretch or pitch-shift isn't a<br>power of 2, the result will be a<br>gobbling gibbering wobbling modulation <br>that's caused by the ratio of the two<br>incommensurate decimation rate-vs.-<br>FFT-widow-sizes.  This procedure<br>can generate some extremely unusual<br>timbres & highly xenharmonic pitches.<br>[4] Try multiplying one sound by another;<br>try dividing one sound by another.<br>You'll discover that division is equivalent<br>to high-pass filtering of one sound<br>ring-modulated by the other; it's incredibly<br>noisy.  Multiplying one sound by another<br>is equivalent to ring-modulating one<br>sound by the other.<br>Results are especially interesting if, say,<br>one input is Mozart and the other input<br>is The Sex Pistols.<br>[5] Try using an envelope follower to <br>control the amount by which you ring<br>modulate a sound; also try making<br>the relationship inverse. (That is,<br>division instead of multiplication.)<br>For pitched highly harmonic material,<br>this can turn a western symphony<br>orchestra is something like a <br>demented gamelan; it's endlessly<br>entertaining, particulatly with the<br>100 strings of Montovani.<br>[6]  Some DSP packages allow you<br>to use a phase vocoder to generate<br>a set of time-varying filters.  This<br>is a real gold mine.  The mundane<br>usage is to analyze speech and<br>apply the time-varying filters to<br>a flute, an electric guitars, etc.,<br>ad nauseum.<br>But it becomes *really* interesting<br>if you abuse & misuse the algorithm<br>by "analyzing" the sound of a<br>thunderstorm, say, or a recording<br>of bugs frying on an electric bug<br>zapper, and then apply the weird<br>non-linear time-varying filters thus<br>obtained to, say, the sound of a<br>ditch witch, or a building being <br>demolished.   The end result, as<br>Carter Scholz put it, is akin to<br>"Lloyd Bridges giving a lecture on just <br>intonation while wearing a scuba <br>regulator and breathing helium."<br>*Highly* xenharmonic!<br>--mclaren<br><br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Sun, 29 Oct 1995 18:03 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id BAA05391; Sun, 29 Oct 1995 01:04:04 -0800<br>Date: Sun, 29 Oct 1995 01:04:04 -0800<br>Message-Id: <Pine.3.89.9510291016.A12098-0100000@styx.ios.com><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2218 href="#2218">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/29/1995 8:35:42 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Our friends at Ensoniq<br>---<br>To date little has been said regarding the<br>Ensoniq corporation.  Someone needs to point<br>out how much we owe  people like Steve Curtin,<br>and his fellow Ensoniq engineers.<br>Let's start with the fact that if you want a<br>sampler with built-in tuning tables,  were it <br>not for Ensoniq you'd be in deep guano.<br>It's incredibly important that a sampler include<br>a tuning table.  Without one, the only<br>reliable way to break out of 12 on a sampler<br>is to use a separate sample for each MIDI note.  <br>This gobbles memory at a *staggering* rate.  For a 2-<br>second stereo sample at 44.1 Khz spread over (say)<br>36 notes, this would demand 6.05 megs of RAM <br>*per MIDI channel.*<br>For 16 MIDI channels, that's a mind-boggling<br>96.89 megs of RAM!<br>By contrast, if your sampler allows you to<br>use a tuning table you save an *incredible*<br>of RAM.  Moving to more than 12 tones<br>per octave lets you spread each sample over<br>even *more* keys than in 12--for a 31-tone<br>equal tempered tuning, for instance, you can<br>spread each sample over 31/12 times as<br>many MIDI notes.  This means that if you've<br>got a multi-sampled sound that spreads<br>each sample over (say) 3 MIDI notes in 12,<br>a tuning table allows you to *drop* memory<br>requirements by letting you spread each sample<br>over 8 MIDI notes.  <br>Compare the two situations.  In one case, the<br>lack of a tuning table forces you to gobble RAM<br>by using 36 separate samples; in the other case,<br>a built-in tuning table lets you *save* that RAM<br>by using only 36/7.8 = 5 separate samples. The<br>savings in RAM is ENORMOUS: a full <br>[1 - (36 - 5/36)] * 100 = 80%!  <br>This really matters.  <br>We're not talking about just 10% or <br>even 20% or 30% savings of RAM here...a tuning <br>table makes an ENORMOUS differece.  It lets<br>you use 1/2-1/6 of the memory you'd otherwise use.<br>This is *crucial* because the problem with every<br>sampler is lack of RAM.  No matter how much <br>you've got it's never enough.  And forcing the<br>microtonal user to burn up gobs and gobs of RAM<br>by duplicating each sample on every single MIDI<br>note is so wasteful as to defy description.<br>Clearly, Ensoniq's inclusion of a tuning table (a<br>separate tuning table for each layer of each sample,<br>in fact) on the ASR-10 qualifies as one of<br>the biggest gifts to microtonalists ever. <br>Period.<br>Of course, there's more.<br>Ensoniq builds reliable products.  They sound pretty<br>good.  Other companies have flashier technology,<br>but Ensoniq's synths sound about as excellent as<br>anything out there.  The big *musical* advantage<br>Ensoniq enjoys, of course, is that they've supported<br>micrtonality by including built-in tuning tables<br>every since 1989.   I'm not sure why they made that<br>decision--there doesn't seem to be a lot of <br>economic benefit in tuning tables.  However, I can<br>say that I've bought a bunch of Ensoniq gear ever<br>since they started building tuning tables into their<br>synths.  As long as they keep including tuning tables,<br>I'll keep buying their equipment.<br>This is particularly noteworthy behavior for a large<br>synth manufcaturer because many of the other clueless<br>and brain-dead synth companies still refuse to include<br>full-keyboard microtuning.  Especially the Japanese.<br>Weird, when you think about it.  Which culture uses<br>a non-12 pentatonic scale?  (The Japanese)  And which<br>culture is more frenziedly committed to 12-TET?<br>(The Japanese!) Kawai, Akai and many others<br>fanatically refuse to let their instruments be retuned.<br>They're adamant about it to the point of psychosis.  The<br>behaviour is almost Manson-like in is self-destructivness,<br>yet they persist.<br>As a result I won't buy Kawai or Akai synths.  Let 'em<br>rot: they can come out with a synth that does<br>everything buy makes coffee and I still wouldn't even<br>use it as a boat anchor.<br>Ensoniq's commitment to microtonality deserves special<br>mention on this forum.  I have nothing but good things to<br>say about their synths. (it would nice if they dropped their<br>prices, but then I wish all mfrs would drop their prices;<br>what else is new?) Bottom line: if you're serious about<br>microtonality, eventually you will discover that kludges<br>and gyrations and contortions and weird clumy work-<br>arounds like tuning each note with pitch-bend, etc.,<br>just don't work after a certain point.  You run out of<br>MIDI bandwidth, notes start to get dropped, attacks <br>sound twangy, and the logistics of such kludges just<br>become insupportable for even moderately complex<br>compositions.<br>In the end, a built-in full keyboard tuning table is <br>an absolute  necessity for serious MIDI microtonality.<br>And Ensoniq and Yamaha are the only two synth <br>manufacturers that have consistently stuck to<br>their support for tuning tables.  <br>Best of all, Ensoniq--unlike Yahama--has refused to<br>throw away its best technology.  Yamaha's insane<br>decision to stop making FM synths is a mistake Ensoniq<br>would never have made: instead, Ensoniq just keeps<br>making its instruments bigger, better and more<br>capable.  Ensoniq refuses to give up on a product. <br>They just keep adding features and upgrading the<br>ROMs until the synth does everything you could reasonably<br>want.  That's a good attitude for a synth company to<br>have, especially nowadays when the Japanese are<br>coming out with a new model every 6 months that<br>renders obsolete all previous RAM cartridges, editors, <br>voice disks, etc.  but doesn't sound any different or<br>do any more than the Japanese synths of 5 years ago.<br>Bottom line?<br>Everyone on this forum should offer Steve Curtin and<br>his fellow engineers at Ensoniq a very long,<br>very appreciative round of applause.<br>We owe them a lot.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Mon, 30 Oct 1995 07:07 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id VAA17788; Sun, 29 Oct 1995 21:07:07 -0800<br>Date: Sun, 29 Oct 1995 21:07:07 -0800<br>Message-Id: <951030050412_71670.2576_HHB30-6@CompuServe.COM><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2224 href="#2224">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>10/31/1995 10:27:18 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Models of reality, the Fourier<br>  mindset, and negative eigenvalues in<br>  Sturm-Liouville problems<br>---<br>Charles Lucy has been regularly pilloried<br>in this forum for his doubts about the<br>Fourier analysis model of acoustic<br>systems.  Several months ago, in Topic<br>1 of Digest 404, John Chalmers also stated <br>that "I can think of no physical principle <br>which would favor flat fifths over natural..." <br>This is a concise expression of a general<br>attitude among acousticians and music<br>theorists, most of whom are not fully<br>conversant with the physics behind the<br>conventional textbook description of<br>vbrating strings and air columns.<br>In fact there are good solid physical  reasons <br>why no simple harmonic mechanical oscillator<br>ever produces strictly harmonic oscillations,<br>and will instead tend to generate partials<br>which are either systematically stretched<br>or shrunk by comparison with the expected<br>harmonics.  There are also excellent physical<br>reasons why 2- and 3-dimensional physical<br>oscillators will in general not exhibit either<br>linear or harmonic oscillatory behavior at all.<br>This point bears on Lucy's criticism of the<br>Fourier analysis mindset that characterizes<br>much of the discussion of this forum, and<br>in a larger sense it also bears on the question<br>of which tunings we use--or even contemplate<br>using.<br>Ultimately, the musics we choose to make are<br>limited by our model of the world.  Whenever<br>we tune an instrument, we inevitably begin<br>to impose a structure on physical reality:<br>and the type of structure we choose to impose<br>is determined by our preconceptions.<br>In the West and Mideast, ever since the time<br>of Pythagoras and almost certainly (before<br>that) the Babylonians and the Egyptians, we<br>(in the West) have conceived of the universe as ruled<br>by number.  The predictive value of number is a<br>touchstone of classical Hellenic thought.<br>This had profound implications<br>for the kind of music made in Greece and<br>the European cultures.<br>However, other cultures bring other<br>preconceptions to the process of tuning.<br>There is no evidence (as Marc Perlman has<br>pointed out) that the Javanese, the Balinese,<br>or any of the other cultures of Southeast<br>Asia conceive of the universe as a manifestion<br>of number, except perhaps in the Kabalist<br>sense implied by gematria, the geomancy of the<br>Dogon peoples of Mali, etc.  Thus their tuning systems do <br>not arise from mathematical or physical-acoustic<br>considerations, and as a result Javanese and<br>Balinese music does not employ the 2:1 octave,<br>4:5:6 harmonies or harmonic-series timbres. The<br>same is true of the  musics found in Africa,<br>Central Asia, most of the South Seas islands and<br>South America.<br>None of these cultures appear to conceive of<br>music in the mathematical framework typical<br>of Western thinking; indeed, as Jon Appleton<br>has pointed out, in many other cultures<br>music is often not analyzed at all, but regarded<br>as belonging to same realm as magic.<br>Thus one's preconceptions exert a potent<br>influence on the kind of music one chooses <br>to make, and different models of reality<br>produce different kinds of tuning.<br>The simple harmonic oscillator equation<br>is one model of reality.  <br>There are many others even within the<br>confines of Western mathematics.<br>According to the simple harmonic motion <br>equation, the displacement<br>x = A*sin(sqrt(k/m)*t) + B*cos(sqrt(k/m)*t)<br>where k is the spring constant, m is<br>the mass, and t is the elapsed time<br>(A and B are constants of propotionality).<br>This is a recipe for perfectly harmonic<br>behaviour.   <br>But the equation which describes<br>simple harmonic motion is a drastic<br>simplification of reality, and there<br>are many other (more sophisticated)<br>mathematical models which describe<br>the same physical oscillatory system.<br>For example, when a simple tube is<br>excited with a laminar airflow the air<br>in the tube will oscillate at a characteristic<br>frequency determined by the length of<br>the tube, the density of the air, the<br>location and number of tone holes, etc.<br>Increasing the airflow produces a  stronger<br>second harmonic, and so on, according<br>to this model.<br>But in the real world two modes of<br>oscillation (fundamental and second harmonic)<br>in a tube tend to "pull in" toward each other<br>so that the fundamental rises slightly in<br>frequency, while the second harmonic drops<br>slightly in frequency.  The simple harmonic<br>motion model of reality cannot explain this<br>because it views air molecules as billiard<br>balls connected by springs, and<br>the system cannot behave in any but<br>a perfectly harmonic way.<br>If instead we look at the air-filled tube as<br>an energy exchange system from a <br>thermodynamic viewpoint, or if we<br>view it as a state-space system, or<br>if we consider it from the standpoint<br>of continuum mechanics, the reasons<br>for the slight inharmonicity of the<br>oscillations become obvious.  Setting<br>up a fundamental mode of oscillation in the <br>the tube changes its acoustical admittance;<br>a second oscillation mode will then lose energy<br>or gain energy, depending on the phase<br>of its compressions and rarefactions <br>relative to that of the fundamental mode.<br>Since the system will tend to minimize its<br>overall potential energy the two acoustic<br>modes will couple; and because the <br>system is closed (negigibly energy is<br>lost via acoustic radiation), the energy lost<br>from the second mode of oscillation has<br>to go somewhere and not all of it will be<br>either transmitted out the bore of the <br>tube or lost as friction against the walls<br>or in the friction created by turbulent non-laminar<br>flow around the tone holes, etc.  Thus the<br>energy lost from the second mode of oscillation<br>will partly flow into the fundamental mode of<br>oscillation, which in turn forces a <br>change in its period.<br>This example serves as a warning about<br>the models we use to explain physical<br>system, and consequently to justify the<br>tuning systems we use.  In the case<br>just considered, the inharmonic behaviour<br>is slight--as long as flow of air through<br>the tube remains slow and laminar.  Thus <br>it can be handled by perturbation theory,<br>as in lord Rayleigh's "Acoustics" of 1896. But<br>as the airflow increases, the flow becomes <br>non-laminar.  Multiphonics appear;<br>then the oscillation patterns become<br>quasi-periodic, start to break up, and<br>finally become completely aperiodic.<br>The oscillation turns to noise.<br>Viewed as a simple energy exchange<br>system, our model cannot explain this.<br>But if we step back yet again and realize<br>that the energy-exchange system we've<br>been picturing is a drastic simplification<br>the reason for this behaviour becomes clear.<br>If, instead, we view the partial differential equations <br>which describe the interaction of non-linear<br>acoustic admittance,  non-laminar airflow and<br>radiated, transmitted and absorbed mechanical<br>energy, and boundary conditions from the<br>viewpoint of complexity theory...  Then it becomes<br>obvious why the system beahves as it does.<br>"Little is known concerning boundary value<br>problems for general nonlinear differential<br>equations..." [Courant and Hilbert, "Methods<br>of Mathematical Physics," 1962, pg. 367.<br>For the class of hyperbolic PDEs which<br>describe one-dimensional physical<br>oscillatory systems, perturbation theory<br>is the classical method of dealing with<br>the increased airflow described above. <br>But as we've seen this does not work<br>beyond a very limited regime.  Nonlinear<br>dynamics must be invoked beyond the region<br>of non-laminar airflow, and in this regime<br>the oscillations in the tube move from<br>being ordinary attractors in phase space<br>to being strange attractors, whose behaviour<br>not only jumps back and forth between<br>aperiodicity and quasi-peridiodicity, but<br>also spans the complete gamut from<br>pure noise to harmonic oscillation. Viewed<br>in phase space, the operation of the compressions<br>and rarefactions in the air of the tube follow<br>orbits which can be bounded, yet not precisely<br>predicted, and which depend crucially on<br>initial conditions.<br>Lest you imagine such chaotic behaviour is<br>restricted only to airflow in tubes,<br>note that in the case of the wave equation<br>describing the general nonhomogeneous <br>vibrating string "whenever an eigenvalue is<br>negative an aperiodic motion occurs <br>instead of the corresponding normal<br>mode." [Courant and Hilbert, "Methods of<br>Mathematical Physics," Vol. 1, pg 292]<br>Thus chaotic oscillation can occur<br>even in vibrating strings--in fact<br>in any one-dimensional oscillator<br>described by a Sturm-Liouville<br>eigenvalue problem.<br>This is not commonly known.<br>Why?   <br>Because every textbook on acoustics<br>which treats the wave equation and<br>the vibrating string  assumes<br>that the egienvalues will never become<br>negative.  As a result, the true complexity<br>of the behjvaiour of even so-called<br>"simple" 1-D physical oscillatory systems<br>is masked from the unquestioning students.<br>(These simplifying assumptions are made<br>so that the equations can be quickly and<br>easily solved.  The usual dodge is to claim<br>that "negative eigenvalues have no physical<br>significance." As so often in physics and<br>engineering, this is a fudge.  In fact <br>the problem is just systematically<br>restricted and our viewpoint successively<br>limited until we arrive at equations which <br>undergrad-level mathematics can dispatch <br>with elegance in a neat closed form.)<br>And what does all this have to do with<br>tuning?<br>The debate on this forum has mostly centered<br>around a restricted set of musical tunings--<br>JI, meantone, a few equal temperaments which<br>well approximate the lower members of the<br>harmonics series.  And this tiny subset of<br>tunings is derived from simplistic physical <br>models (as we've seen).  These acoustic models<br>are described by the usual textbook<br>solutions of the wave equation, simple<br>harmonic motion, and the rest of the<br>18th- and 19th-century baggage.<br>But the reality can be very different from<br>the universe predicted by these 18th-century<br>mathematical models.  <br>"For three centuries science has successfully<br>uncovered many of the workings of the<br>universe, armed with the mathematics of<br>Newton and Leibniz.  It was essentially a<br>clockwork world, one characterized by<br>repetition and predictability. (..) Most of<br>nature, however, is nonlinear and is not<br>easily predicted. (..) In nonlinear systems<br>small inputs can lead to dramatically<br>large consequences." [Lewin, Roger, <br>"Complexity," 1993, pg. 12]<br>By now it should now be clear why the Fourier <br>transform has gained such popularity, and also <br>why Charles Lucy's doubts about it are<br>well-founded.  In "a clockwork world,<br>one characterized by regularity and<br>predictability," a mathematical technique<br>which breaks all physical oscillations<br>down into sets of perfectly periodic<br>sinusoidal functions with no beginning<br>and no end makes a lot of sense.  In a<br>clockwork 18th-century universe, the<br>Fourier transform enjoys enormous descriptive<br>power.<br>But we now know that the 18th-century clockwork<br>model of the world is not a complete picture.  In the<br>real world, where chaotic strange attractors<br>characterize the action of real oscillatory<br>systems, the Fourier transform often falls apart.<br>And instead of describing reality, the Fourier<br>transform can put blinders on us and prevent<br>us from seeing the world as it really is.<br>In some cases, this is unimportant--because<br>the oscillations of real physical systems are<br>sometimes only a little different from the simplistic<br>clockwork-universe description of the Fourier<br>Theorem.  In instruments like strings, winds<br>and brasses (after the initital attack of the<br>tone is over, and if the instruments aren't<br>played too loudly, and if we're talking only<br>about the notes in the middle range of these<br>instruments) a short-time Fourier analysis<br>tells us *something* about what's going on<br>in *some* of the notes, during *part* of<br>their duration.  But even for this restricted<br>class of sounds, Fourier techniques fail <br>during the first 10 milliseconds or so of the<br>note's attack. FFTs fail because when t < 10ms  <br>the amplitude and frequency of the component<br>partials are both changing with great rapidity,<br>and the Fourier transform *cannot* provide<br>accurate information about both the period<br>*and* the spectrum of an input function. An<br>increase in resolution in one parameter forces<br>a descrease in resolution in the other.  This is<br>inherent in the mathematics of the FFT, and<br>*cannot* be sidestepped.<br>A much greater limitation on the Fourier mindset<br>is the fact that most of the musical instruments used <br>by most of the cultures in the world are not violins<br>or French horns or flutes.  Most of the musical<br>instruments used by other cultures are two- <br>or three-dimensional oscillators which <br>generate inharmonic partials & noise, and store<br>energy from one vibrational cycle to the next...<br>so that their behaviour is often extraordinarily <br>non-linear.  See Rossing's discussion of the<br>energy storage from one cycle to the next in<br>a tam-tam, for example. [Rossing, 1992]<br>For such instruments, the Fourier description<br>is a hindrance rather than an aid to understanding.<br>And the class of tunings to which we in the west <br>have systematically restricted<br>ourselves--namely JI, meantone and equal<br>temperaments with good approximations of <br>the lower harmonics--are also inadequate for<br>such instruments. <br>This perhaps addresses John Chalmers' doubts<br>about the validity of any "physical system that<br>would favor flat fifths over natural." Simply<br>moving from one-dimensional physical oscilaltors<br>to two- and three-dimensional oscillators<br>generate fifths which are either *very* flat or<br>*very* sharp (depending on the oscillatory<br>geometry)...indeed, the whole 18th- and 19th-century<br>armamentarium of Western acoustic terminology is <br>inapplicable to such  physical oscillators: "fifth" and <br>"third" and "natural harmonics" are terms without<br>meaning for such physical systems. The tam-tam<br>or the metallophone or the vibrating drumhead<br>or (as we've seen) even purportedly "simple"<br>one-dimensional systems like the vibrating<br>string often operate in the region of complexity...<br>a region of oscillation that lies between the<br>complete chaos of noise and the clockwork perfection<br>of perfect harmonicity.  The Fourier view of<br>the universe does not yield useful information<br>when applied to such acoustic systems, or<br>even when applied to a vibrating string characterized<br>by negative eigenvalues in the associated<br>Sturm-Liouville equations.<br>One of the central revelations of complexity<br>theory is that patterns lie hidden in chaos.<br>Emergent order appears ex nihilio when <br>systems reach the edge of chaotic behavior,<br>as in woodwind multiphonics, etc.  In fact<br>the Brookhaven National Laboratory phsyicist<br>Per Bak has developed the hypothesis that<br>dynamical systems naturally evolve toward<br>a critical state in which the edge of chaos<br>spontaneously generates order. [See Bak, P.<br>and Chen  K,. in Scientific American, Jan. 1991;<br>also see Packard, N., "Adaptation Toward the<br>Edge of Chaos," Technical Report, Center for<br>Complex Systems Research, University of<br>Illinois, CCSR-88-5, 1988.]<br>What does this have to do with tuning &<br>music?<br>It seems possible (if not probable) that<br>non-just non-equal-tempered tunings <br>represent an adaptation toward spontaneous<br>order generated by the non-linear dynamical<br>systems used in so many other musical<br>cultures (i.e., two- and three-dimensional<br>physical oscillatory systems: drums, <br>flat or curves metal plates, non-linearly<br>coupled oscillators like those used in<br>parts of Africa in conjuction with resonant<br>strings, etc).<br>Interestingly enough, throwing away the<br>Fourier transform does not mean a loss<br>of predictive power.  Many other analytic<br>models for acoustic systems exist: Walsh<br>transforms, Daubechies wavelets, Gabor's<br>acoustic quantum, and even more recent<br>non-linear mathematical transforms such<br>as the slope transform [See Maragos, P., <br>"Slope Transforms: Theory and Application <br>to Nonlinear Signal Processing," IEEE<br>Trans. Sig. Proc.,  43(40, Paril 1995, pp. <br>864-877.]<br>The fact that so astute and insightful<br>a thinker as John Chalmers could fall<br>into the trap of looking at all tuning<br>systems and physical oscillators through<br>the narrow distorting lens of the<br>Fourier transform is an indication of<br>the power the Fourier mindset to<br>brainwash the unwary.  While the Fourier<br>transform is a marvellous mathematical tool,<br>is does not describe all of acoustic reality--<br>only a small part of it.<br>Thus  Charles Lucy's doubts about the<br>universal value of the FFT are well<br>founded, and the attacks he has suffered<br>for voicing these doubts in this forum<br>are an indication of just how thoroughly<br>the Fourier mindset can blind us to the<br>wonderfully complex nature of real <br>instruments, real tunings and real music<br>in the real world.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Tue, 31 Oct 1995 20:59 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id KAA08873; Tue, 31 Oct 1995 10:58:57 -0800<br>Date: Tue, 31 Oct 1995 10:58:57 -0800<br>Message-Id: <v01530502acbc2e7c1883@[194.137.64.56]><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2228 href="#2228">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>11/1/1995 10:05:06 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Music & western science<br>---<br>On encountering the interesting book<br>"Measure for measure: a musical history<br>of science," by Thomas Levenson, one<br>passage in particular caught my eye:<br>"Music and science have been intertwined in<br>Western thinking from the moment of their<br>shared origins, of course: the first even<br>vaguely scientific theory of the universe<br>was a musical one, Pythagoras' arrangement <br>of the planets on the scaffolding of his musical<br>intervals, with every heavenly body sounding<br>out its note in what became known as the music<br>of the spheres." [Levenson, T.,  1994, pg. 13]<br>Even though this is probably incorrect (the<br>Bablyonians, Egyptians & Sumerians likely<br>originated most of the musical and geometric<br>discoveries attributed to Pythagoras), Levenson<br>makes a cogent point.<br>To a large extent the current schism in music can be<br>described by the three stages of Western science:<br>Newtonian science, quantum theory and nonlinear<br>dynamics.<br>The Newtonian model of the universe is a giant<br>clockwork mechanism.  Harmonic cycles naturally<br>arise from such a scheme: the well-known <br>example in elementary physics textbooks of<br>planetary orbits as clocks naturally suggests the<br>idea of ratios between oscillating cycles of <br>both planetary and (inside the atom) electron-<br>orbital motion.<br>In the macroscopic everyday world, tides,<br>rates of chemical reaction, the compounding<br>increase in velocity produced by uniform Newtonian <br>acceleration, as well as the  densities of<br>Maxwell's electric and magnetic fields as a<br>function of distance from the charge center all<br>produce sets of ratios.  In a Newtonian universe, it's<br>hard to escape from ratios--and many of them <br>involve small integers.<br>Such a worldview inevitably tilts toward just intonation.<br>This bias is not necessarily conscious.  It is so pervasive<br>that it often shows up as an unconscious or even<br>as a subsconscious  assumption--a "well, of <br>course...obviously" set of musical axioms <br>from which all subsequent musical theorems derive.<br>In the quantum universe, however, particles are<br>replaced by probability  waves--exotic<br>critters often called "wavicles."  The best way <br>to deal with a quantum universe is a pragmatic<br>approach: sum the probabilities, assume the<br>most likely interaction, calculate the likely result.<br>This sort of approach suggests equal temperament--<br>not a perfect intonation, but given the pragmatic<br>realities (and the uncertainties in performed<br>pitch and actual tuning) the best compromise.<br>Chaos theory views the universe as a playground<br>for nonlinear dynamics.  Here, bifurcation and<br>period-doubling render predictions useless even<br>when made by the most powerful computers: <br>an *infinite* number of digits is necessary<br>to represent initial conditions accurately.<br>In the real universe of nonlinear mechanics,<br>planetary orbits grow chaotic and cannot be<br>used as celestial clocks over more than a few<br>hundred million years. (See "Newton's Clock,"<br>Ivars Peterson, 1994.)<br>This view of the universe stresses the nonlinearity<br>of real physical processes and naturally gives rise<br>to non-just non-equal-tempered tunings (that is,<br>tunings not generated either by Nth roots of K or<br>by ratios of integers).  These tunings are just<br>as "natural" as the harmonic series...yet such tunings<br>are profoundly alien to Western music.<br>It occurs to me that a good deal of the friction on<br>this tuning forum between advocates of this or that<br>tuning system derives from a deeper cognitive<br>dissonance twixt contrary worldviews.  One of the implicit<br>goals of the JI crowd seems to be a clear distinction<br>between consonance and dissonance: this implies, presumably,<br> that consonance can be unambiguously defined as<br>*sensory* consonance, and that more complex notions<br>like concordance and ambisonance can be derived<br>directly therefrom.  In a universe thus ordered,<br>the JI view is that of a cosmos capable of balance,<br>rationality, harmony and what the Hellenes called<br>"taxis," along with the related concept of "logos"<br>(which only very rarely means "word:" more often<br>"logos" mean "underlying order behind," as in<br>meteorology = "the underlying order behind the<br>sky.")<br>The main goal of the equal-tempered crowd, by contrast,<br>seems to be "to get something that works with usable<br>instruments."  Equal temperament aficionados stress<br>the ease of modulation, the ready-to-use simplicity of<br>their tunings.  No infinite sea of commas, no troubling<br>hard-to-classify intervals like the 11/9 or the 9/7.<br>This accords with a subconscious view of the universe<br>as a place in which uncertainty and chance conspire to<br>defeat efforts to attain harmony, balance, simplicity:<br>instead, the best we can hope for (according to this<br>view) is a workable compromise.<br>The chaos-theory worldview is by far the most radical.<br>It's one that's still working its way through our culture.<br>While the Newtonian cosmos produced Baroque music<br>and Christopher Wren's architecture, and the quantum<br>worldview produced modernism and Bauhaus glass-cube<br>monopitch-roof architecture, the chaos-theory universe hasn't<br>yet made its full impact felt on art and music and<br>literature.  A few compositions like Bruno de Gazio's<br>algorithmic works of the early 1990s and Mark Trayle's<br>Mattel Power Glove compositions have filtered into<br>our consciousness...but by and large the *weltbildung*<br>suggested by chaos theory seems hallucinogenic to <br>Western artists and composers and writers.  The idea<br>that the universe is a place shaped by violent, complex, <br>unexpected events which grow out of microscopic<br>chance events...well, it's  not a comfortable one.<br>The notion of huge effects blossoming from trivial causes<br>is not something with which Aristotelian dramatic<br>theory is well equipped to cope.  It's as though Oedipus were<br>and his entire family were to die horribly from infections <br>caused by scratching mosquito bites(!) In music, however,<br>the seeds of this kind of exponential and uncontrolled<br>growth of emergent structure  have always been nascent<br>in Western tradition.  Ever since composers began to<br>generate huge compositions from small cellular<br>motifs, the notion of order boiling out of chaos seems<br>to have lurked just outside the peripheral vision of<br>Western music theory.<br>Of course, non-just non-equal-tempered tunings<br>are particularly alien to our (read: white European) <br>concept of music. <br>And so it's fascinating to note the historical Western<br>response to the Indonesian gamelan, which uses a<br>classic n-j n-e-t tuning (in fact, each gamelan<br>uses a different one).<br>The first time a Western composer appears to have<br>encountered the gamelan was when Debussy heard <br>one at the Paris Exposition in 1895.  He was struck<br>most forcefully by the rhythms, which he ecstatically<br>described as "complex enough to put the finest<br>Western composers to shame" (or words to that effect;<br>this is from memory).<br>Mantle Hood's importation of a gamelan in 1956 appears<br>to have sparked Lou Harrison's interest, and a general<br>American gamelan movement--ironically founded on<br>tunings using just intonation.  As Marc Perlman has<br>pointed out,  this is a radical departure from actual<br>Javanese/Balinese tuning practice...  And it indicates<br>just how completely *unable* Western composers are<br>to assimilate the Javanese tuning in its *own terms.*<br>Indeed, Lou Harrison himself admitted to being<br>terrified of the non-just non-equal-tempered intervals<br>of "slippery slendro;"  without the Western rationalistic<br>landmark of small integers, he found himself at sea.<br>And finally during the 80s and early 90s digital signal<br>processing compositions produced with the spectra<br>and tones of gamelans (for example, Robert Valin's<br>"Tat tvam asi," 1990, UMUS CD "Bali In Montreal,"<br>UMM CD 104) again emphasize Fourier manipulations and <br>transformations.  *Again* the Western composer is <br>reduced to grasping at harmonics and integer-ratio<br>frequencies *even* when manipulating the raw<br>non-integer, inharmonic, non-just non-equal-tempered<br>partials and spectra of Javanese/Balinese<br>gamelan: *again,* there is a complete inability to<br>incorporate the gamelan worldview into the composer's<br>milieu and assimilate it as part of Western compositional<br>process. Instead, the Javanese n-j n-e-t tuning and<br>chaos-theory worldview of clashing rhythms producing<br>a mysteriously regular emergent order can *only* be<br>assimilated by the Western composer/theorist<br>if *first* coated with the antibodies of Fourier theory<br>and harmonic overtones.<br>Thus it's fascinating to observe the clashes between<br>these three factions on this tuning forum.  My <br>observations concerning non-just non-equal-tempered<br>tunings matched to n-j n-e-t additive-synthesis timbres<br>have provoked incomprehension, with some outright<br>hostility and no little puzzlement thrown in; meanwhile,<br>the main hot spot seems to be the flash point between <br>equal temperament advocates and JI enthusiasts.<br>This is particularly revealing because it shows not<br>only the tremendously long lead time for new ideas <br>to percolate from the sciences into the arts, but it<br>also clearly demonstrates the enormous staying power of<br>classic worldviews. Many writers on just intonation<br>evoke a view of Apollonian poise and balance, and a<br>yearning for perfect order.  Indeed, the title of one<br>of the best current compilation series of JI music is in<br>itself revealing: "Rational Music For An Irrational<br>World."  A vision of literally classical order in a disarrayed<br>universe.   And (also revealingly) JI composers see<br> have a fondness for classical Hellenic subject <br>matter: from Partch's exceptional series of settings<br>of Greek drama to Fonville's setting of poems by<br>Sappho, the nostalgic quest for order and balance<br>harks back to the Italian Renaissance, the early part of <br>the 19th century in England, and the early 20s<br>of this century in England and America.  In such a<br>worldview, Keats' Greek vase is the ideal: "Heard melodies<br>are sweet, but those unheard/are sweeter; therefore,<br>ye soft pipes, play on;/ not to the sensual ear, but,<br>more endeared,/Pipe to the spirit ditties of no tone..."<br>[Keats, John, "Ode On A Grecian Urn," lines 11-14]<br>(Sounds almost as though Keats yearned for a yet-<br>unheard xenharmonic music far outside the 19th<br>century 12-tone equal tempered scheme of things...)<br> Modernism rarely evokes such longings.  Instead, the<br>emphasis in modernist music is often on statistical<br>and probabilistic effects. From the regular distribution<br>of pitch classes in the 2nd School of Vienna to the<br>thermodynamically- and quantum-theory inspired<br>stochastic sound-clouds of Xenakis, much modernist<br>music might almost be called  "quantum probability-<br>clouds made audible."  Subsequent refinement of these<br>procedures in algorithmic compositions programs <br>changed the emphasis, but not the essential inspiration--<br>nor the worldview implied.<br>And thus the best of modernist compositions conjure<br>up for me a statistically determined universe of <br>strange and terrifying beauty...and notably one in which<br>tuning is a secondary consideration.  Modernist <br>music appears to have emphasized the processes by<br>which pitches were *ordered,* rather than by which they<br>were *derived.*<br>Perhaps the existence of this forum signals a shift<br>toward the third or nonlinear worldview.  As the ideas<br>of chaos theory and complexity theory seep<br>into our culture, the notion of emergent order generated<br>at the edge of nonlinear musical processes becomes<br>more "natural" (the single word most fiercely<br>argued over on this forum, and perhaps the one word<br>used by the largest number of subscribers with the<br>largest numbers of different meanings) and more<br>acceptable.<br>Pushing forward, it's hard to see where this worldview<br>might take music...  The terrain ahead is indeed<br>alien.  One imagines algorithmic compositions generated<br>by nonlinear processes in which even the tuning is<br>produced at run-time, and is a different non-just non-<br>equal-tempered set of pitches in each performance.<br>On the level of the microstructure of musical tones,<br>Sethares', Pierce's, Carlos', Dashow's and (yes) my<br>notion of matching partials to tuning raises many<br>possibilities from hierarchical order in n-j n-e-t<br>compositions: notes whose overtone structure changes<br>kaleidoscopically as the pitches run through various<br>timbral strange attractors.  Jean-Claude Risset, Paul Lansky,<br>John Chowning, James Dashow, William Schottstaedt, <br>Richard Karpen, Mark Trayle, Cindy McTee, Richard Boulanger,<br>Hugh Davies, Jonathan Harvey, Warren Burt, William Sethares <br>and others have already produced compositions which<br>give a glimpse of this brave new musical world: and they<br>are indeed breathtakingly beautiful. <br>Still, very little work has been done in this area.  To quote<br>Ivor Darreg, "It will require the work of many composers <br>for many years to map out the vastness of xenharmonic <br>territory."<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Wed, 1 Nov 1995 20:55 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id KAA19194; Wed, 1 Nov 1995 10:55:39 -0800<br>Date: Wed, 1 Nov 1995 10:55:39 -0800<br>Message-Id: <199511011848.AA22720@net4you.co.at><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2234 href="#2234">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>11/2/1995 8:38:00 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: The Gelfond-Schneider Theorem and<br> non-just non-equal-tempered scales<br>---<br>It occurs to me that n-j n-e-t scales undoubtedly<br>seem more mysterious than either just or equal<br>tempered tunings because the mathematical<br>basis of n-j n-e-t scales is not as obvious.<br>This post attempts to clarify that mathematical<br>basis.<br>First, a word about traditional tunings:<br>If we describe the scale steps of any given<br>tuning as a number between 0 and 1, the<br>mathematical basis of just tunings is simple<br>and straightforward:  k[n] = A/B  where both<br>A and B are integers.  The only ambiguity here<br>is the question of whether or not A and B are<br>"small."  This is clearly a matter of personal<br>taste.  John Chalmers and Your Humble E-Mail<br>Correspondent consider many of Erv Wilson's<br>CPS  tuning to be examples of just intonation, and<br>thus made up of the ratio of "small" integers:<br>however, many of those integers are not small<br>in the usual sense defined by Partch, Doty,<br>Johnston, et al.  For example, the [1,7, 19, 37]<br>hexany consists of ratios of numbers to the<br>generator 7*19*37 = 4921.  This number is<br>"small" compared to a googol, or to the <br>number of atoms in the Local Cluster of<br>galaxies: but it is large compared to, say,<br>31 or 43.  Thus, some tuning theorists <br>would consider this Wilson CPS tuning *not*<br>to be a just tuning, while others *would.*<br>It is a matter of taste.<br>For equal-tempered tunings, the scale-<br>step is described with equal simplicity:<br>k[n] = 2^[n/M]<br>In this case every scale-step of every<br>equal-tempered tuning is described by<br>an irrational number.<br>So far, so good.   Just tunings have scale<br>steps described by ratios of integers: <br>equal-tempered tunings have scale steps<br>described by irrational numbers. <br>An irrational number is a real solution of an<br>algebraic equation.  An integer is the<br>real solution of an ordinal arithmetic <br>equation.<br>Thus tunings can be defined by the class<br>of equations to which the ratios which define<br>the scale-steps of the tuning form solutions.<br>For example: <br>Algebraic equations involve a finite<br>number of integers raised to integer<br>powers:  say, X = A + By^2 + Cy^5.<br>Ordinal arithmetic equations involve integers:<br>X = A/C + D or X = A*B, etc.<br>(You might have noticed that my definition<br>of integers is circular.  This is because the<br>question of what an integer is happens to<br>be a very deep one.  It is indeed very,<br>*very* difficult to define an integer in<br>abstract terms without using an equation<br>which involves integers.  If memory serves,<br>the Bourbaki collective devoted an entire<br>volume to the definition of an integer.)<br>This gives us a handle on what is meant<br>by a "non-just non-equal-tempered scale."<br>Clearly, if the scale-steps of a just scale<br>are *integers* and if the scale-steps of<br>an equal-tempered scale are *irrationals,*<br>then the scale-steps of a non-just non-<br>equal-tempered scale must be given by<br>transcendental numbers.<br>What is a transcendental number?<br>How is such a number defined?<br>Is there a general mathematical procedure<br>for obtaining transcendental numbers?<br>This, as it happens, is also a deep question.<br>In fact it is often *VERY* difficult to *prove*<br>mathematically that a given number is<br>transcendental.<br>For instance, e^pi is known to be <br>transcendental--but pi^e has never<br>been proven transcendental (though most<br>mathematicians believe it to be).<br>In fact the number pi itself was not<br>proven transcendental until 1882. <br>(F. Lindemann, in the paper "Ueber die<br>Zahl Pi," took that honor.)<br>One of the perplexities which attend<br>transcendental numbers is the fact<br>that while there is a general criterion<br>for determining whether a number is an<br>integer (Does it satisfy an ordinal arithmetic<br>equation?) and for determining whether<br>a number is irrational (Does it *NOT*<br>satisfy an ordinary arithmetic equation and is it <br>a real root ofan algebraic equation?) there <br>appears to be NO general criterion for <br>determining whether a number is <br>transcendental.<br>Consequently, many different (non-obvious,<br>counterintuitive) equations generate<br>transcendental numbers.<br>For example, the number i^i is <br>transcendental--in fact it is equal to<br>e^[-pi/2] = 0.2078795.   ("i" here refers <br>to the square root of -1.)<br>This sounds absolutely insane, but it<br>happens to be true...and provable!<br>Like quantum mechanics, many of<br>the results of mathematics follow<br>the rule: "If it makes intuitive sense<br>to you, then you don't really understand it."<br>The real part of log(i) is also<br>transcendental: log(i) = i*pi/2.<br>Thus, while there's no general<br>formula or method for generating<br>transcenedental numbers, quite a<br>few transcendental numbers have<br>been discovered over the last few<br>milennia...mainly by chance.<br>Here are few:<br>Liouville numbers have been<br>proven transcendental. They were<br>discovered in 1851 (much later<br>than pi or e) and are given by the<br>formula: Sum from k = 1 to<br>infinity over a[k]*r^[-k!] where<br>"!" means "factorial" and a[k]<br>is an integer twixt 0 and r.   <br>There are infinitely many<br>Liouville numbers.  For instance,<br>if all a[k] = 1 and base r = 10,<br>we get 1/10 + 1/(10^[1*2]) +<br>1/(10^[1*2*3]) + ...  =<br>0.1100010000000000000000001000...<br>Depending on how the a[k] are<br>chosen, many different Liouville<br>numbers arise. One might pick the<br>a[k] as the fractional part of the <br>decimal expansion of e, or pi, <br>or of an irrational number such<br>as 2^[1/3], etc. <br>Euler's constant gamma is transcendental.<br>It's given by the limit for n = - infinity<br>of the series 1 + 1/2 + 1/3 + 1/4 + ...+ <br>1/n - ln(n)<br>Gamma = 0.577215...<br>Catlan's constant is another lesser-known<br>number. It has not yet been proven <br>transcendental, but mathematicians<br>widely believe it to be. It's given by<br>the formula G = sum of (-1)^k/(2k+ 1)^2<br>= 1 - 1/9 + 1/25 - 1/49...<br>Chapernowne's number is also generally<br>believed transcendental.  It is constructed<br>by concatenating the digits of the<br>positive integers: C = <br>0.1234567891011121314151617181920...<br>As mentioned in my series of posts on<br>generating non-just non-equal-tempered<br>scales last year, the zeta function also yields<br>transcendental numbers.  However, my<br>post did not specify that the zeta function<br>must be evaluated at rational points: zeta(K)<br>can be either real or imaginary, since K can<br>be either real or imaginary.  For K not equal<br>to a real integer, zeta(K) is in general not<br>transcendental.  However this still leaves us<br>with zeta(2), zeta(3), zeta(5), etc., all<br>trascendental.<br>Of particular interest in the construction<br>of non-just non-equal-tempered scales is<br>the Gelfond-Schneider theorem.  According<br>to this theorem, any number of the form a^b is <br>trascendental where a and b are algebraic (a<br><> 0, a <> 1) and b is not a rational number.<br>This formula spews out an infinite number<br>of transcendental numbers, since (for example)<br>Hilbert's number, 2^[sqrt(2)] is clearly<br>transcendental, ditto 2^[sqrt(5)], 3^[fifth root of 7],<br>etc.<br>Feigenbaum numbers are also transcendental.<br>These numbers arise from chaos theory and<br>are related to properties of dynamical systems<br>which exhibit period-doubling and other chaotic<br>behaviour.  The Feigenbaum number is<br>4.66920160910299067185320382046620161725...<br>Alas, equations involving transcendental numbers<br>do not necessarily produce solutions which are<br>transcendental.  e^[i*pi] = 1, an integer, while (e^[i*pi]) + <br>2*phi = sqrt(5), an irrational number.<br>Clearly phi, the Golden Ratio, is not transcendental<br>since it is the solution of an algebraic equation:<br>phi = [sqrt(5) - 1]/2 = (5^[1/2] - 1)/2<br>One of my own amateur mathematical discoveries<br>(I've not seen it published elsewhere, at any rate)<br>is an infinite number series given by the iterated absolute <br>log of K, where K is an integer.  I believe (but cannot<br>prove) that the scale-steps given by the terms of<br>this series form a non-just non-equal-tempered<br>scale.<br>This is a peculiar and interesting series of numbers<br>since the terms oscillate between 0 and 1.  The first<br>term is transcendental, but I have not been able to<br>prove that the succeeding terms are (or are not)<br>transcendental.<br>For instance, the first 10 terms of the iterated <br>abs log of 2 are:<br>i[1] = abs(log(2)) = 0.30103...<br>i[2] = abs(log(i[1])) = 0.5213902...<br>i[3] = abs(log(i[2])) = 0.2828372...<br>i[4] = abs(log(i[3])) = 0.5484636...<br>i[5] = abs(log(i[4])) = 0.2608521...<br>i[6] = abs(log(i[5])) = 0.2338806...<br>i[7] = abs(log(i[6])) = 0.6310057...<br>i[8] = abs(log(i[7])) = 0.1999666...<br>i[9] = abs(log(i[8])) = 0.6990424...<br>i[10] = abs(log(i[9])) = 0.1554964...<br>and so on.<br>There does not appear to be an obvious<br>pattern to the terms.<br>If one were so inclined, one might call<br>this the McLaren series: this is surely<br>the first post on this tuning forum to<br>feature an original mathematical<br>discovery, albeit a trivial one.<br>As can be seen, all of the above methods<br>for generating transcendental numbers<br>can produce an infinite variety of 'em.<br>Depending on the pattern of generators<br>(the numbers you plug into the various<br>equations to produce transcendental<br>numbers), you get an endless variety of<br>non-just non-equal-tempered scales.<br>The choice of whether to terminate the<br>series with a 2/1 or not is a matter<br>of taste.  (One might call it "terminating<br>the series with extreme prejudice.")<br>In that case, one obtains a non-just<br>non-equal-tempered scale which repeats<br>at the octave.  Choosing another termination<br>integer (or irrational) would produce a<br>non-just non-equal-tempered scale without<br>octaves.<br>As can readily be seen, these are the obverse<br>of the equal tempered class of octave and<br>non-octave scales.  My limited experiments<br>with non-just non-equal-tempered octave<br>and n-j n-e-t non-octave scales appear to<br>show that there is a marked  difference in "sound"<br>between the two classes of tunings.  As Gary<br>Morrison so aptly put it, "non-octave scales<br>sound like rich thick chocolate milk shakes."<br>They are very exotic and harmonically rich,<br>and seem to have a sonic colouration which<br>lends an eldritch quality to the compositions<br>one produces in such scales.  <br>For n-j n-e-t non-octave scales, the same<br>appears to be true, only more so.  They are<br>among the most exotic and sonically luxuriant<br>of all tunings in my experience, and an<br>extraordinary realm for new music exploration.<br>--mclaren<br> <br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Thu, 2 Nov 1995 18:40 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id IAA29513; Thu, 2 Nov 1995 08:40:23 -0800<br>Date: Thu, 2 Nov 1995 08:40:23 -0800<br>Message-Id:  <9511020838.aa10245@cyber.cyber.net><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2243 href="#2243">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>11/3/1995 9:00:50 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>>From : mclaren<br>Subject: Larry Polansky & adaptive tuning<br>---<br>Long ago in a galaxy far away, Larry Polansky<br>wrote an article entitled "Paratactical tuning."<br>In it he posited a  system of dynamic tuning which<br>adaptively changes the size of interval classes<br>depending on musical context.<br>While in one sense this is a sophisticated<br>software method for facilitating modulation<br>in JI (similar to such arrangements as<br>Harold Waage's logic-gate just intonation system<br>which detected fingering patterns and retuned<br>intervals so as to produce maximally beatless<br>chords regardless of key)...in another sense<br>Larry was getting at something much deeper.<br>Paratactical tuning is far more than mere dynamic<br>retuning to produce the "best" chords according<br>to the location of the current 1/1.  Because Larry P.<br>leaves it pretty much open-ended as to what<br>the criteria are. They could be "which 1/1 are we<br>on?" but they could easily be something else.  Once<br>it's all in software, the rule-set that determines<br>how JI intervals shift can respond to a lot more than<br>local key center...for instance, the software could<br>respond to the player's dynamics, or the shape of<br>the melody line, or the nature of the harmonies<br>being played.  More: Larry suggests that the<br>criteria for the rule-set geoverning the adaptive<br>tuning might be open-ended as well--possibly even<br>dynamic.  <br>One could imagine, for instance, an adaptive <br>tuning which morphs JI intervals from "plaintive"<br>to "luminous" or from "tense" to "resolute." (As<br>William Schottstaedt has so dextrously done<br>in an intuitive fashion in the fourth movement<br>of his composition "Water Music," albeit in<br>that case moving from 13-TET to Pythagorean.<br>If you haven't heard this composition, you're<br>missing a truly spectacular piece of music.)<br>As a first advance, this leads directly to<br>a systematization of Lou Harrison's "free style"<br>of composition, in which successive intervals<br>are tuned not with reference to a fixed 1/1, but<br>with respect to the previous note.  Clearly such a<br>practice produces a much more complex system of <br>just tonality--but, as Boomsliter and Creel pointed <br>out, this might also more closely mirror the way<br>the average person hears music.  Our hearing appears<br>to be relative rather than centered on an absolute<br>1/1 (except for those rare listeners with absolute<br>pitch), if the psychoacoustic evidence is to be<br>credited.<br>However, Larry's idea of adaptive tuning goes<br>much further than simply the B&C idea of the<br>"the long pattern hypothesis."   While useful,<br>B&C's concept of melodic sections moving between<br>separate and distinct 1/1s is in itself limiting<br>because it posits simplistic patterns of linear<br>movement twixt striaghtforward JI melodic<br>contours, overtone structures, etc.<br>When combined with the concept of morphological<br>metrics, Larry Polansky's paratactical (or adaptive) <br>tuning really begins to open a *lot* of new doors. <br>For instance, changing one morphological metric<br>into another introduces (on the level of the melodic<br>phrase) a complex set of requirements between<br>vertical and horizontal interval-relations.  As<br>Larry so insightfully realized, this is an ideal<br>case for adpative tuning: and with sufficiently<br>complex software, paratactical tuning does <br>indeed seem the ideal solution to this ever-present<br>tension twixt vertical and horizontal relationships<br>in the context of changing from one vertical or<br>horizontal morph to another.<br>But when you throw in the concept of changing<br>from one *timbral* morphological metric to another<br>at the same time....!  Then, adaptive tuning--in<br>this case extended downward into the micro-level<br>of the individual overtone--is the *only* practical<br>solution to the complexities introduced.  Because<br>of the extraordinary explosion of interactions<br>between timbre, vertical and sequential structure<br>in tihs case, a set of adaptively tuned overtones<br>offers by far the simplest solution. (Jean-Claude<br>Risset and John Chowning and Bill Sethares and<br>James Dashow have produced some compositions<br>which use elements of this technique: the pieces<br>are astonishingly beautiful, yet only a preliminary<br>step toward the total integration of timbre with<br>harmony.  Because of the incredibly cumbersome nature <br>of "doing it all by hand" in Csound, further advances<br>along this line seem likely to be made only with<br>the aid of some sort of automated morphological<br>metric software.) <br>However, there's even more to Larry's idea than this.<br>At the highest level, adaptive tuning can be <br>thought of a way to generate a single "composite"<br>instrument from a number of subinstruments. If<br>you think of each dynamically-retuned section <br>of the score as a specific subinstrument, the real<br>depth of Larry's idea becomes clear.  In order to<br>wander over the entire solution space  you'd need<br>huge numbers of actual physical instruments--not<br>a reasonable solution.  Thus Larry substitutes *virtual*<br>instruments.   And adaptive tuning shows its true<br>power by effect switching betwen those virtual<br>instruments instantaneously: the net result is<br>infinitely more efficient & flexible than either the <br>Partch solution of limiting the composition to a <br>single key, or  the Harrison solution of requiring the<br>performer to be painstakingly exact in moving from one<br>just ratio to another as well as keep in hi/r head<br>where the melody has been and where it's going<br>to (in terms of moving 1/1s).<br>Larry has written a composition that puts some of<br>these ideas into practice.  Due to be premiered<br>in Japan, it looks to this old score-reader like  <br>another remarkably beautiful JI composition, yet<br>(as mentioned) it's more than that...  Larry's <br>upcoming piece promises to significantly<br>advance the state of the microtonal art.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Fri, 3 Nov 1995 19:14 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id JAA00103; Fri, 3 Nov 1995 09:14:02 -0800<br>Date: Fri, 3 Nov 1995 09:14:02 -0800<br>Message-Id: <Pine.SUN.3.91.951103090144.11512C-100000@garcia.efn.org><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2254 href="#2254">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>11/4/1995 11:53:34 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Bach wars<br>---<br>Many forum subscribers have added their 2 cents<br>to the long-running "Bach wars."  For my part,<br>permit me to say that the posts by all concerned<br>were absolutely superb.  Full of detailed quotes,<br>specific references, cogent reasoning.  Paul Hahn,<br>Gary Morrison, Manuel Op de Coul, Aleksander Frosztega,<br>Johnny Reinhard and Helmut Wabnig did a marvellous <br>job of distilling the references and citing competing<br>sources.<br>As to who is right or wrong, that is not nearly<br>as interesting as the citations themselves.  This<br>controversy, raked over in admirable detail, gives<br>*all* of us the references and direct quotes required<br>to decide for ourselves.  That should be the goal of <br>scholarship...and in the "Bach wars" series of posts,<br>all subscribers concerned have adhered to high <br>standards of scholarship and logical reasoning.<br>Unlike so many posts in which sarcasm, appeals<br>to authority, or sheer naysaying substituted for<br>a reasoned debate, the "Bach wars" have proven <br>enormously enlightening.   Reading this series of<br>posts has taught me a good deal about an important<br>question in the history of tuning.  Congratulations<br>to everyone who posted on the subject.  You've all<br>shown us how interesting and educational this forum<br>can be at its best.<br>---<br>As to the specific question of the "Bach wars" posts--<br>"What tuning did Bach use?"--it does not behoove me<br>to speak directly, given the abysmal nature of my<br>ignorance about the period and the people involved.<br>However, some general observations seem in order:<br>[1] "Statisticum radix scientiae malorum."  It is my<br>firm belief that misuse of stastistics is the root of all<br>bad science. (As opposed to pseudo-science, like the<br>N-rays which destroyed Rene Blondlot's reputation <br>in 1906 and the abominable E-rays which constitute<br>such a blot on the credibility of German science<br>today.  E-rays are nothing but dowsing performed on<br>purported electromagnetic radiations, which radiations<br>can neither be detected by any known instruments nor<br>cut off by any known form of shielding.  Yet they <br>"cause cancer."  What's the German word for "scam"?)<br>One of the worst uses of statistics is what I call <br>"stripmining the noise floor."  When you've got too<br>little data to form a reliable representation of a<br>statistical universe, or when you've got dribs and<br>drabs of data collected at time A, time B, time C,<br>under wildly different conditions and with dubious<br>controls...you're basically pushing linear parametric<br>statistical methods beyond their useful limits. You're<br>trying to statistically analyze noise...trying to<br>make soup out of dishwater, mathematically speaking.<br>The result?<br>Hard numbers that look convincing but turn out to be<br>"junk science."<br>My best guess is that the "What tuning did Bach use?"<br>controversy is undecidable because all participants<br>concerned are stripmining the noise floor.<br>---<br>Let me give some concrete examples:<br>Statistical analysis of Bach's harpsichord compositions<br>looks like a reasonable strategy at first glance. However,<br>Bach's collected harpsichord compositions do not form<br>a reliably complete representation of an underlying<br>statistical universe for the following reasons:<br>[1] Bach wrote his harpsichord compositions over a number<br>of years.  Some were penned in Cothen, some earlier, some<br>later.  If Bach's style of composition changed, this throws<br>into doubt one of the underlying assumptions of a statistical<br>analysis: namely, that all samples derive from the same<br>statistical universe.  To use an acoustics analogy, this is<br>like taking half your measurements of reverberation time<br>in a closet and half your measurements in Carnegie Hall.<br>You've got a mixed set of data and you're lumping all the<br>data points together willy-nilly.  A guaranteed shortcut <br>to "junk science."<br>[2] Bach may have written some compositions for a harpsichord,<br>others for clavichord.  Does the statistical analysis take<br>this possibility into account?  Do scholars know for *certain* <br>which compositions were written for which instrument?   Did<br>Bach (or his patron, the prince) use different tunings on<br>different keyboard instruments?  Are we *sure*?  Are<br>scholars *sure* that many of Bach's compositions weren't<br>written to be played on *both* a harpsichord *and* a<br>clavichord (whichever might have presented itself and<br>been available) and might thus have represented Bach's attempt<br>to compose music which sounded good *regardless* of the<br>particular tuning used?<br>For example, the clavichord might have used one well temperament,<br>the harpsichord another--or the clavichord might have used, say,<br>Kirnberger III, while the harpischord might have used equal<br>temperament because harpsichord continuo often had to<br>accompany an instrumental ensemble at Cothen. (Remember,<br>Bach's harpsichord concerti were written at Cothen.)<br>Did the statistical analysis take these issues into account?<br>If not, why not?<br>[3] Many assumptions are inevitably implicit in any linear<br>parametric statistical analysis.  In order to calculate r values,<br>you have to fix parameters and make guesstimates about their<br>influence and constancy.   If you correlate verbal IQ test scores<br>with length of stay in the US for new immigrants and assume<br>strong causality, you come to the bizarre conclusion that <br>emigrating to the United States raises people's <br>intelligence.  <br>You get this garbage answer out of linear parametric statistics<br>because you put garbage *into* the equations: namely, garbage<br>assumptions.  Without basis, you assumed two parameters to <br>be deeply causally connected for the wrong reason, and ran too<br>far ahead of yourself with the results.<br>This raises questions about the Bach statistical study.  Questions<br>of *both* causation *and* correlation. What are the *specific* r values<br>by interval category for Bach's compositions?  Do they imply<br>causation?  If so, what *kind* of causation? For a classic<br>example of garbage science, see the r values buried in the appendix<br>of Charles Murray's "The Bell Curve."  You'll find r values between<br>0.4 and 0.6.  As a rule, an r below about 0.75-0.8 is a sure-fire<br>indicator of smoke & mirrors. The correlation is so weak that the<br>researcher had better answer some *very* tough questions or<br>risk being called slipshod, or worse, a fraud.<br>So I for one want to know those r values on the Bach statistics.  <br>Did the Bach statistical analysis use linear regression?  <br>Quadratic?  Cubic?  Least-squares?<br>What's the mean, median and the standard deviations for the r values<br>of each interval broken down by year of composition?  What do these<br>profiles tell us about causation?  Was multiple regression used on<br>*different variables*?  Were the results compared?  What did *that*<br>say about causation as opposed to correlation or <br>even mere coincidence (AKA low r values)?  Did the<br>statistical analysis even bother to consider such issues?<br>If not, I want to know why.  Bach may in some compositions have<br>been interested in exploring unusual dissonances: thus at certain<br>points in his career his compositions might have *deliberately*<br>used "bad" intervals in a given well temperament (if indeed he used<br>a well temperament).  But at other times in his career, he might <br>have been more interested in exploring unusually perfect consonances<br>in a given well temperament.  This would change the intervals<br>Bach tended to use over time: did the statistical analysis take<br>this into account?<br>We know for a fact that Bach's 7th chords were considered wildly<br>dissonant and highly outre in his day.  Therefore it seems  <br>reasonable to posit that he might have systematically explored<br>sets of intervals unusual for composers of the period.  Did the<br>statistical analysis take this into account?  Or did the statistical<br>analysis arbitrarily assume that Bach would have used the most<br>consonant (read: beatless) intervals in a given well temperament<br>most often, and the least consonant intervals least often?<br>More complexly, Bach (being the genius he was) might have switched<br>his interests constantly, exploring one set of unusual dissonances in<br>one composition, another set of exotic consonances (available only<br>in a given well temperament) in another composition.  Conflating<br>all of the interval data into a single linear regression would destroy<br>all of this information and produce *wildly* misleading answers.<br>In this case, multivariate analysis would be called for.  Was it<br>applied?  Was multidimensional statistical analysis used?  Did<br>the researcher test for correlation between (say) timbre *and*<br>interval and interval, or only twixt interval and interval?<br>[4] Bach might have preferred certain intervals (even if he used<br>equal temperament) for numerological or ecclesiastical reasons.<br>We know with surety that he considered C minor and D minor "special"<br>keys.  Only a few of his compositions use these keys: they are<br>statistically underrepresented.  Bach clearly invested these keys<br>with some special significance, because he reserved these keys<br>for his most ambitious works.  The Chaconne (of which Bach wrote<br>exactly ONE), for instance, uses d minor: so does the famous prelude<br>and fugue.  The passacaglia & fugue (again Bach wrote only ONE<br>passacaglia) uses c minor...and so on.<br>Does the statistical analysis take this into account?  Depending<br>on the well temperament (if such a tuning was indeed used),<br>d minor and c minor might well have exhibited special intervallic<br>properties.  We can be reasonably certain from statistical analysis,<br>for example, that a number of Buxtehude's later compositions use<br>keys which when transposed down on the meantone Luneborg organ offer<br>unusually consonant sets of intervals.<br>Did the person who performed the statistical analysis take this<br>possibility into account? Did s/he run a separate analysis on<br>this assumption?  Were the results compared with the straightforward<br>statistical analysis?  <br>If not, why not?<br>Bach could have had many reasons for using certain intervals.<br>We know, for example, that Bach was numerologically inclined.<br>In one of his chorales the melody enters 10 times, representing<br>the 10 commandments: other examples abound.  Does the statistical<br>analysis of Bach's use of intervals take into account the possibility<br>that he might well have used a given interval-set for reasons *other*<br>than considerations of acoustic consonance and dissonance?<br>This same objection applies to fugue subjects and counter-subjects.<br>One fugue of the 48 deliberately uses all 12 tones of the chromatic<br>scale in succession, for instance: does the statistical analysis<br>take into account the effects of such part-writing?<br>[5] Some of Bach's klavier compositions were originally written<br>for organ, some are alterations or emendations of works written<br>for instrumental ensemble, and some are greatly modified versions<br>of other composer's works--specifically, the "transcriptions" of<br>pieces by Vivaldi, which are very much more than mere<br>transcriptions.   Does the statistical analysis take this into account?<br>If not, why not?<br>---<br>Statistical arguments for or against this or that historical trend<br>fill me with foreboding. They're a fertile breeding ground for "junk<br>science" (without the researcher *intending* to do junk science, of<br>course--or even realizing it).  So many assumptions and <br>presuppositions are implicit in any linear parametric statistical <br>analysis of historical data as almost to force me to proclaim:<br> "a pox on all historical statistical studies!"<br>Classic examples of "junk science" from statistics abound<br> in economics. For instance, those bogus United States GNP <br>charts going back to 1876--charts which completely ignore the fact<br>that the U.S. switched from an agrarian economy in the early 19th<br>century to a steam-driven Bessemer-furnace economy in the late 19th <br>century to an oil-and-steel-driven machine-tool economy in<br>the early 20th century to an information-driven service <br>economy in the late 20th century.  What's the net discounted dollar<br>value of a bushel of tobacco in 1876 compared to the net discounted<br>dollar value of a megabyte of computer code in 1996?  The<br>question is unanswerable.  You're not just comparing apples<br>and oranges, you're comparing apples and *mu-mesons.*  The<br>question doesn't even make *sense.*<br>Again, sociological historical studies purporting to show <br>improvements in "quality of life" as the century progressed<br>are equally flawed.  While in 1880 there were no antibiotics,<br>it was also standard for a middle-class family to have 2 or 3<br>live-in servants.  If you're a healthy person, would you be<br>willing to trade lack of antibiotics for being waited on hand<br>and foot and having your meals cooked for you and your washing<br>done by a crew of servants?  Would this be an overall improvement<br>or decline in your standard of living, as opposed to today?<br>The answer isn't obvious to me.  Again, apples compared<br>with oranges.  Again, garbage science produced by a misuse of<br>statistics.<br>All told, the value of historical statistical studies of Bach's<br>interval-usage seems at best right on the borderline of<br>junk science, and at worst little more use than <br>examining bird entrails.<br>---<br>This leaves us with the written historical record.<br>Does any specific numerical record exist of the frequencies<br>to which Bach tuned each of the keys on his harpsichord?<br>Clearly not.<br>Thus we are left with inadequate data.  *Grossly* inadequate<br>data.  Regardless of what tuning you think Bach used, the<br>fact remains that (unless we want to swim in the VERY<br>murky waters of statistical historical numerology) we must<br>fall back on vaguely-worded hearsay testimony about Bach's<br>tuning.<br>My standard for this kind of historical hearsay is: would you<br>convict someone of murder on the basis of this stuff?<br>In this case, no way.  You don't need O.J.'s Dream Team<br>on this one.  The testimony is so weak and so open to<br>interpretation that even a grand jury would no-bill the <br>defendant.  It wouldn't even get to trial.<br>Thus my sense here (reading the "Bach wars" posts) is again <br>that the question is undecidable on the basis of the hearsay<br>testimony from Bach's relatives and acquaintances. <br>Many of the quotes supposedly come from "eyewitness"<br>accounts--but can we be *sure* it was *actually* <br>an eyewitness account, or was Forkel remembering<br>long after the event?  Or did Forkel miss the incident<br>entirely, and perhaps have to rely on C.P.E. Bach's <br>recollection?  Or was it one of those "a friend of my<br>cousin's brother told me he heard someone say..." things, <br>gussied up in first-person narrative form?<br>What's that?<br>Did someone mention "false memory syndrom"...?  Meaning:<br>people tend *not* to remember the event itself, but what<br>someone else *told* them about it...?<br>We know *some* generalities with reasonable certainty:<br>Bach was considered "old-fashioned" during his lifetime,<br>and his style was out of date long before he reached middle<br>age.   The  homophonic, racier, faster-paced "Italian<br>style" was much more in vogue by the 1720s than Bach's<br>almost quattrocentric polyphony.<br>Did this influence what friends and acquaintances <br>remembered about Bach's tuning?  Did they unconsciously<br>exaggerate the "meantone" quality of Bach's music because<br>of the old-fashioned nature of his polyphony?  Or did they<br>instead unconsciously redact their memories of his tuning <br>procedures so as to "modernize" Bach and unwittingly<br>make his music more fashionable to fit in with the new <br>music everyone was used to?<br>I don't know the answer to these questions.  Before making<br>up my mind about "what tuning did Bach use?"  I'd sure like<br>to.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Sun, 5 Nov 1995 04:39 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id SAA29690; Sat, 4 Nov 1995 18:39:15 -0800<br>Date: Sat, 4 Nov 1995 18:39:15 -0800<br>Message-Id: <951105023715_71670.2576_HHB54-5@CompuServe.COM><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2260 href="#2260">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>11/5/1995 2:30:11 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: academia, jibes, hurt feelings, the search <br>  for truth<br>---<br>With his usual insight and common sense, Bill Alves<br>offered some tart rejoinders to my posts on <br>psychoacoustics.<br>As to the question of who is or is not ignorant, it is <br>sufficient to observe: "Hic ego barbarus sum quia non<br>intelligor illis."  But Alves' point about my  "bigoted <br>statements about academics" is right on the money.<br>Your Humble E-Mail Correspondents pleads guilty...<br>with an explanation.<br>To paraphrase Richard Preston, "Music is a lesser activity<br>than religion in the sense that we've agreed not to kill each<br>other but to discuss things."  To the extent that any of<br>my statements about academia or people with PhDs has<br>hindered the discussion on this forum, or poisoned it<br>with unnecessary bad feeling, I certainly apologize.<br>For making bigoted statements about no-talent academics<br>who try to maintain a brain-dead status quo, however,<br>I do NOT apologize.  I *AM* bigoted against such people. <br>I intend to *continue* my bigotry against such people,<br>and wherever possible to deeper and broaden the scope<br>of my bigotry against these no-talents.  I make no apologies <br>whatsoever for this kind of bigotry.  On the contrary: I<br>*celebrate* this kind of bigotry.  Indeed, in an apotheosis<br> of political incorrectness, I *glory* in my bigotry<br>against people with big reps and no competence,  big<br>degrees and no talent, big grants and no imagination.<br>I exult in my capacity to distinguish twixt crap and<br>the beaux arts.  If this is bigotry, *great.*  Sounds like<br>a PLAN!  <br>Lemme at 'em!  <br>Come get some, !@#%#+#@%$ers!<br>It's hard to say whether the no-talent duffers are in the<br>majority or the minority in music departments.  Many folks<br>with PhDs in music use a kind of protective coloration: they<br>keep a low profile, don't make waves, and quietly go about<br>their radical xenharmonic explorations while giving an<br>outward appearance of conformity to the Perversions of<br>New Music ideal. (Namely, that the very model of the modern<br>composer is one who talks and talks and talks and talks, and<br>hardly every produces any music...and then only dribs and drabs<br>of warmed-over Webern and kludged-up Cage.  Above all, ya<br>gotta have a theory!  Theeee-ory!  Theeee-ory!  Git yer red-hot <br>theee-ory! Ice cold muuu-sic, red hot theeee-ory!<br>Can't enjoy the music without a theee-ory!)<br>Many of the academics who subscribe to this forum are<br>extraordinarily talented polymaths.  For example, Larry<br>Polansky fills me with awe: this guy not only writes <br>original & groundbreaking articles, he's not only a terrific<br>teacher & thesis adviser (by all accounts), he's not only<br>a fine amateur ethnomusicologist, but he's also a world-class<br>computer programmer *AND* a startlingly talented composer.<br>Is there *anything* this guy can't do?  Is he in next year's<br>olympics?  Has he climbed Mount Kilamanjaro yet? Will<br>he be the first xenharmonist in space?<br>William Schottstaedt is another example.  A top-notch<br>programmer, able to design entire object-oriented music<br>languages in a single bound, debug cranky antique computer<br>systems faster than a speeding bullet, but then he ducks<br>into a phone booth and becomes...a world-class composer.<br>Amazing.<br>David Cope is not only a fine composer, by all accounts a<br>splendid teacher, an excellent writer (the "New Directions<br>In Music" books are classics of their kind in each of their<br>various editions), but he's also a world-class AI music<br>programmer whose LISP syntactic models of composition<br>have broken genuinely new ground in the field.  <br>Astounding.<br>Johnny Reinhard is not only one of the world's great<br>scholars of microtonality, a bibliomane with the most<br>impressive library of microtonal scores on the planet,<br>an administrative wizard who single-handedly forced<br>the New York concert scene to bow to microtonality,<br>AND a living link between thousands of xenharmonic <br>composers, researchers and performers...but Johnny <br>is *also* the reincarnation of Jimi Hendrix as a <br>bassoon player.  Virtuoso par excellence.<br>And speaking of universally talented people...<br>William Alves himself is an extremely impressive guy.<br>Not only a first-rate JI composer, but a scholar of<br>tuning history, a crack computer programmer, a DSP<br>wizard, *and* a fine teacher (by all reports).  Another<br>polymath.<br>To continue in this vein would  embarrass *a great many*<br>PhDs who subscribe to this forum...  Suffice it to say that<br>this tuning forum represents an extraordinary confluence<br>of exceptionally talented academics.  It's fashionable to claim<br>that "the day of the Renaissance man (woman? person?) is<br>past."  Whoever believes this hasn't logged onto the tuning <br>forum.<br>Having said all that, permit me to add not my own words,<br>but those of Norbert Weiner:<br>"What sometimes enrages me and always disappoints and<br>grieves me is the preference of great schools of learning<br>for the derivative as opposed to the original, for the<br>conventional and thin which can be duplicated in many<br>copies rather than the new and powerful, and for arid<br>correctness and limitation of scope and method rather<br>than for universal newness and beauty, wherever it<br>may be seen." [Weiner, Norbert, "The Human Use of<br>Human Beings," 2nd edition., 1954, pg. 135]<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Mon, 6 Nov 1995 00:48 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id OAA10844; Sun, 5 Nov 1995 14:48:24 -0800<br>Date: Sun, 5 Nov 1995 14:48:24 -0800<br>Message-Id: <199511052247.RAA08615@freenet3.carleton.ca><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2267 href="#2267">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>11/6/1995 9:18:32 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject:  RATED NC-17: ALL COMPOSERS OVER AGE<br>  17 MUST BE ACCOMPANIED BY THE GHOST OF JOHN CAGE<br>---<br>"Modernism is now being seriously challenged for the first<br>time in almost a century or more.  Which, considering the <br>really awful degree of narcissism, nihilism, inanity and <br>self-indulgence that late modernism has allowed itself,<br>is probably the best thing that could happen to it. What<br>has been permanently lost is the sense of the absolute<br>that the modernist movement once gave to its loyal <br>followers.  And to that we can say: good riddance.<br>We are none of us now--either artists or critics or the <br>public--quite as susceptible as we once were to the <br>idea that at a given moment in time, history ordains <br>that one and only one style, one vision, one way of <br>making art or one way of thinking about it, must <br>triumph and all others be consigned to oblivion." <br>[Kramer, Hilton, The New York Times, 28 March 1982,<br> Section 2, pg. 32]<br>Most awful of all modernist excesses, naturally, <br>are those perpetrated by John Cage and Pierre <br>Boulez.<br>Of course everyone already knows this.  There's no <br>controversy about it.  The facts have long since been<br>admitted in those code phrases so beloved of the<br>New York critical establishment.<br>When TIME magazine (in its Cage obit, 1 November 1993, <br>pg. 87) oozes: "There was always the whiff of the<br>charlatan about John Cage," we all know what they<br>REALLY mean.  ("Cage was a con artist without a shred<br>of musical talent.")  They just don't want to come right<br>out and *admit* it because (after all) it would prove<br>embarrassing to explain why so many New York<br>critics kow-towed to Cage for so many years.<br>And when Roger Reynolds oohs and ahhs in an<br>interview-cum-suck-up with the Great Mountebank,"Your main<br>contribution has been to expand the idea of what it is<br>reasonable to do in music," we all know what Reynolds<br>is *really* saying:  "John Cage gave audiences the<br>musical equivalent of a golden shower for 40 years."<br>Of course, Reynolds doesn't want to come right out<br>and actually *say* that.  "Epater le bourgeoisie" doesn't<br>go over too well in the land of Oprah and Geraldo<br>unless you sugar-coat the pill.<br>And thus, while we all know and covertly admit that<br>John Cage was a stunt man whose musical fame  is<br>conducive to an understanding of how the Egyptians<br>could have worshipped insects...even so, none of us<br>really want to *admit that.*<br>This is peculiar, especially on a microtonal discussion<br>forum like this one.  After all, Cage's early prepared-<br>piano works flirted with the edges of the 12-tone equal<br>tempered scale.  It's hard to say that Cage's early <br>prepared piano pieces are in any particular tuning--<br>least of all 12--and certainly the "Imaginary Landscape"<br>for radios skirted the idea of departing from 12 via <br>electronic sounds.<br>Naturally, none of these early gimmicks provoked <br>enough critical attention: and so stunt man Cage was<br>obliged to find some really TALL buses over<br>which to jump his musical Evel Kneival act.  4<br>minutes 33 seconds...a burning piano...whatever.<br>The end result, naturally, was that pathetic orgy of<br>gimmickry, fetishism and sheer silliness that<br>characterized Cage's so-called "musical" output<br>post-1948.<br>And so, instead of doing something to advance music,<br>he vanished into the tarpit of "narcissism, nihilism,<br>inanity and self-indulgence" so aptly described by<br>Kramer.<br>Boulez is a different story.<br>While Cage displayed dazzling early sparks of musical<br>talent in his "Three Constructions" and his prepared<br>piano pieces only to throw away his abilities in favor<br>of a career scamming the gullible (the compositional<br>equivalent of L. Ron Hubbard's reign as Dianetics<br>guru), Boulez never betrayed any such rudiments of <br>compositional talent. <br>Boulez's music created a tremendous impression in<br>the 1950s--until people actually heard it.  Thereafter,<br>his popularity dropped off sharply.<br>To be sure, Boulez's "acknowledged masterworks" <br>(acknowledged by the other dry-as-dust theorists,<br>all of whose judgments and compostions are now<br>equally inconsequential and outdated) sound pretty, <br>albeit in an inoffensive Muzak-y sort of way...  <br>Boulex had a gift for orchestration.  <br>But after about 5 minutes of "Le Marteau sans Maitre," <br>or "Pli Selon Pli," you  realize it's just warmed-over <br>Webern with a  Chet Baker arrangement.<br>Why listen to a pale imitation?  <br>Why drink from the toilet, instead of the tap?<br>Why listen to Boulez when the original--<br>and much more interesting--Chet Baker is available<br>on CD?  To say nothing of Webern.<br>All told, it's a shame that Boulez had no compositional<br>talent, nor any original ideas.  Because in the early 1950s <br>Boulez (unlike Cage) actually thought seriously and at<br>length about microtonality:<br>"In considering his electronic means, the composer<br>has first to free himself from the conception of absolute<br>interval.  This can certainly be done. The tempered system<br>of twelve equal semi-tones seems to lose its necessity<br>at the very moment at which it passes from chromatic<br>organization to the Series.  There have already been<br>experiments with intervals of less than a semi-tone: of<br>uarter-, third- and even sixth-tones. (...) In fact, to<br>select a fundamental unit other than the semi-tone, <br>means to conceive a kind of temperament peculiar to<br>a single composition; all intervals are to be heard as <br>derviing from this fundamental tempering, thus affecting<br>the listener's conditions of perception. (...)  This tempering<br>may take place within the octave...or, it is equally possible<br>to construct in such a way that the interval with which <br>the demarche of the scale commences in other than the<br>octave.  (...)  In this way it would be possible to derive from<br>one structure based on wide intervals, i.e., having a wide<br>compass and a semi-tone as the unit, a corresponding<br>structure based upon micro-intervals, in which the compass <br>would be greatly reduced and where the unit would be either<br>a very small interval or irregular intervals defined by a<br>series. [Boulez, P., "At the End of Fruitful Lands..." Die Reihe, <br>Vol. 1, No. 2, 1955: English translation 1957]<br>Alas, such ideas would have resulted in an actual *expansion*<br>of available musical resources...  And that could not be<br>permitted.  Like rock music, the modernist avant garde was<br>always a fanatically reactionary cult cloaked in the image<br>of a revolutionary vanguard.  Any *real* emancipation of<br>the dissonance leading to a break with the sacred 12 tones<br>would have thrown into disarray the whole Tammany Hall-style<br>patronage system of orchestras, conductors, concert halls,<br>the Beaux Arts, circle-jerk New York music critics, and the<br>rest of the corrupt musical machine.  Without the Tammany Hall<br> of 12 equal tones per octave,  those who benefited from the <br>patronage system of the Sacred 12 Tones (like Boulez, who <br>now makes megabucks recycling tired 12-equal dribs and <br>drabs as a conductor) would find themselves<br>out of a job.<br>Boulez on a street corner?<br>Begging for dimes?  Holding up a sign WILL CONDUCT IN 12 <br>FOR FOOD???<br>Ye gods.<br>Such could not be permitted. Thus, after flirting with<br>tdea of actually breaking free of his pathological<br>dodecaphilia, Boulez threw in the towel and made the<br>obligatory obeisance to the Sacred 12 Tones.<br>The result was predictable:<br>"Just as Marxist-Leninist thought led to forms of<br>government meant to remedy the excesses supposedly<br>caused by the exhaustion of capitalism, so Schoenbergian-<br>Boulezian practice was touted as the alternative to<br>an exhausted system called `tonality.'  These attempts<br>to revolutionize, respectively, our economic and musical<br>worlds had several other things in common besides<br>the Germanic origin.  The application or enactment of<br>both ideologies required that their alternatives--and<br>those who would support them--be publicly denounced <br>and discredited, and a form of double-speak was<br>employed in support of these `revolutionary' ideas.<br>The apologists writing in Pravda held sway in support<br>of a failing system in the same way that Herbert<br>Eimert, Milton Babbitt, and Charles Wuorinen dominated<br>the pages of Die Reihe and Perspectives of New Music<br>for many years.  What is so interesting is the <br>suddenness with which these applications of <br>science--some have said pseudo-science--to economics<br>and music have been rejected and are now seen as<br>merely interesting experiments that failed<br>because they denied basic human realities:<br>economic and cultural diveristy in the political<br>realm and the necessity for perceptual forms of<br>organization and the power of intuitive processes <br>in the world of music." [Appleton, Jon, "Machine Songs<br>III: Music In the Service of Science--Science in the<br>Service of Music," Computer Music Journal, vol. 16,<br>No. 3, Fall 1992, pp. 17-21]<br>Which leaves us back where we started.  Now that<br>everyone has tacitly admitted that Cage and Boulez<br>were mere pimples on the rear end of 20th<br>century music, it's time to look around for a new<br>graven idol.  The next Great Composer (now that<br>we've realized that the most famous so-called "Great <br>Composers" of the 1950s didn't produce anything of<br>lasting interest)...akin to the Next Great Rock Star.<br>In both cases the focus is the same: keep the rubes<br>gawking, wow 'em with glitter and glitz, dazzle 'em<br>with music videos & half-naked girls (or, in the<br>case of prestigious New Music Journals, ritzy-<br>looking hypercomplex diagrams and equations)<br>and hit 'em with jargon....anything to keep the rubes<br>from realizing that it's all just a dog and pony<br>show. (Meanwhile, the REAL great composers like<br>Nancarrow, Risset, Chowning, et alii, go all but unnoticed<br>and all but remarked.)<br>And so the focus in new music has again turned <br>toward the cheery cherub with the cheekiest charts, <br>the wildest word-count, the most scrumptious-<br>looking (read: indecipherable) scores:<br>Namely, Ferneyhough.<br>This is an interesting aberration, and it spotlights<br>one of the deepest ruts into which post-<br>modernist music has fallen.  Namely, the<br>obsession with *intellectualizing* music.<br>Why do Western composers and critics and<br>music theorists so fanatically chart and<br>diagram and plot out and schematize modern<br>compositions?<br>Primarily (one suspects) in order to justify<br>the long-held euroschlock "doctrine that<br>Western European art music is superior<br>to all other music of the world," which<br>"remains a given, a truism. Otherwise<br>intelligent and sophisticated scholars<br>continue to the use the word `primitive'<br>when referring to the music of Africa,<br>American Indians, aboriginal Australians,<br>and Melanesians, among others."  [Becker,<br>Judith, "Is Western Art Music Superior?"<br>Musical Quarterly, Vol. 72, No. 2, 1986, pg.<br>341]<br>Yo!<br>Western composers and performers might<br>not be able to produce rhythms as complex<br>as those of the Balinese gamelan, or tunings<br>as subtle as those used in the sub-Saharan<br>ugubhu, or to move audiences as deeply<br>as do the "weeping" pitches of Kaluli <br>gisalo songs, but...hey!  <br>At least *we* euro-dudes can ALWAYS<br>come up with bigger, better, more<br>impressive *charts* of our compositions<br>than any other musical culture on earth!<br>(A typically priapic male obsession.  "Mine<br>is bigger than yours..."  My compositional<br>diagram, that is.  No wonder there are<br>so few famous women composers.  Can anyone<br>imagine a *woman* wasting 6 months of her<br>life straight-edging a bunch of chicken-scratches<br>that explain something everyone can already<br>*hear*???)<br>Thus the bizarre and otherwise incomprehensible<br>elevation of such  duffers as  Ferneyhough...whose <br>scores are, indeed, quite  impressive--as grafitti.<br>Indeed, nary a subway train in New York or a wall<br>in South Central L.A. is as crammed with in-group<br>jargon and chock-a-block with meaningless verbiage as<br>one of Ferneyhough's articles. (In fact one very<br>prominent member of this tuning forum laughed<br>out loud while perusing one of Ferneyhough's<br>ludicrous "Perversions of New Music" articles,<br>chuckling: "Looks like the guy follows the same<br>aesthetic when writing as when composing... Or<br>should one say, the same lack thereof?"  NO, folks,<br>it wasn't this little lad, but someone much better<br>known.) <br>This teaches an important lesson to microtonalists:<br>if ya wanna get famous, ya gotta make diagrams.<br>1/1 has made a start at this--ratio-space<br>charts look impressive, and to infants<br>or the mentally retarded or the average new music<br>doyen they'll doubtless exert an irresistable<br>attraction.<br>Baby go goo-goo at pwetty pitchah! <br>Of course, this is the Motown approach to <br>popularizing microtonality.  According to this<br>guerilla strategy (practiced extensively in New <br>York), the objective is a "crossover" composition<br>that "breaks through" into the white male<br>New York  critical establishment.<br>As with the de-funked un-gotten-down R&B of  <br>Motown records, all potentially controversial and<br>threatening aspects of the music must be<br>shaved off and polished away, leaving a<br>bland whitebread generic product sufficiently<br>"mainstream" to attract a mass audience.<br>And while the New York composers/performers<br>represent the Motown approach to microtonality,<br>those of us on the West Coast represent the<br>Stax approach.<br>"F*** 'em!" is the West Coast philosophy with<br>regard to the New York critical establishment:<br>if they can't stand the microtonal heat, let<br>'em flee the concert hall. This alternative<br>approach to popularizing microtonality <br>relies on the rasty nasty snazzy sound of<br>strange intervals and unfamiliar musical<br>forms to attract the adventurous concert-goer<br>and CD buyer.  While the New York crowd blows <br>dust off musty scores like Dick Stein's 1906 1/4-tone<br>cello piece for a concert at Juilliard, the<br>West Coast crowd blasts the audience with<br>full-bore hard-core microtones from the <br>git-go in exotic tunings like 13-TET and<br>13-limit JI and harmonic series 1-60.<br>Each approach has its merits.  Stax or Motown,<br>both seem to attract their share of "mainstream"<br>"crossover" audience from standard bland 12.<br>Regardless of the approach, it remains an<br>unfortunate fact that "I have learned that if<br>I produce a complex structural diagram of a piece<br>of music from anywhere, the students will listen<br>to the piece more carefully and will regard it with <br>greater respect.  A structural diagram gives the<br>music a legitimacy it does not have without <br>the analysis." [Becker, Judith, "Is Western Art<br>Music Superior?" Musical Quarterly, Vol. 72, No<br>2, 1986, pg. 346.]<br>So here's a helpful suggestion: when giving lectures or<br>concerts, microtonalists should project an overhead<br>transparency of the New York subway system and<br>throw in some gibberish about "pitch class<br>matrices" and "all-interval sets" and "maximally<br>symmetric stochastic distributions."  This will<br>wow the eurogeeks and ensure that the microtonal<br>music is listened to with *great* attention.  <br>After all, it requires hardly *any* skill or<br>intelligence to perpetrate this kind of musico-<br>theoretic scam, and the rewards are VAST...as <br>Cage and Boulez have so amply demonstrated.<br>--mclaren<br> <br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Mon, 6 Nov 1995 19:21 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id JAA25588; Mon, 6 Nov 1995 09:21:02 -0800<br>Date: Mon, 6 Nov 1995 09:21:02 -0800<br>Message-Id:  <9511060919.aa20661@cyber.cyber.net><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2277 href="#2277">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>11/7/1995 9:55:58 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: More about n-j n-e-t scales<br>---<br>"As physicians have always their instruments<br>and knives ready for cases which suddenly<br>require their skill, so you must have principles ready<br>for the understanding of things..." [Marcus<br>Aurelius, "Meditations"]<br>Because of the general lack of incomprehension<br>and puzzlement at my mention of non-just non-<br>equal-tempered scales, it's clear that some<br>further info is required. <br>In general, I'm not talking about linear or<br>meantone tunings.  While it's true that these<br>are technically non-just non-equal-tempered<br>scales, most of 'em are just one or another<br>way of bending twelve tones to obtain a<br>more consonant third or fifth in a traditional<br>Western triad.  This surely has its value,<br>but meantone scales decidely represent the<br>outermost extreme conservative  side<br>of non-just non-equal-tempered scales.<br>Instead, the kind of n-j n-e-t tunings I'm<br>concerned with--and have been since the<br>git-go--are those tunings which break<br>completely with the Western mold.  Some<br>of these kinds of tunings have octaves, others<br>don't.  In general, they're so wildly foreign<br>to any conventional harmonic or scalar <br>vocabulary that there is hardly any intelligible<br>way to talk about such scales as yet, except<br>as raw numbers.<br>For example:<br>One of the simplest ways of generating such<br>a completely non-Western non-just non-equal-<br>tempered scale is by taking the natural logarithm of<br>the factorial of a set of integers:<br>1! = 1, ln(1) = 0<br>2! = 2, ln(2) = 0.693147<br>3! = 6, ln(6) = 1.7181759<br>4! = 24, ln(24) = 3.17805383<br>5! = 125, ln(125) =  4.82831373<br>6! = 720, ln(720) = 6.5792512<br>7! = 5040, ln(5040) = 8.52516136<br>and so on.<br>Taking ratios so as to eliminate<br>dependence on the base of the logarithm,<br>we have:<br>scale step 1: 1.0<br>scale step 2:  2.478808<br>scale step 3:  4.5849625<br>scale step 4:  6.9657842<br>scale step 5:  9.4918531<br>scale step 6:  12.299208<br>These values can be octave-reduced or not.<br>If not, the scale will have no octaves.  <br>If octave-reduced, carrying out the procedure<br>will produce ever larger numbers of scale-<br>steps within the octave, never overlapping.<br>This is an inherently fractal process, first<br>described by Thorwald Kornerup in his Golden<br>Section scale.<br>In a sense the procedure is analagous to<br>that of just intonation, in which successive<br>addition and subtraction of various small-<br>integer-ratio intervals produces an ever-larger<br>profusion of unequal divisions of the octave. <br>However, there are a number of differences.<br>At this point it's useful to introduce the<br>concept of the "inharmonic series."  By<br>analogy with the harmonic series, an<br>inharmonic series serves as the backbone<br>of a non-just non-equal-tempered scale.<br>In this case, the inharmonic series is <br>Log(N!) where N runs from 1...infinity.<br>Of course choosing N by some other criterion<br>(perhaps by some recurrence relation: say,<br>N4 = N1 - sqrt(N2 + N3^2)*N1) would produce<br>an entirely different inharmonic series.  There<br>are an infinite number of inharmonic series,<br>each generated by choosing N by a different<br>method and then applying some non-linear<br>operation to N.<br>By contrast, the familiar harmonic series is<br>obtained by setting N = the class of integers<br>and performing the simplest possible linear<br>operation on them--namely, the unary<br>operation (which leaves the operand unchanged).<br>Inharmnic series are important as a source<br>of modulation and of vertical structures<br>in non-just non-equal-tempered scales.<br>One of the most interesting implications<br>of non-just non-equal-tempered tunings,<br>however, is the prospect of generating<br>a scale of note durations (read: rhythms)<br>derived from the scale steps, by analogy<br>with the comparable procedure in traditional<br>Western music.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Tue, 7 Nov 1995 20:04 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id KAA19700; Tue, 7 Nov 1995 10:04:49 -0800<br>Date: Tue, 7 Nov 1995 10:04:49 -0800<br>Message-Id: <9511071803.AA09055@ ccrma.Stanford.EDU ><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2288 href="#2288">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>11/8/1995 4:18:10 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Rhythm, tuning & the extension of Charles<br>  Seeger's 1930 article into n-j n-e-t scales<br>---<br>"Look within.  Let neither the peculiar quality of<br>anything nor its value escape you."  [Marcus Aurelius,<br>"Meditations"]<br>With typical insight, Ivor Darreg once commented that<br>the rhythms of Baroque music arose from the 18th-century<br>love of clockwork and chronometry.  And in fact one<br>of the greatest achievements of Enlightment technology<br>was the development of a ship's chronometer capable of<br>keeping sufficiently accurate time to allow Royal Navy<br>ship to navigate along lines of longitude. The inventor won<br>a 10,000-pound prize--at the time a huge fortune.<br>In a larger sense, the infrastructure of music (the tuning) has<br>probably always exerted a potent influence over its overt<br>superstructure--specifically, over the rhythms used.  <br>It's only in the last century, however, that the relationship<br>appears to have been restored to the approximate level<br>of complexity characteristic of the music of the late 14th<br>century.<br>Just intonation music naturally lends itself to a <br>complementary arrangement of ratios of small integer <br>numbers of beats.  Ben Johnston pioneered this idea in <br>the rhythms of his quartets.  Thus a 4:3 will often <br>be mirrored with 4 beats against 3, a 6:5 with 6<br>beats against five, and so on. Toby Twining picked <br>this procedure up from Johnston, and employs it in<br>his own just intonation choral compositions: the<br>polyrythms consistently mirror on a larger time-scale<br>the vibrational ratios produced at the waveform level.<br>This is not a new idea.  The masters of ars subtilitas<br>in the 1380s played with this idea extensively and<br>with great subtlety: and in the 1920s Leon Theremin <br>implemented it with his now-lost instrument "the<br>rhythmicon."  Theremin's instrument responded to <br>the presence of dancers in a space (sensed by <br>changes in capacitance as detected by 3 sensors) <br>and produced polyrhythms accompanied by just <br>intonation ratios.  As it turns out, just intonation<br>intervals are very much easier to generate with<br>analog electronic circuits than equal-tempered <br>intervals.  So Theremin's rhythmicon was <br>an early JI synthesizer as well as an interesting<br>example of very early integration between rhythm<br>and tuning.<br>In this century the massive strip-mining and <br>subsequent exhaustion of the 12-tone equal-<br>tempered tuning appears to have led to an<br>increasing dissatisfaction with chronometric<br>18th-century rhythms.  Thus the history of avant<br>garde music in the 20th century is a history of <br>ever less regular rhythm.  First 3 against 4...<br>most famously in the section of "Rite of Spring"<br>where the conductor is supposed to conduct 3<br>beats with one hand and 4 beats in the other.<br>Then, onward and upward to other beat-ratios.<br>"As tonally in 900, so rhythmically in 1900,<br>the relations 2:3 and 3:4 represented the <br>ultimate in harmonic comprehensibility." <br>[Seeger, Charles, "On Dissonant Counterpoint,"<br>Modern Music, Vol. 7, No. 4, 1930, pp. 25-31]<br>Copland's 1924 piano concerto  and<br>Gershwin's Rhapsody in Blue from the same<br>period both use extensive syncopation and <br>hemiolas.  Elliott Carter's metric modulation<br>procedures extended the irregularity of the<br>basic pulse, as did Bartok's essentially barline-<br>less compositions, ditto Varese's "Density 21.5,"<br>"Arcana," "Ionisation," etc.--in many cases <br>using a new key signature every<br>barline.  The real break came when Khaikosru<br>Shapurji Sorabji introduced multiple embedded<br>n-tuplets during the 30s and 40s, and when<br>Nancarrow started stretching the tempi<br>of multiple polyphonic lines by different<br>rates simultaneously.  You get multiple<br>simultaneous tempo-shift curves going on<br>that deform time in a completely plastic<br>way: rhythmic regularity has completely<br>disappeared.  The basic pulse is continuously<br>changing even within the individual note.<br>This has led to rhythmic complexities<br>like those of Michael Gordon's "Yo, Shakespeare!",<br>or Trimpin's, computer-controlled vorsetzer works,<br> or Warren Burt's "I Have My Standards"<br>and "Notes From the Jungle of Intonational <br>Complexity."  <br>It seems likely that the reason for this<br>increasing irregularity and complexity in<br>rhythm is that composers simply beat the<br>12-tone equal tempered scale to death. <br>By the 9th century A.D. they had introduced <br>the third as a consonance, by the 18th<br>century they'd started using sixths  as <br>consonant intervals, by the 1920s and 1930s<br>the major and minor 2nd and major and<br>minor 7ths as part of the spectrum of<br>consonance.  Schoenberg's "emancipation<br>of the dissonance" effectively placed all<br>intervals on a continuous scale--there<br>were no longer any "forbidden" intervals.<br>Everything could be a consonance, depending<br>on context--and the "rules" of consonance and<br>dissonance could be turned upside-down, if <br>desired.  Charles Seeger's "dissonant counterpoint,"<br>introduced in 1916, was a typical example:<br>"Dissonant Counterpoint...is essentially an<br>inverted species counterpoint, the species of <br>the older discipline remaining intact but<br>*dissonance* (seconds, tritones, sevenths,<br>ninths) becoming the norm and *consonance*<br>(thirds, fourths, fifths, sixths, octaves)<br>requiring preparation and resolution." [Nelson,<br>Mark, "In Pursuit of Charles Seeger's Heterophonic<br>Ideal: Three Palindromic Works by Ruth Crawford,"<br>Musical Quarterly, Vol. 72, No. 4, 1986, pg. 459.]<br>The above prescription is a blueprint for <br>post-Webern modernism up to the late 1970s:<br>and indeed, the exhortations of Kyle Gann's<br>music professors to "use more good solid <br>20th century intervals--tritones, minor<br>seconds, major sevenths," is of course nothing<br>but standard Palestrina species counterpoint<br>turned inside out: the "good" intervals of the<br>1500s have become the "bad" intervals of the<br>1920s-1970s, and vice versa.  Modernism did<br>not expand the language of music, of course:<br>there were no new intervals introduced.  The<br>list of preferred intervals had merely been<br>swapped for the list of intervals formerly<br>proscribed. Thus,  by the 1930s there was nothing<br>left to do with harmony or melody in the 12-tone equal<br>tempered system.  The harmonic resources<br>had been played out.  The 12-tone tuning had been<br>strip-mined, leaving a hole in the ground and an<br>enormous amount of bad wannabe-Webern.<br>That left rhythm.<br>So, starting circa 1948,  composers began to explore <br>ever more complex, ever more irregular divisions of<br>the beat.<br>More than one commentator has suggested that<br>Nancarrow represents some kind of "ultima<br>thule" for rhythmic complexity in this progression<br>toward ever more complex time-relationships.<br>However,  this is obviously incorrect.<br>One of the most interesting frontiers in xenharmonic<br>composition is, in fact, the extension of rhythm<br>in accord with the tuning of non-just non-equal-<br>tempered scales.  This is nothing more than a self-<br>evident expansion of Charles Seeger's 1930<br>suggestion  of "a recognition of rhythmic harmony<br>as a category on a par with tonal harmony." [Seeger,<br>Charles, "On Dissonant Counterpoint," Modern Music,<br>Vol. 7, No. 2, 1930, pp. 25-31.]  (Since this is an<br>obvious extension of Seeger's classic modernist<br>insight, naturally no academic has yet suggested<br>it. Score another one for the same no-talent PhDs who<br>barred the greatest tape music composer of the<br>20th century from the Columbia-Princeton Electronic<br>Music Center because of his "lack of credentials"--<br>the composer being, of course, Tod Dockstader.)<br>As we've seen, just intonation compositions naturally<br>lend themselves to small integer ratios of beats (as<br>Johnston, Twining, Partch, et al., have skilfully shown).<br>Indeed, Kenneth Gaburo produced a composition, "Lemon Drops,"<br>using a bank of sine wave oscillators at the U. of Illinois,<br>which uses the same principle of moving micro-ratios<br>on the waveform level into macro-ratios on the level<br>of time of the individual measure. (Circa 1972?)<br>And, as we've seen, equal tempered compositions appear<br>to lend themselves  to much more complex <br>divisions of the beat: embedded n-tuplets, metric<br>modulation, and so on.  On the macro-level of<br>the individual measure this is very similar to approximating <br>an irrational number with two large rationals. If<br>you've heard a complex rhythm like 7 in the time of<br>4 inside 11 in the time of 9 inside 3 in the time of 2<br>inside 17 in the time of 13, you realize that the end<br>result is a set of timings that sound nearly like<br>ratios of irrational numbers--above a sufficient<br>level of embedded n-tuplets, no underlying pulse is<br>audible at all.  This is obviously akin (on the macro-level)<br>to the ratio of irrational numbers on the micro-level of<br>the individual waveform which defines an equal-tempered<br>scale, in which all pitches are some Nth root of K.<br>By analogy, the next step in rhythmic complexity is<br>self-evident:  move to ratios of transcendental numbers<br>on the macro-level of the beat, mirroring the non-just<br>non-equal-tempered pitches of n-j n-e-t scales.<br>Our present system of notating music has no way of<br>dealing with such divisions of the beat.  They are really<br>impossible to notate with anything like conventional<br>musical notation.                                5       11   17<br>While regular pulses like cut time or  8  or  8  +  8  can<br>be easily notated, and even very complex ratios made up of<br>embedded n-tuplets *can* be written down in conventional<br>notation, the kind of rhythmic pulsations I'm talking<br>about here lie completely outside the range of Western<br>notation.  The system just breaks down.  Conventional<br>notation can't handle these rhythms *at all.*<br>Let me give an example, so you can get an idea of what<br>I'm talking about here:<br>At a tempo of 60 each quarter note lasts exactly one<br>second.  So common time (4/4) produce measures<br>lasting 4 seconds, with each quarter note lasting one second,<br>each eighth note last 1/2 second, each 16th note lasting<br>1/4 second...and so on.  A triplet 8th note would use 3<br>8th in the time of 2, so each 8th note would last 1/3 second.<br>This is a simple extension of micro-ratios at the<br>waveform level into macro-ratios at the level of the beat.<br>A more complex embedded tuplet might require, say,<br>a measure in 4/4 to have 11 eighths in the time of 8 eighths,<br>with 5 in the time of 4 inside it, with 3 in the<br>time of 2 inside that.  If we had a measure like this:<br>4  |-------- 11:8------------------------------------------|<br>4  |----5 : 4---------------------| 8th 8th 8th 8th 8th 8th 8th<br>     8th 8th 8th |----3:2--------|<br>                         8th  8th  8th<br>Working from the outside in, the divisions of the beat are:<br> <br>the last 7 8th notes have a duration of 8/11 of 1/2  second =<br>8/22  of a second;  the first 3 8th notes have a duration of<br>4/5 of that, or 4/5*8/22 = 40/110 or 20/55 of a second,<br>and the 3 eight note sof hte inenrmost n-tuplet have a <br>duration of 2/3 that, or 40/165 of a second.  This is <br>number complex enough that any underlying pulse (if<br>audible) is quite obscure and irergular-sounding.  Again,<br>a reasonable analogy to the irrational Nth root of K <br>ratios of equal-tempered pitches.<br>However, moving on to non-just non-equal-tempered<br>tuning produces a new level of rhythmic complexity,<br>when the individual scale pitches are projected<br>upwards into the macro-level of the individual measure.<br>A typical n-j n-e-t scale is one of the subset of tunings<br>produced by taking ratios of inifnite continued fractions.<br>The fraction N1 +  N2<br>                           ___ <br> 		        N3 +<br>      			   __<br>			   N4 + <br>			       __<br>			       N5 + ...<br>in general produces numbers which are neither simple <br>integers nor Nth roots of K.   For example, if N1...NJ<br>= 1, the result is 1.61803399, or phi (the Golden Ratio).<br>By using a very simple computer program (3 lines)<br>to evaluate such a continued fraction out to, say,<br>N20, it's easy to calculate the frequencies of<br>such scale-steps to an accuracy of 7 figures.<br>The first 5 infinite continued fractions for<br>N1...NJ = 1 through 5 are:<br> <br>f1 = 1.618034<br>f2 = 2.414213<br>f3 = 3.302775<br>f4 = 4.236067<br>f5 = 5.192582<br>f6 = 6.162277<br> <br>If we let f0 = 1.0, this gives 6 scale-steps.  Now,<br>notice that these ratios when expressed as rhythms<br>*cannot be notated in any conventional way.*<br>There is just no reasonable method of writing<br>down a rhythmic system in which the longest<br>note lasts 1.0, the next longest note last 1/1.618034,<br>the next longest note lasts 1/2.414213, the next<br>longest note lasts 1/3.302775, and so on.  The<br>concept is totally alien to anything in our<br>notational convention.  <br>These kinds of rhythms just blow Western notation<br>right out of the water.   In fact, not only can we<br>not *write music* that *notates* such divisions<br>of the measure, at present we cannot even *talk*<br>about such divisions of the measure with a <br>comprehensible vocabulary.  We do not even have<br>the *words* to begin a discussion of such temporal<br>divisions.  We are, literally, mute.  <br>Why does this matter?<br>It matters because one of the clearest and simplest<br>compositional strategies involving non-just non-equal-<br>tempered scales is to work with such rhythms on<br>the level of the individual measure, then in blocks of<br>phrases which last for times proportional to these<br>ratios, then in sections of the work which last for<br>times also proportional to these ratios on a larger<br>time-scale.  This continues traditional musical practice<br>in a sensible and straightforward way: namely, by<br>systematically extending  the micro-level<br>of frequencies up into the macro-level of the beat.<br>In such a non-just non-equal-tempered composition,<br>all timbres could (using Csound) easily be made up of<br>additive sets of freuqnecies described by a non-just<br>non-equal-tempered tuning, and all the durations<br>of the notes *also* described by the same<br>ratios, along with durations of sections, movements,<br>etc.<br>However!<br>Trying to keep track of the rhythms is mind-bending<br>and maddening.  Because of the total inadequacy of<br>notational systems or even vocabulary, I have been<br>forced to notate these rhythms as delta start times:<br>that is, note durations--which must then be<br>added to the absolute run time (as demanded by<br>Csound).  It's *incredibly* meticulous, and requires<br>a *great deal* of bothersome calculation.<br>Interestingly, the rhythms sound jazzy and almost<br>improvisational.  They are not conventional.  And<br>in particular, when two or more strata of such rhythms<br>are going at once, made of notes broken down<br>into subvalues of these infinite continued fraction<br>convergents, with each note-stream at a tempo<br>also described by the an infinite continued fraction,<br>the results are truly exotic.<br>Next post, some suggestions for a generalized<br>rhythmic vocabulary that would at least allow<br>an approach to coherent manipulation of time-<br>streams and durations derived from non-just<br>non-equal-tempered tunings.<br>--mclaren <br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Thu, 9 Nov 1995 06:50 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id UAA26952; Wed, 8 Nov 1995 20:50:30 -0800<br>Date: Wed, 8 Nov 1995 20:50:30 -0800<br>Message-Id: <951109043956_71670.2576_HHB32-6@CompuServe.COM><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2292 href="#2292">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>11/9/1995 10:28:53 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: A new rhythmic vocabulary<br>---<br>"All things come from thence, from<br>that universal rule either directly proceeding<br>or by way of sequence." [Marcus Aurelius,<br>"Meditations"]<br>The previous post explored the outer<br>edges of rhythm by suggesting an<br>extension of the waveform periodicity<br>in the frequency domain of non-just<br>non-equal-tempered scales up into<br>the beat level of the individual measure.<br>As mentioned, there is a complete and<br>utter lack of generalized rhythmic<br>vocabulary to talk about these kinds<br>of divisions of the beat.  We can talk<br>sensibly in Western music about "half notes,"<br>"3 eighth notes in the time of 2," and so on,<br>and we can even (with some difficulty)<br>talk about "40% of a half note" (notated<br>as the N-tuplet `8 in the time of 5'),<br>but when it comes to something like<br>1/1.61803399 of a half note, conventional<br>Western notation falls mute.  Indeed, there<br>is not even the ghost of a clue where to<br>start talking about such divisions of the<br>beat except in raw numbers--which are<br>tremendously hard to deal with intuitively,<br>or manipulate as ensembles without huge<br>amounts of gratuitous calculation.<br>What does this have to do with tuning?<br>It seems clear that the natural way to compose<br>in non-just non-equal-tempered scales is to<br>extend the frequencies into divisions of the<br>beat.  But what we want is a simple way of<br>manipulating such rhythms.  Ideally, we should be<br>able to easily and simply apply such familiar<br>concepts as rhythmic augmentation and diminution<br>to sets of rhythms derived from the pitches of<br>non-just non-equal-tempered scale frequencies.<br>If we can't do this, it cripples us at the start <br>in composing with non-just non-equal-tempered<br>scales.<br>First, let me suggest a generalization of the<br>standard Western rhythmic vocabulary.<br>Traditionally, divisions of the beat are <br>handled with a descriptive vocabaular that<br>directly specifies the division of the beat:<br>half note lasts one half a whole note,  quarter<br>note lasts one quarter of a whole, triplet<br>quarter packs 3 quarters into the time of 2,<br>and so on.  This is fine as far as it goes. But<br>extending to anything other than simple<br>integer divisions of the beat is impossible:<br>there's no such thing as a "1.618034-note."<br>Instead, permit me to suggest what the<br>computer programmers have christened<br>a "call by reference," rather than the<br>"call by value" of conventional Western<br>rhythmic vocabulary.<br>Instead of using words for the divisions<br>of the beat that describe the actual <br>values, suppose we use a rhythmic <br>vocabulary which describes the successive<br>position of the rhythm in a hierarchy from<br>long to short.  This kind of rhythmic <br>vocabulary could be applied to an unlimited<br>range of different divisions of the beat, rather<br>than the extremely limited set of integer<br>divisions of the beat which can be described<br>by traditional Western usage.<br>PRIMARY -- longest duration within the measure<br>SECONDARY -- next longest duration<br>TERNARY -- next longest<br>QUATERNARY -- next longest<br>..and so on.<br>With this change of vocabulary, it suddenly<br>becomes possible to write down a set of<br>rhythms derived from our non-just non-equal-<br>tempered scale:<br>P S S P T P <br>Given the non-just non-equal-tempered<br>scale described in the previous post, this<br>is a set of notes of duration:<br>1.0 1/1.618034  1/1.618034 1.0 1/2.414213 1.0<br>In the context of this new rhythmic vocabulary,<br>all of the traditional techniques of Western<br>rhythm can be applied.  Here, augmentation<br>refers to multiplying all notes by the value<br>of 1/SECONDARY beat duration.  <br>In traditional Western usage, the secondary<br>beat duration is always 1/2, so augmentation<br>is always a simple doubling of note durations.<br>Contrariwise, diminution is a simple havling<br>of note durations.<br>In the context of the rhythms derived from our<br>non-just non-equal-tempered scale, however,<br>augmentation means multiplying all note<br>durations by 1.618034, while diminution <br>means multipying all note durations by <br>1/1.618034.<br>Embedded tuplets can also be carried over<br>into the new rhythmic scheme, with a<br>concomittant increase in rhythmic<br>complexity.  A triplet in traditional Western<br>usage is obtained by adding the primary to<br>the secondary duration; here it's obtained<br>by doing the same thing, but the result<br>(instead of being a 3:2 duration) is a 2.618034:1<br>duration.  And so on.<br>This gives us at least some reasonable way<br>to *talk* about rhythmic divisions derived<br>by time-scaling our non-just non-equal-tempered<br>micro-level of frequency up into the level<br>of the individual measure.  Because of the<br>obvious implications for new kinds of compositional<br>techniques, this derivation of rhythm from<br>non-just non-equal-tempered scale<br>frequencies clearly demands further<br>exploration.<br>The next post will discuss generalizations of<br>vertical structures in non-just non-equal-tempered<br>scales, along with an examination of consonant<br>vertical structures in a representative non-just<br>non-equal-tempered scale, along with several<br>kinds of near-equivalents to conventional modulation<br>between keys (equal temperaments) or 1/1s (JI).<br>---mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Fri, 10 Nov 1995 00:38 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id OAA22718; Thu, 9 Nov 1995 14:38:39 -0800<br>Date: Thu, 9 Nov 1995 14:38:39 -0800<br>Message-Id: <Pine.3.89.9511091753.A26367-0100000@email.ir.miami.edu><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2298 href="#2298">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>11/10/1995 10:56:58 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: A generalized approach to harmony<br> in non-just non-equal-tempered scales<br>---<br>"Observe constantly that all things take place<br>by change, and accustom yourself to consider that<br>the nature of the universe loves nothing so much<br>as to change the things which are to make new things <br>like them.  For everthing that exists is in a manner<br>the seed of that which will be." [Marcus Aurelius, <br>"Meditations"]<br>Bill Sethares and Your Humble E-Mail Correspondent<br>have both struggled for more than a year with the<br>vertical implications of non-just non-equal-tempered<br>scales.<br>While Bill's spectral mapping procedure offers a<br>way of adroitly controlling *sensory* consonance<br>and dissonance in n-j n-e-t scales, this is quite a<br>different matter from the tonal substructure implicit<br>within the scale.<br>Douglas Keislar's PhD thesis makes this clear. By<br>rendering a scale like (say) 13/oct more consonant<br>on the level of individual partials interacting<br>within the critical band, we do *not* produce<br>any greater sense of overall "tonality" for the listener.<br>Even with smoothly beatless chords, 13-TET *still*<br>sounds profoundly anti-tonal and non-cadential. Even<br>though a I-IV-V-I may be made beatless through the<br>miracle of modern digital signal processing, it still<br>doesn't sound like "the way the scale wants to behave."<br>And thus other compositional strategies must be <br>employed, different from  those dragged out of 12-TET <br>and press-ganged into service. <br>In short, "I don't think we're in Kansas anymore, Toto."<br>And outside of 12-TET, you'd better take that into <br>account...or your compositions will sound like very<br>badly out-of-tune 12-TET leftovers.<br>These complexities are sufficient to give pause to<br>a composer contemplating a work in 19- or 53-tone<br>equal, or (say) 13-limit or 31-limit JI; but when<br>it comes to non-just non-equal-tempered tunings,<br>what's a xenharmonic composer to do?<br>The first and most important point in generating<br>vertical structures in non-just non-equal-scales<br>is to recognize that some general procedures *do*<br>carry over from other tunings, albeit in highly<br>modified form.<br>John Chalmers has elaborated a classical method<br>for scale construction which he calls "tritriadic"<br>scale generation.  The basic idea (based on a very<br>ancient principle) is that scales have typically<br>been generated by taking the Tonic,  forming a triad;<br>then a Mediant, and forming a triad, and finally<br>a Dominant, and forming a triad.  The set of tones<br>formed by the union of all the pitches in the triads<br>has conventionally produced the scales characteristic<br>of Western music.  John's inspiration was to vary<br>the frequency ratios of the T, D and M chords to<br>generate variant scales. (John Chalmers' tritriadic<br>techniques have been unjustly neglected as a topic<br>for this tuning forum; if something doesn't change,<br>clearly I shall have to author several future posts<br>on the subject.) <br>Interestingly, something akin to this procedure can be<br>employed with non-just non-equal-tempered tunings.<br>One of the more obvious n-j n-e-t scales is the<br>set of modes of the ideal vibrating cylinder free at<br>both ends.  These are given by Lord Rayleigh (1896)<br>in his "Theory of Acoustics," Vol. 2, pg. 25, refining<br>the result obtained by Hoppe in 1871:<br>The frequency f of each partial is proportional to<br>sqrt[[s^2]*[(s^2 -1)^2]/(s^2 + 1)]   <br>Setting s successivey to 2, 3, 4... and referring each<br>tone to the fundamental of the inharmonic series,<br>the partial frequencies are:<br>f0 = sqrt(4*9/5) = 2.68328/2.68328 = 1.0<br>f1 = sqrt(9*64/10) = 7.58946/2.68328 = 2.82842<br>f2 = sqrt(16*225/17) = 14.55197/2.68328 = 5.4320<br>f3 = sqrt(25*576/26) = 23.5339/2.68328 = 8.77057<br>f4 = sqrt(36*1225/37) = 34.5329/2.68328 = 12.8696<br>f5 = sqrt(49*2304/50) = 47.5173/2.68328 = 17.7086<br>f6 = sqrt(64*3969/65) = 62.5135/2.68328 = 23.297422<br>f7 = sqrt(81*6400/82) = 79.510699/2.68328 = 29.631905<br>f8 = sqrt(100*9801/101) = 98.508682/2.68328 = 36.71204<br>f9 = sqrt(121*14400/120) = 120.00417/2.68328 = 44.72294<br>f10 = sqrt(144*20449/143) = 143.49913/2.68328 = 53.47899<br>&c.<br>Reducing these values to cents gives<br>Pitch 1 = 0 cents<br>Pitch 2 =  1799.99 cents<br>Pitch 3 =  2926.97 cents<br>Pitch 4 =  3759.204 cents<br>Pitch 5 =  4423.074 cents<br>Pitch 6 =  4975.653 cents<br>Pitch 7 =  5450.5181 cents<br>Pitch 8 =  5866.8954 cents<br>Pitch 9 =  6237.8177 cents<br>Pitch 10 = 6579.5317 cents<br>Pitch 11 = 6889.0807 cents<br>&c.<br>The primary consonant vertical structure in this<br>system will be the complex Pitch 1 + Pitch 2 + Pitch 3.<br>This is the *least* compact vertical structure available;<br>notice that, because of the wide spacing between<br>members of this inharmonic series, Plomp & Levelt's<br>findings tell us that this primary vertical structure<br>in this n-j n-e-t tuning will be consonant (provided<br>that the timbre is made up of partials tuned to this<br>scale) because no two partials will fall within the<br>same critical band.<br>However, there are other consonant vertical structures<br>than the primary: for example, members 2, 3 and 4<br>of this inharmonic series could be used as a chord.<br>This would produce:<br>Secondary vertical structure: <br>Pitch 1 = 0 cents<br>Pitch 2 =  1126.98 cents<br>Pitch 3 = 1959.214 cents<br>A third-order vertical structure comes from<br>members 3, 4 and 5 of the inharmonic series:<br>Pitch 1 = 0 cents<br>Pitch 2 = 832.234 cents<br>Pitch 3 = 1496.104 cents<br>And a fourth-order vertical structure comes<br>from members 4, 5 and 6 of the inharmonic series:<br>Pitch 1 = 0 cents<br>Pitch 2 = 663.87 cents<br>Pitch 3 = 1216.449 cents<br>A fifth-order vertical structure comes from<br>member 5, 6 and 7 of the inharmonic series:<br>Pitch 1 = 0 cents<br>Pitch 2 = 552.579 cents<br>Pitch 3 = 1027.4441 cents<br>A sixth-order vertical structure comes<br>from members 6, 7 and 8 of the inharmonic series:<br>Pitch 1 = 0 cents<br>Pitch 2 = 474.858 cents<br>Pitch 3 = 891.2424 cents<br>A 7th-order vertical structure comes from<br>members 7, 8 and 9 of the inharmonic series:<br>Pitch 1 = 0 cents<br>Pitch 2 = 416.3773 cents<br>Pitch 3 = 787.2995 cents<br>And an 8th-order vertical structures comes<br>from members 8, 9 and 10 of the inharmonic series:<br>Pitch 1 = 0 cents<br>Pitch 2 = 370.9223 cents<br>Pitch 3 = 712.6363 cents<br>This is a slightly stretched neutral triad with<br>both the fifth and the third somewhat sharper<br>than the values of Erv Wilson's hypermeantone<br>scale. <br>A 9th-order vertical structures comes<br>from members 8, 9 and 10 of the inharmonic series:<br>Pitch 1 = 0 cents<br>Pitch 2 = 341.714 cents<br>Pitch 3 = 651.263 cents<br>This vertical structure is not consonant because<br>the distance between Pitch 2 and Pitch 3 is less<br>than a critical bandwidth (290.5 cents) in the midrange<br>of human hearing.  (At extremely high frequencies this<br>vertical complex would sound consonant, primarily<br>because the upper partials lie above the range of human<br>hearing.)<br>Subsequent nth-order vertical complexes will<br>clearly be less consonant.<br>This gives us a set of harmonies which can be<br>transposed to different steps of the scale to<br>produce inharmonic progressions.  (Again, we<br>assume the partials are matched to the tuning.)<br>Several points of note:<br>First, John Chalmers' tritriadic scale generation<br>techniques can be employed with the 8th-order<br>consonant vertical structure.  It will produce <br>modes significantly different from those familiar<br>from the harmonic series.  <br>Second, the inharmonic series considered here<br>requires us to travel farther up to find a familiar<br>vertical structure than does the ordinary harmonic<br>series.  In the classical Western case, the 4th-order<br>vertical structure using harmonic series members<br>4, 5 and 6 forms the basis of Western harmony. Here,<br>the 8th-order vertical structures using inharmonic<br>series members 8, 9 and 10 form the basis of <br>n-j n-e-t harmony in this particular inharmonic<br>series.  <br>Third, different inharmonic series can easily be<br>generated by modifying the equation for the modes<br>of a vibrating tube.  For instance, instead of<br>The frequency f of each partial being proportional to<br>sqrt[[s^2]*[(s^2 -1)^2]/(s^2 + 1)] , we could set<br>f proportional to <br>sqrt[[(s + 1)^2]*[(s^2 -1)^2]/s^2]<br>or<br>sqrt[[(s + 3)^2]*[(s^2 -1)^2]/(s+1)^2]<br>or<br>sqrt[[(s + 5)^2]*[(s^2 -3)^2]/(s+1)^2]<br>or<br>cube root of[[(s + 1)^2]*[(s^2 -1)^2]/s^2]<br>or<br>cube root of [[(s + 1)^3]*[(s^2 -1)^2]/s^3]<br>or<br>sqrt[[(s - 1)^2]*[s^3]/s^2] <br>and so on.  Clearly there are an infinite<br>number of equations describing non-just<br>non-equal-tempered scales, which can be obtained<br>merely by varying the equation for the modes<br>of a vibrating cylinder. <br>A larger question is: What physical oscillator<br>geometry corresponds to a given arbitrary<br>equation?  This is an extraordinarily difficult<br>problem.  It may be insoluble.  While the inverse<br>problem--given an arbitrary oscillator geometry,<br>can the equation describing the modes of the system<br>be found?--can at least be attacked numerically<br>(if all else fails), the problem of obtaining an<br>oscillator geometry from an inspection of the<br>equations describing the modes of a cylinder may<br>not have a single-valued solution.  That is, different<br>physical oscillatory system may produce the same<br>frequency spectrum. <br>This has been proven true in several cases, particularly<br>the case of different drum geometries, and may<br>be true for all physical oscillators. (For discussion of <br>a general mathematical proof of this proposition, see <br>Gordon, C., Webb D., and S. Wolpert, "One Cannot Hear <br>the Shape Of A Drum," Bulletin of the American <br>Mathematical Society (New Series), July 1992, Vol. <br>27, No. 1, pp.134-138)<br>Thus far, we have examined only the overtone-<br>equivalent members of the inharmonic series.<br>What about subinharmonic vertical structures?<br>That is the subject of the next post.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Fri, 10 Nov 1995 23:33 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id NAA16690; Fri, 10 Nov 1995 13:33:38 -0800<br>Date: Fri, 10 Nov 1995 13:33:38 -0800<br>Message-Id:  <9511101332.aa06606@cyber.cyber.net><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2314 href="#2314">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>11/13/1995 9:45:55 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: n-j n-e-t vertical structures - part 5<br>---<br>"The safety of life is this: to examine everything <br>all through, what is it of itself, what is its <br>nature, what is its form..." [Marcus Aurelius, <br>"Meditations"]<br>Of the nature of vertical structures in a <br>typical subinharmonic series, some has<br>been said: more remains.<br>By analogy with just intonation, the subinharmonic<br>series formed from the vibrational modes of<br>an ideal vibrating cylinder are obtained <br>by inverting the values<br>f0 = sqrt(4*9/5) = 2.68328/2.68328 = 1.0<br>f1 = sqrt(9*64/10) = 7.58946/2.68328 = 2.82842<br>f2 = sqrt(16*225/17) = 14.55197/2.68328 = 5.4320<br>f3 = sqrt(25*576/26) = 23.5339/2.68328 = 8.77057<br>f4 = sqrt(36*1225/37) = 34.5329/2.68328 = 12.8696<br>f5 = sqrt(49*2304/50) = 47.5173/2.68328 = 17.7086<br>f6 = sqrt(64*3969/65) = 62.5135/2.68328 = 23.297422<br>f7 = sqrt(81*6400/82) = 79.510699/2.68328 = 29.631905<br>f8 = sqrt(100*9801/101) = 98.508682/2.68328 = 36.71204<br>f9 = sqrt(121*14400/120) = 120.00417/2.68328 = 44.72294<br>f10 = sqrt(144*20449/143) = 143.49913/2.68328 = 53.47899<br>&c.<br>to obtain<br>fsub0 = 1/sqrt(4*9/5) = 2.68328/2.68328 = 1.0<br>fsub1 = 1/sqrt(9*64/10) = 7.58946/2.68328 = 0.353554<br>fsub2 = 1/sqrt(16*225/17) = 14.55197/2.68328 = 0.1840942<br>fsub3 = 1/sqrt(25*576/26) = 23.5339/2.68328 = 0.1140176<br>fsub4 = 1/sqrt(36*1225/37) = 34.5329/2.68328 = 0.0777024<br>fsub5 = 1/sqrt(49*2304/50) = 47.5173/2.68328 = 0.0564697<br>fsub6 = 1/sqrt(64*3969/65) = 62.5135/2.68328 = 0.0429232<br>fsub7 = 1/sqrt(81*6400/82) = 79.510699/2.68328 = 0.0337474<br>fsub8 = 1/sqrt(100*9801/101) = 98.508682/2.68328 = 0.027239<br>fsub9 = 1/sqrt(121*14400/120) = 120.00417/2.68328 = 0.0223598<br>fsub10 = 1/sqrt(144*20449/143) = 143.49913/2.68328 = 0.0186989<br>&c.<br>Forming the subinharmonic series starting on inharmonic series<br>member 10 produces:<br>faleph    = 53.47899*0.027239    =  1.4567142<br>fbeth     = 53.47899*0.0223598   =  1.1957795<br>fgem      = 53.47899*0.0186989  =   1.0<br>Reducing, this becomes<br>faleph = 831.77662 cents<br>fbeth  =  309.52791 cents<br>fgem   =  0 cents<br>Of particular interest here is the quasi-sixth formed by<br>falph, which happens to identical with phi, the golden<br>ratio.   This vertical complex is very similar to one discussed by<br>Thorwald Kornerup, and it is particularly interesting<br>in this context to observe that this one arises *naturally*<br>out of an ordinary physical process--namely, a subinharmonic<br>series based on the modes of an ideal vibrating cylinder.<br>Since Kornerup's Golden Scale is well known and <br>discussed in detail in Mandelbaum's thesis (among other<br>references), further discussion of this similar scale is<br>of less interest than a consideration of general principles<br>for organizing vertical progressions in n-j n-e-t scales.<br>Thus, this example may serve to show the subtle<br>links between relatively familiar non-just non-equal-tempered<br>tunings and the purely mathematical derivation of n-j n-e-t<br>scales from combinations of inharmonic and subinharmonic<br>series.<br>Clearly, both the inharmonic series vertical strucures *and* the<br>subinharmonic series structures may be formed on any scale<br>member.<br>Equally clearly, one might imagine "modulating" between<br>entirely different inharmonic or subinharmonic series.  <br>In that case, one could bring along the vertical complexes<br>derived from one inharmonic series into another, entirely<br>different, inharmonic series. For example, a series of<br>vertical structures derived from the inharmonic series<br>of the clamped metal bar might be played first in<br>the n-n n-e-t scale derived from the modes of the clamped<br>bar, then the same progression of vertical structures <br>might continue to play while the tuning changed to<br>that of an ideal vibrating sphere, and the tuning might<br>then change into that of an ideal vibrating cylinder, and<br>so on.<br>In fact one could just as easily "modulate" between different<br>modes of vibration of a sphere: zonal harmonics, torsional<br>vibrations, etc., each giving rise to a different non-just<br>non-equal-tempered scale.<br>This is a process conceptually akin to "modulation" in<br>JI and equal temperament, but more complex: for the<br>subinharmonic series formed on a given n-j n-e-t are,<br>as we have seen, in general not as closely related to<br>the vertical structures formed from inharmonic series<br>as is the minor triad to the harmonic series of the major<br>triad in traditional Western harmony.<br>Regardless, this set of posts may have given a glimpse<br>of the universe of new harmonies and melodies awaiting<br>the composer adventurous enough to dare composing<br>in non-just non-equal-tempered tunings.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Tue, 14 Nov 1995 07:55 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id VAA08993; Mon, 13 Nov 1995 21:55:42 -0800<br>Date: Mon, 13 Nov 1995 21:55:42 -0800<br>Message-Id: <951114005507_105935759@mail04.mail.aol.com><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2384 href="#2384">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>12/17/1995 8:31:26 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject:  Xenharmonic CDs<br>---<br>Time once again to give brief reviews of<br>the latest xenharmonic laser cookies...<br>First and most impressive, Marc Battier's<br>"Transparence."  This CD is available from<br>EMF, Joel Chabade's Electronic Music<br>Foundation.  Their catalog is available<br>on-line from emusic@aol.com.<br>Battier uses a single sentence from Henry<br>Chopin as source material for a virtuoso<br>set of digital signal processing<br>manipulations.  This CD is beautiful,<br>non-12-sounding, and endlessly varied<br>and interesting.<br>Many of the manipulations appear to center<br>around resonant filters: the effect is to pick<br>out distinctly non-12 pitches and generate<br>effects which sound nothing like the original<br>material. <br>The entire CD can be thought of as a giant set<br>of "variations on a theme" of a single acoustic<br>input.  Highly recommended!<br>Next, Anna Homler's "Do Ya Sa Di Do."  Ms.<br>Homler specializes is singing what sound like<br>Japanese or Korean chants against sampler-<br>manipulated electronic backgrounds.  The<br>net effect is often impressive, and distinctly<br>outside the standard 12-tone equal-tempered<br>scale.<br>The most xenharmonic tracks on this CD are<br>No. 1, in which she fringes her chant with<br>an aureole of xenharmonic "inflexional"<br>pitches (as in Balinese and Javanese vocal<br>music, where slendro and pelog are generally<br>used as a pont of departure, or as in the<br> vocal xenharmonies of Sinead O'Connor, <br>Louis Armstrong, Ofrah Haza, et alii).<br>Most wildly microtonal, however, is track<br>9--where Ms. Homler produces squeaks and<br>whistles which the human vocal track does<br>not appear to have been designed to<br>accomodate.  The effect is xenharmonic,<br>beautiful, and altogether exotic.<br>The CD is available from:<br>Homler, PO Box 48770, Los Angeles CA<br>90048.<br>Ben Johnston's "Calamity Jane to her Daughter"<br>on the CD "Urban Diva" is an impressive example<br>of extended just intonation.  This just array<br>appears to extend upward to around 31-limit,<br>and offers a formidable challenge to the<br>aspiring po-mo vocalist.<br>Forunately, soprano Dora Ohrenstein is more<br>than up to the challenge.  Her rendition proves<br>both sonically idirescent and emotionally<br>compelling.<br>*Highly* recommended!<br>The CD "Urban Diva" is available from Composer's<br>Recordings Inc., 73 Spring St., New York NY 10012-<br>5800, phone # (212) 941-9673.<br>Last and decidedly least: Chris Brown's<br>"Lava."  This composition combines electronically<br>manipulated sounds with live percussion and<br>digital keyboards.  <br>Alas, the piece quickly grows unbearably<br>repetitive and wearisome.  Most of the electronic<br>manipulations involve uninteresting delay or<br>filter effects applied to inherently ugly percussive<br>sounds.  The result is less than impressive.<br>My patience did not extend to the end of this CD.<br>Not recommended.<br> <br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Sun, 17 Dec 1995 17:48 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id IAA24152; Sun, 17 Dec 1995 08:48:09 -0800<br>Date: Sun, 17 Dec 1995 08:48:09 -0800<br>Message-Id:  <9512170815.aa22014@cyber.cyber.net><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2385 href="#2385">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>12/17/1995 8:48:09 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Sonics Arts Gallery concert<br>---<br>On Friday, 5 November, Your Humble E-Mail<br>Correspondent gave a concert along with Jonathan<br>Glasier at the Sonic Arts Gallery in San Diego.<br>The program consisted of:<br>[1] Dual pianos tuned to different 12-pitch subsets<br>of 34/oct.  With J. Glasier on one piano and myself<br>on another, we explored 34-tone equal temperament<br>in a piece which sounded as though one person was<br>playing, albeit with superhuman facility.  By judiciously<br>switching MIDI channels during the piece to obtain the<br>third 12-tone set of 34-equal, the entire 34/oct scale<br>was covered.<br>[2] The second piece also featured Glasier and YHC on<br>dual MIDI keyboards--this time using a 5 and a 7-pitch<br>subset of 34-TET with gamelan-like timbres.  The<br>general effect was that of a digital trip to Bali.<br>[3] The third piece used harmonic series 1-60 for<br>an old favorite, also played at last year's sonic arts<br>gallery concert series.  A staple concert piece, extremely<br>xenharmonic.<br>[4] The fourth piece used a TX802 harmonium timbre <br>and a cello to explore Harry Partch's 43-tone just array<br>[5] In the fifth piece, a vibraphone timbre counterpointed<br>pizzicato cello--also in Partch 43.<br>[6] The fifth piece juxtaposed exotic synth timbres in<br>the Carlos Gamma non-octave scale against Tibetan bells,<br>waterphone, and struck pieces of scrap metal to generate<br>an eerie and unfamiliar sound-world.  This may be the<br>first time Carlos Gamma has been performed at a public<br>concert.<br>All told, the concert was a success.  In attendance: Ted<br>Melnechuk, the xenharmonist Ralph David Hill, and a variety<br>of other sonically adventurous folk.  <br>The placement of contact mike on the cello did not produce<br>good recordings of the Partch pieces, but the other concert<br>pieces were recorded on digital tape and will form part of<br>a forthcoming compilation tape.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Mon, 18 Dec 1995 16:29 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id HAA03300; Mon, 18 Dec 1995 07:28:56 -0800<br>Date: Mon, 18 Dec 1995 07:28:56 -0800<br>Message-Id:  <9512180728.aa02212@cyber.cyber.net><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2386 href="#2386">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>12/18/1995 7:28:56 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Chalmers' Constant and a<br> family of constants giving rise to<br> yet another non-just non-equal-tempered<br>  scale<br>---<br>As John Chalmers has pointed out, the<br>iterated absolute log function produces<br>a set of unpredictable numbers unless it<br>starts with a certain number.<br>In that case, the series enters a fixed point.<br>If the function is called the mclaren series,<br>clearly this constant should be named <br>Chalmers' Constant.  It lies between <br>0.399012979 and 0.399012978.<br>This constant is different for each <br>logarithmic base.  Thus a family of<br>constants is implied.  For base e,<br>the constant lies between 0.567143289<br>and 0.567143291.  For other bases,<br>the constant is different.<br>This implies in turn an infinite number<br>of non-just non-equal-tempered scales.<br>One could, for example, generate one<br>such scale from the constants for the<br>logarithmic bases of the primes:<br>C[1] = fixed point for iterated log base 3<br>C[2] = fixed point for iterated log base 5<br>C[3] = fixed point for iterated log base 7<br>C[4] = fixed point for iterated log base11<br>C[5] = fixed point for iterated log base 13<br>C[6] = fixed point for iterated log base 17<br>C[7] = fixed point for iterated log base 19<br>C[8] = fixed point for iterated log base 23<br>and so on.<br>Another scale could be generated by<br>taking<br>C[1] = fixed point for iterated log base pi<br>C[2] = fixed point for iterated log base e<br>C[3] = fixed point for iterated log base F<br>C[4] = fixed point for iterated log base L<br>C[5] = fixed point for iterated log base C<br>C[6] = fixed point for iterated log base G<br>and so on, where F is Feigenbaum's<br>constant, L is the first Liouville number,<br>C is Chapernowne's number, G is the<br>Euler gamma constant, and so on.<br>As musical intervals all these values<br>appear to be particularly intractable<br>from a just intonation point of view;<br>large rational fractions are needed to<br>approximate virtually all of them.  Clearly<br>these musical intervals do not fit into<br>the just scheme of things.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Mon, 18 Dec 1995 16:31 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id HAA03909; Mon, 18 Dec 1995 07:31:02 -0800<br>Date: Mon, 18 Dec 1995 07:31:02 -0800<br>Message-Id:  <9512180729.aa02219@cyber.cyber.net><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2387 href="#2387">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>12/18/1995 7:31:02 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: a new iterated function for<br>  generating non-just non-equal-tempered<br>  tunings<br>---<br>While boring holes for resonators in a<br>pentatonic percussion instrument to be<br>installed at the Exploratorium, a new <br>iteration function occurred to me.  Since<br>these functions are a fertile breeding<br>ground for non-just non-equal-tempered<br>scales, this one might prove of interest<br>to forum subscribers.<br>Operating an industrial drill press is<br>extremely peaceful work--excellent for<br>mathematical contemplation.<br>The function is an alternating series:<br>start with a number, take the tan(x),<br>and whenever it drops below 1.0, take<br>e^x.<br>The first 10 terms of the function are:<br>i[1] = abs(tan(sqrt(2))) = 6.334119167...<br>i[2] = abs(tan(6.334119167)) = 0.05097795...<br>i[3] = abs(e^(0.05097795)) = 1.05229964...<br>i[4] = abs(tan(1.05229964)) = 1.752641506...<br>i[5] = abs(tan(1.752641506)) = 5.438434336...<br>i[6] = abs(tan(5.438434336)) = 1.126353452...<br>i[7] = abs(tan(1.126353452)) = 2.099871982...<br>i[8] = abs(tan(2.099871982)) = 1.710348942...<br>i[9] = abs(tan(1.710348942)) = 7.1119178021...<br>i[10] =  abs(tan(7.1119178021)) = 1.106677438...<br>I believe but cannot prove that all of these<br>numbers are transcendental.  Numbers > 2.0<br>when octave-reduced, and < 1.0 when added to 1.0,<br>produce a musical scale:<br>p[1] =  795.7728117 cents<br>p[2] =  86.07888146 cents<br>p[3] =  88.25468083 cents<br>p[4] =  971.4371163 cents<br>p[5] =  531.8296507 cents<br>p[6] =  205.991463 cents<br>p[7] =  164.8027358 cents<br>p[8] =  929.1488291 cents<br>p[9] =  996.2863799 cents<br>p[10] = 175.4817393 cents<br>As usual, there does not appear to be any<br>obvious pattern in these numbers.<br>Another number arises from this series:<br>1 + the number of successive iterations<br>required for switchover between e^x<br>and abs(tan(x)), or vice versa.  That<br>number is: <br>1.21311151312121913141313111313...<br>This number also appears to be<br>a transcendental.  Can you prove it?<br>As a musical interval this equates to<br>a neutral third of 334.4597716 cents.<br>This is a third which has not to<br>my knowledge appeared previously<br>in the musical literature.<br>--mclaren<br> <br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Mon, 18 Dec 1995 16:33 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id HAA04502; Mon, 18 Dec 1995 07:33:07 -0800<br>Date: Mon, 18 Dec 1995 07:33:07 -0800<br>Message-Id:  <9512180731.aa02233@cyber.cyber.net><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2390 href="#2390">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>12/18/1995 6:19:28 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: transcendental numbers, the entropy<br> of musical scales, and Shannon's theorems<br> applied to tunings<br>---<br>Some time ago, Gary Morrison very unjustly<br>impugned his own mathematical abilities (which<br>are considerable) in the process of asking the<br>question: What is a transcendental number?<br>Looking back at my previous posts on the subject,<br>the source of the confusion is easy to spot. <br>My statement: "In general, it is extremely <br>difficult to determine whether a given number<br>is transcendental or not" could be interpreted<br>in several ways.<br>One could take the statement to mean that<br>the Turing halting problem for a general<br>algorithm that sieves the field of reals<br>and always produces all transcendental<br>numbers has not yet been solved.  <br>Or one could take the statement to mean:<br>"It's impossible to define the term <br>'transcendental number.'"  This is surely<br>untrue.<br>There are many ways to define a<br>transcendental number.  One way is:<br>a transcendental number is the solution<br>of a transcendental equation--that is,<br>an equation involving logarithms or<br>antilogarithms.<br>This is not always true, since the equation<br>e^[i*pi] + X = 0  has the solution 1.  However,<br>perhaps one could say that a transcendental<br>number is one which arises *only* as the<br>solution of an equation involving logarithms<br>or antilogarithms.  (Manuel and John Fitch may<br>jump on me for this one; it may not be 100%<br>true all the time.  Can you think of a counter-<br>example?)<br>Another way of defining a transcendental number<br>is: It's a number which is not the solution of an<br>ordinal arithmetic equation or an algebraic<br>equation with rational-fraction coefficients and<br>exponents and a finite number of terms.<br>Algebraic and arithmetic equations can, of course,<br>also involve an infinite number of terms: pi and e<br>both arise as a result of many different infinite<br>series, the most spectacular of which were <br>discovered by Srinivasas Ramanujan.  <br>Pi and e also arise from equations involving<br>logarithms and antilogarithms: X^[i*pi] + 1 = 0<br>defines e, while e^[i*X] + 1 = 0 defines pi.<br>This latter definition is close to Grolier's,<br>although strictly speaking Grolier's definition<br>is incorrect since it appears to leave out the<br>requirement that a transcendental number<br>cannot be the solution of an arithmetic or<br>algebraic equation with a *finite* number of<br>terms.  (Many of Ramanujan's series involve<br>algebraic products & quotients but an infinite <br>number of terms.)<br>Transcendental numbers also tend to arise when<br>the exponents of an algebraic equation are<br>imaginary. <br>Another way of defining a transcendental number<br>is by the amount of information required to <br>describe it.  How complex an algorithm is<br>needed to generate the number?  How long does<br>it take to run?<br>Claude Shannon proved elegantly that the amount<br>of information required to generate (or parse) a<br>message is proportional to the log to the base 2<br>of the number of bits in the message.  By this<br>standard, an integer requires very little<br>information to parse (or generate).  Even if very<br>long, any finite integer can be entirely written<br>down.  Once the last digit is written, your're<br>finished. A simple "copy this array" algorithm<br>suffices. <br>A rational fraction requires somewhat more<br>information to parse (or generate).  However,<br>the algorithm required to describe the digits <br>in the number 1/9 (for example) is still simple:<br>"Keep writing ones."  I.e., 1/9 = .11111...<br>The information contained in an algebraic<br>irrational is somewhat greater.  (There are<br>two kinds of irrational reals: algebraic<br>irrationals and transcendental irrationals.<br>Algebraic irrationals are those numbers which<br>arise as real roots of equations involving rational <br>coefficients and rational exponents.<br>Transcendental irrationals arise when the<br>algebraic exponent, for example, is itself<br>an algebraic irrational--as in Hilbert's number,<br>2^[sqrt(2)]. )<br>In the case of an algebraic irrational, the algorithm<br>required to generate the number is lengthier<br>than that required to generate the decimal<br>expansion of a rational fraction--thus the<br>algebraic irrational contains more information<br>than does a finite rational fraction.<br>However, transcendental numbers appear to<br>require the most information of all.  To my<br>knowledge, there is as yet no known algorithm<br>by which the entire field of reals may be sieved <br>and by which all transcendental numbers will<br>always be found.  Yet, since we live in a Goedelian<br>universe,  such an algorithm might well exist--<br>and worse still, it might be very simple.<br>Another way of stating this proposition is that<br>the simplest description of a transcendental<br>number appears to be...itself.  If true, this<br> makes transcendental number unique.<br>It has been speculated that the digits in the<br>decimal expansion of transcendental numbers<br>never repeat.  One subscriber has even stated as<br>much on this forum.  However, this proposition<br>has never been proven mathematically.  (Most<br>mathematicians believe this supposition to be<br>true, but belief is *not* the same thing as proof.)<br>Thus it is not yet known how random the digits of (say)<br>pi or e really are.  Many functions, graphs and plots<br>seem random from one perspective, but when rotated<br>they reveal hidden patterns.  The same might be<br>true of pi or e.  So it's entirely conceivable that<br>out beyond a googol decimal places, all the<br>digits of pi might turn to 1's, for example.<br>A disturbing thought...yet one which cannot be<br>dismissed until a proof of the true randomness <br>of pi's digits is found.<br>In view of this possibility, the randomness of<br>a transcendental number's digits cannot be<br>defined. If an infinite number of pi's digits<br>are, say, 1, or 3, or 9, or what-have-you, after<br>a given point, then clearly the number is hardly<br>random at all.<br>However, in order to determine this by brute<br>force we would have to calculate an *infinite*<br>number of digits in pi's decimal expansion. <br>For no matter how far we go, there's always<br>the possibility that at the next digit, the <br>digits fall into a predictable and eternally<br>repeating pattern.<br>Thus the devilish undecidability in so many<br>cases of the question: "Is a given number<br>transcendental?"<br>For example: the number 1 + a googol zeroes<br>+ 1 + an infinite number of zeroes might be<br>transcendental.  <br>Is it?  <br>I don't know.  You don't know.  It's impossible <br>to calculate. No proof exists that this number is<br>transcendental (or not transcendental).  <br>Thus we will likely never know.<br>Mathematicians widely believe the digits<br>in pi to be completely random.  If so, this<br>provides another way of defining transcendental<br>numbers: by the power spectral density of<br>their decimal expansion.<br>By taking the Fourier transform of a number's<br>decimal expansion, its spectrum can be<br>determined.  The spectrum will contain Dirac<br>delta functions at those frequencies which<br>define a periodicity.  Thus the number <br>1.212121212.... will have a sharp spike in<br>its spectrum at 2, since the decimal expansion<br>has a periodicity of 2 digits. There will be little <br>energy anywhere else.<br>Integers have an FFT which forms a narrow<br>or broad Gaussian, depending on the length <br>of the integer.  Rational fractions have<br>broader spectra: algebraic irrationals have<br>spectra which are broader still.  <br>Transcendental numbers (if the<br>mathematicians are right) likely have flat<br>spectra: that is, their digits never<br>repeat.  (This has not been proven, but<br>is universally believed.) <br>Since Parseval's Theorem tells us that the<br>Fourier Transform of the autocorrelation<br>function is the power spectral density, this<br>is only as we would expect--it is, after all,<br>merely another way of saying that the digits of<br>transcendental numbers appear to exhibit<br>no correlation with one another.  There is<br>no pattern hidden in the decimal expansion.<br>Returning to the question of musical scales,<br>this gives us another way of defining tunings:<br>by their entropy.  <br>Since statistical mechanics teaches us that<br>entropy is a measure of the total number of<br>available states in a system, clearly the <br>number of states available in a number's<br>decimal expansion is greatest for transcendental<br>numbers and least for integers.  <br>The next digit in a transcendental number could<br>be anything: the number has maximum extropy.<br>Thus the entropy of a musical scale and<br>be defined by summing the entropies of the<br>numbers which comprise it.<br>The harmonic series clearly has least entropy;<br>next come JI scales made up of rational<br>fractions, next equal tempered scales made<br>up of algebraic irrationals, and finally<br>non-just non-equal-tempered scales made up<br>of transcendental numbers.<br>In this sense, transcendental numbers can be<br>thought of as micro-universes, containing an<br>infinite possible number of available states,<br>and requiring an infinite amount of energy<br>to parse.<br>Although the full workings of the ear/brain<br>system are not yet completely understood,<br>it is safe to assume that however it operates,<br>the human auditory system can be modelled<br>as some sort of state-space machine.  <br>In this case, we have a possible explanation<br>for the response of the ear to the octave<br>as well as Enrique Moreno's extended chroma<br>phenomenon.   Since information is logarithmically<br>proportional to energy (another of Shannon's<br>theorems), it requires the least amount of<br>information/energy to parse a musical<br>interval which is an integer ratio of another<br>interval.  Next most energy is required to<br>parse JI scales, still more to parse scales<br>involving algebraic irrationals (ET scales),<br>and the most energy/information is required<br>when parsing non-just non-equal-tempered<br>scales.<br>This accords well with Gary Morrison's and<br>my own findings about non-octave scales.<br>JI scales sound more "bland" than equal<br>tempered scales--or one might prefer<br>to put it the other way around and say<br>that Nth root of 2 tunings sound muddier<br>and more turbulent than JI tunings. Non-octave<br>scales sound "like thick rich chocolate milk<br>shakes," as Gary has pointed out, and my<br>own experience with non-just non-equal-<br>tempered scales indicates that these<br>tunings sound most complex and sonically<br>luxuriant of all.<br>However, this hypothesis is not supported<br>by the psychoacoustic data which demonstrate<br>clearly that listeners universally hear intervals<br>about 15 cents > the octave as "pure octaves"<br>and intervals of 2.0 as "too flat" and "out of<br>tune."  Moreover, this assumes that the <br>human auditory system can be modelled as<br>a Turing machine which obeys linearity<br>and the superposition principle.  However,<br>the data appears to indicate that many parts<br>of the human auditory system are non-linear<br>and do not obey the superposition principle.<br>In this case, the analogy with finite<br>automata may not be apt.<br>Lastly, if one wanted to go completely over<br>the edge, one could describe numbers in terms<br>of their dB signal-to-noise ratio by comparing<br>the normalizing power spectral density of<br>the integer 1 to the psd of the target number.<br>In this case transcendentals would exhibit<br>a zero dB signal-to-noise ratio, while integers<br>would exhibit no noise whatever and thus an<br>infinite signal-to-noise ratio. (Describing<br>numbers in terms of their signal-to-noise<br>ratio sounds absolutely insane until you<br>realize that this explains the extreme<br>noisiness of digital reverb systems; the<br>input signal becomes progressively degraded<br>by roundoff error during its trip through the<br>recirulating delay lines of the reverb<br>algorithm, and thus each sample of the<br>input suffers a progressive randomization<br>of its bits and thus a progressive decrease<br>in its singal-to-noise ratio.)<br>Incidentally, Gary's purported "mathematical<br>idiocy" pales before my own.  Alert readers<br>will still be guffawing at my statement that<br>"i is the square root of -1."  Obviously untrue,<br>since -i is also the square root of -1...  As<br>Manuel op de Coul so delicately pointed out<br>during our meeting across the street from<br>Disneyland (an apt venue for wild-eyed<br>microtonalists).<br>Moreover, e^[i*pi] = -1, not 1.<br>No duh dude, as Gauss would doubtless say.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Tue, 19 Dec 1995 15:20 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id GAA28265; Tue, 19 Dec 1995 06:20:47 -0800<br>Date: Tue, 19 Dec 1995 06:20:47 -0800<br>Message-Id: <199512191519.QAA09965@elevator.source.co.at><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2394 href="#2394">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>12/19/1995 2:32:36 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: A window of opportunity for synth<br>  manufacturers<br>---<br>Csound allows users to generate csound<br>timbres in real time from MIDI input.  At<br>present, this capability is limited.  But as<br>time passes and massively parallel<br>P7 desktop machines become typical,<br> this will change.<br>This means that synthesizer manufacturers<br>have a limited window of opportunity.  They<br>can either get off their rear ends and start<br>building *real* synthesizers--instead of digital<br>sample playback boxes full of canned sounds<br>burned into ROM--or they can go the way of<br>the dinosaurs.<br>Within 5-10 years, the average computer<br>user will be able to generate complex<br>and interesting csound timbres in real<br>time via MIDI using a standard desktop<br>computer.<br>This brings up the issue of Csound's support<br>for real-time microtonality.<br>There isn't any.<br>Having mentioned this to John Fitch, and<br>have received no reply, it seems appropriate<br>to bring it to the attention of the rest of the<br>forum subscribers.  If you examine the source<br>code for Csound, you'll discover that Csound<br>translates MIDI note input into real-time<br>frequencies by using a 2^N/12  function.<br>Yes, having thrown off the shackles of<br>the piano keyboard and all limitations on<br>scale and tuning, Csound now makes it<br>possible for us to...play in 12 tones per<br>octave via MIDI.<br>Unbelievable.  Disgusting.  Outlandish.<br>Yet true. <br>Csound is locked into 12-TET for MIDI<br>playback until someone, somewhere<br>changes the source code.  Naturally, since<br>this is the prime venue for non-12<br>computer applications in musical tuning,<br>not a single person on this forum has<br>ventured to deal with the problem.<br>Thus, as always, we head forward into<br>the past at the speed of light!  Soon,<br>extraordinary sounds will issue from<br>our desktop computers...sounds locked <br>into 12-TET, thanks to the crippled<br>artifically limited MIDI-to-Csound<br>routines frozen into the current<br>generation of Csound.<br>There's another issue of concern to<br>microtonalists:<br>Has anyone noticed that frequencies<br>in the HETRO output are specified as<br>16-bit integers?  With a frequency<br>range of 20 Khz, this gives a precision<br>of 20000/32768, not adequate to<br>describe the fine frequency shifts<br>that take place within individual<br>partials during the course of real-<br>world musical notes.  2/3 of a cent,<br>for instance, is 4% of a 72-TET scale<br>step.  While this kind of tuning accuracy<br>is perfectly acceptable for the overall<br>musical scale-step, it is surely INadequate<br>for specifying the fine frequency shifts that<br>give each changing overtone its "lifelike"<br>sound during resynthesis, especially when<br>the resynthesized timbre plays in a microtonal<br>tuning.<br>Naturally, no one has bothered to mention this<br>and naturally, no one has bothered to correct it.<br>More neglect of microtonality in the very field<br>(computer music) which ought to be most<br>congenial to new tunings & new scales.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Tue, 19 Dec 1995 23:36 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id OAA04729; Tue, 19 Dec 1995 14:36:47 -0800<br>Date: Tue, 19 Dec 1995 14:36:47 -0800<br>Message-Id:  <9512191434.aa18824@cyber.cyber.net><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2395 href="#2395">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>12/19/1995 2:36:47 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: The dirty truth about Csound<br>---<br>Since no one has ever bothered to respond<br>to any of my e-mail about the problems<br>with Csound,  time to go public.<br>Around 40% of the features of Csound do<br>not work and appear to be unimplemented.<br>Most of these features deal with spectral<br>modification of input signals, but the delay<br>line features also do not work. <br>One at a time, Csound's current problems are:<br>[1] One of the most obvious reasons to use<br>Csound is to analyze input timbres with<br>the Csound HETRO program and resynthesize<br>them with the partials warped into the<br>frequencies maximally consonant for a given<br>tuning.  <br>Naturally, HETRO does not work and Csound's<br>ADSYN routines does not work.  Way back<br>when, HETRO was written as an add-on to <br>analyze input sounds with a hetrodyne filter.<br>It blew up if the input exceeded 32 kilobytes<br>in length.  The problem was inherent to the <br>HETRO code, not the machine on which it ran.<br>Barry Vercoe fixed this problem in December<br>1994 but in so doing changed the format in<br>which HETRO stores numbers.  The old format<br>stored partials in pairs: frequency, amplitude,<br>timeslice, frequency, amplitude, timeslice...&c.<br>The new format uses the same data structure<br>but the timeslice is now variable and indicates<br>a detla-t in milliseconds to the next envelope<br>breakpoint.<br>In the old HETRO, the user specified the number<br>of breakpoints and the spectral analysis output<br>automatically took care of giving a spectral<br>"snapshot" every length/(number of breakpoints)<br>milliseconds.<br>In the new HETRO, an internal algorithm minimizes<br>the number of breakpoints.  This number is thus<br>entirely variable and the time between spectral<br>"snapshots" for each harmonic is unpredictable.<br>Alas, Csound cannot read spectral analysis files<br>in the new HETRO format.<br>This is of some concern to xenharmonists on this<br>tuning forum, inasmuch as one of the main areas<br>of interest for microtonalists working in computer<br>music is modifying acoustic spectra to render them <br>maximally consonant in a given tuning.<br>Thus, the two primary routines designed to analyze <br>and resynthesize Csound timbres are vaporware.<br>ADSYN and HETRO no longer work.<br>(Naturally, various forum subscribers will<br>deny this, and naturally they'll be--let us say--<br>"deliberately mistaked.") <br>This is a classic example of academic garbageware,<br>a subject to which I shall return in future posts.<br>Garbageware promises wonderful results, doesn't<br>work, and is always undocumented and bug-ridden.<br>Garbageware is always written by someone with 3<br>PhDs as a diversion, and naturally no support is<br>ever available for the software, since the programmer<br>is now in the Arctic studying the mating habits of the<br>krill shrimp under the permanent ice pack.  Garbageware<br>always *almost* works--it does *just enough* to<br>tantalize the unwary user, but *never* enough to<br>be useful.<br>Naturally, no one has bothered to mention<br>garbageware in Computer Music Journal, ARRAY, or<br>anywhere else--so it's up to me (as usual).<br>Csound's "spectral modification" routines are<br>a classic example of garbageware.<br>If you try to use HETRO, you'll get an output<br>file, all right--an output file unreadable by<br>Csound.  (Various people will now claim this<br>is not so, and they'll be--let us say--"deliberately<br>mistaken.")<br>Try it.  Feed a sound into the HETRO program.<br>You'll get a .HET file out.  Now feed it into<br>your Csound program using the ADSYN command.<br>Guess what?  You'll get the message "bad<br>file read."<br>Yes, Barry Vercoe has changed the Csound<br>HETRO format without telling anyone.  Thus<br>Csound's ADSYN command now cannot be used,<br>and has not run since the December 1994<br>build of Csound.<br>(Again, many forum subscribers will claim<br>this is not so, and again they'll be--let us<br>say--"deliberately mistaken.")<br>[2] Let's talk about ADSYN.  This is an almost<br>entirely undocumented feature of<br>Csound.  Vercoe's docs from a 1989 release<br>of Csound (not present in the current 1994<br>release of Csound available on John Fitch's<br>bulletin board) claim that "more details about<br>ADSYN will be given later."  They never are.<br>ADSYN's command syntax is a mystery.  No<br>one knows what it is.  Why?  Because only<br>Vercoe knows the full command syntax for<br>ADSYN, and he isn't telling. <br>Thus ADSYN is useless and might as well<br>not be a part of Csound.  (Again, various<br>forum subscribers will deny this, and<br>again they'll be--let us say--"deliberately<br>mistaken.")<br>[3] One of the most grotesque paradoxes<br>of Csound is that the program is theoretically<br>capable of generating the world's most <br>impressive reverb.  Naturally, no diagrams or<br>sample reverb programs exist.  Of course<br>many diagrams and sample reverb programs<br>exist for MUSIC11 or other ancient programs; and<br>and of course all these sample reverb programs <br>require special instructions not present in<br>the C versin of Csound. Naturally, no one has ever <br>made public the code for any of the high-quality<br>reverbs used in Csound instruments from places<br>like CCRMA or IRCAM.  Therefore (naturally!)<br>the only reverb currently available to users of<br>Csound is the 1970-vintage reverb using<br>4 all-pass filters and 2 comb filters.  This is<br>one of the world's worst-sounding reverbs:<br>it sounds like a tile bathroom.<br>The result?<br>If you want to add high-quality reverb<br>to your Csound composition, you must<br>compile the Csound compisition dry and<br>then play it through a commercial digital<br>reverb unit, then re-record the reverberated<br>Csound composition.<br>(Naturally, various forum subscribers will deny<br>this, and naturally they'll be--let us say--"deliberately<br>mistaken."  There is a less polite term.)<br>This is so grotesque and so unthinkably<br>bizarre as to defy credibility.  Yet there it is.<br>You want high-quality Csound reverb?  Record<br>your Csound composition through a PCM-80<br>or an Alesis Quadraverb and re-record it.<br>When you realize tha this means many, *many*<br>layers of re-recording to get different levels of<br>reverberation on a Csound compotiion, you<br>begin to realize the utterly insane nature<br>of the situation.  Yet it persists.  No high-<br>quality digital reverb instrument has ever been <br>published, no source code for a Csound<br>high-quality reverb is available anywhere, <br>at any time, in any way, for any reason.<br>(Naturally, various forum subscribers will deny<br>this, and naturally they'll be--let us say--<br>"deliberately mistaken.") <br>[4] Aside from a hi-fi type "tone control"<br>and a sharply resonant filter called reson,<br>Csound offers no facilities whatever for<br>spectral modification of input sounds. (Naturally,<br>various forum subscribers will deny this, <br>and naturally, they'll be--let us say--"deliberately<br>mistaken.")  <br>Mark Dolson's LPC and the Lansky LPC routines<br>built into Csound produce unbearably distorted<br>output with so many artifacts as to be musically<br>unusable. Cutting down the input volume doesn't<br>help.  Naturally, Paul Lansky's own LPC-<br>processed sounds exhibit *none* of these<br>artifacts...so (naturally) Paul Lansky must <br>be using a bunch of special C code he hasn't<br>bothered to make public.<br>However, not only do the Dolson and Lansky<br>LPC modules in CSound produce unlistenable<br>garbage audio output, there are no other<br>less sophisticated spectral modification<br>routines in Csound (aside from the reson<br>and tone modules).<br>There is, for example, no way to apply <br>a 50-peak formant filter to an input sound,<br>or to a Csound instrument on output.  There is,<br>for example, no way within Csound to apply the<br>equivalent of a graphic or parametric<br>equalizer to the sound.  There is assuredly<br> no way to apply anything like 256 bands<br>of boost and cut to various frequencies,<br>with the boost and cut specified to the fraction<br>of a dB.<br>Naturally, this would be trivial given Csound's<br>processing capacbilities.  So, naturally,<br>it's impossible.<br>(Again, various forum subscribers will deny this,<br>and again they'll be--let us say--"deliberately<br>mistaken.")<br>[5] The IRCAM fof module is almost completely<br>undocumented. I've never been able to get it to<br>work.  <br>[6] The -f option to output floating point format<br>soundfiles doesn't work.  Output is a blaring roar.<br>Pure high-quality noise.<br>[7] On the GCC builde of Csound for the IBM PC,<br>instrument .orc files crash when the number of<br>variables exceeds 65535.  It's fairly easy to<br>exceed that number with a single large additive<br>synthesis instrument--day, 128 partials with<br>128-point amplitude and frequency envelopes.<br>So let's see: <br>Fof doesn't work, HETRO and ADSYN don't work,<br>there's no way to build reverb in Csound, the -f<br>flag doesn't work, and there are no spectral <br>modifiers other than RESON and TONE--and the<br>Dolson and Lansky LPC produce unlistenable<br>distorted garbage output when used inside<br>Csound.  You can't compile large additive<br>synthesis .orc files.  And the Dolson PVOC routines<br>produce the message MATH ERROR and a register<br>dump after time-stretching long files, but it<br>doesn't appear to affect the soundfiles.<br>That's a good 40% of Csound that doesn't work.<br>While this sounds awful, it's actually a tremendous<br>achievement.  A full 60% of Csound actually WORKS.<br>By contrast, the winner and all-time champion of<br>academic garbageware,  F. R. Moore's cmusic, is<br>100% non-functional.<br>Carrying on the UCSD music department's tradition<br>of producing unusable junk software, csmusic is *classic*<br>garbageware.  In the words of one of the members of<br>this tuning forum: "Even I know better than to download<br>that crap.  With more than 3000 files in hundreds of<br>directories, it would probably take a month of recompiles<br>just to get cmusic to work on the machine it was<br>written for--much less port it." <br>As world-class garbageware, cmusic exhibits<br>all 4 of that species' salient characteristics:<br>[1] It's totally undocmented, and totally <br>unsupported.  A vaguely-worded ASCII <br>file always arrives with the garbageware<br>executables--"You can do X, Y and Z with<br>this wonderful pieceof software developed at<br>IRCAM!"  And naturally, there's not a ghost<br>of a clue *how* to use the software.  Naturally,<br>the command syntax always involves something baroque<br>and outlandish--CRT-ALT-SHIFT-LEFT PARENTHESIS-<br>+-BACKSLASH-SUB-COLON-COMMAND-F7, or <br>some such.  Naturally, you'll *never* find this out<br>from the "docs" which arrive with the<br>garbageware, so naturally the software<br>is useless.  Inputting a "?" or "HELP COMMAND"<br>message always produces the message "INCORRECT<br>SYNTAX."<br>[2] Garbageware always needs 5 special hidden install files<br>to run on *your* computer.  Meanwhile, it comes with 5693<br>different install files for OTHER computers--a PRISM compiler <br>for the Connection Machine, an assembly loader for the <br>Commodore PET, and an INSTALL routine that runs on the <br>mercury delay line of a 1948 ENIAC--but if you want<br>to run the Garbageware on *YOUR* computer (a Mac or a<br>PC), hey!  Guess what?<br>Yep. <br>You're out of luck.  <br>Naturally!<br>Yes, indeedy, the special install files *aren't* included <br>with YOUR version of the garbageware.  And where can<br>you find them?<br>You can't!<br>The programmer wrote the garbageware to run only on<br>(say) his Kaypro Robby, and never anticipated that anyone<br>would run the software on an exotic outre machine...<br>like, say, a Macintosh or an IBM PC.<br>[3] Once you get the garbageware up and running,<br>you'll discover some delightful bugs.  The <br>garbageware goes south on Tuesday during full <br>moons but only when it's raining.  Naturally,<br>the developer at IRCAM  or wherever<br>will describe this as a "special feature."<br>One of the most interesting of the "special<br>features" of the latest GCC compile of<br>Csound is that it never stops compiling on<br>long scores.  Yes, the compile continues from<br>forever to forever--infinite compilation!  What<br>an advance!  Why not devote an issue of Confuser<br>Music Urinal to this marvellous feature???<br>Do you have 400 megs free on your hard disk?  Want<br>to use it up?  Compile a 7-minute Csound score under <br>the GCC Csound--you'll use up all 400 megs in 1 file!<br>Meanwhile, if you want to end the comiple session,<br>you do so by hitting CTRL-BREAK.  Clever command<br>syntax, eh?<br>[4] Last and best of all,  you'll finally come<br>across docs for the garbageware--docs to version <br>2.19 from Carnegie-Mellon.  However,<br>all ftp sites curently carry v. 5.62 from<br>CCRMA.  And guess what?<br>Yep!  The command syntax has changed toally!<br>The command CSOUND -D -H %1 %2 now does<br>something interesting and different--perhaps, say,<br>wiping your hard disk and reformatting it.  (Gosh.<br>What a useful feature...)<br>Hurrah for academic garbageware!  Without<br>it, where would we be?<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Wed, 20 Dec 1995 06:05 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id VAA07412; Tue, 19 Dec 1995 21:05:36 -0800<br>Date: Tue, 19 Dec 1995 21:05:36 -0800<br>Message-Id: <951220000424_59067722@mail06.mail.aol.com><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2399 href="#2399">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>12/20/1995 1:02:56 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject:  The collapse of innovation <br>in post-1988 synthesizer technology<br>---<br>In a previous post, Your Humble E-Mail <br>Correspondent mentioned the general<br>excellence of Ensoniq's synths.  They<br>sound about as good as anything else out<br>there,  Ensoniq synths are rock-solid<br>reliable, and their sampler operating<br>systems are particularly intuitive and<br>easy to use.  Anyone who battled the<br>hellish TX16-W Yamaha sampler operating<br>system or the botched E-Mu sampler OS's<br>from the late 80s is well qualified to<br>appreciate the excellence of the EPS/<br>EPS-16/ASR-10's operating system. <br>However,  there's still plenty of room<br>for improvement in the Ensoniq line.<br>Someone posted a query about that--how<br>can anyone say Ensoniq isn't up to date<br>technologically?<br>Here's how:<br>[1] The ASR-10 needs more RAM.  A *LOT*<br>more RAM.  Right now, the Kurzweill 2500<br>series can take up to 128 megs.  This<br>is a reasonable minimum amount: 256 megs<br>would be more like it.  But 128 megs is a<br>start.<br>The ASR-10, by contrast, is stuck with 16 megs.<br>This is around 90 seconds of sampling time at<br>44.1 khz stereo.  Completely unacceptable.  Far<br>too small an amount of RAM to be useful.<br>Part of the problem is the kbd controller chip<br>Ensoniq uses to address the RAM, part of the<br>problem is the burden of maintaining backwards<br>compatability with the EPS/EPS-16 &c.  <br>Backward compatability must go.  The ASR-10's<br>successor needs more RAM.  A *LOT* more.  <br>With EDO, the people at Ensoniq need to start<br>thinking in terms of *gigabytes* of RAM.<br>(As always, readers will call this "insane"<br>today, "a little over the top," in 6 months,<br>and "very sensible, but somewhat conservative"<br>in a year.) <br>[2] A rule of thumb is that a decent saxophone<br>or clarinet needs 25-40 multisamples.  The<br>ASR-10 allows 8 layers per instrument, <br>8 instruments total.  This is utterly inadequate.<br>Backward compatability must go.  Dump the 8<br>layer limit.  At least 127 A-B crossfades should<br>be allowed per multisampled instrumnet, at least<br>16 MIDI channels/instruments at a time.<br>[3] David Doty made a point about accessing various<br>layers during performance.  Clearly Ensoniq needs<br>to upgrade the ASR-10's successor to allow MIDI<br>access to each of the 127 layers within an<br>instrument.  Since these would often be used for<br>alternate tunings, it's a particular priority.<br>[4] Ensoniq may want to think about implementing<br>some new technology.  <br>Ever since innovation ground to a screeching halt<br>in the synthesizer industry, somewhere around 1988,<br>industry pundits have wondered why sales of<br>digital keyboard instruments have dropped<br>steadily.<br>There's no mystery. <br>The Korg M-1 provided the original and ever since<br>then all the keyboard manufacturers have concentrated<br>on cranking out endless xerox copies of that instrument,<br>all using exactly the same antique technology:<br>sample playback.<br>With the exception of the Yamaha VL-1M/VL-7 and<br>the E-Mu Morpheus, all current synthesizers are <br>nothing but sample playback machines that spit back<br>digital recordings burned into ROM when you press<br>a key.<br>Now, there's nothing wrong with sample playback. It's<br>a fine technology.  But after a while,  you get tired of<br>hearing nothing but sample playback.<br>Even today's samplers use exactly the same technology--<br>with the only wrinkle being that *you* get to choose <br>what digital recording is regurgitated when you press<br>a key, instead of *the synth company** choosing the sound.<br>All today's synths are basically nothing but digital<br>Mellotrons.  Where's the synthesis?<br>Does anyone remember the origin of the term "synthesizer"?<br>These instruments are supposed to *generate new sounds.*<br>Instead, we get yet another canned B-3 sample<br>burned into ROM.  And no matter how mich reverb, phasing,<br>ring modulation, flanging or delay you slather on top of<br>a sound burned into ROM, it all sounds pretty much the<br>same.<br>Around 1988, synth companies stopped making synthesizers.<br>Instead, they all followed the cattle stampede toward<br>the easy dollar.<br>The net result is that there is today hardly any reason<br>to buy one synth from one manufacturer rather than another.<br>Ensoniq's tuning tables make a difference.  But if they *really*<br>want to increase sales, how about building some actual <br>synthesizers for a change?<br>Even Yamah has dropped the ball.  Today, if you want to<br>buy an FM synth you're out of luck.  You have to buy one<br>used, or pay for a Kyma.<br>The brutal reality is there are *dozens* of synthesis<br>methods: digital additive, subtractive, frequency<br>modulation, amplitude modulation, Chebyshev<br>distortion, Miller Puckette's formant synthesis,<br>Lansky's LPC synthesis, phase vocoder analysis/<br>resynthesis, Daubechies wavelets, Walsh function <br>analysis/resynthesis, Dashow's exponentiation<br>synthesis, Hiller & Ruiz's physical modelling<br>synthesis, waveguide synthesis, many others.<br>Yet aside from Yamaha's VL-7/VL-1M physical<br>modelling synth, not a single manufacturer has<br>implemented *any* of these synthesis techniques<br>in a currently available commercial synthesizer.<br>Amazing.<br>Shocking.<br>Yet true.<br>If Ensoniq wants to jump-start synth sales,<br>they might think about implementing some of<br>these synthesis techniques.<br>Now that Korg's OASYS synthesizer has been<br>discontinued--yet another case of classic<br>vaporware--and the Gibson/G-WIZ labs' FAR<br>Fourier resynthesizer cannot be purchased<br>by anyone, anywhere, for any reason, at any time,<br>any way, shape or form...well, now that these<br>vaporware instruments have bitten the dust,<br>what else is there on the horizon?<br>Zero.<br>Zilch.<br>Zip.<br>Squat.<br>Diddly.<br>Nada.<br>These synths have joined the parade of<br>vaporware formed by the Prism synthesizer<br>(remember that one?), the additive synth<br>built from the Amiga's Amy sound chip<br>(256 additive partials--it gobbled the Amiga's<br>entire CPU and memory so the company dumped<br>it and licensed the rights to a start-up which<br>was promptly sued out of existence), and the<br>marvellous Technos 16pi...a synthesizer which,<br>if it had ever existed, would have been <br>superlative.<br>Well, chances are this is all blue-sky<br>fabulation.  Chances are Ensoniq won't bother<br>to actually build synthesizers.  Too much work.<br>And the MR rack tends to bolster that <br>viewpoint.  Yet another wannabe sample-playback<br>box, yet another digital Mellotron.  <br>It's ironic that Ensoniq is giving up the opportunity<br>to crush the Japanese synth companies.  What with<br>their little Yen crisis and teetering financial<br>system, this is an ideal chance for American synth<br>companies to steal back the initiative that was<br>lost when the Japanese licensed FM technology<br>and ground the American analog synth manufacturers<br>into the dirt back circa 1983.<br>In any case, these remarks should be understood<br>inthe context of making Ensoniq's excellent products<br>better.  Rather than angering the engineers and<br>management at Ensoniq, perhaps these words <br>will irk them into improving already fine<br>synths.<br>N.B.: Even though the Kurzweil 2500 series offers<br>gobs of RAM, the sampler does *NOT* have a<br>full-keyboard tuning table.  Thus my next sampler<br>will be an ASR-10.  Also, Dave Rossum at E-Mu<br>needs to take a look at Ensoniq's multiple tuning<br>tables and realize the *immense* importance of<br>more than one tuning table.  JI compositions<br>which change key centers demand multiple tuning<br>tables, as does work with (say) a Wilson 70-note<br>hebdomekontany in only 128 MIDI notes.  Allen<br>Strange has mentioned that he gets only 3 octaves<br>of Partch's 43-tone just scale in MIDI's 128 notes;<br>using the same timbre on 3 MIDI channels tuned<br>3 octaves apart would increase his range to<br>9 octaves.  And, as usual, Ensoniq is the *only*<br>current manufacurer to support multiple tuning<br>tables.<br>Thus, for many microtonal applications, Ensoniq<br>synths remain the only real choice.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Wed, 20 Dec 1995 22:57 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id NAA26137; Wed, 20 Dec 1995 13:56:54 -0800<br>Date: Wed, 20 Dec 1995 13:56:54 -0800<br>Message-Id: <v01530501acfddf656c7a@[128.83.112.40]><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2407 href="#2407">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>12/21/1995 4:00:01 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: unsavory habits of the musical intelligentsia -- or --<br>  the 12-TET musical elite have a point, but if they comb their hair<br>  properly, it won't show<br>---<br>The savage dictatorship of the concert-hall-and-conservatory<br>musical establishment, which Greg Taylor is pleased to<br>imagine the product of my paranoid delusions, will brook<br>no deviation from the totalitarian musical status quo.<br>The clearest example of this Orwellian and ruthless<br>state of musical conformity is of course the string<br>quartet.  Offhand, there's no reason at all why 4 fretless<br>string instruments couldn't perform in any scale desired--<br>19-TET, 31-TET, 53-TET, 11-TET, the free-free metal<br>bar scale, the Bohlen-Pierce scale, or any other tuning.<br>Naturally, any string quartet that gets handed such a score<br>will burn the offending sheaf of music paper and<br>bury the ashes.  Naturally, all string players have been<br>programmed to perform in 12, only 12, always 12, forever<br>12.<br>Another example of ruthless 12-TET tyranny is the computer<br>music scene. Given the opportunity to explore any possible<br>musical scale, any possible set of harmonies, any conceivable<br>set of melodic pitches, the contributors to Confuser Music Urinal<br>choose to...explore 12 tones per octave. (For the most part. There<br>are a few exceptions. Dashow, Schottstaedt, a few others. All<br>have been ostracized and marginalized for their troubles.)<br>This is reminiscent of aged Devil's Island convicts who, being<br>set free of their ball-and-chain, still drag one foot and move<br>with snail-like gait.  In this case the musiKKKal establishment has admirably attained its implicit goal of brainwashing<br>all & sundry into the use of 12 tones per octave: indeed, the Red<br>Chinese during the Korean war could hardly have hoped for better<br>results with U.N. prisoners.  Such a state of mindless (musical)<br>conformity would bring joy to the heart of Stalin, and<br>send Hitler to sleep with an ecstatic smile on his face.<br>After composing some pieces recently in the Greek enharmonic <br>genus for an upcoming performance in a San Diego experimental<br>music club, the true bestiality of the current musiKKKal  status<br>quo really began to become clear to me.  Think of it: for hundreds<br>of years, it would have been a simple matter to retune a harpsichord<br>or a piano to the Greek enharmonic...yet *no one* did so.  This is an<br>case of conformity unexampled in the history of mind control.<br>Such machine-like zombification would make even Mussolini cringe--<br>yet, somehow, we accept this grotesque and obscene lockstep<br>mentality as "the progress of music."  ("From 12 to 12...in the beginning<br>was 12, and 12 was the Word, and the Word was 12..."  One's puke-<br>meter pegs. One's gag reflex kicks in. And *still* it continues...)<br>The enharmonic genus is, as Ralph David Hill has pointed out, "almost<br>the most beautiful of all the Greek genera," and simple to <br>obtain on a 12-TET retunable instrument.  No note would need to be<br>retuned by more than about half a semitone.  Yet not a single composer,<br>not a single adventurous soul, dared to compose a piano sonata in<br>the Greek enharmonic genus.  Too, with 12 pitches available, more<br>than one key center could have been explored: yet this was apparently<br>too terrifying an extremum for generation upon generation of<br>composers to contemplate.<br>In the words of the Outer Limits episode "O.B.I.T.": "O savage <br>despairing planet!  When we come here to live, you will fall<br>without a single shot.  Enjoy the few years left to you..."<br>Naturally these brutal and disgusting facts will be prestidigitated<br>away by gtaylor and his cronies with yet more smoke and mirrors,<br>reason upon  complicated and  unlikely reason why the iron fist of <br>12 equal tones doesn't *actually* rule inside the velvet glove of the <br>musiKKKal concert-hall-and-conservatory establishment.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Fri, 22 Dec 1995 16:29 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id HAA22330; Fri, 22 Dec 1995 07:29:49 -0800<br>Date: Fri, 22 Dec 1995 07:29:49 -0800<br>Message-Id:  <9512220730.aa20418@cyber.cyber.net><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2408 href="#2408">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>12/22/1995 7:29:49 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Transfinite systems Nugget or Gold Brick<br>---<br>Having obtained a used Mattel Power Glove from<br>one of the members of this tuning forum, I<br>recently learned that the company which makes<br>the widget that goes twixt the Power Glove<br>and the Mac ADB port has changed its address.<br>Called the number for Transfinite Systems.<br>Someone answered.  Not Transfinite Systems.<br>Didn't know what had happened to the company.<br>Folks, it shouldn't be this goddamn hard.  You<br>try and you try and you try, and the net result<br>is: zero.<br>Does anyone out there have a new address or<br>phone number for Transfinite Systems?<br>Does anyone out there have a lead on a Gold Brick<br>or a Nugget interface box?<br>--mclaren<br><br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Fri, 22 Dec 1995 16:32 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id HAA22937; Fri, 22 Dec 1995 07:32:34 -0800<br>Date: Fri, 22 Dec 1995 07:32:34 -0800<br>Message-Id:  <9512220730.aa20424@cyber.cyber.net><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2409 href="#2409">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>12/22/1995 7:32:34 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject:  Yamaha VL-1M and VL-7<br>---<br>   The Yamaha VL-7/VL-1M physical modelling<br>synthesizers implement tuning in a weird way.<br>Here's the skinny:<br>  You can't edit the 2 user tuning table I01 and I02.<br>Instead, you have to edit them on a TG-77 or SY-77<br>or on JICalc, then do a sys-ex dump to the VL-7/<br>VL-1M.<br>  Why Yamaha chose to implement microtuning this<br>way is beyond me.  It certainly makes it less<br>convenient to retune the instrument.  As a plus, <br>user tunings are reportedly stored with the <br>instrument patches and are loaded from the disk<br>automatically.<br>  The way Yamaha implements physical modelling<br>on the instrument is also peculiar and worth a <br>metnion.  The physical model is fixed: a blown tube.<br>To get a Karplus-Strong plucked string sound (typified<br>by the fretless bass and sitar patches), the physical<br>model's mouthpiece is connected to its output.  A <br>kludge--but one that works.  A recirculating system<br>is created which, with appropriate losses for<br>acoustic admittance, mimcs the Karplus-Strong<br>algorithm pretty well.<br>  To get a vibrating string, the tube is apparently<br>shrunk down to near-zero width.  The resulting<br>one-dimensional tube subs for a vibrating string<br>and apparently also allows the user to apply a<br>mouthpiece with "embrouchure" to the vibrating<br>string--something not possible with a standard<br>Hiller-Ruiz vibrating string physical model or<br>the classic Julius Smith waveguide physical<br>model of the string.<br>  Rumor has it that Yamaha has a MAX patch <br>available that'll allow users to completely<br>change the internal physical model.  Instead<br>of being limited to a blown tube, the user can<br>dunk with internal VL-7 parameters and specify<br>any acoutsical system desired.  Apparently, the<br>MAX patch comes with a WARNING -- KNOWLEDGE<br>of PHYSICAL ACOUSTICS IS REQUIRED TO USE<br>THIS EDITOR.  Apparently it's easy to specify<br>an acoustic system which *cannot* produce<br>sound output. (Arthur Benade called these<br>things "tacit horns."  Nice design, no sound.)<br>  Does anyone have any knowledge of this<br>mythical MAX patch?  As a xenharmonizing<br>future VL-7 owner, this question is of<br>some interest<br>--mclaren<br><br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Fri, 22 Dec 1995 16:51 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id HAA23570; Fri, 22 Dec 1995 07:51:24 -0800<br>Date: Fri, 22 Dec 1995 07:51:24 -0800<br>Message-Id: <0099B415E1E82CFE.5467@ezh.nl><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2435 href="#2435">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>1/4/1996 8:23:26 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Paul Rapoport's article <br>"The Notation of Equal Temperaments"<br>---<br>Xenharmonikon 16, available now from Frog Peak<br>Music or from John Chalmers, contains Paul's<br>latest essay on non-12 notation.<br>This is a subject littered with caltrops. To date, no<br>one has succeeded in producing a universal notation<br>which allows both easy performance AND analysis <br>of xenharmonic music.<br>Nonetheless, Paul makes many good points in <br>this article.<br>"Despite the considerable history of ETs, few<br>theorists have studied their properties or created<br>musical notations for them systematically.  Because<br>most of the ad hoc solutions in notation of one ET<br>do not extend easily to many other ETs, such solutions<br>obscure similarities in related temperaments."<br>[Rapoport, P., XH 16, pg. 61]<br>However, the worm soon munches its way free of the<br>apple: "This article explores almost exclusively ETs<br>of the octave and implications based on harmonics<br>no higher than 5."<br>The implicit presumption? That one ought to strive for <br>a unified system of notation which relates all the<br>especially 12-like tunings with good fifths.<br>While this is a laudable goal, one needs must ask:<br>why spend so much effort on the 12-like tunings?<br>By far the most interesting equal temperaments<br>are those which have *little or nothing* in common with<br>traditional Pythagorean and 5-limit tunings.  There<br>exist many oddball equal temperaments which<br>cannot be notated usefully by a 5-limit scheme,<br>yet whose "sound" compels ever-growing interest.<br>In this regard, 9-TET, 10-TET, 23-TET, 22-TET<br>and 21-TET stand out in particular.<br>9-TET, for example, violently abjures traditional notation,<br>yet it remains an endlessly fertile breeding ground<br>for xenharmonic compositions. In fact Erv Wilson has<br>called it one of his favorite tunings.<br>Paul derives several guiding principles:<br>[1] Additional signs must be perceptually distinct<br>from one another.<br>[2] Notation must reflect the determined nature of<br>the termperament.  If there's more than one<br>way of deriving the temperament, there should <br>be more than one way of notating it.<br>[3] Additional signs beyond bb X, etc, should be<br>created for kommata representing the differences<br>in pairs of multiples of just intervals.<br>The first 2 points are eminently sensible. <br>Point 3 seems incomprehensible to me.  If you're<br>going to relate your equal temperament explicitly to <br>just intonation via the notation used, you might as<br>well abandon equal temperament and go straight to<br>just intonation.  Few equal temperaments < 48 are awfully<br>JI-like, and all of 'em contain internal structures <br>which inevitably frustrate the attempt to view<br>them as this or that outgrowth of just intonation.<br>As a result, many of the intervals which Paul <br>defines as "kommata" do not function as such in <br>equal temperaments below 48-TET. For instance, in 22-TET<br>a single scale-step is numerically a fair approximation<br>of the Pythagorean komma, but it does NOT REMOTELY<br>function like a just interval in context.(Significantly,<br>Paul does not discuss 22-TET.)<br>Again, the 1/17 octave interval in 17-TET, while<br>numerically near-indistinguishable from the <br>difference twixt the 6/5 and the 5/4, sounds in<br>practice like a semitone.   In an actual 17-TET<br>composition, this interval contains NO audible <br>implications of just intonation whatever.<br>31-TET contains an interval quite close to the<br>41.059 cent "diesis," yet a single scale-step of<br>31 conjures up no auditory ghost of just<br>intonation.  In fast chromatic runs,  the 31-TET<br>scale-step functions like a very strange semitone,<br>and when used as a passing-tone twixt chords <br>its function is a somewhat small chromatic<br>passing-tone.<br>The idea of imposing on any but a few ETs with very<br>good fifths (all > 48, 46, 43, 41, 39, 37, 36, 34, <br>31, 29, 24, 19, 17, 12) a set of just kommata purporting<br>to represent the substructure of the tuning<br>seems suspect to me.  Many intervals numerically<br>close to JI kommata do not function as such<br>such in the context of the equal tempered scales below<br><br>48-TET, and the futile attempt to force them to do so <br><br>produces mediocre music.  <br>Examples of such music include some of Easley <br>Blackwood's "Twelve Microtonal Etudes For Electronic<br> Music Media," a project only partially successful. <br>The etudes which hew most closely to Blackwood's<br>theoretical and notational principles prove LEAST<br>successful as music: in particular, 17-TET, 16-TET,<br>19-TET and 20-TET.  Blackwood jams 19-TET into a<br>12/oct straitjacket, and his 19-tone etude<br>suffers greatly from his refusal to showcase 19's<br>exotic non-Pythagorean intervals.<br>In the 16-TET etude, Blackwood derives an awkward<br>pseudo-tonal mode which goes against the inherently<br>anti-tonal, non-cadential grain of the tuning,<br>and the result sounds bad. The 17-TET etude suffers <br>grievously from Blackwood's unwillingness to recognize<br>& use the 5-unit neutral third as the ONLY functional<br>triadic third, while the 20-TET etude is mangled <br>by Blackwood's relentless insistence on generating<br>diatonic modes from 20/oct, rather than exploiting its<br>intercessant circles of NON-diatonic pentatonic 5ths<br>(as he did in 15-TET).<br>All of these problems stem from Blackwood's<br>doomed attempt to extend 12-like structures<br>into entirely xenharmonic tunings. He could have<br>avoided these faux pas if he'd ignored his<br>Pythagorean notational kommatic calculations and <br>relied on his ear instead of v, a, k, t and p.<br>To put it succinctly, Easley Blackwood concentrated<br>far too much on the "harmonic" and far too little<br>on the "xen" aspects of these xenharmonic scales.<br>By contrast, those etudes in which Blackwood <br>pretty much tossed out his theories and just sort <br>of gave up & winged it seem by FAR the most successful<br> musically: 13-TET, 23-TET, 14-TET.<br>Moreover:<br>In calling Blackwood's project "the most substantial<br>non-improvised recorded project in different<br>equal temperaments," Paul renders a decidedly<br> peculiar definition of "notation."  Most of us would<br>argue that William Schottstaedt's and Jean-Claude<br>Risset's and James Dashow's and John Chowning's<br>and Richard Karpen's and Richard Boulanger's <br>computer compositions are FULLY notated...they<br>simply use a notation radically at odds with Paul's<br>cherished Pythagorean common-practice-period-based<br>paradigm. <br>Moreover, my own MIDI compositions and those of <br>many other xenharmonic composers use a notation<br>which is also perfectly standardized, entirely<br>reproducible, and which allows others to examine<br>and analyze the compositions--we use the MIDI<br>file format in which notes are represented as numbers<br>from 0 to 127.  Again, presumably because this<br>notation is something that Beethoven wouldn't have<br>used, somehow our compositions don't exist and<br>aren't worthy of audition, analysis or (presumably)<br>mention.<br>Peculiar indeed.<br>This leaves aside, of course, algorithmically<br>composed xenharmonic music.  That's a whole 'nother<br>passel o' varmints, chilluns.<br>Yet all the pieces of music mentioned above are carefully<br>and painstakingly composed, note by note, with *AT<br>LEAST* as much attention to detail as shown in <br>Blackwood's scores.  The main difference is not<br>that "many such [electronic/computer music] works<br>are created without a score," but rather that they use<br>musical scores which Paul chooses *NOT* to recognize <br>as a valid symbology.<br>Thus, while Paul mentions "this article does not <br>address the issue of the utility of scores," it ALSO<br>(much more glaringly) does not address the issue of<br>whether a piece of carefully-composed, closely-<br>worked-out music notated in a completely untraditional<br>way (e.g., Csound .sco file or MIDI file) ought to be<br>treated as though it doesn't exist merely because<br>the notation cannot be viewed as a variant of<br>some 19th-century central European concoction.<br>(Slippery slope time: do Gregorian chants notated<br>with neumes qualify as musical scores?  If so, why <br>don't MIDI files printed out in piano-roll notation?<br>And why aren't sonograms of Risset's and Chowning's<br>and Dashow's and Schottstaedt's and Lanksy's <br>computer music pieces *also* scores?  ...We're on the<br>slippery slope, and it's gettin' slipperier by the minute...<br>In desperation,  one MIGHT claim that 19th century musical<br>scores allow acoustic performers to reproduce the music.<br>This (such logic goes) distinguishes them from MIDI<br>files or Csound .sco files.<br>But how many live acoustic xenharmonic concerts did<br>YOU attend last year?  And didn't ALL of 'em use one-of-<br>a-kind exotic homebuilt acoustic microtonal instruments?<br>So what good is a 19th-century-type score if there's only<br>one set of microtonal instruments in the world that <br>can play 'em?<br>..Slippery slope time, kiddies!  Let's face it: <br>essentially no one attends or gives live acoustic <br>concerts any more, and since 99.999999% of the music we<br>all hear is now delivered via electronic media, this is<br>a VERY weak and flabby and etiolated argument for ANY <br>particular flavor of musical notation.) <br>Paul's chart of kommata is admirably clear and his<br>ranking exemplary; he is probably right that,<br>for ETs with good fifths, the syntonic komma is<br>most important for quasi-19th-century notation.<br>Paul makes a good point in dealing with 17:<br>"the third in question (5 u) happens to lie very close<br>to half way between the actual just major third<br>(386.314 cents) and just minor third (315.64 cents).<br>It may therefore be interpreted as either or neither,<br>depending on musical treatment of the temperament."<br>This leads to an alternate notation which does not<br>involve sharps or flats, and proves much superior to <br>Easley Blackwood's notation for 17.   <br>However, those of us who've worked extensively<br>with 17 would go even farther--many of us would<br>contend that 17 has only ONE functional triadic third:<br>the 5-unit third.  The so-called "major" third in 17<br>is unbearably dissonant and useful only in melodies,<br>or vertically as a passing tone or a cambiata.   Thus <br>many of us would urge that the so-called "major" third<br> of 17 be notated as a species of fourth--since, like <br>that interval, it is functionally unstable when employed<br>vertically.<br>Paul's 2nd notation of 53 seems as good as any other. <br>It avoids the problem of too many flats and sharps, <br>as usual by substituting odd new symbols. Again,<br>this eases clutter but reduces sight-readbility. New<br>symbols instead of the familiar sharp & flat will<br>always prove more ambiguous for sight-readintg,<br>since they're by definition unfamiliar.<br>Paul's first notation for 25-TET seems less than<br>successful, since it uses note-names E & F.<br>25-TET's most obvious audible characteristic is<br>its pentatonic "mood." This, because 25 boasts<br>not one but 5 circles of identical 5-TET fifths.  <br>The 25-TET fifth sounds unmistakably pentatonic--<br>it's the same 720-cent fifth found in all multiples<br> of 5-TET up to 45-TET. <br>Thus, a notation which implies that there are<br>more tones than sharped- or flatted-versions<br>of C, D, E, G and A proves less than useful.<br>Paul's 2nd proposed notation admirably corrects<br>this problem and exposes the five pentatonic<br>circles of fifths, as does Paul's third<br>suggested notation. This is a big improvement<br>over Blackwood's notation, which retained<br>E and F and B and C as exact enharmonic <br>equivalents (talk about willful obfuscation!).<br>Paul also points out that even *his* generalized<br>notation breaks down for ETs without fifths.<br>As an example, he gives 13...which has certainly<br>resisted any attempt to force it into a traditional<br>notational mold.<br>This is inevitable.  No notation can cover all<br>equal temperaments.  The main question is:<br>where ought the notation to break down?<br>And how?<br>Curiously absent in this regard are tunings with<br>good fifths but absolutely no point of contact to<br>traditional tunings: 26-TET, 22-TET, 35-TET, etc.<br>Paul's treatment of 13-TET as every other note<br>of 26-TET strikes me as peculiar, inasmuch<br>as the two tunings bear not even the most remote<br>audible relation to one another.  Any relationship<br>is a purely augenmusik calculated-numbers-on-<br>paper sort of thing, and does not strike me as<br>productive.  Similarly, notating 11 as every <br>other note of 22 would be equally fruitless--the <br>mind can calculate, but the ear cannot hear, <br>a relationship between the two.  In both cases,<br>one must *listen* to the tuning and *throw out* the<br>numbers if they conflict with common sense.<br>In both cases, notation for 11-TET ought to bear<br>NO resemblance to notation for 22, ditto<br>notation for 13 and 26.  If the two tunings sound<br>utterly different, they should be notated utterly<br>differently.<br>Perhaps Paul should add this as a 4th general<br>principle...?<br>Paul's treatment of negative kommata (33-TET)<br>seems eminently reasonable.  By avoiding sharps<br>and flats, many notational paradoxes are averted.<br>Of course, dispensing with sharps and flats also<br>eliminates much of the analytic value of a <br>musical notation.  If you can't tell at a glance<br>whether one note is higher or lower than another,<br>it automatically poses problems for musical<br>analysis.  In this case, one might be better off<br>studying a printout of the MIDI note numbers, or<br>the Csound .sco file Hz values.  But for Paul's<br>purposes it is obviously better not to raise such<br>unsettling questions.<br>His treatment of 14-TET proves less satisfactory.<br>Alas, in 14 (as in 7-TET) the modes collapse back<br>into the keys.  There is no major or minor: 3<br>scale-steps give 257.1 cents, too small to<br>sound or function as a minor third, while 4<br>scale-steps yield 342.8 cents, a neutral <br>third antithetical to Pythagorean theory. 5<br>units = 423.5 cents,  too large to function<br>as any kind of recognizable major third.<br>This situation proves so puzzling to devotees of <br>19th-century-style symbology that it forces<br>the unwary notation-theorist to twist hi/rself<br>into knots to get out of the problem.<br>Notating 14 by taking every other note from 28<br>begs the problem.  In fact, the issue is that<br>14 has two circles of 7 identical fifths, whereas<br>28 has 4 of them, and they ALL use neutral intervals<br>as building-blocks.  The 2-out-of-28 dodge  <br>obscures this basic fact, and tends to dupe the<br>inexperienced xenharmonist into imagining<br>that 14 has something like a major or a minor<br>mode when in fact it has neither: merely two<br>overlapping neutral 7-tone scales melding into<br>a neutral 14-tone scale--and not a diatonic 14,<br>either.   Logic would indicate two simple<br>overlapping sets of identical A B C D E F G <br>symbols.  Perhaps  A  A*  B B* C C* D D* E E*<br>F F* G G*? (Ivor Darrg's notation.)<br>This example illustrates the problems that Paul's <br>generalized notation creates when there are<br>NO Pythagorean landmarks--in this case, because<br>the multiples of 7-TET up to 42-TET are constructed<br>from completely non-diatonic building blocks.<br>A Pythagorean musical paradigm fails when faced<br>with 7 anti-diatonic utterly equidistant tones:<br>it flails like a moth caught in a  searchlight.<br>The product of a xenharmonic notation based on <br>inappropriate diatonic kommatic assumptions is bound<br>to falter & collapse for multiples of 7-equal.<br>In fairness, Paul points out the problems his notation<br>encounters with 50-TET, which is certainly no<br>surprise:  no proposed notation has dealt adroitly<br>with such an oddball tuning.  (Ditto 32, 27, 29, and<br>particularly 35, which is probably the ultimate <br>nightmare from notation hell!)<br>Paul's introduction of numbers as superscripts is<br>clearly UNsuccessful.  The entire reason for using<br>symbols to notate notes, rather than Arabic numerals,<br>is that the human brain has evolved a marvellous<br>pattern-recognition facility which operates at vastly<br>greater speed than any possible number-calculation<br>facility.<br>Once memorized, symbols are instantly processed<br>by a huge glob of visual cortex.  Ergo, the<br>miracle of sight-reading.  Not so numbers.  Numeric<br>stuff crawls through the  forebrain, where it clogs<br>everything up and bogs everything down.<br>Thus, it is impossible to instantly sight-read<br>columns of numerals, whereas one can easily sight-read<br>and musically analyze a bunch of visually striking<br>symbols.<br>Combining numerals with symbols forces the<br>brain's spiffy pattern-recognition wetware to slow<br>down to the pace of the number-recognizing forebrain <br>(a much more recent and thus less efficient evolutionary<br>addition), auguring ill both for the prospective <br>sight-reader AND the would-be music theorist.<br>Paul points out that F. R. Herf's and E. Sims' 72-TET<br>notation is a one-off chimera, not useful for other <br>temperaments.  True, alas, and typical of all too many<br>xenharmonic notations based on but a single tuning.<br>The same could be said of Joseph Yasser's 19-TET <br>notation, etc.<br>Overall, the article is refreshing and offers<br>excellent insights.  While many of us would quarrel<br>with the issue of what constitutes notation, Paul<br>appears to have generally succeeded in producing<br>a notation flexible enough to accomodate non-weird<br>non-oddball equal temperaments below about 53--<br>or at least, those which boast good fifths.<br>In my judgment the "weird" tunings like 26<br>and 19 and 22 and 32 demand entirely separate<br>treatment.  Ideally, thse tunings ought to have their<br>OWN notations--preferably as distinct as possible<br>from any others.<br>It seems clear that sharps and flats are most useful<br>in those tunings which *sound* as though though they<br>have recognizable semitones.  Thus, use of sharps and<br>flats in 19 is wilfully perverse--and hellishly confusing<br>in 9 or 10.  There may be no way out of this conundrum.<br>The issue of ETs without fifths was deftly resolved<br>by Augusto Novaro, who simply proposed using<br>numbers instead of noteheads on a single staff<br>line.<br>Incidentally, by proposing a notation for 171-TET<br>Paul has also notated the non-octave scale Carlos<br>Gamma, since it is audibly identical to every 5th note<br>out of 171-TET.<br>A much larger issue is the quesion of whether 7 basic<br>note-names is or should be the be-all and end-all of<br>music notation.  Miller's article "The Magic Number Seven,<br>Plus or Minus Two" (J. Psychol., 1956) makes it clear that <br>the human brain can efficaciously process as few as 5<br>or as many as 9 different note-names.  Yet there have,<br>to date, been almost NO suggestions for eugmenting<br>the basic A B C D E F G seven note names by<br>including up to two more--say, H and I (NOT to<br>be confused with the German H for "B flat").<br>There have also been NO discussions whatever<br>to my knowledge about 6-note or 8-note modes,<br>especially in prime-number ETs.<br>(How about it, Mnauel?  Any chance of your <br>writing a computer program to find & list all<br>the 5-, 6-, 7-, 8-, and 9-note modes of every <br><br>relatively prime ET with fifths less than 21 <br><br>cents away from 3/2, from 5/oct through 53/oct?)<br>Why such 12-centric thinking?<br>Why must ALL xenharmonic equal temperaments<br>employ always and only SEVEN note names?<br>Why must ALL xenharmonic musical modes use always<br>and only 5 or 7 notes?  <br>True, 5 and 7 are relatively prime to 12--and so what?<br>6 and 8 and 9 are relatively prime to 19, or 17, or<br>29. <br>Why only 5- or 7-note modes when we move outside<br>of 12 tones/oct? <br>Why not 6? <br>Why not 8?<br>Why not 9?<br>Paul will probably take issue with some of<br>these points, particularly where music-theory students<br>analyzing pieces of xenharmonic music are concerned.<br>However, I would point out that so few xenharmonic<br>pieces of music have been composed--and so few<br>music students have gotten together to analyze them!--<br>that to date the issue remains a pie-in-the-sky<br>abstraction at best.<br>It is entirely possible that xenharmonic composition<br>will demand such a schismatic break with the past that<br>previous 19th-century notational paradigms must<br>be thrown out.  However, we must be wary of such <br>proposals.  John Cage and other foolish folk made <br>similar noises in the 50s about *their* brand<br>of foofaraw, and--as the magazine "The Wire" put it <br>so concisely in its November 1995 issue--"John<br>Cage's music was intensely theoretical and centered <br>around the cult of personality of John Cage, and as a <br>result most of it is today unlistenable." <br>Claims that "THIS musical revolution requires a COMPLETE<br>break with the past!" are perennial, and have never proven<br>true.  Thus we must view with the utmost skepticism any such<br>pronouncements made on behalf of microtonality.<br>For the moment, until this issue is resolved, Paul's article<br> seems an admirable advance in the state of the art of <br>microtonal notation.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Fri, 5 Jan 1996 08:43 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id XAA29081; Thu, 4 Jan 1996 23:43:23 -0800<br>Date: Thu, 4 Jan 1996 23:43:23 -0800<br>Message-Id: <01HZMVBYZ5YA9D7TAS@delphi.com><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2440 href="#2440">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>1/5/1996 2:16:09 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: novelty, craftsmanship and microtonality<br>---<br>Among its many blessings, musical modernism bequeathed <br>post-1945 composers  the freedom to explore new<br>musical forms and new musical languages.  Among its<br>many sins, musical modernism elevated novelty as<br>sole yardstick of musical value.<br>Like Marxism, musical modernism is now defunct.  Each<br>ideology  discredited itself after failing its promise to<br>engineer the ultimate state of human affairs.<br>In the case of Marxism, history had reached<br>its end...or so its followers were told.<br>Any day, "real soon now," world communism would produce<br>a workers' paradise.  <br>Similarly, in the case of musical modernism,<br>musical history supposedly ended in the 1920s with<br>Schoenberg's invention of the tone row and the various<br>fetishes concocted by post-Webern serialism.  After 1930,<br>(according to the modernists) no further musical<br>evolution was possible.  All future serious music, from 1930<br>until the end of time, could consist only of successively<br>more subtle refinements of serial atonal technique.<br>(Some would call them successively more bizarre<br>perversions of the basic fetish, but this is a matter<br>of terminology. Whether one calls one's attire "a stylish<br>informal outfit" or "leather S&M bondage gear" depends on<br>one's point of view.]<br>Of course the existence of *this* microtonal tuning forum<br>disproves musical modernism's claims.  If 12-tone<br>serialism was in fact the beginning and end of all musical<br>wisdom, why did subsequent generations of  composers <br>bother to reach outside the 12 sacred tones? After all,<br>serial atonality stood at the very apex of musical evolution--<br>so any deviation from that orthodoxy constituted a fall from <br>grace. Microtonality can only be viewed by the modernists<br>as, in John Cage's words, "just another wing on the chapel,"<br>one of the most breathtakingly short-sighted faux pas <br>by a Zen  master of short-sightedness.<br>Thus anything other than the standard 12 tones per octave<br>constitutes a debased state of musical practice, according <br>to the Holy Writ brought down from Mount Princeton by<br>Milton Babbitt and his toadies.<br>This, of course, shows up one of the most glaring flaws<br>of modernist dogma: in idolizing novelty for its own<br>sake,  modernism creates a self-destructive paradox.<br>To wit: if it's the ultimate endpoint of musical evolution, <br>then any other kind of music cannot be taken seriously.  <br>But if novelty is the exclusive measure of musical value, <br>then music MUST constantly change  in order to be taken <br>seriously.  <br>Thus modernism demands that, in order to measure<br>up, new music simultaneously remain the same and <br>constantly change.  Since this is obviously<br>impossible, modernist music faced irreconcilable internal<br>conflicts.<br>One harks back to the berserk computers in old Star Trek<br>episodes: "ERROR!  ERROR! ILLOGICAL! ERROR!"<br>There remains the question of which of the three tenets<br>of musical modernism can be salvaged for future <br>generations of composers--if indeed *any* of its tenets<br> can be salvaged.<br>The existence of this forum would tend to undermine<br>the odd notion that there is something sacred about<br>the number 12 when applied to divisions of the octave.<br>The whole idea is reminiscent of those alleged "666"s<br>in the Procter & Gamble's logo. <br>But what about the value of atonal serialism, and  <br>of using novelty as the exclusive basis for judging <br>the quality of new music?<br>Like most late 20th-century trends, the reaction against <br>serialism has gone overboard.  Some excellent serial<br> music was composed early in this century--almost<br>all of it prior to 1945. Perhaps with a reduction<br>in the total number of tones (Schoenberg's first serial<br>composition used 11 out of 12) or a change to new<br>tuning sytems, or the separation of the yoked requirements<br>of atonality and serialism (in 19-tone equal temperament,<br>for instance, a 12-tone serial row can modulate from one<br>key center to another--see M. Joel Mandelbaum's Prelude<br>No. VI, 1961) serialism will provide a useful direction<br> for future composers.<br>This leaves the question of  using novelty as a yardstick<br>for quality.<br>By itself, novelty is a dead end.  One of the most peculiar<br>and interesting experiences I've had recently is in<br>making up a computer hard disk file of 3 CD recordings<br>interleaved at random.  The three compostions are<br>the second movement of  Schoenberg's "Five<br>Orchestral Pieces" from 1915, Stockhausen's "Gruppen"<br>from 1958 and Elliott Carter's "Orchestral Variations"<br>from 1989.  Each of these compositions was created<br>about 30-40 years apart, yet the overall effect of listening <br>to them is that they're basically the same piece of music.<br>This illuminates the paradox of using novelty as the standard<br>for judging new music.  After a generation  of trying<br>all possible new combinations of instruments and<br>musical structures, new music got caught in a rut.<br>Very quickly all possible wacky schemes for generating<br>new shock-value stunts are used up: scraping phono cartridges,<br>shooting a machine gun at a piece of manuscipt paper,<br>rolling naked women in paint on a graphic score, <br>performing a score without sound so that only the<br>finger-clicks of the woodwinds and rustle of string players' <br>sleeves make noise; composing huge textural<br>pieces in which every piece in the orchestra perforrms a<br>different melody, notating impossible-to-play solo<br>instrumental pieces with far too many embedded<br>tuplets and extended techniques for humans<br>to perform; ad nauseum.<br>Wjether it's whipped cream and hamsters, or flipping coins<br>and burning pianos...the whole sorry spectacle tends to blur<br>after a while.<br>After a few years, every possible three-card musical <br>monte trick that could be tried *had* been tried.<br>Thereafter, so-called "serious" modern composers ran<br>up against the limits of the human perceptual system.<br>While they continued to produce music that *looked*<br>ever more complex on paper, to the human ear it *sounded*<br>the same as last week's purportedly "breakthrough" new<br>composition, and as next week's supposedly "groundbreaking"<br>new composition, because the human perceptual system<br>had saturated.  <br>Beyond a certain level of complexity, all those notes <br>lumped into a big random glob; beyond a certain<br>level of rhythmic subtlety, all the embedded n-tuplets<br>sounded like a Parkinson's patient  playing <br>"chopsticks." <br>Thus novelty (paradoxically) when pushed to its outermost<br>limit forced modern composers away from so many perceptible<br>and comprehensible musical structures that the only <br>structures and techniques left were imperceptible.<br>The result?<br>Random-sounding junk.<br>This is the state at which so-called "serious" composers<br>(most of whose compositions could not be taken seriously)<br>had arrived by the late 70s, and it is also the reason for<br>the existence of this tuning forum.<br>As a result,  novelty  is not a useful yardstick of compositional<br>value.  Any more than the length of a composition is useful as a <br>measure of value...  Other measures of compositional<br>quality must be found.  <br>I would suggest craftsmanship and competence, at <br>the risk of being burned at the stake--since these values<br>are even more discredited nowadays than atonal<br>serialism.  <br>As witness young composers like Alison Cameron--folks <br>with plenty of raw musical talent who haven't yet mastered<br>elementary musical skills like learning when to take a<br>breath (metaphorically speaking), or constructing a<br>musically interesting dramtic arc... Much less  the<br>arcane and forgotten art of counterpoint.<br>Oddly, although serialism and atonality have been completely <br>devalued by the doyens of today's musical avant garde, most <br>composers who call themselves post-modernists still worship <br>at the musty altar of novelty and still obsess over the <br>length of their compositions.<br>This is true even in microtonality, and it's proven a real<br>surprise to me.  More than one person has dismissed<br>this or that just intonation composition on the grounds<br>that "it's just another 7-limit piece," or "it's just another <br>example of 13-limit."  <br>We who compose outside the 12 tone scale should take note<br>(all puns intended) of this lamentable trend<br>and be on our guard against it.  Just as novelty was<br>ultimately self-destructive and trivializing when misused <br>as a measure of musical quality, it is equally self-<br>destructive when applied as the gauge of <br>a microtonal composition's worth.<br>One of the greatest sins of musical modernism was the<br>devaluation of basic competence in favor of stunts and<br>scams.  This ultimately led to the eradication of a whole<br>spectrum of basic skills from an entire generation <br>of composers.  <br>Until the recent advent of the MAX composition <br>language and the widespread use of MIDI in <br>post-modern music,  counterpoint was a lost<br>art among modern computer composers.  (With notable<br>exceptions: Lansky, Schottstaedt, et alii.) The ability <br>to write an interesting melody, add another equally <br>interesting melody on top of it, turn them both upside <br>down and add another interesting melody on top, then <br>reverse the whole front-to-back and add another interesting<br>melody on top, ad infinitum...  <br>This is a forgotten skill.<br>Just as few post-modern artists have any aptitude at<br>draughtsmanship because drawing is no longer<br>emphasized in modern art classes, today's generation<br>of composers have virtually no skill at counterpoint--<br>because it is a subject no longer emphasized in modern<br>music classes.  Instead, elaborate formal methods<br>are the focus of contemporary composition courses--<br>beginning (naturally) with pitch class matrix trivia and <br>progressing through ever-more-convoluted, ever-more-novel<br>algorithmic contortions.  (I should add here that the <br>current species counterpoint exercises used in<br>composition classes are not only useless in teaching<br>real-world contrapuntal skills, but probably destructive. <br>Students get the idea that counterpoint is a dusty 16th-<br>century academic exercise without redeeming practical<br>value; the only way to *truly* teach counterpoint is to<br>require students to compose *real* pieces of music<br>using the techniques perfected in the era of ars subtilitas.<br>Since few music teachers are nowadays qualified to do this,<br>it's hardly any surprise that counterpoint is a lost art.<br>After all--how many of today's music professors can<br>even *pronounce* "ars subtilitas," much less demonstrate<br>expertly the contrapuntal techniques perfected in that<br>era?)<br>I have not addressed the question of serial counterpoint<br>as such since with more than two widely-separated notes<br>serial counterpoint is neither interesting nor perceptible,<br>and thus cannot be said to exist save in an abstract sense.<br>To his great credit, Webern understood this; the bulk of<br>his middle-to-late works use no more than two notes<br>(lines) at once.  To their great discredit, subsequent <br>generations of serialists ignored this lesson.<br>For proof of my contention one need look no farther<br>than the alleged compositions of John Cage, John Corigliano,<br>Brian Ferneyhough and Larry Austin.  These duffers<br>demonstrate a complete lack of contrapuntal<br>skills--indeed, their level of contrapuntal ability<br>is so remedial as to embarrass even a junior high<br>school student. <br>Fortunately, MIDI and MAX have radically changed<br>the character of avant garde. Music and composers <br>of more recent vintage are beginning to discover <br>that some rudiments of contrapuntal craftsmanship <br>are helpful when algorithmically combining <br>separate melodic strata.<br>Oddly enough, formal gyrations and contortions<br>with this or that fractal or this or that chaotic<br>attractor do not suffice to produce interesting<br>melodies combined and manipulated in interesting<br>ways. <br>Gosh... What a shock, eh?<br>In the same way, the extinction of the short <br>composition is a trend much to be lamented.  Indeed,<br>short pieces of music survive nowadays only as<br>commissions for large orchestra--the truism being that<br>if you compose anything too long and too hard,<br>it will take more than 1 rehearsal to learn and the<br>orchestra won't play it properly as its one and<br>only public performance.<br>The idea that a 2-minute composition is inherently<br>less "weighty" or less "substantial" than a 2-hour<br>composition is a bizarre notion, and one I'm at a loss<br>to explain.  One would expect that the collapse of the <br>romantic-composer-as-titan myth would also have<br>discredited enormous complex multi-hour-long<br>pieces of new music as the ultimate ideal for<br>the po-mo composer...  But no.<br>Oddly enough, po-mo compositions seem to have<br>suffered *more* hypertrophy of late, rather than *less*--<br>po-mo works have grown even *more* Wagnerian<br>as the 20th century winds to a close.  Thus<br>Stockhausen's wacky unlistenable multi-<br>day-long opera "Licht," LaMonte Young's<br>preposterous day-long drones, and the rest<br>of the sorry spectacle of longer-is-better<br>snore-a-thons.<br>The idea that a 2- or 3-minute-long composition<br>isn't a serious piece of music seems to have taken root<br>even in this tuning forum.<br>Amazing!<br>It's a weird and outlandish delusion...<br>According to this off-kilter topsy-turvy logic,<br>Bach's inventions aren't "real music," they're<br>just "sketches" or "demonstrations."  This is<br>a concept so strange that it just bounces off<br>my brain...I cannot imagine the hebephrenic state<br>in which such a conclusion makes sense.<br>The quality of a composition depends, one<br>would expect, on the quality of the compostioin...<br>not on its tuning, its length, its instrumentation,<br>or any other incidental factor.<br>It seems to me that this is an especially mischievious<br>misconception, and one against which we must be <br>ever-vigiliantly on guard. Particularly in<br>the case of microtonal compositions.  With so<br>many tunings to explore, xenharmonic<br>composers are especially liable to produce<br>many short compositions rather than a few<br>long ones.  ("So many tunings...so little time.")<br>Thus the pathological and fetishistic<br>worship of sheer length--the more minutes,<br>the better the piece--is particuarly pernicious<br>when misguidedly applied to microtonality.<br>--mclaren<br><br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Sat, 6 Jan 1996 06:20 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id VAA19051; Fri, 5 Jan 1996 21:20:24 -0800<br>Date: Fri, 5 Jan 1996 21:20:24 -0800<br>Message-Id: <960106001847_33235881@mail04.mail.aol.com><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2444 href="#2444">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>1/6/1996 11:33:49 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: CLM, Linux, and microtonality<br>---<br>In graciously responding to some of my<br>gripes about Csound, William<br>Schottstaedt mentioned that his CLM<br>emvironment runs under Linux.  <br>This was news to me.  Since CLM is by all<br>accounts one of the most deluxe composition/<br>synthesis environments, it's welcome news<br>indeed.<br>This forum has, since its inception, served<br>as hang-out for 2 kinds of subscribers:<br>ordinary schmucks with IBM or Mac desktop<br>systems and mostly MIDI synths and software,<br>and the few, the rich, the tenured--who generally <br>use some flavor of UNIX (NeXTstep, typically) <br>to run software-based synthesis apps like CMix,<br>CLM, or Csound.<br>Relatively few of the ordinary yutzes (like,<br>say, moi) compose much with software-based<br>synthesis languages.  In part, this is because<br>it's so much faster & more efficient to use MIDI.<br>In part it's because the academic freeware<br>is so damn hard to use and almost completely<br>undocumented, but let's not beat *that* <br>dead horse.<br>This leads to a huge echoing chasm twixt<br>the academic microtonalists and their <br>dirt-poor scumsucker "just folks" counterparts.  <br>The two groups literally speak different musical <br>languages.<br>MIDI is a dumb, slow protocol that basically<br>tells dedicated hardware when to goose-step.<br>99% of MIDI's messages revolve around<br>modulation--vibrato, filter cutoff, tremolo <br>settings, reverb depth, envelope bias, etc.<br>There is no MIDI continuous controller<br>dedicated, for example, to making a timbre<br>more inharmonic or adjusting the Nyquist rate<br>of the synth.<br>MIDI commands reflect this concern<br>with note start times. There's a note-on, but<br>no message that tells the synth how long the<br>note will be--a clear indication of MIDI's design<br>as a real-time performance protocol. 90% of the<br>parameters in all MIDI synth patches control<br>real-time modulation--response to aftertouch,<br>vibrato depth as a function of wheel position, <br>attack rate as a function of key velocity, etc.<br>MIDI is a coarse-grained protocol.  If you <br>send more than 20 or 30 note-ons, you'll<br>get arpeggios instead of chords.<br>In contrast, the software synthesis languages<br>like CLM, Csound and CMix are relatively smart<br>and very finely granular.   While MIDI doesn't<br>know or care how a synth responds to a note-on<br>message, software instruments can change <br>their behaviour depending on the note's <br>pitch, its duration, the number and type of<br>other notes playing at the same time, the<br>location in space or in the overall composition<br>at which the note appears, etc.<br>Software synthesis instruments are typically<br>specified at the level of the individual overtone<br>and involve no real-time modulation parameters.<br>Computer composers often write programs to<br>explicitly generate dozens or even hundreds of<br>parameters for each software-synthesized note<br>outside of real time, so responsiveness to <br>real-time modulation parameters is a<br>non-issue when composing in Csound or CLM<br>or CMix.  The parameters are "built in" for each<br>individual note and can be exquisitely fine-tuned.<br>This has important consequences for microtonal<br>composition.<br>Software-synthesized xenharmonies tend to be<br>very finely wrought, with layer upon layer of<br>acoustic complexity.  Software-synthesis<br>microtonality appears to be centered as much<br>around timbre as around notes.  Even in the works<br>of those composers notable for their contrapuntal<br>skill (Paul Lansky, William Schottstaedt, Bill<br>Alves, Jonathan Harvey) timbre remains uppermost<br>as a factor in the "non-12" sound of the music.<br>By contrast, MIDI microtonality centers almost<br>entirely on harmony and melody. Timbre is of minimal<br>concern, because commercial synthesizers offer<br>nothing in the way of detailed fine-grained<br>control over that parameter.<br>Retuning individual overtones remains outside of<br>the purview of the MIDI composer, *especially*<br>during the course of the composition.  (William<br>Sethares has written some custom FORTRAN <br>routines to read LEMUR analysis files and warp<br>FFT'd sounds into a given tuning, but this is<br>a rare exception, takes gobs of time, and demands<br>a sampler with enormous amounts of  RAM.  Thus Bill<br>Sethares remains the lone exception in this regard.)<br>The very model of the MIDI microtonal composer<br>is Warren Burt, whose compositions are essentially<br>contrapuntal and harmonic.  Timbre is a non-<br>issue.<br>This gives an interesting 18th-century "gebrauchmusik"<br>sound to Warren's compositions, even though they<br>use rhythms, melodies and harmonies no 18th-century<br>composer would ever contemplate, while it gives<br>the compositions of someone like Paul Lansky an<br>oddly modernistic sound--despite the fact that Lansky<br>often uses conventional 12-tone equal temperament<br>(as in the "idle chatter" series of compositions, all<br>in g minor, whitebread 12/oct).<br> To date there's been little contact twixt the two<br>camps of microtonalists.  Thus, many MIDI xenharmonists<br>confidently make statements about timbre, consonance<br>and dissonance which are simply untrue when software<br>synthesis (allowing individual partials to be retuned)<br>is involved.  In like manner, many academic microtonalists<br>lose sight of the musical forest by exploring mathematical<br>partition-function and pitch-class set/chaotic note generator <br>minutia, rather than asking the larger questions: What kind<br>of intervals does this tuning have?  How does it "sound"?<br>How can harmony and melody be used in this tuning in<br>ways which differ productively from harmony and melody<br>in 12/oct?<br>Thus, the investigations of John Clough, Gerald Balzano<br>and Carlton Gamer appear to have had much more impact <br>on MIDI microtonalists (for example) than on software<br>synthesis composers.<br>Meanwhile, the ideas of folks like William Sethares and<br>James Dashow appear to have percolated more thoroughly<br>into the software synthesis camp than the MIDI contingent.<br>This has led to further confusion and miscommunication.<br>Academics often write some of the most insightful<br>discussions about the internal structure of non-12 tunings,<br>while non-academics often write some of the most<br>useful monographs on the "sound" of non-12 tunings<br>and the interaction of tuning with timbre.<br>NeXTStep might have bridged the gap twixt these two<br>microtonal factions--but alas!  That operating system<br>is now dead and buried.  It's been overpriced FAR out<br>of reach both of academics *and* the rest of us, and is<br>now essentially defunct except on antique legacy <br>machines like the NeXT cube. (A machine roughly<br>25 times slower than the P6 @ 200 Mhz.)<br>Recently, however, Linux appeared...and this<br>operating system might finally offer a bridge twixt <br>the two worlds of microtonal composition. <br>Linux is extremely stable, according to my UNIX-<br>guru friend. Under X Windows, it's reportedly easy<br>to use.  The big stumbling block right now appears<br>to be setting up Linux to run under X Windows<br>with your particular monitor...  The process is<br>more complex than superstring theory.<br>(Do YOU know the "dot rate" of YOUR monitor?<br>Not me!!)<br>Only within the last 5 years have desktop<br>IBM machines grown fast enough to fully shoulder<br>the burden of software synthesis.  But now that<br>it's happened, IBM PC prices have dropped so<br>far so fast that it's hard to imagine anyone in or<br>out of academia will be using NeXT cubes or  <br>other legacy antique machines for very much longer.<br>The InfoMagic  4-CD set of Linux with complete<br>X Window support and all utilities now runs a<br>whopping $20 down at your local software store.<br>It's very hard for me to believe that NeXTStep-486,<br>at a cost of 5 thousand dollars (yes, $5000.00),<br>will survive the competition with the $20.00  Linux<br>operating system.<br>Linux can read DOS disks and apparently<br>offers the user the option of setting aside one<br>partition of the hard disk for DOS files.  This<br>clearly would go quite a ways in bridging the<br>gap between software and MIDI synthesis.  <br>Ideally, as a microtonal composer, I want total<br>control over EVERY asect of the composition--<br>and reasonably easy, fast, efficient control.<br>Combining Linux-based spectral modification<br>programs with CMIX, a sampler, and MIDI sequencers<br>might accomplish this.<br>My ideal system would let me tear apart an<br>acoustic sound, retune the individual partials,<br>then generate real-time scores with the ease<br>and simplicity of a MIDI sequencer.<br>Obviously this goal lies some years in the future,<br>but the Linux and DOS/Windows combo seems at<br>least a step in that direction.<br>Right now this kind of integration is essentially<br>impossible.  Even the NeXT cube didn't offer<br>MIDI sequencing with audio synchronization,<br>nor analysis with real-time resynthesis.<br>But now, with Linux, there might finally be a<br>bridge between these two styles of microtonal<br>composition.  Especially if & when someone<br>produces a microtonal synthesis program like James<br>McCartney's SuperCollider that runs in real<br>time on an *affordable* computer (the Power Mac<br>is not currentlfordable and probably never<br>will be--everyone with $4000 to spend on<br>a Power Mac raise your hand, please).<br>Such a program would bode well for interactive<br>real-time (those 90s buzz-words!) acoustic-and-<br>digital microtonality.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Sun, 7 Jan 1996 00:16 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id PAA00718; Sat, 6 Jan 1996 15:16:46 -0800<br>Date: Sat, 6 Jan 1996 15:16:46 -0800<br>Message-Id: <v01530501ad145f4f4c0b@[128.83.112.162]><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2448 href="#2448">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>1/6/1996 7:36:15 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject:  A wish list for microtonal<br> synthesizers<br>---<br>Let me tell you a story...<br>The tale starts back in 1975, when Hal Alles<br>at Bell Labs designs a spiffy board that <br>spits out 256 separate additive sine waves &<br>uses it to build the Bell Labs DIgital<br>Synthesizer.<br>Fast forward to 1978:<br>Crumar (then a big synth manufacturer, now<br>defunct) decided to build a digital synthesizer<br>based on Alles' board.<br>4 years later, Crumar rolled out the Synergy.<br>This instrument was controlled by (gasp!)<br>two Z-80 chips.  Super hi-tech, eh?  Wow!<br>A full eight bits of computing power! And<br>running at the awesome speed of 4 Mhz!!!  <br>Well, now that the laughter's over, here's<br>a sobering thought:<br>The Synergy STILL has, even TODAY, by far<br>the most complex architecture of any digital<br>synthesizer ever built.<br>Hello!<br>Ensoniq?<br>Are you there?<br>Q: What's the most important part of any<br>synthesizer?<br>A: Envelopes, envelopes, envelopes!<br>The complexity of the synthesizer's envelopes<br>ENTIRELY determines how complex and subtle its<br>sounds can be.<br>A synth with the world's most elaborate synthesis<br>algorithm, the most exotic & beautiful wavetables<br>ever designed, and the most sophisticated effects<br>buss in christendom, still sounds like crap if it<br>uses crude 4-stage ADSR envelopes for the <br>oscillators.<br>It's shocking and alarming to me that the Synergy,<br>designed in 1978, STILL has not been approached in<br>the sophistication and flexibility of its envelopes.<br>The Synergy allowed up to 16 envelope points<br>for each oscillator. You could set any two of<br>the points as loop points for sustain<br>when the key was held down.  <br>But wait!  There's more!<br>You voiced each oscillator TWICE--one 16-point<br>envelope for minimum key velocity, the other<br>16-point envelope for maximum key velocity.<br>Then the synth interpolated between those<br>2 envelopes in real time for all other <br>key velocities.<br>This gave the oscillators a remarkably subtle<br>"lifelike" quality.<br>But wait!  There's more!<br>You also voiced each oscillator TWICE for<br>the frequency envelopes--which could also<br>contain up to 16 points, for both min and max<br>key velocity.<br>The synth gave you a pool of 32 oscillators.<br>You could assign 'em any way you liked.<br>You could add oscillators or use 'em to <br>modulate one another--MORE flexibility.  Not<br>only that, but you could choose from 8 different<br>waveforms--for each individual oscillator.<br>But wait!  There's more!<br>Lastly, the Synergy let you set the amplitude<br>of each oscillator for each group of 3 keys--this<br>was essentially what Yamaha now calls "fractional<br>scaling."  <br>In effect, a digital formant filter.<br>The result?<br>Unparallelled subtlety and complexity of sound.<br>The Synergy has NEVER been equalled by ANY<br>other digital synthesizer in this regard.<br>It had aperiodic vibrato--that is, it allowed you<br>to mix a controllable amount of digital noise<br>with the LFO...again, giving the Synergy<br>a remarkable lifelike vibrato or tremolo.<br>Now, let's fast-forward 20 years...<br>Desktop supercomputers...cheap 1 gig disk drives...<br>magneto-optical storage...DSP chips cranking out<br>hundreds of MIPs...Csound on desktop machines<br>running at lightning speeds...<br>And guess what?<br>NO synthesizer manufacturer has YET implemented<br>envelopes REMOTELY as flexible and complex<br>as those on the antique 2-Z-80-controlled<br>Synergy of 1978.<br>C'mon, folks!<br>The problem CAN'T be hardware!  We've got hardware<br>up the wazoo.  We can handle such a synthesis <br>architecture with elan.  Today's synths could eat <br>those kinds of envelopes for breakfast.<br>Yet no one, absolutely NO synthesizer manufacturer,<br>has implemented such flexible envelopes.<br>To its credit, Ensoniq has done slightly better<br>than the rest of the synth manufacturers in this<br>regard.<br>Ensoniq's 8-point interpolating amplitude envelopes<br>are the closest I've seen...but that ain't <br>too close.<br>As a microtonal composer, my most basic need<br>is for a synthesizer with complex, flexible envelopes<br>each of whose oscillators can be precisely detuned.<br>The ideal would be a synth that can do what my<br>Csound instruments do: a synth that allows<br>20-point frequency AND amplitude envelopes with<br>30 to 60 oscillators at a time in real time.<br>Offer me such a synth with a tuning table, and I'll<br>fight through a nest of amphetamine-crazed<br>echidnas to buy it.<br>Until then, I gotta ask myself: why does the latest<br>issue of Confuser Music Urinal make a big deal<br>about an article that describes a chip with 127<br>additive oscillators?<br>C'mon, folks.  The Synergy offered 32 oscillators<br>(2 banks of up to 16 each) back in 1978. <br>Gimme a break.<br>It's time we moved up to the level of sophistication<br>attained 20 years ago with a pair of 4 Mhz eight-<br>bit Z-80s, don't you think?<br>--mclaren<br><br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Mon, 8 Jan 1996 16:48 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id HAA13530; Mon, 8 Jan 1996 07:48:32 -0800<br>Date: Mon, 8 Jan 1996 07:48:32 -0800<br>Message-Id:  <9601080749.aa17311@cyber.cyber.net><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2449 href="#2449">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>1/8/1996 7:48:32 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Bruce Kanzelmeyer's post,<br> Neil Haverstick's ideas about Bach,<br> guy xenharmonists vs. girl xenharmonists<br>---<br>As usual, Bruce Kanzelmeyer makes a number<br>of excellent points.  His post of some<br>weeks ago questioned the utility of<br>ever-more abstract investigations into<br>the mathematics behind various tuning<br>systems.<br>On balance, I agree. In the end the music's<br>what matters. If the elaborate theories lead<br>to music that sounds like crap--as in the case<br>of IRCAM, Pierre Boulez, Brian Ferneyhough,<br>John Cage, and Milton Babbitt, well, hell.<br>Dump the theory.  <br>Go back to noodling on the B3 in a <br>lounge in Schenechtady.<br>Questions of musical quality are necessarily<br>subjective.  My best take on the state of<br>the art in xenharmonics is that a whole lotta<br>good music's being produced.  Some of it<br>comes out of highly theoretical considerations--<br>some of it comes out of a wing & a prayer.<br>Given the unsavory tendency of the 20th century<br>to take every trend to its wildest possible<br>extreme, obviously there WILL be theorists who<br>run amok with math at the expense of music, sanity, <br>and general good taste. This is surely a trend<br>we need to keep an eye on in microtonality,<br>as in the rest of contemporary music.<br>The 20th century will NOT be remembered as an<br>era of moderation, but instead as a profligate and<br>outlandishly undisciplined period of wild excess<br>where every possible harebrained scheme was pushed <br>to the outermost edge of its wackiest implications, <br>and then several light-years beyond.<br>Well, what else is new?  What other century gave<br>us both a Hitler AND a Ghandi?  What other century<br>boasted BOTH a Piet Mondrian AND a Pablo <br>Picasso?<br>But there's room for a lot of different<br>apoproaches in a field as large as non-12<br>composition...  As Ted Melnechuk put it,<br>"Music's house has many mansions."  It seems<br>unfair to penalize or ostracize good microtonal<br>composers  just because they arrived at their<br> end product via the route of mathematics,<br>rather than intuition--or whatever other approach<br>is the fashion de jour.<br>Incidentally, this is similar to the schism twixt<br>guy & girl xenharmonists on this forum.  Women<br>consistently get repelled by the math, the relentless<br>theory, the endless terminology. Their usual <br>objection seems to be: <br>"Where's the music???"<br>Guys seems to be afflicted with a certain amount of<br>"number macho."  Something along the lines of, "Hey!<br>MY list of intervals is bigger than YOURS!"<br>Women have persistently  called fsr more discussion of<br>aesthetc isses in microtonal music...  A topic<br>which male subscribers to this forum appear to be<br>unwilling to touch.<br>Not sure why.<br>(There are exceptions. Laudably, the Scarlet Aardvark.)<br>Maybe aesthetic concerns are too touchy-feelie?<br>Maybe talking about the MUSIC, rather than the<br>NUMBERS, would leave the males a wee bit...vulnerable? <br>Or perhaps such colloquy might even touch upon <br>(horror of horrors!) the EMOTIONAL impact of <br>xenharmonic music, rather than this or that <br>komma or skhisma?<br>Well...hard to say.<br>But it do bear thinkin' on, chilluns.<br>Typical of a sizable contingent on this forum, Bruce<br>evokes the horrors of musical chaos and paints <br>a glowing picture of Appolonian order.  Of course,<br>some of us LIKE chaos.  Some of us view chaos as<br>a fertile maelstrom wherein brew dandy new<br>worlds of harmony & melody...  As Ilya Prigoine<br>points out, order only appears in thermodynamic<br>systems at the edge of disorder.  Without uncontrolled<br>and promiscuous chaos, a system tends to enter<br>stagnant cyclic states.<br>Of course the JI crowd will view this notion with the<br>utmost horror..."son cosas de la vidas."<br>Re: Bruce's objection that listeners will inevitably<br>disagree, etc. etc., & there's a margin of error<br>in all auditory systems, therefore the psychoacoustic<br>data can be explained away...<br>Nope.<br>If we were talking about ranges of error or some<br>such, the complexities of the human auditory system<br>COULD be swept under the rug.  But it ain't<br>that simple.<br>Alas, the psychoacoustic data clearly show that<br>many auditory stimuli produce contradictory<br>results when applied under different circumstances.<br>This is a conclusion that CANNOT be swept under<br>the rug.  NO amount of talk about "ranges of error"<br>or "imperfections in the ear/brain system" will<br>suffice to esplain away outright paradoxes and<br>contradictions in the human auditory system.<br>This kind of argument was put forward in the 1870s<br>to bolster Helmholtz's crumbilng Fourier analysis<br>model of the ear.  The argument didn't explain away<br>Seebeck's siren experiment, the extreme contradiction<br>twixt calculated jnds and observed just noticeable<br>differences, nor did it explain combination tones,<br>the Zwicker tone, or any of the other paradoxes<br>and puzzles which continue to plague modern <br>psychoacousticians.<br>Alas, such arguments failed in the 1870s and they<br>still fail today.  In the end, the only resonable<br>conclusion is that a LOT of complex phenomena are<br>taking place in the ear/brain system, many of<br>which appear to require contradicotry and mututally<br>exclusive explanations...and no one model of hearing<br> suffices to explain even a significant fraction of<br>the extant data.<br>As for Neil Haverstick's deification of Bach...well,<br>permit me to demur.  Bach was a fine composer who<br>also churned out a fair amount of Muzak.  His cantatas<br>are classic Muzak, the notebook of Anna Magdalena<br>Bach is pure make-work, and many of his chorales<br>and even a few of the 48 constitute mere busywork<br>noodling-around.<br>Bach was certainly an excellent composer when he<br>was at the top of his form.  Equally certainly,<br>he wasn't always.<br>In particular, the destructive idea that no human<br>can excel Bach is bizarre and outlandish.<br>In fact, Bach's lute suites (which are transcriptions<br>of his cello suites, by the way) are good music...<br>But infinitely inferior to the far more impressive <br>lute masterpieces of the late renaissance.<br>John Dowland in particular wrote many superb pieces<br> for lute which put Bach's lute suites to shame.<br>The idea that Bach is some sort of unapproachable<br>god strikes me as just plain silly. <br>As for Neil's contention that there are very few<br>great pieces of xenharmonic music, well, <br>bosh and twaddle.  I can name 20 masterpieces<br>of xenharmonic music without breaking a sweat:<br>[1] Easley Blackwood's 15-tone etude<br>[2] Easley Blackwood's 23-tone etude<br>[3] Paul Lansky's "Late Autumn"<br>[4] Richard Boulanger's "In Slow Glass"<br>[5] Gary Lee Nelson's "Fractal Mountains"<br>[6] William Schottstaedt's "Water Music"<br>[7] Jean-Claude Risset's "Inharmonique"<br>[8] John Chowning's "Stria"<br>[9] Larry Polansky's variations on "My Funny<br> Valentine"<br>[10] Ivor Darreg's "Prelude No. 1 for 19-tone<br>guitar"<br>[11] Ezra Sims' "Quintet" (1987)<br>[12] Charles Ives' "Three Pieces for Quarter-Tone<br>Piano"<br>[13] Julian Carillo's "Prelude A Cristobal Colon"<br>[14] Ivan Vyshnegradsky's "Quartet en quarts a tons."<br>[15] Alois Haba's opera "Die Mutter"<br>[16] Edgard Varese's "Arcana" <br>[17] Louis & Bebe Barron's tape score for "Forbidden Planet"<br>[18] Ben Johnston's Quartet No. 4<br>[19] Mayumi Reinhard's "Peach"<br>[20] Jonathan Harvey's "Mortuos Plango Vivos Voco"<br> And I could rattle off 30 or 40 other masterworks of<br>non-12 music without any trouble at all.  But, as always,<br>there's neither time nor space.<br>The idea that there are "very few xenharmnic masterpieces"<br>just doesn't jibe with the facts. On the cotnrary: it seems<br>clear that xenharmonic composition as a field has<br>generated a hugely disproportiate number of masterworks--<br>and at a rate that seems to be *constantly increasing.*  <br>--mclaren <br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Tue, 9 Jan 1996 02:48 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id RAA21888; Mon, 8 Jan 1996 17:48:11 -0800<br>Date: Mon, 8 Jan 1996 17:48:11 -0800<br>Message-Id: <199601090147.BAA22400@smtp-gw01.ny.us.ibm.net><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2479 href="#2479">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>1/21/1996 4:07:15 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: The adoration of the Cage-i (Round 2 of 15)<br>---<br>A recent recording session involved overdubs of<br>a cassette tape of harmonic series members 1-44<br>made 10 years ago by Jeff Stayton with megalyra <br>solos recorded last week.<br>After hearing the resulting composite, Bill<br>Wesley offered some choice comments.<br>"That sounds like an interesting use of chance. As<br>opposed to John Cage's *stupid* use of chance."<br>"You mean the idea of flipping coins to choose notes?<br>What's stupid about that, Bill?"<br>"You get a bunch of random pitches.  White noise.<br>But the human ear is specifically adapted to detect<br>and filter out noise--because if you can't hear a<br>sabre-tooth tiger's roar through the noise of the <br>jungle, you're dead.  So what did John Cage elevate<br>to highest status in his brain-dead musical theories?<br>Just what the human ear is best designed to<br>throw out...noise.  Another word for chance."<br>"But wait a minute, Bill.  Cage worshippers like to<br>point out that he didn't just pick notes at random--Cage<br>*constrained* the choice of notes and phrases.  In <br>'Music of Changes,' for instance, he used coin flips <br>to choose among constrained start-times and <br>transpositions of a set of pre-composed phrases."<br>"It doesn't matter, Brian.  If you throw the aces<br>out of a card deck, that doesn't make the distribution<br>of cards any less random after you shuffle 'em."<br>"That's a good analogy.  I wonder why none of these<br>people seem to understand that?"<br>"Because the cult of personality tends to impair judgment.<br>In the end, no matter how you constrain it, noise is noise.  <br>Even if you narrow down the choice to two notes, it's<br>still random.  And you'll detect and be bored by that<br>randomness."<br>"I've noticed that, Bill."<br>"It's why, even if you alternate between only two<br>phrase start-times, your ear will hear the random<br>distribution and find it trivial."<br>"You make a good point there, Bill.  I have to admit<br>it certainly is easy to pick a conversation out of the<br>noise of a crowded room. And it certainly explains<br>why 'Music of Changes' sounds like complete  crap."<br>"Exactly.  Noise is noise, no matter how you constrain<br>it. The notion that there's anything interesting about<br>a random distribution is a stupid idea--pure and simple.<br>It's dumb.  But then, that's the whole point."<br>"Eh?"<br>"It's what always happens in a group of monkeys.  Whenever<br>some lesser monkey shows  imagination or initiative, the <br>alpha males always crush him.  They've got to--to  maintain <br>the status quo."<br>"I don't understand, Bill."<br>"The whole idea behind Cage's music is that he wasn't part<br>of a revolution at all.  He was part of a *suppression* on the<br>part of the aristocracy.  The rich people want to play golf<br>all day and swig martinis.  They don't want *anyone* to rock<br>the boat.  You start adding extra pitches to the octave, and who<br>knows what's next?  Everything could come unglued. So the <br>artistocracy hire someone like Cage to crush people with <br>*real* imagination and drive them out of music."<br>"People with imagination?  You mean...like, microtonalists?"<br>"Yep."<br>"Well...  Cage *did* call microtonality 'just another wing <br>on the academy...'"<br>"Sure. The whole point of Cage's music was to take anyone<br>with enthusiasm and originality and horrify him to the<br>point where he gets out of the field and goes to work at<br>McDonald's."<br>"Isn't that kind of harsh, Bill?  After all, people like Warren<br>Burt are already accusing me of 'showing bad manners<br>freely, and displaying an appalling lack of gentleness and<br>generosity' to people like Cage.  God only knows what they'd<br>say if I repeated *your* comments on the tuning forum."<br>"Of course they accused you of showing 'bad manners.' Creativity <br>is considered the *ultimate* in bad manners by the aristocracy.  <br>It's another way of maintaining the status quo."<br>"How's that, Bill?"<br>"You call imagination 'rude' and then hire people like Cage to<br>make sure that only cynical, empty people have any power<br> in the field  of music.  All that talk about 'removing intention<br>from the music' and 'letting the music be itself' was nothing<br>but another way of making music students into a bunch of<br>monks who flagellate themselves on command."<br>"Flipping coins never did seem like much of a musical<br>revolution, I must admit...  But, gosh, Bill--this is pretty<br>blunt talk, isn't it?"<br>"That's a laugh!  These people bleat about 'gentleness<br>and generosity'--and the minute you suggest emperor Cage<br>has no clothes, they come after you with a bowie knife<br>and murder in their eye.  So much for 'gentleness.'  So<br>much for 'generosity.'"<br>"It *is* strange...  You'd think the microtonalists would stick<br>together, despite their minor differences."<br>"Well, remember what Harry Partch said in his program<br>notes to 'Water, Water':<br>'The creative man is not specialized by inclination, but<br>by the autocracy of modern education. (..) Ordinarily,<br>however, he is so closely intimidated by his specialty<br>that if he decides to make some slight deviation<br>from the norm, in some creative work, it will seem<br>like a 'revolution,' both to him and to others, and<br>he can easily become the progenitor of a 'new' <br>movement.  But the deviation must be slight, because a<br>large deviation is not only incredible, it isn't even<br>recognizable.  In the end, it is just ridiculous.'"<br>"You mean a deviation like throwing out octave<br>equivalence, Bill?  Or pointing out that the <br>psychoacoustic evidence doesn't support just <br>intonation?"<br>"Exactamundo."<br>"Gee...when you put it that way, Bill, it *does* sound<br>as though Cage was just another toady."<br>"Right.  Another errand boy elevated by the musical <br>aristocracy into a position of godhood to keep the <br>*really* creative people from rocking the boat."<br>"Creative people?  Like Partch? Or Carrillo?"<br>"You got it."<br>"But if I ever dared to post something like *that* on the<br>tuning forum...ye gods. They'd go ballistic, Bill."<br>"Maybe.  But from what you've said, most of the academics <br>on that tuning forum are too lazy even to write a letter.<br>So I don't think *I* have anything to worry about."<br>"Come to think of it, Bill, you're probably right."<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Mon, 22 Jan 1996 07:38 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id WAA10477; Sun, 21 Jan 1996 22:38:53 -0800<br>Date: Sun, 21 Jan 1996 22:38:53 -0800<br>Message-Id: <9601212325167216@csst.com><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2483 href="#2483">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>1/22/1996 2:39:03 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: 10 smart ideas in late <br> 20th century music theory<br>---<br>Everybody knows that  the most important<br>composers and music theorists are those<br>who influence the largest number of<br>people.<br>Everybody knows this, and it's wrong.<br>The rock group KISS influenced far more people<br>than any avant-garde theorist or composer. Should<br>we devote a chapter of every modern music textbook<br>to KISS?<br>I propose a different (and more sensible) definition of<br>"influential."<br>If a dumb fad influences 500 composers to write <br>rotten music, the idea is NOT influential.  It's a craze,<br>like pogs, or hula hoops, or pet rocks. <br>And it has no importance.<br>But if a smart idea influences 5 composers to write<br>excellent music, then the idea IS influential.  And it<br>has *vast* importance.<br>As I've mentioned before, Tops 40s corporate rock and<br>the avant garde are evil twins. They both use identical<br>means of promotion: hoopla, ballyhoo, shock-value stunts<br>and the cult of personality. They both use identical means of<br>measuring a composer's importance: SHEER QUANTITY.<br>If rock star X sells 8 squillion CDs, he's a "genius" and<br>a "brilliant composer."  If avant garde music theorist<br>X inveigles 50,000 gullible students to spew out<br>reams of bad music derivative of the latest craze,<br>he's a "genius" and a "brilliant composer."<br>Obviously, a new definition of "influential composer"<br>is required.<br>Now, what this has to do with microtonality is obvious:<br>the two most influential (as opposed to faddish) composers<br>of the second half of the 20th century are clearly Conlon<br>Nancarrow and Harry Partch. <br>Neither of these guys were on the cognitive elite's TOP<br>TEN charts during the 50s or 60s.  On the contrary. As<br>Joel Mandelbaum has pointed out, "It is a matter of<br>everlasting shame that the musical establishment<br>gave Harry Partch the back of the hand treatment."<br>This alone should give all music students<br>pause.   <br>When you read the conventional history texts of 20th<br>century music, ask yourself: Why isn't microtonality <br>mentioned?  And why isn't music by "the big names" of<br>the post-1950s played any longer? <br>The answers to these questions are connected.<br>And they can be found in the following list of the 10 <br>best ideas of post-1950 music theory:<br>---------------------------------------------<br>SMART IDEA #1:<br>Joseph Yasser pointed out in his 1938 book "Theory<br>Of Evolving Tonality" that musical tunings change<br>with time.  Intonation fashionable in one era becomes<br>unfashionable in another.<br>Any composer who, in the 1940s or 1950s, had read<br>Yasser's book would have realized that serialism was<br>just another fad...neither better nor worse than<br>Venetian antiphonal brass choirs, Baroque quodlibet,<br>or late Medieval mensuration canons.  Yasser's realization <br>that tunings are not static, and that musical cultures<br>influence one anther and tend to blend and intermingle<br>over time, is a lesson that STILL hasn't been absorbed <br>by the writers of conventional music theory texts.<br>---------------------------------------------<br>SMART IDEA #2:<br>Harry Partch proposed abandoning the conventional<br>12 tones. Instead, he built his own instruments<br>and trained his own performers.  It doesn't much<br>matter what you abandon those 12 tones for...<br>just intonation?  Non-12 equal temperaments?<br>The original tunings of Dowland and Byrd and Bach?  <br>Non-just non-equal-tempered scales?<br>The crucial decision is to kick over the chess board<br>by building your own instruments.  This alone<br>changes the rules of the conservatory-and-concert-<br>hall con game.<br>The fact of the matter is that Partch's decision to<br>step on the 12-tone anthill breathed much-needed<br>life into post-1950s music... And the existence of<br>this tuning forum is testimony to the continuing<br>power of that idea.<br>--------------------------------------------<br>SMART IDEA #3:<br>Jean-Claude Risset's idea (following John Pierce's<br>and Max Mathews' 1966 & 1969 papers, & later taken <br>up by John Chowning, James Dashow, William Sethares<br> and most recently Parncutt and Strasburg in the <br>1995 PNM article  "'Harmonic'  Progressions of <br>Inharmonic Tones") of basing non-12-tone methods <br>of tonal and timbral organization on the findings <br>of modern psychoacoustics  was a brilliant one.  <br>It has consistently led to beautiful music.<br>-----------------------------------------<br>SMART IDEA #4:<br>Erv Wilson's notion of augmenting with permutation<br>techniques the conventional Partchian organization <br>by harmonic and subharmonic series (viz., the tonality <br>diamond).   Erv's technique offers a more tonally<br>efficient  alternative to Partch's tonality diamond, <br>and it has proven  exceptionally useful to just intonation  <br>composers.  <br>As Kraig Grady wrote in 1/1, "With the introduction <br>of Erv Wilson's combination product set, Just intonation <br>took a giant leap forward." [Grady, K., "Erv Wilson's <br>Hexany," 1/1,  7(1), 1991, pp. 8-11.]<br>If anyone needs further proof, Warren Burt's superb <br>composition "Vingt Enflures Sur L'Enfant Melvin" is<br>a vivid demonstration of the musical value of Erv's ideas.<br>----------------------------------------------<br>SMART IDEA #5:<br>Fokker's introduction of ratio space has influenced<br>generations of composers to produce interesting<br>and impressive music.  The idea has been extended by<br>Tenney, Polansky, Johnston, Chalmers, Scholz and<br>many others. One of the very best po-mo xenharmonic<br>compositions, "Lattice [2237]" by Carter Scholz, would<br>be impossible without Fokker's original organizing<br>principle.<br>----------------------------------------------<br>SMART IDEA #7:<br>Lou Harrison's notion that all music students should<br>be trained in at least one other culture's musical<br>traditions.  If this were done, it would end at one<br>stroke the onanistic over-theorizing, the bizarre<br>yearning to convert music into a species of <br>mathematics... Yes, it might even straighten out the <br>tortuous verbiage that has made a bottomless <br>chum bucket of 12-tone  music theory.<br>Lou's idea is a brilliant one, long overdue.<br>When will someone put it into practice?<br>----------------------------------------------<br>SMART IDEA #8:<br>Ben Johnston's idea of training conventional performers<br>in non-12 techniques.  Just as dinosaurs turned into<br>birds, the smart post-Webern serialists turned into <br>extended JI composers working with conventional<br>performers.  If Webern had lived, he'd obviously have<br>given up 12 by 1950 at the latest.<br>-----------------------------------------------<br>SMART IDEA #9:<br>Max Mathews did what all geniuses do when he<br>applied the computer to music:  something<br>that at first looked bizarre, then  became<br>blindingly obvious, and finally seemed inevitable.  <br>With its binary precision and enormous speed,<br>the computer was and is an ideal musical<br>instrument.  Max Mathews gave a huge impetus<br>to 20th century composition in general (and non-<br>12 composition in particular) by writing the<br>first acoustic compiler.<br>------------------------------------------<br>SMART IDEA #10:<br>Ivor Darreg pointed out in 1975 that every kind tuning<br>has its own "sound" or "mood" or "sonic fingerprint."<br>Choosing the "sound" of a composition by choosing<br>the tuning has proven an endlessly productive idea,<br>and inspired a wide variety of xenharmonic<br>composers.<br>------------------------------------------<br>It's worth noting that every one of these post-1950<br>ideas is inherently xenharmonic.  That ought to tell<br>us something about the direction of the vital <br>currents of late 20th century music...<br>Attention, music students!  How about asking your<br>professors why THESE ideas aren't mentioned in<br>your textbooks?<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Tue, 23 Jan 1996 08:01 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id XAA26305; Mon, 22 Jan 1996 23:01:20 -0800<br>Date: Mon, 22 Jan 1996 23:01:20 -0800<br>Message-Id: <v01520d03ad29b8d61abd@[10.0.2.15]><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2523 href="#2523">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>2/1/1996 3:56:58 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: melodic modes in 19 & 17<br>---<br>As mentioned some months ago,<br>efforts to force-fit the 19 tone<br>equal tempered scale into the <br>melodic patterns familiar throughout<br>Western music are doomed to <br>failure.<br>This, because there's nothing like a<br>semitone in the 19-tone system.<br>Since 19 is a member of the third-tone<br>family of scales, this is obvious.  Yet<br>many notation schemes and suggested<br>melodic modes depend on the mistaken<br>idea that 19 has something that sounds<br>or functions like a semitone.<br>In actual musical practice, two 19-tone<br>scale-steps do not sound anything like<br>a semitone--the resulting interval,<br>126.315 cents, sounds a full quarter<br>of a semitone larger than the semitone<br>found in 12.  Alternating this interval<br>with the 3-step whole-tone in 19<br>produces a queasy effect that cannot<br>be described as either "major" or<br>"minor"--instead, the overall impression<br>is that of a 7-out-of-48-tone mode<br>which sounds distinctly out of tune.<br>Since major and minor melodic modes<br>do not exist as such in 19, this creates<br>a substantial conflict.  After all, major<br>and minor *vertical* triads are easy to<br>play in 19--but a major or minor melodic<br>mode are not to be found.<br>So what's the solution?<br>The experience of the Southern California<br>Microtonal Group has shown definitively<br>that the concept of  major and minor<br>melodic modes must be abandoned in 19.<br>To avoid producing a bizarre and queasy<br>out-of-joint melody, 12-tone melodic<br>paradigms must be thrown overboard and new <br>forms used.<br>Recently, Jeff Stayton recorded a duet<br>with me in the 19-tone system.  Stayton<br>used one melodic mode, while Your Humble<br>E-Mail Correspondent used another.  Neither<br>mode, however, had any point of contact<br>whatever with 12--and as a result, the<br>combination sounded entirely natural in<br>19.<br>My melodic mode used ascending and <br>descending subsets of the following:<br>LssLssssLsL  L = 3 scale-steps in 19,<br>                      s = 1 scale-step in 19<br>This "super-mode" appeared as two<br>different modes, one ascending, the<br>other descending:<br>ASCENDING:<br>LssLsLLsL   (intervals shown as number<br>                     of 19-tone scale-steps)<br>I.e., <br>1  4  5  6  9  10 12  15  16 (20=1)<br>                     (scale degrees played: numbered<br>                     from 1 to 19, with 20 = 1)<br>DESCENDING:<br>LsLsLsLsL  (intervals shown as number<br>                    of 19-tone scale-steps)<br>I.e., <br>20=1  17  16  13  12  11  8  5  4   (20=1)<br>                   (scale degrees played: numbered<br>                     from 1 to 19, with 20 = 1)<br>Variety was added by borrowing additional<br>steps from the "super-mode" and adding<br>them ornamentally to either the ascending<br>or descending mode.<br>Jeff Stayton's guitar accompaniment used<br>an entirely different mode:<br>(Descending)<br>LsmssmsL  where L = 3 scale-steps in 19<br>                             s = 1 scale-step in 19<br>                             m = 2 scale-steps in 19<br>I.e., <br>4  20=1  19  17  16  15 13  12  9<br>		(scale degrees played: numbered<br>                     from 1 to 19, with 20 = 1)<br>Stayton varied his mode by substituting 2<br>single scale-steps for a 2-degree "m" step:<br>thus he might play<br>LsssssmsL instead of LsmssmsL, for<br>example.<br>The combination of these two melodic modes<br>worked smoothly and sounded entirely natural<br>in 19.  However, they do NOT derive from any<br>12-tone or Pythagorean paradigm.<br>More to the point, both of these modes use<br>*more* than 7 tones.  It has been my experience<br>when improvising in or writing scores in 19<br>that more than 7 tones are required for a <br>natural-sounding melodic mode.<br>This should not come as a surprise.  In 1956,<br>Miller's paper "The Magic Number Seven, Plus<br>or Minus Two" pointed out that the human<br>cognitive system is capable of easily <br>assimilating as few as 5 or as many as 9<br>"units."  If each step of the melodic mode<br>is thought of as a unit, this explains why<br>9-tone modes come so naturally to 19--<br>even though such modes use 2 more steps<br>than the Pythagorean-based 12-tone <br>melodic modes familiar from Western music<br>theory, a 9-tone mode still fits comfortably <br>the limits of the  channel capacity of the<br>human sensorium.<br>(By contrast, serialism's 12 notes are too<br>many.)<br>Thus my experience indicates that at least<br>8 and usually 9 steps are needed to create a<br>convincing and natural-sounding melodic<br>mode in 19.<br>On the other end of the perceptual scale,<br>the 17-tone equal-tempered scale sounds<br>best melodically when used with 5-step<br>or 6-step modes:<br>1  6  4  1  5  (ascending: intervals in <br>                      number of 19-tone scale-steps)<br>I.e.,<br>1  2  8  12  13  17  (18=1)<br>or<br>1  6  1  4  4  1 (ascending: intervals in number<br>                         of 17-tone scale-steps)<br>I.e., 1  2  8  9  13  17 (18=1) (ascending: scale <br>                      degrees played--numbered from<br>                       1 to 17, with 18 = 1)<br>Not all xenharmonic equal temperaments <br>require a complete rejection of 12-tone<br>melodic modes.  22, 24, 27, 29, 31, 36 and so on<br>all have familiar 7-note major and minor melodic<br>modes.<br>19, however, does not.  This startling contrast<br>between the familiar-sounding major and minor<br>triads available in 19 and the utterly alien-sounding<br>melodic modes is one of the greatest resources<br>of the 19 tone equal temperament.  Composers who<br>ignore this fact do so at the peril of producing<br>awkward-sounding out-of-joint music that<br>gives the impression of 12 badly mistuned.<br>--mclaren <br>ATDT *70, 633-4360<br> <br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Fri, 2 Feb 1996 04:20 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id TAA26453; Thu, 1 Feb 1996 19:20:00 -0800<br>Date: Thu, 1 Feb 1996 19:20:00 -0800<br>Message-Id: <960201221740_412518206@emout10.mail.aol.com><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2526 href="#2526">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>2/2/1996 9:57:52 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: A saga of low cunning and<br>feral persistence<br>---<br>As a chronically unrepentant electronics<br>gonzo, permit me a small confession:<br>Yes, I finally built myself a duplicate of<br>Harry Partch's Harmonic Canon I (minus<br>Harry's bad design features).<br>And it sounds INCREDIBLE.<br>Johnny Reinhard has roundly chided me<br>for slighting acoustic music.  Of course,<br>he's right.  <br>In the end, there's no substitute for live<br>acoustic music played by good performers<br>on real acoustic instruments.  The richness<br>and subtlety of the sound is nonpareil.<br>On the other hand, some of us are interested<br>in exploring worlds of timbre and massed<br>sonority which would not be possible to<br>realize (xenharmonically, anyway) without<br>the aid of "pushing a button on electronic<br>boxes." <br>Thus circumstances will doubtless force<br>me to continue "pushing buttons." If you<br>can get together a 100-piece orchestra<br>that can play accurately in 15-TET, though,<br>Johnny, let me know.  In that case my<br>computer will definitely be mothballed. <br>:-)<br>The Harmonic Canon is a marvel, though. A<br>universe of subtle & gorgeous xenharmonies<br>lie within its bridges and pinblocks.<br>For example, entirely different timbres can<br>be gotten by stroking the strings with one's<br>fingers; by plucking them with guitar picks;<br>by tapping them with a knitting needle; by<br>thumping them with a piece of a piano action<br>(Harry gets his revenge against the piano--<br>50 years late!); and by whanging the strings<br>with a soft paint roller.<br>Moreover, non-Partchian string-bending<br>koto-style performance techniques<br>bring out an entirely different side<br>of the instrument.<br>The great virtue of the Harmonic Canon<br>lies in its potential as a kind of mechanical<br>sequencer.  You set up various justly-intoned<br>melodies by moving the many independent<br>bridges, and you can get triplets, repeated<br>notes, single notes, entire melodic chains<br>playing at a rate entirely controlled by<br>the rate at which you move your finger or<br>your pick across the strings.  Add to this<br>the potential gestural effects--pitch-bent<br>ji chords, for instance, or dissonant clusters<br>obtained by rapidly brushing groups of<br>strings--and a single player has got a<br>whole galaxy of microtonal sounds at<br>hi/r beck and call.<br>Harry called this instrument his "blank<br>canvas," and after playing it for a while it's<br>easy to see why.  He also mentioned that<br>placing the bridges was almost as much of <br>an art as playing the instrument--another <br>truism which becomes even clearer with<br>personal experience in sliding 37-odd <br>bridges around.<br>The Harmonic Canon is to my mind the most<br>impressive of Partch's instruments.  It's one<br>of the few that can't be approximated by a sampler<br>or a DX7.  To everyone who's interested in<br>composing acoustic xenharmonic music, my first<br>suggestion wuold be: build a Harmonic Canon I.<br>Costs less than $100, and it'll open your<br>ears to a new cosmos of xenharmonic<br>harmonies and melodies.<br>To construct one, follow the plans in Harry's<br>Genesis Of A Music--sans the bad design ideas.<br>N.B.: Harry's bad design ideas were 1) Using<br>guitar tuning gears; 2) using glued wooden<br>pegs to anchor the guitar strings on the<br>other pinblock; 3) sliding that wacky plexiglas<br>pitch-bender under the strings.<br>Instead of tacking triangular wooden tongues<br>onto the end of the left-hand pinblock and <br>then mounting guitar tuning gears on 'em,<br>just anchor 44 piano tuning pins directly in the<br>left-hand pinblock.  It works fine.  The problem<br>with the wooden tongues is that they will<br>inevitably crack under all the tension from<br>those 44 guitar strings--Harry himself had<br>to bolt metal supports under the wooden<br>tongues to keep 'em from splitting off<br>entirely.  Moreover, the guitar tuning gears<br>never stay in tune long.  So the blasted original<br>Partch-design Harmonic Canon was *always*<br>going out of tune during performances.<br>By contrast, our Harmonic Canon stays in<br>tuen for days at a time and can support<br>a much higher tension--thus the sound is<br>louder, and the plucked or struck guitar <br>strings will ring much  longer than Harry's <br>strings did.<br>Also: avoid the wooden pegs.  Bad idea.<br>Instead, use 1/4" machine screws on the <br>right-hand pinblock.  (Make sure both<br>pinblocks are hardened rock maple.) <br>Under the screws, settle 5/16" washers.<br>Between the screws and washers thread the<br>guitar string, and voila!  The brass loop end<br>of the guitar string will automatically catch<br>tight when you sink the screws with a screwdriver.<br>This was Bill Wesley's inspiration, and it's<br>infinitely simpler and less trouble-prone than<br>Partch's original design.<br>Q: What did Partch do when he went surfing?<br>A: He used to "hang eleven."<br>--mclaren<br><br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Fri, 2 Feb 1996 19:01 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id KAA16240; Fri, 2 Feb 1996 10:01:20 -0800<br>Date: Fri, 2 Feb 1996 10:01:20 -0800<br>Message-Id: <0099D528F3AA41A5.9363@ezh.nl><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2533 href="#2533">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>2/3/1996 2:42:50 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Xenharmonics on a broken<br> shoestring<br>---<br>While it's easy to gripe about the lack<br>of this or that sophisticated synthesis<br>algorithm on today's MIDI synths, it's<br>sobering to realize how far we've come.<br>In many ways we live in the golden age of<br>xenharmonics.<br>A whole lot of dirt cheap fully retunable<br>MIDI synthesizers are available used--and<br>most of 'em for a pittance.  For example,<br>the prospective microtonalist can today<br>grab a used TX81Z for about $250, or a<br>used VFX for about $600.  These are both<br>excellent synthesizers.  Add an antique DOS<br>286 machine, used, for another $200 or<br>so, tack on a DOS sequencing program<br>like Cakewalk or Texture, a cheap MIDI<br>interface, and you can do an astounding<br>amount of sophisticated microtonal<br>composition.<br>Move up to a Windows 386 machine (for<br>about $100 more) and a program like<br>Finale, and you've got the ability to<br>score and perform compositions of<br>a complexity unthinkable a few years<br>ago. You can record xenharmonic scores<br>that world-class ensembles would have<br>had to practice for 6 months to perform!<br>None of this was possible just 10 years<br>ago.<br>So much inexpensive high-quality<br>equipment has washed up in the USED<br>section of the classified ads today <br>and in the backs of cheapo guitar shops<br>that it's mind-boggling.<br>A look at a 1986 issue of "Keyboard" puts<br>the situation in focus--back then, analog<br>MIDI synths were the state of the art. <br>2,000 note sequencers running on the <br>Commodore 64 were considered "powerful."<br>The only affordable sampler was the Mirage,<br>and to detwelvulate *that*, you had to<br>buy an alternative operating system from<br>Dick Lord in New Hampshire.<br>Recently, US Snail brought me the latest tapes <br>by Warren Burt and Gary Morrison.  While both<br>of these composers have asked me not to <br>review their work in public, they probably<br>wouldn't mind my saying that their <br>latest work is excellent.  <br>And in both cases what's especially <br>impressive is how much they were able <br>to do with modest resources.<br>Gary Morrison, for instance, has an obsolete <br>68030-vintage Macintosh with a DAT<br>machine, a two-track Sound Tools setup,<br>and an Ensoniq ASR-10.  Yet he's been able<br>to simulate a very convincing orchestral<br>wind and percussion ensemble.<br>Warren Burt has an equally modest set-up.<br>An "obsolete" 286 DOS laptop, a MIDI<br>interface, a little A/D-D/A box that hooks<br>into the computer's parallel port (cost<br>$150, maximum stereo output rate 22.05<br>khz), the public-domain program US from<br>the U of Illinois, a commercial DOS sample<br>editor, the Buchla Lightning MIDI controller,<br>a Proteus I, a Roland SCC-1 Sound Canvas<br>sound card, and a couple of reverb and delay <br>boxes, along with an obsolete 13-bit EPS<br>sampler. (Still an *extremely* useful synth--<br>as I can testify, since I still use one myself!)<br>Yet with this modest setup--which wouldn't <br>even rate a sneer from a Keyboard or Electronic<br>Musician reviewer--Warren manages to tease<br>a kaleidoscope of interesting  music.  <br>His latest work ranges from digital musique<br>concrete, to algorithmic music which<br>uses William Sethares' idea of matching<br>partials to the microtonal tuning, to pastiches<br>which employ public-domain algorithmic composition<br>programs  processing musical material from<br>neoclassical composers in a 19-tone extension<br>of serialism.<br>This kind of fine work done with so-called "obsolete"<br>MIDI equipment should tell us something important.<br>In the end, you don't really need a DigiDesign TDM<br>48-track Power Mac system.  You don't really<br>need NeXTStep-486 running on an 80686 machine.<br>You don't really need a monster 16-bit sampler<br>with 64 or 128 megs or RAM.<br>This kind of bleeding-edge technology is nice--<br>but it's not *necessary* to produce good microtonal<br>music.<br>In the end, what matters most is imagination and <br>ingenuity.  My own computer music never uses<br>a sampling rate higher than 20 khz; and you<br>can do a surprising amount with a 20 or 30<br>khz sampling rate on a 13-bit 1 megaword <br>sampler like the EPS.   <br>Moreover, vintage synths like the 1986 <br>TX81Z or the 1989 VFX have so many features <br>that it's difficult to believe *anyone*<br>has come close to exhausting their sonic<br>potential, even though they've been in use for<br>years and years.<br>Beyond that, there remains the largely unexplored <br>option of combining live acoustic home-built <br>xenharmonic instruments with digital synths<br>in live and recorded performances.<br>For some reason, microtonalists have long faced off<br>into oposing groups: the "acoustic only!" camp<br>and the "digital only!" camp.  But why not mix<br>and match instruments of both kinds?<br>Why not combine *both* sound-worlds?  <br>This is a direction we in the Southern California<br>micorotnal group have been pursuing for years, <br>and it has so far proven fruitful.<br>Recently I finished building my own copy of a<br>Harry Partch-style harmonic canon I.<br>Essentially a monochord multiplied times 44,<br>with movable bridges for each string, the<br>instrument turned out to be much simpler<br>to construct than my forebodings indicated.<br>Best of all, it cost less than $100.<br>Yet with a harmonic canon  you can tune up<br>all the tetrachords listed in John Chalmers<br>magnum opus "Divisions of the Tetrachord"--<br>four or five at a time, simultaneously.<br>Or you can tune up a single tetrachord with<br>a variety of harmonizations.<br>You can also get Partch's 29-note, 37-note, 39-note,<br>41-note and 43-note just scales, or 43-tone<br>or 41-tone equal temperament.   Not to mention<br>multiple courses of strings with lesser divisions<br>of the octave.  The harmonic canon is  an<br>endlessly useful instrument--it sounds splendid,<br>yet it's easy to maintain (run emory cloth along<br>teh strings to get rid of rust once a week, and dust<br>and oil the wood) and almost trivial to <br>build.<br>Building my own megalyra has proven even<br>easier, and cost considerably less than $100.  <br>These instruments require no special carpentry<br>skills--even a duffer like myself can cut and <br>plane maple and pine planks, drill holes, and<br>screw in 44 piano pins.  Making a megalyra<br>is literally no more complex than drilling<br>11 pairs of holes, sinking 11 pairs of<br>piano pins, and winding tight 11 pairs of <br>piano strings across a piezoelectric pickup.<br>That's essentially all there is.  (Hint: get<br>used rusted piano pins from a piano repair<br>shop.  You can emory-cloth the rust off the<br>pins, and they work just fine. The only real<br>expense is the piezo pickup, the 11 piano<br>strings, and the piano tuning hammer.  Once<br>again, rusted used piano pins work fine.)<br>Anyone can build these simple xenharmonic<br>instruments, yet the resulting music<br>sounds impressive in live performance--<br>especially when combined with digital MIDI <br>synths and/or playback of computer-generated <br>soundfiles.<br>When I see the latest issue of Computer Music<br>Journal, I have to wonder: Why aren't these<br>people talking about "more is less" in computer<br>music?<br>As Warren Burt has pointed out, in the age of<br>downsizing, most of our incomes are dropping <br>even more rapidly than the price of computer <br>hardware--so getting the mostest out of the <br>leastest is a matter of real concern.  <br>It's also a fun challenge.  <br>So every time that latest, greatest new<br>synth beckons to me from the music shop<br>window, a little voice in the back of head <br>whispers: You still haven't used more than<br>1/10 of the capabilities of the equipment <br>you've already got!<br>Frankly, both Gary and Warren  would do us<br>a favor if they'd  post more about getting <br>"the mostest from the leastest."  <br>Like Ivor Darreg's, their work has produced <br>impressive results with very modest resources, <br>and we could all learn a thing or two from <br>these fine composers.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Sun, 4 Feb 1996 19:47 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id KAA23868; Sun, 4 Feb 1996 10:47:46 -0800<br>Date: Sun, 4 Feb 1996 10:47:46 -0800<br>Message-Id:  <9602041045.aa27022@cyber.cyber.net><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2534 href="#2534">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>2/4/1996 10:47:46 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: miscellany<br>---<br>Congratulations to Steven M. Miller, Harold Fortuin,<br>Matthew Puzan, Enrique Moreno and Neil Haverstick. <br>Even after a month, Neil's amazing MicroStock continues <br>to reverberate in the form of the recordings of the<br>concert.  A first-rate event.  Utterly superb!  <br>Way to go, Neil.<br>Steven M. Miller deserves kudos for reaching outside of <br>academia to solicit tapes for the U. of Santa Fe's upcoming<br>electronic music concert series.  In so doing, he discovered<br>a remarkable fact: some of the best music out there is<br>being done by ordinary schmucks with NO university<br>affiliation, NO resources, and NO predelection for<br>elaborate mathematics.<br>Congrats also to Harold Fortuin both for building a<br>xenharmonic generalized MIDI keyboard (see the Huyghens-<br>Fokkers 1994 Yearbook for more info). Any chance of<br>commercializing the widget?  <br>Good idea also to offer to exchange copies of your<br>music. <br>All too few forum subscribers seem to be interested<br>in making and sharing MUSIC, as opposed to words<br>about numbers about theories about words about<br>numbers about...<br>Especially praiseworthy: the scholarly labors of<br>Mssrs. Moreno and Puzan, whose theses promise a<br>comprehensive survey of xenharmonic incunabula.<br>Speaking of which--<br>Several articles touching on xenharmonics have<br>recently been published.  Of particular interest<br>is Contemporary Music Review, Vol. 10, 1994.<br>The issue is *entirely* devoted to "composition<br>with timbre."   As we all know, composing with<br>timbre is the gateway to non-12..  Thus this issue<br>is of inherent promise to xenharmonists.<br>Also of interest: "Musical Scales In Central Africa <br>and Java: Modelling by Synthesis," by Frederic Voisin,<br>Leonardo Music Journal, Vol. 4, 1994, pp. 85-90.<br>Voisin describes the results of a series of <br>experiments in which indigenous tuning experts<br>were allowed to tune up their own scales on<br>a DX7II: the process was recorded with a MIDI<br>sequencer, and the researchers returned after<br>several days in each case and asked the same<br>tuning expert to evaluate the tuning again (so<br>as to confirm the reliability of the results).<br>When the DX7II was tuned correctly, the researchers<br>report that the tuning expert and a group of<br>bystanders would spontaneously perform a piece<br>from their repertory.  <br>This methodology sounds like a significant advance<br>in ethnomusicology.  It's orders of magnitude<br>beyond the relatively useless previous practice<br>of asking the indigenous tuning expert a series<br>of questions--if the questions are phrased in<br>terms of Western European musical assumptions,<br>what possible use can the answers be?  It's as<br>though a bunch of Javanese music theorists came to<br>the U.S. and asked Western symphony orchestra<br>musicians: "What bem do you use?  And how<br>do you arrive at your rasa?"  The answers could<br>not possibly make sense.<br>And the previous practice of simply measuring<br>tunings in terms of cents and trying to fit them<br>into Western equal-tempered or ji tuning models<br>was also less than satisfactory. After all, a set of<br>measurements of native instruments does not<br>*by itself* tell us what the local tuning experts<br>were trying to achieve...while a digital record of the<br>tuning process *might just do that*<br>"Applying Psychoacoustics in Composition: 'Harmonic'<br>Progressions of 'Nonharmonic' Sonorities," by Richard<br>Parncutt and Hans Strasburger, in Perspectives of New<br>Music, Vol. 32, No. 1, 1995, is also likely to prove<br>interesting to the prospective xenharmonic composer.<br>Finally--finally!--music theorists are beginning to wake<br>up to the reality Plomp and Levelt revealed in 1965:<br>--An INharmonic series of vertical partials will sound<br>entirely transparent and consonant as long as the distance<br>between each successive partial is greater than the<br>critical bandwidth at that frequency.<br>While visionary composers like Jean-Claude Risset,<br>John Chowning, James Dashow and Jonathan Harvey<br>have long taken advantage of this psychoacoustic fact, <br>for just as many decades the music theorists have <br>ignored this reality.  <br>Parncutt & Strasberg's paper is thus a welcome addition<br>to the literature.  By basing their compositional theories<br>on Ernst Terhardt's model of hearing, they've gone<br>back to basics--to the way the human ear hears, rather<br>than abstract set theory, or partition functions, or<br>abstract algebra, or combinatorics, or matrix operations, <br>none of which has any necessary connection to what <br>the ear actually HEARS.<br>Among other praiseworthy ideas, P & S suggest:<br>"(i) the model takes as its starting point the spectrum of<br>a sonority, rather than its musical notation."  This is<br>a VITAL advance in music theory.  Now that arbitrarily<br>complex and inharmonic timbres can be generated by<br>computer, the composer needs to consider the implications<br>of timbre as well as such familiar concepts as root note,<br>voice-leading, the relationship twixt harmony and melody,<br>etc.<br>Moreover, P & S insure that "The model is not octave <br>generalized; it is based on pitch height...rather than pitch<br>class."  Another extremely important point.  Octaves<br>certainly have their uses, but many of us compose in<br>tunings without octaves.  Why ought we to be hamstrung<br>by  600-year-old dogmas obsessed with subdividing a<br>2:1 interval...which interval does not exist in many of <br>the tunings we happen to use?<br>P & S also point out many subtleties often unrecognized<br>by music theorists: for instance, the  psychoacoustic<br>effects produced by mistuned harmonics, etc. Listeners<br>still perceive substantially mistuned harmonics as<br>making a contribution to the formant--and so on.<br>P & S offer C code for an algorithm to evaluate vertical<br>sonorities according to their theory--something sure to<br>be useful to many xenharmonists who compose with timbre.<br>Alas, the article also suffers from a number of <br>omissions and oversights.<br>First and most important, P & S base their compositional<br>theory solely on Ernst Terhardt's theory of hearing.<br>Terhardt is a well-known psychoacoustician who's done<br>excellent work in the field.  However, Terhardt's theory<br>of hearing is merely one among many.  More: Tehardt is<br>a dyed-in-the-wool place theorist, and this tends to<br>bias some of his conclusions.  There is, for<br>example, *no* discussion in any of Terhardt's papers<br>of the contradictions and paradoxes bedeviling place<br>theory--for example, that measured jnd's substantially<br>exceed those predicted by the physics of the place<br>theory of hearing.  <br>Thus there is good reason to believe that the model of<br>hearing on which Parncutt & Strasberg have based their<br>compositional theory is incomplete, and does not explain<br>many important aspects of the human auditory system.<br>P & S also make statements which tend to mislead<br>the unwary reader: "The perception of the pitch of a <br>complex tone such as a musical tone (piano, violin, voice, <br>and so on) involves pattern recognition (Goldstein<br>1973, Terhardt 1972 and 1974)."  <br>In fact there is no consensus, nor yet any convincing<br>body of evidence, as to the exact processes  involved in <br>the perception of the pitch of a complex tone. While<br>Parncutt & Strasberg claim that musical perception<br>is a matter of "pattern recognition," in actual fact<br>this is merely one of three competing theories of<br>the way the ear/brains system operates.<br>The other theories are that the inner ear performs<br>a mechanical Fourier transform, and that the<br>auditory nerve running from the inner ear to the<br>brain extracts & encodes the underlying periodicity<br>of sound waves detected by the inner ear.<br>While there is some evidence in support of the<br>pattern recognition of hearing (first advanced<br>by Wightman, by the way--not Goldstein!),<br>there is also some evidence AGAINST the<br>pattern recognition theory of hearing.  There is<br>also a great deal of evidence FOR the other two<br>theories of hearing, none of which Parncutt &<br>Strsberg seem to be aware of.<br>On top of these lacunae, P & S proceed to collapse<br>their model down to 12 pitch-classes.  This is a<br>pretty low blow.  After much fine talk about freeing<br>the composer from octave equivalence, etc., they<br>wind up giving another recipe for producing pretty<br>sounds in 12-equal.<br>File that one under the category "The beatings were<br>scientifically designed to enhance creativity."<br>Lastly, P & S betray a profound lack of familiarity<br>with the microtonal and psychoacoustics literature.<br>Their bibliography is full of extremely glaring<br>gaps and omissions:  for instance, they omit completely<br>most of the CLASSIC articles on composing with inharmonic<br>sonorities:   John R. Pierce's letter "Attaining Consonance<br>in Arbitrary Scales," In JASA, 1966; Mathews' and Pierce's<br>"Control of Consonance and Dissonance With Nonharmonic<br>Overtones"  in "Music by Computers," ed. Beauchamp & Von <br>Foerster, 1969; Jean-Claude Risset's "Digital Experiments: <br>1964...." in Computer Music Journal, 1984; James Dashow's <br>"Spectra As Chords" in Comptuer Music Journal, 1980; <br>William Sethares' "Local Consonance and..."  in JASA, September<br>1992, my own "The Uses and Characterisics of Non-Just<br>Non-Equal-Tempered Scales" in Xenharmonikon 15, 1993,<br>and last (but not least!) Slaymaker, "Chords From Tones<br>Having Stretched Partials," JASA, 1970 and Geary, J. R., <br>"Consonance of Pairs of Inharmonic Tones," JASA, 1980.<br>If a nudnik like myself can rattle off this many obvious<br>references from memory, shouldn't Parncutt & Strasberg<br>have been able to do the half an hour or so of research <br>required by minimal standards of scholarships?  Ought <br>not these two distinguished researchers to have been able <br>to dredge up adequate citations for their article?<br>Such negligence bespeaks more than mere laziness; it<br>augurs a total lack of interest in looking outside their own<br>narrow little sphere of interest--namely, the theories<br>developed "by Ernst Terhardt and his colleauges at the <br>Institute of Electroacoustics, Technical University of <br>Munich."<br>Thus, while Parncutt & Strasberg's article is a promising<br>start, it falls short on many counts.  <br>Withal, still a worthwhile and useful article.<br>--mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Mon, 5 Feb 1996 00:17 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id PAA29226; Sun, 4 Feb 1996 15:16:58 -0800<br>Date: Sun, 4 Feb 1996 15:16:58 -0800<br>Message-Id: <960204231257_71670.2576_HHB69-6@CompuServe.COM><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=3026 href="#3026">ðŸ”—</a>emoon@netvoyage.net (Eric Moon)</h3><span>6/7/1996 10:50:23 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>>>>>>This attitude is the natural consequence of a causal relationship<br>>>>>>where the great works are first and the theoretical interest<br>>afterwards.<br>>        It would seem equally natural, then, that there is no interest for<br>>a generalized practice of educating music students in<br>>the *how-to*s of some "exotic" intonation systems for which there is no<br>>significant corpus of real masterpieces.<<<<<<<br><br><br>To the extent that this is tru, it certainly underscores the irrelevance of<br>academia to the creative process.<br><br>However, I was "turned on to", if not educated in, microtonalism through my<br>university composition teacher.<br><br>Even in a purely historical context, it would be nice to see a broader<br>understanding  of the nature and use of pre-ET in the rennaissance and<br>baroque.  I am amazed at how few music students are aware of the existence<br>of anything but ET.<br><br><br><br><br>Eric Moon<br>Temiqui Music<br><br><br><br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Fri, 7 Jun 1996 21:13 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id MAA16266; Fri, 7 Jun 1996 12:13:20 -0700<br>Date: Fri, 7 Jun 1996 12:13:20 -0700<br>Message-Id: <v01520d00addc9d3a3b2b@[199.212.63.117]><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=3829 href="#3829">ðŸ”—</a>&#x22;Jonathan M. Szanto&#x22; &#x3C;jszanto@adnc.com&#x3E;</h3><span>10/25/1996 12:28:10 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>Buddies,<br><br>Since I have been lurking, a couple of comments came together to get me<br>babbling again, and they be:<br><br>>and boy, this list is sort of dull lately...too much polite math<br>>talk...we need a good controversy to get things rolling...Hstick<br><br>.. followed closely by ...<br><br>>Or perhaps people don't use ANY notation if they can avoid it. Those of <br>>us who use non-realtime instruments might need some sort of chart or <br>>table to help in making a piece, but a detailed score seems superfluous. <br>>Of course, the situation may be different where performers are involved <br>>but I find it a tremendous relief not to have to bother with it.<br>><br>>Paul Turner <br><br>Seems to me that the last few weeks have been looking as if sponsored by the<br>old HP Calculators.  Question in general: being that most all involved here<br>are interested in tuning alternatives to 12TET, and sounds like most wish<br>that more people could experience the lovely/ugly/amazing worlds that these<br>intonations open up, wouldn't we all be forwarding the cause if more music<br>were created that *involved* people, rather than spanking the<br>software-monkey another time?<br><br>I know the pleasures myself of having the control of every note and nuance,<br>or letting an algorithm do it's thing.  Nonetheless, and cognizant of the<br>wonderful pieces that have been done in 'non-realtime', does any of it<br>compare to the community experience of, say, playing in a gamelan?  And<br>doesn't Paul's last bit, "the situation may be different where performers<br>are involved but I find it a tremendous relief not to have to bother with<br>it" read almost like "bother with them" (i.e., live musicians performing the<br>work)?<br><br>[NOTE: apparently the PC police have been attempting to control the terms<br>here on the tuning list, too: is it non-12TET? allotonal? microtonal?<br>xenharmonic? what???]<br><br>Given the choice of *doing* intonational music or *having it done to me*, I<br>know which I would choose, and it is the same one that I propose would be<br>most, um, beneficially nurturing to a larger audience and/or new performers.<br><br>..or something like that.  Gad, it's true: Neil H. and I are twin<br>love-children of Elvis and Nadia Boulanger!<br><br>Cheers,<br>Jon<br><br>PS: What I find lacking in the list of late are the laconic and luxurious<br>linguistics of G. Taylor, but maybe that's just me...<br>*--------------------------------------------------------------------*<br>   Jonathan M. Szanto   | If spirits can live online . . . . . . . . .<br> Backbeats & Interrupts |  . . . then Harry lives in Corporeal Meadows<br>   jszanto@adnc.com     | http://www.adnc.com/web/jszanto/welcome.html<br>*--------------------------------------------------------------------*<br><br><br>Received: from ns.ezh.nl [137.174.112.59] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Fri, 25 Oct 1996 14:56 +0200<br>Received: by ns.ezh.nl; (5.65v3.2/1.3/10May95) id AA08319; Fri, 25 Oct 1996 14:57:58 +0200<br>Received: from eartha.mills.edu by ns (smtpxd); id XA08303<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <manuel.op.de.coul@ezh.nl> id FAA06190; Fri, 25 Oct 1996 05:57:55 -0700<br>Date: Fri, 25 Oct 1996 05:57:55 -0700<br>Message-Id: <Pine.SOL.3.91.961025084918.13216A-100000@minerva.cis.yale.edu><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=3925 href="#3925">ðŸ”—</a>bte@MIT.EDU</h3><span>11/4/1996 10:15:39 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>i'm looking for a chinese musical scale in cents,<br>if anyone knows one :)<br><br>thanks.<br><br>Ben Erwin<br><br><br><br><br>--<-@--<-@--<-@--<-@--<-@--<-@--<-@--<-@--<-@--<-@<br>it is then unconditional positive regard or love which releases<br>the infinite potential of creativity.<br>					- Paul W. Dixon<br><br><br><br><br>Received: from ns.ezh.nl [137.174.112.59] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Tue, 5 Nov 1996 07:16 +0100<br>Received: by ns.ezh.nl; (5.65v3.2/1.3/10May95) id AA00495; Mon, 4 Nov 1996 03:27:31 +0100<br>Received: from eartha.mills.edu by ns (smtpxd); id XA00493<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <manuel.op.de.coul@ezh.nl> id SAA15377; Sun, 3 Nov 1996 18:27:29 -0800<br>Date: Sun, 3 Nov 1996 18:27:29 -0800<br>Message-Id: <v03007800aea30e5fd6fc@[130.132.159.42]><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=4467 href="#4467">ðŸ”—</a>Manuel.Op.de.Coul@ezh.nl (Manuel Op de Coul)</h3><span>1/2/1997 9:08:17 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>Gary says:<br>>    Manuel refuted my claim that there is not historical precedent for<br>> "pure" being synonymous with "just", refering to small-whole-number-ratio<br>> (SWNR) pitch relationships.  (Or more specifically, I claimed only that I<br>> did not no of any such precedent.)  <br><br>Ok, I was merely saying that the connotation of "pure" has a meaning in<br>tuning theory. Maybe I misread your statement in that.<br><br>> Adding a new definition to the synonym stew only risks novices thinking<br>> that the two mean two subtly different things.  <br><br>Hmm, I don't see that. Many words have an inherently vague meaning, <br>including "pure". If you take every word literally, life would become<br>difficult.<br><br>>    So I personally think that we ought to accept the hand of vocabulary<br>> cards the English language deals us whenever possible.  <br><br>Languages are constantly changing. It happens all the time that words get<br>new meanings, sometimes they even get the opposite meaning of what they had.<br><br>Manuel Op de Coul    coul@ezh.nl<br><br>Received: from ns.ezh.nl [137.174.112.59] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Thu, 2 Jan 1997 18:36 +0100<br>Received: by ns.ezh.nl; (5.65v3.2/1.3/10May95) id AA00768; Thu, 2 Jan 1997 18:38:59 +0100<br>Received: from eartha.mills.edu by ns (smtpxd); id XA00766<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <manuel.op.de.coul@ezh.nl> id JAA07064; Thu, 2 Jan 1997 09:38:56 -0800<br>Date: Thu, 2 Jan 1997 09:38:56 -0800<br>Message-Id: <62970102173726/0005695065PK2EM@MCIMAIL.COM><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=4555 href="#4555">ðŸ”—</a>Heikki Jamsa &#x3C;hjamsa@raita.oulu.fi&#x3E;</h3><span>1/7/1997 2:12:07 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>>From: William Sethares <sethares@eceserv0.ece.wisc.edu><br>>To: tuning<br>>Subject: stretching of strings<br><br>>A couple of days ago, someone asked <br>>how close to harmonic real strings are.<br>>One early article that addressed this is<br><br>>Young shows that the partials of piano wire are <br>>``stretched" by a factor of about 1.0013, which is <br>>about 2 cents per octave. <br><br>>-Bill Sethares<br><br>Mathematical formula is in small amplitudes<br><br>   f a ( n + k n^2 ) / ( 1 + k )<br><br>where<br>f is frequenz of n:th partial,<br>a is frequenz of grundtone, i.e 1:st partial,<br>n is integer, number of partial,<br>k is small constant, it depends from stiffness, tension and mass of<br>the string.<br><br>Heikki Jamsa<br><br><br><br><br>Received: from ns.ezh.nl [137.174.112.59] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Wed, 8 Jan 1997 02:39 +0100<br>Received: by ns.ezh.nl; (5.65v3.2/1.3/10May95) id AA19476; Wed, 8 Jan 1997 02:42:04 +0100<br>Received: from eartha.mills.edu by ns (smtpxd); id XA19474<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <manuel.op.de.coul@ezh.nl> id RAA23110; Tue, 7 Jan 1997 17:42:00 -0800<br>Date: Tue, 7 Jan 1997 17:42:00 -0800<br>Message-Id: <199701072039_MC1-E45-7C84@compuserve.com><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=4563 href="#4563">ðŸ”—</a>Heikki Jamsa &#x3C;hjamsa@raita.oulu.fi&#x3E;</h3><span>1/8/1997 12:56:36 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>>From: Gary Morrison <71670.2576@compuserve.com><br><br>>> Yes, 41 is simplest, but 53 system is much better. Fifts are even better,<br>>> and thirds are much better than in 41 system.<br><br>>   That's certainly true for the traditional thirds, but 41 fits 9:7 and<br>>7:6 better, although only slightly better.  41 is however significantly<br>>better at the 11:9 neutral third.  Then again, 11:9 isn't 9-limit of<br>>course.  <br><br>So we see, that in 9-limit 53 system is better.<br><br>Heikki Jamsa<br><br><br><br><br><br><br>Received: from ns.ezh.nl [137.174.112.59] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Thu, 9 Jan 1997 18:05 +0100<br>Received: by ns.ezh.nl; (5.65v3.2/1.3/10May95) id AA12433; Thu, 9 Jan 1997 18:08:45 +0100<br>Received: from eartha.mills.edu by ns (smtpxd); id XA12436<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <manuel.op.de.coul@ezh.nl> id JAA03966; Thu, 9 Jan 1997 09:08:42 -0800<br>Date: Thu, 9 Jan 1997 09:08:42 -0800<br>Message-Id: <32970109170523/0005695065PK2EM@MCIMAIL.COM><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=4617 href="#4617">ðŸ”—</a>Judith.Parkinson@anu.edu.au (Judith Parkinson)</h3><span>1/15/1997 4:22:35 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>I would like to unsubscribe. How do I do it?<br><br><br><br>Received: from ns.ezh.nl [137.174.112.59] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Thu, 16 Jan 1997 16:48 +0100<br>Received: by ns.ezh.nl; (5.65v3.2/1.3/10May95) id AA12870; Thu, 16 Jan 1997 16:51:54 +0100<br>Received: from eartha.mills.edu by ns (smtpxd); id XA12932<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <manuel.op.de.coul@ezh.nl> id HAA26757; Thu, 16 Jan 1997 07:51:52 -0800<br>Date: Thu, 16 Jan 1997 07:51:52 -0800<br>Message-Id: <52970116154525/0005695065PK1EM@MCIMAIL.COM><br>Errors-To: madole@mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=8982 href="#8982">ðŸ”—</a>From:&#x9;iann@inch.com (Ian Nagoski)</h3><span>12/30/1996 9:03:39 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>Hey, David - Would you do me a big favor and post this to the tuning list?<br>Thanks!<br><br>MELA Foundation Inc.    275 Church Street New York, NY 10013      <br>212-925-8270<br><br>January 1997<br><br>Mela Foundation is seeking interns for unpaid volunteer positions <br>of Monitor for Dream House exhibition.<br><br>Dream House: Seven Years of Sound and Light, a collaborative <br>Sound and Light Environment by composer La Monte Young and <br>visual artist Marian Zazeela, is presented in an extended exhibition <br>at MELA Foundation, 275 Church Street, 3rd Floor.  Young and <br>Zazeela characterize the Sound and Light Environment<br>as a "time installation measured by a setting of continuous <br>frequencies in sound and light."<br><br>POSITION: MONITOR for DREAM HOUSE exhibition <br>(Volunteer Interns)<br><br>Hours:  Exhibition is open Thursdays and Saturdays from 2:00 <br>PM to Midnight. Time slots of four to six hours need to be filled <br>on those days.<br><br>Description:  Monitor will open or close exhibition; turn on <br>electronic sound equiptment and turn up light environment; <br>make sure all technical equiptment is running properly; greet <br>visitors; distribute information; answer questions concerning <br>the environment; sell books and recordings.<br><br>Contact:  Call Ian Nagoski, MELA Foundation, 212-925-8270, <br>or email at iann@inch.com.  If you call, leave a message on the <br>answering machine with your phone number and times we can <br>reach you.  Or come to 275 Church Street, 3rd Floor, Thursdays <br>and Saturdays, 2:00 PM to Midnight, and experience the environment <br>and speak to the monitor on duty.<br><br>Press Commentary on Exhibition:<br><br>"... the multifaceted form of the 35-frequency construction of Young's<br>current installation is the principal reason it changes hallucinogenically<br>with every shift in perspective and why the tones freeze in place as long as<br>one is perfectly still while the slightest gesture will startle forth<br>unnamable, wildly plumed melodies from the luxuriant harmonic foliage.<br>Zazeela's light sculptures have invariably, teasingly refused to surrender<br>their entire secret to photographic reprodution, so much do they depend on<br>the retinal impact of activated photons in real time and so much do they<br>exploit, in ways analagous to Young's techniques, the creation of visual<br>combination tones and an accumulation of after-images."<br>            -- Sandy McCroskey, 1/1, The Journal of the Just Intonation<br>Network<br><br>"Young's newest sine-tone sculpture shimmers and swirls as you walk <br>around the room and, amazingly, when you freeze, it does too.  <br>Stay at least long enough to stare at Zazeela's Imagic Light and <br>Ruine Window, which will imprint your retina with blues and <br>purples you haven't felt before."<br>                                                -- Kyle Gann, The Village<br>Voice<br><br>"The visitor with an acute ear can actually 'play' the room like an<br>instrument: explore the sound close to the wall, close to the floor, <br>in the corner, or just standing still.  Or lie on the floor and allow <br>the sound to float you into heaven, slide you into hell, or transport <br>you wherever you want to go.  See if you agree with those who <br>call Young's sound sculpture a precursor of ambient music.<br>Zazeela's light installation, "Imagic Light," offers an intriuging<br>complement to the sound, even though it is equally effective when <br>viewed in silence.  Using pairs of colored lights and suspended <br>aluminum mobiles cut out in calligraphic shapes, Zazeela explores <br>the relationship between object and shadow, making the tangible <br>intangible, and vice versa.  Enjoy the installation for its <br>mesmerizing beauty, or try to analyze how the different colors <br>are achieved, how the mobiles create the resulting shadows, or<br>perspective the infinite number of symmetrical patterns in the room."<br>                                                    -- David Farneth,<br>Metrobeat<br><br>Music                  Eternal                    Light<br>Art <br><br>-------------------------------------------<END>------------------------------<br>--------<br><br>Received: from ns.ezh.nl [137.174.112.59] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Wed, 1 Jan 1997 05:55 +0100<br>Received: by ns.ezh.nl; (5.65v3.2/1.3/10May95) id AA06186; Wed, 1 Jan 1997 05:58:17 +0100<br>Received: from eartha.mills.edu by ns (smtpxd); id XA06079<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <manuel.op.de.coul@ezh.nl> id UAA21343; Tue, 31 Dec 1996 20:58:06 -0800<br>Date: Tue, 31 Dec 1996 20:58:06 -0800<br>Message-Id: <970101045521_75023.2426_GHJ56-1@CompuServe.COM><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div>