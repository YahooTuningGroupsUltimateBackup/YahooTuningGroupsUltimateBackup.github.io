<a href="/old-tuning-list">back to list</a><h1></h1><h3><a id=2037 href="#2037">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>9/23/1995 8:39:53 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Misinformation about psychoacoustics<br> & an upcoming series of 25 posts<br>---<br>The psychoacoustic information posted on this<br>forum seems to stop around 1940.   This would<br>be of little concern if psychoacoustics had but<br>a tangential affect on microtonality; alas,<br>such is not the case.  The workings of the ear-brain<br>system are crucial to real-world music.<br>Thus *someone* must point out the veritable<br>deluge of incomplete information, inaccuracies and<br>outright canards that has characterized the psychoacoustics-<br>related posts on this forum.  And since no one else<br>has bothered to do it...<br>This is no one's fault.  As Enrique Moreno has pointed<br>out in his 1992 book "Expanded Tunings In Contemporary<br>Music," (The Edwin Mellen Press, pg. 107), during this century <br>knowledge about the ear/brain system has grown *much* faster<br>than music professors' awareness of it, or musicians'<br>understanding of it.<br>Thus in pointing out the pervasive inaccuracies in the<br>psychoacoustic (mis)information posted on this forum,<br>my intent is to engender  a quest for truth, rather than<br>impugn anyone's credibility or good intentions.<br>It's important, however, that the *facts* (as opposed to the<br>myths) about the ear/brain system come out.  Differences<br>of opinion are one thing; but overt misinformation is <br>another.<br>The subject of psychoacoustics, as Larry Polansky<br>pointed out in his 1985 guest editorial in 1/1, is<br>one of the most fruitful areas of musical exploration<br>for the late 20th century. Anyone who doubts this need<br>only listen to the music of the best computer <br>composers around--almost without exception Risset,<br>Wessel, Chowning, et alii are deeply involved in<br>psychoacoustic research.<br>Harry Partch made the same point about the importance<br>of psychoacoustics in "Genesis of A Music."<br>Alas, as previous posts have shown, Partch quotes no<br>psychoacoustics references dated later than 1947--and<br>most of what Partch said about the ear/brain system turns<br>out to be poppycock.  Subsequent psychoacoustic research<br>has largely invalidated his claims about psychoacoustics.<br>While my earlier posts to this effect 8 months ago spurred<br>a brief frenzy of name-calling and denial-for-the-sake-of-denial,<br>the frenzy now seems to have abated. And  most <br>of the people who initially reacted like vampires in a <br>crucifix factory to my posts about Partch's errors on <br>psychoacoutics now tacitly (sometimes overtly) recognize <br>that, yes, Partch's statements on the subject are claptrap.<br>This does *NOT* mean that Partch was wrong in stressing<br>the importance of psychoacoustics in microtonality.  <br>Harry Partch was a genius, far ahead of his time.  <br>He simply had the misfortune to study a psychoacoustic literature <br> which Max Mathews' acoustic compiler of 1959 was to render obsolete virtually overnight. <br>Partch's essential emphasis on psychoacoustics was and is crucial<br>to an understanding of the musical uses of microtonality.  Good<br>music *can* be composed even if one doesn't know how a given<br>tuning interacts with the human auditory....but common sense<br>tells us it's an awful lot *easier* to compose  microtonal<br>music that does what you want it to do if you  know something<br>about what's going on in the ear/brain system.<br>In short, the limits we put on the musics we make are a result<br>of what we understand about how the ear hears.  If we wish to<br>remove the limits on the microtonal music we can imagine, we<br>must first remove the limits on our understanding of the ear.<br>Thus for the next month or so John Chalmers will be uploading<br>a series of 25 posts on tuning and psychoacoustic by Your<br>Humble E-Mail Correspondent.  This series will bear on real music <br>and real tunings as much as on the ear/brain system, and should <br>prove interesting to at least some of you.  <br>Even if it doesn't, this upcoming series of  posts is sure to <br>provoke enough discussion to clarify the underlying<br>psychoacoustic facts.  <br>Before starting that series, permit me to give a few examples<br>of the kind of misinformation that's been drifting around on <br>this forum since day 1:<br>In Topic 1 of Tuning Digest 427 Johnny Reinhard wrote: "Since<br>Julian Carrillo recognized the physical structure of the ear as<br>having `hairs' that corresponded - like a harp - to specific pitch<br>frequencies, with corresponding octaves, I have wondered about<br>these hairs or `cilia.'  The New York Times wrote about them a few <br>weeks ago and I have yet to hear about an exact number of <br>hairs-per-octave." [Johnny Reinhard, Topic 1, Digest 427]<br>Compounding the confusion, David Doty, David Worrall and<br>William Alves chimed in to "correct" Johnny's post.  Doty <br>claims: "I think there's a misunderstanding here.  As I <br>understand the matter, a given frequency excites a fairly<br>wide region on the basilar membrane, and hence, a considerable<br>number of hair cells.  Maximum excitation occurs at the center <br>for the band, with excitation diminishing toward the ends."<br>[David Doty, Topic 1, Digest 429]<br>David Worrall claims: "Futhermore, when two tones are close<br>together these bands of cells overlaps, causing an inability<br>to distinguish the two frequencies: hence difference<br>between frequency and pitch. Related to the Critical Band..."<br>[David Worrall, Topic 3, Digest 429]<br>And William Alves claims: "This is true.  Apparently along the<br>neural pathways to the brain, the middle frequency is calculated,<br>and that is what we hear." [William Alves, Topic 4, Digest 429]<br>The problem is that each of these statements, while in general<br>incorrect, contains enough crumbs of fact to bamboozle the <br>unwary reader.  <br>Johnny Reinhard's idea that each hair cell on the basilar <br>membrane corresponds to a given frequency isn't correct, but<br>it has an important germ of truth in it.<br>Why couldn't each hair cell on the basilar membrane corresond<br>to a given musical pitch?  First, because there aren't enough <br>hairs to account for  human sensitivity to small pitch changes.<br>While there are 15,000 hair cells in the average human ear, only<br>3000 inner hair cells are responsible for pitch detection; the <br>other 12,000 outer hair cells serve a supporting role. The 10-octave<br>range of human hearing divided by 3000 inner hair cells gives a<br>a just noticeable frequency difference limen of 4 cents, but measured<br>human frequency sensitivity  for prolonged test tones is much<br>finer, down to + or -1 Hz for long-held harmonic test tones. <br>In fact the theory that individual stereocilia are "tuned" to <br>particular notes is not a new idea--it was first advanced by<br>Herophilus and Erasistratus around 490 B.C. and  then by Aristotle <br>in 344 B.C. The notion imported into Europe in modern times<br>by Joannes Muelle in his 1838 text Handbuch der Physiologie, in which<br>he called it the doctrine of "specific nerve energies."  While<br>this theory of hearing is now known to be incorrect, at the<br>time it was a significant advance over Empedocles' theory of<br>"implanted air." <br>Thus, while incorrect, "the doctrine of specific nerve energies<br>prepared the way for interpretations of new anatomical<br>discoveries that came with the development of better methods,<br>such as the improved compound microscope that appeared around<br>1830." ["Hearing: Physiological Acoustics, Neural Coding and<br>Psychoacoustics," W. Lawrence Gulick, George A. Gescheider and<br>Robert D. Frisina, Oxford University Press, 1989, pg. 59] <br>So while this notion comes from antique sources, there's an important<br>element of truth in Johnny's concept of the ear.  As Pierre Buser &<br>Michel Imbert point out in "Audition," (MIT Press, 1995), "some<br>neurons [in the auditory nerve] produce strong signals when<br>presented with tones in a particular range, but do not respond<br>to tones in other frequency ranges.  A small proportion of<br>neurons emit strong signals when two different frequencies<br>are sounded togehter but respond weakly when either of<br>these frequencies is sounded alone.  Some neurons are activated<br>best by sounds at particular amplitudes and less well at lower<br>or higher amplitudes.  For yet other nerve cells, the higher the <br>amplitude of the sound, the stronger the signal that is produced,<br>until some saturation point is reached."<br>Thus Johnny's specific picture is inaccurate, but it's founded on<br>a deep insight: certain nerve cells [NOT hair cells--we're talking<br>about neurons in the auditory nerve and other brain centers]<br>in the ear/brain system *do* react to specific frequencies.  <br>Thus, crucial elements of the ear/brain system *are* in fact <br>sensitive to specific frequencies (and amplitudes, and specific <br>frequency-differences, etc.), contrary to the implications of<br>Doty, Alves, Worrall, et al.<br>Johnny's post also raises an important question--one which<br>Doty, Worrall and Alves conveniently ignore.  To wit:<br>If the human ear/brain system performs a purely mechanical<br>Fourier analyzer of input sounds, what need is there for all these<br>different kinds of neurons in the auditory nerve, the medial<br>geniculate nucleus, the Sylvian fissure, etc.?  <br>It is well known that the description of the ear to which Doty,<br>Worrall and Alves (known as the place theory of hearing) refer is<br>incomplete and conflicts with much of the psychoacoustic<br>evidence.  "A second difficulty with the place theory lies in the<br>fact that, in complex sounds, components are often heard<br>that are present in the Fourier analysis.  or loudness judgments <br>of components may be made which do not agree with the amplitudes <br>obtained for Fourier components.  It is certainly true that there<br>are phenomena which cannot at the present time be explained by<br>the place theory of hearing." [von Bekesy, Georg, "Hearing Theories<br>and Complex Sounds," Journ. of the Acoust. Soc. Am, 35(4), April<br>1963, pg. 589]  Be it noted that von Bekesy is the researcher most<br>responsible for compiling experimental evidence for the place<br>theory. (In fact he won the Nobel prize for it.)<br>The place theory describes the ear as a mechanical Fourier<br>analyzer. This model of the ear does not explain many of the observed<br>characteristics of the ear/brain system. For example, given<br>the width of regions of maximal stimulation along the basilar<br>membrane, human frequency discrimination should<br>be quite coarse--yet tests should that we can easily detect very<br>fine changes in frequency. "For a sinusoidal tone, the locus of maximum<br>stimulation [of the basilar membrane] changes regularly with frequency<br>only from about 50 through 16,000 Hz, so that place cannot account for<br>low pitches from 20 through 50 Hz. Further, the just noticeable difference<br>(jnd) in frequency of sinusoidal tones apears to be too small to be accounted<br>for by spectral resolution along the basilar membrane. Figure 3.5 shows that for  500 Hz the critical band width is about 100 Hz, yet jnd's having values less than 1 Hz have been reported (Moore, 1974; Nordmark, 1968). While <br>there are mechanisms based on place which have been proposed for <br>discriminating tones separated by considerably less than a critical band <br>(Bekesy, 1960; Tonndorf, 1970; Zwicker, 1970), none seems capable of handling jnd's as small as those reported by Nordmark and Moore."<br>["Auditory Perception: A New Synthesis," Warren, R. A, Pergamon Press,<br>New York, 1985] <br>Moreover, according to the place theory the ear should be insensitive to<br>phase.  But both Newman Guttman's 1959 data and Robert M. Green's<br>1973 experiments show this is not the case.  Most damning of all, if the<br>ear merely performs a mechanical Fourier transform (as Worrall,<br>Doty and Alves claim), how do we account for the ear's ability<br>to extract a missing fundamental?  Schouten's siren experiment,<br>Seebeck's fifth and sixth click series, and Stumpf's experiments<br>all contradict this model of the ear as a simple mechanical Fourier<br>analyzer.  In short, "The discovery of second order effects in auditory <br>processing, such as the perception of phase changes, beats of mistuned <br>consonances and fundamental tracking, has had a great impact on the <br>theory of hearing.  Indeed, these effects cannot be explained appropriately<br>with the conventional `place' theory." [Roderer, Juan, "The Physics and<br>Psychophysics of Music," 1973, 2nd, ed., pg. 41]<br>Moreover, Doty, Worrall and Alves leave unanswered the question of <br>how the ear conjures up a sensation of pitch from a flat noise spectrum.<br>According to a Fourier model of the ear, a broad-band noise with a flat<br>spectrum *cannot* produce a sensation of pitch.  It is by definition UNpitched.<br>Yet, as we all know, white noise generates a weak sensation of<br>pitch.  Eberhard Zwicker summarizes this point concisely: <br>"While the pitch of the noises so far can be traced back to a<br>spectral feature, namely a distinct change in the spectrum, broad-band <br>noises with flat spectra also produce pitch sensations." [Zwicker, E. and <br>H. Fastl, "Psychoacoustics: Facts and Models," 1990, pg. 121]<br>This conclusion is so antithetical to the Fourier description of the ear<br>as to that it's clear that "Auditory physiologists divide into three <br>groups, namely those that think only temporal information [from <br>the firing of neurons] is used, those that think only place information<br>[location on the basilar membrane] is used, and an eclectice group<br>whoe supporse that temporal information is used at low frequencies<br>and place information at high. (..) There are several lines of evidence<br>for and against these theories, none of which is conclusive." [Pickles,<br>James. O, "An Introduction to the Physiology of Hearing," Academic<br>Press, 1988, pg. 271]<br>Doty, Worrall and Alves pointedly ignore this controversy between<br>psychoacoustic researchers--charitably, we'll assume there was no duplicitous intent.  Regardless, the net effect of their posts is <br>to create a false impression.<br>Moreover, the arguments put forward in their posts hide a multitude of<br>contradictions and inconsistencies by giving only a few scraps of<br>fact and suppressing the rest.<br>Alves claims that the center regions of the basilar membrane excitatory regions are  "calculated"--implying the  involvement of higher brain regions.<br>This is one of the three competing hypotheses of the ear, today<br>known as the "pattern recognition" model.  <br>What Alves does NOT mention is that "calculation" by neurons<br>cannot be whole story.  Recent experiments with cochlear impants<br>in the deaf have cast grave doubts on the pattern recognition model<br>of hearing, according to which the ear "calculates" pitches from<br>volleys of neural impulses produced by excitation of the basilar<br>membrane: <br>"If we believe the extreme position that at low requencies information<br>is carried purely by the temporal pattern of nerve impulses, then periodic<br>electrical stimulation should produce faithful auditory sensations and<br>good discrimination of frequencies. The results of electrical stimulation<br>have on the whole been disappointing for such a prediciton. In only a few<br>few cases do electrical stimuli seem to produce clear tonal sensations. A typical report is that tones sound like "comb and paper" (e.g., Fourcin et<br>al, 1979)." [Pickles, James O., "An Introduction to the Physiology of<br>Hearing," 1988, Academic Press, pg. 316]  <br>And in any case Alves' notion of "calcuation" of center frequencies from basilar membrane maxima  opens up a Pandora's box and undermines the very place theory he esposes.<br>If higher brain centers supervene to "calculate" pitch, the Fourier analysis<br>activity of the basilar membrane becomes suspect as adequate explanation<br>for human hearing.  And in fact an approximate Fourier analysis is only<br>performed on the lower six harmonics, and then only above 5 khz...<br>casting strong doubts about the importance of the entire mechanical<br>Fourier analysis activity of the basilar membrane.<br>But if basilar membrane activity *isn't* the whole<br>picture, how to account for the Zwicker tone?   How to explain <br>Wessel's "streaming" phenomenon?  How can we then explain Risset's<br>auditory illusions? <br>The invocation of higher brain centers leads to endless amounts<br>of trouble for the place theory--yet, as Alves' post shows, it<br>cannot be avoided if we want to explain many auditory<br>phenomena.  <br>A classic catch-22. <br>If indeed higher brain centers  *are* involved in hearing, we're now on the slippery slope.  <br>Because if the ear "calculates" frequencies rather than perceiving<br>them via von Bekesy's model of mechanical Fourier analysis, why not posit<br>a greater role for "calculation"...to the point where the ear's mechanical<br>Fourier analysis role becomes unimportant? Since it only operates on<br>the lower six harmonics and then only above 5 Khz, its importance is<br>surely questionable to begin with.<br>Recent models of hearing emphasize the operation of higher brain centers <br>and discount the significance of the basilar membrane in hearing.<br>ial optimum-processor model all tend to bely the  purported importance of the basilar membrane in favor of higher-level processing.<br>Experimental data also show that higher brain centers are crucial to the perception of pitch:<br>A. J. Dowling's article "The 1215-Cent Octave: Convergence of Western<br>and Non-Western Data on Pitch Scaling," Abstract QQ5, 84th Meeting of the <br>Acoustical Society of Maerica, Friday, December 1, 1971, pg. 101, adduces<br>a wealth of data proving that the preference for stretched octaves<br>is universal.  Sunderg and Linqvist, in "Musical Octaves and Pitch," Journ.<br>Acoust. Soc. Am., Vol. 54, No 4, 1973, pp. 973-929, and Lichte's, Ward's,<br>Corso's and Burn's research also show the same result: "As a rule, the<br>perceptual octave corresponds to a fundamental frequency ratio exceeding<br>2:1."  [Sundberg, J. and Lindqvist, J. "Musical Octaves and Pitch," JASA, <br>54(4), 1973, pg. 978]  All of these data broadly contradict the predictions<br>that follow from a model of the ear as Fourier analyzer, and instead<br>tend to support the hypothesis that the ear is a learned-response system.<br>Moreover, the known data showing that when Fourier analysis operates along<br>the basilar membrane (much of the time it doesn't; other ear/brain mechanisms operate, depending on the type of auditory input) only for the lower 6 harmonics raises the question:<br>How can the ear decipher the fundmental pitch of a harmonic sounds<br>whose lower 6 harmonics have been completely filtered out?  Schouten<br>and Seebeck have shown that this occurs--the Fourier-analysis view<br>of the ear cannot possiply explain it.  <br>Again, Doty, Worrall and Alves conveniently slither & slide over this point without so much as a word of explanation.<br>And there's more: the brain employs feedback networks between<br>auditory neurons in  many<br>of different brain regions.  Some feedback loops run from<br>the Sylvian fissure, still others from the medial geniculate body. And in<br>all cases neural filaments radiate from fourth-order auditory neurons<br>in the cerebral cortex back to the geniculate body, thence to the auditory<br>neurons of the inferior colliculus, back even farther to the primary<br>auditory neurons of the cochlear nucleus.  If the ear is a simple mechanical<br>Fourier analyzer, why such a complex software-controlled feedback loop,<br>full of neurons which react in so many different ways to so many different<br>kinds of amplitudes and frequencies and frequency differences?  <br>Clearly something more is going on in the ear than the simplistic<br>mechanical Fourier transform which Doty, Worrall and Alves claim.<br>My point here is not that Reinhard, Doty, Worrall and Alves were<br>right or wrong: the big problem is that these posts (like so many others on <br>this forum) purvey information dredged up from a single antique model of <br>the ear/brain system as though it were *the ONLY* model of the ear/brain <br>system.  As though one single 1940-vintage hypothesis<br> were the truth, the whole truth, and nothing but the truth.<br>In addition, the posts by Mssrs. Reinhard, Doty, Worrall and Alves<br>systematically avoid mentioning auditory phenomena which<br>contradict their particular pet theory of hearing. <br>The place theory of hearing is the *only* theory  congenial to just intonation; thus Mssrs. Doty and Alves have a hidden agenda when<br>they purvey this notion and neglect to mention the many<br>psychoacoustic results which minimize the significance of just<br>intonation, or militate against it.  For example, Mssrs. Doty and<br>Alves do not mention the results of Plomp & Levelt or Kameoka and<br>Kuriyagawa, which demonstrate that consonance is a matter not<br>of harmonic spectra but of partials separated by more than a<br>critical bandwidth; moreover, K&K, von Bekesy, Johan Sundberg<br>and John Pierce all point out that even in pure harmonic spectra<br>intervals theoretically consonant can sound dissonant depending<br>on sequence of overtones and temporal sequence of notes. "It<br>became clear that the fifth was not always a consonant interval. <br>A chord of two tones that consists of only odd harmonics, for example,<br>shows much worse consonance at the fith (2:3) than at the major sixth<br>(3:5) or some other frequency ratios. This was proved true by psychological<br>experiments carried out in another institute (Sensory Inspection<br>Committee in the Japan Union of Scientists and Engineers with a <br>different method of scaling. Thus, the fact warns against making a <br>mistake in applying the conventional theory of harmony to musical<br>tones that can take on a variety in the harmnic structure." [Kameoka,<br>A. and Kuriyagawa, M. "Consonance Theory Part II: Consonance of Complex<br>Tones and Its Calculation Method," Journ. Acoust. Socc. Am., 45 (6), 1969, pg. <br>1460]<br> etc., etc.<br>While Doty, Alves, Canright and other have puffed up the aging and<br>antiquated place theory as though it were the only one ever advanced to<br>explain the operation of the ear, there are in fact 3 models of human hearing: the place theory ; the periodicity theory, and the learned-response (or software)  model.<br>Thus the place theory, put forward as THE model of human hearing by Doty, <br>Worrall and Alves, is merely one of several.  It has a lot of problems.  <br>There's plenty of data contradicting this model of the ear/brain system--<br>none of which has ever been mentioned in this forum by anyone but Your<br>Humble E-Mail Correspondent.<br>Even more surprising is that fact that *none* of these theories of<br>human hearing is at all new.  <br>All 3 models of the ear/brain system were proposed within 5<br>years of each other--between 1841 and 1845.  Moreover, experimental<br>evidence was brought forward by proponents of each of these <br>psychoacoustic models to confute the other paradigms.<br>Thus, while some psychoacoustic experiments strongly support each<br>model of human hearing, other evidence strongly contradicts it.  For<br>example, strong evidence for the place theory (ear as mechanical<br>Fourier analyzer) is provided by "cocktail party effect," through which<br>the ear easily manages to extract a single conversation from many<br>overlapping sounds.  Strong evidence against the place theory, however,<br>comes from the Schouten/Seebeck missing fundamental effect (the ear's<br>uncanny ability to "fill in" a fundamental that's been filtered out<br>of a sound, which can only be explained if the ear is detecting the<br>fundamental periodicity of the sound rather than its <br>Fourier components).  Strong evidence *for* the periodicity theory<br>of hearing is provided by the observed neural coding of sounds as<br>pulse-coded action potentials along the auditory nerve,<br>measured via microelectrodes.  However, strong evidence *against* the<br>periodicity theory comes from the calculated width of the pulses<br>on the auditory nerve--a datum leading inevitably to the conclusion that<br>the ear cannot sense frequencies higher than 1600 hz due to the<br>latency of the auditory nerve and the known limit of propagation of<br>nerve impulses in the human nervous system (circa 240 mph).  Since<br>the ear is obviously sensitive to frequencies *higher* than 1600 Hz,<br>the periodicity theory cannot be whole story either.<br>Strong evidence for the Fetis/Ward/Burns theory of the ear/brain<br>system as governed by learned response comes from the many<br>musical cultures on this planet...many of which do not use harmonic<br>timbres or just intervals.  (Are the Javanese and the Balinese <br>deluded?  Or are their inner ears physically different from ours? <br>There is no evidence for this, yet--as Marc Perlman has pointed out,<br>no one has shown how Javanese or Balinese  music can be described<br>by small whole-number ratios.  Ditto the musics of the Thais, of<br>sub-Sharan Africa, of various Brazilian indian tribes, of the Mongolian<br>herders and of indigenous peoples of Nepal and Tibet...ad infinitum.)<br>Strong evidence *against* the Fetis/Ward/Burns model of the ear<br>as molded primarily by learned response comes from the data showing <br>that for some timbres Fourier analysis of the lower 6 harmonics does<br>occur on the basilar membrane for at least some kinds of tones.<br>And so the reality of psychoacoustics is a lot more complex than<br>the simplistic claims made on this forum.<br>One reason for this confusion has been the rate at which science<br>has progressed over the last 70 years. Up to the late 1940s,<br>researchers'  understanding of the entire ear/brain<br>system stopped at the physical level--the level of the basilar<br>membrane.  (These are the results, primarily from von Bekesy, cited<br>by most of the subscribers to this forum.  As we have seen, however, von <br>Bekesy himself was well aware of the problems with this view of<br>the ear.) Then, in the late 1940s, technology for the first time<br>allowed researchers to insert microelectrodes into the auditory<br>nerves of living creatures and study the pattern of nerve impulses<br>generated by sound.  <br>Thus, while the view of researchers during the 1920s-1940s was<br>that the ear was a purely physical system that performed a <br>mechanical Fourier analysis of input sound waves, the view changed<br>after the 1940s.  Researchers who analyzed the pattern of nerve<br>impulses in the ear/brain system began to emphasize the<br>role of neural coding in human perception of sound.   The application<br>of the computer from the 1960s onward led to a third theory<br>of the ear/brain system which emphasized the "software" aspects<br>of the brain and the role of software-controlled feedback paths<br>in the ear/brain system. Roger Shepard, Carol Krumhansl, Burns,<br>Ward,  and many others have advanced such models of the ear<br>within the last few years.<br>>From this standpoint it becomes clear why so many older textbooks<br>are filled with so much outdated or simply incorrect information.<br>It is less easy to explain why so many subscribers to this forum <br>continue to blow the dust off moldy texts and cite obsolete<br>hypotheses as though a majority of current researchers<br>still believed them. <br>With any luck, my upcoming series of posts will clear up some of<br>this confusion, and replace citations of obsolete hypotheses & texts <br>dating from the1940s with modern research and accurate data.<br> --mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Sun, 24 Sep 1995 18:55 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id JAA11775; Sun, 24 Sep 1995 09:55:13 -0700<br>Date: Sun, 24 Sep 1995 09:55:13 -0700<br>Message-Id:  <9509240954.aa14951@cyber.cyber.net><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2040 href="#2040">ðŸ”—</a>Timothy Tikker and Julia Harlow &#x3C;tjt@efn.org&#x3E;</h3><span>9/24/1995 8:50:37 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>On Sun, 24 Sep 1995, Gary Morrison wrote:<br><br>>    Does anybody know how Amazing Grace became popular to play on Bagpipes?  Just<br>> curious of course.  <br>> <br><br>Speaking as a piper, I would guess it's been popular at least 20 years.  <br><br>Julia Harlow<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Mon, 25 Sep 1995 07:01 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id WAA16862; Sun, 24 Sep 1995 22:00:51 -0700<br>Date: Sun, 24 Sep 1995 22:00:51 -0700<br>Message-Id: <v01510100ac8bf3c1f5ad@[205.161.158.181]><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><a href="/old-tuning-list">back to list</a><h1></h1><h3><a id=2037 href="#2037">ðŸ”—</a>&#x22;John H. Chalmers&#x22; &#x3C;non12@cyber.net&#x3E;</h3><span>9/23/1995 8:39:53 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>From: mclaren<br>Subject: Misinformation about psychoacoustics<br> & an upcoming series of 25 posts<br>---<br>The psychoacoustic information posted on this<br>forum seems to stop around 1940.   This would<br>be of little concern if psychoacoustics had but<br>a tangential affect on microtonality; alas,<br>such is not the case.  The workings of the ear-brain<br>system are crucial to real-world music.<br>Thus *someone* must point out the veritable<br>deluge of incomplete information, inaccuracies and<br>outright canards that has characterized the psychoacoustics-<br>related posts on this forum.  And since no one else<br>has bothered to do it...<br>This is no one's fault.  As Enrique Moreno has pointed<br>out in his 1992 book "Expanded Tunings In Contemporary<br>Music," (The Edwin Mellen Press, pg. 107), during this century <br>knowledge about the ear/brain system has grown *much* faster<br>than music professors' awareness of it, or musicians'<br>understanding of it.<br>Thus in pointing out the pervasive inaccuracies in the<br>psychoacoustic (mis)information posted on this forum,<br>my intent is to engender  a quest for truth, rather than<br>impugn anyone's credibility or good intentions.<br>It's important, however, that the *facts* (as opposed to the<br>myths) about the ear/brain system come out.  Differences<br>of opinion are one thing; but overt misinformation is <br>another.<br>The subject of psychoacoustics, as Larry Polansky<br>pointed out in his 1985 guest editorial in 1/1, is<br>one of the most fruitful areas of musical exploration<br>for the late 20th century. Anyone who doubts this need<br>only listen to the music of the best computer <br>composers around--almost without exception Risset,<br>Wessel, Chowning, et alii are deeply involved in<br>psychoacoustic research.<br>Harry Partch made the same point about the importance<br>of psychoacoustics in "Genesis of A Music."<br>Alas, as previous posts have shown, Partch quotes no<br>psychoacoustics references dated later than 1947--and<br>most of what Partch said about the ear/brain system turns<br>out to be poppycock.  Subsequent psychoacoustic research<br>has largely invalidated his claims about psychoacoustics.<br>While my earlier posts to this effect 8 months ago spurred<br>a brief frenzy of name-calling and denial-for-the-sake-of-denial,<br>the frenzy now seems to have abated. And  most <br>of the people who initially reacted like vampires in a <br>crucifix factory to my posts about Partch's errors on <br>psychoacoutics now tacitly (sometimes overtly) recognize <br>that, yes, Partch's statements on the subject are claptrap.<br>This does *NOT* mean that Partch was wrong in stressing<br>the importance of psychoacoustics in microtonality.  <br>Harry Partch was a genius, far ahead of his time.  <br>He simply had the misfortune to study a psychoacoustic literature <br> which Max Mathews' acoustic compiler of 1959 was to render obsolete virtually overnight. <br>Partch's essential emphasis on psychoacoustics was and is crucial<br>to an understanding of the musical uses of microtonality.  Good<br>music *can* be composed even if one doesn't know how a given<br>tuning interacts with the human auditory....but common sense<br>tells us it's an awful lot *easier* to compose  microtonal<br>music that does what you want it to do if you  know something<br>about what's going on in the ear/brain system.<br>In short, the limits we put on the musics we make are a result<br>of what we understand about how the ear hears.  If we wish to<br>remove the limits on the microtonal music we can imagine, we<br>must first remove the limits on our understanding of the ear.<br>Thus for the next month or so John Chalmers will be uploading<br>a series of 25 posts on tuning and psychoacoustic by Your<br>Humble E-Mail Correspondent.  This series will bear on real music <br>and real tunings as much as on the ear/brain system, and should <br>prove interesting to at least some of you.  <br>Even if it doesn't, this upcoming series of  posts is sure to <br>provoke enough discussion to clarify the underlying<br>psychoacoustic facts.  <br>Before starting that series, permit me to give a few examples<br>of the kind of misinformation that's been drifting around on <br>this forum since day 1:<br>In Topic 1 of Tuning Digest 427 Johnny Reinhard wrote: "Since<br>Julian Carrillo recognized the physical structure of the ear as<br>having `hairs' that corresponded - like a harp - to specific pitch<br>frequencies, with corresponding octaves, I have wondered about<br>these hairs or `cilia.'  The New York Times wrote about them a few <br>weeks ago and I have yet to hear about an exact number of <br>hairs-per-octave." [Johnny Reinhard, Topic 1, Digest 427]<br>Compounding the confusion, David Doty, David Worrall and<br>William Alves chimed in to "correct" Johnny's post.  Doty <br>claims: "I think there's a misunderstanding here.  As I <br>understand the matter, a given frequency excites a fairly<br>wide region on the basilar membrane, and hence, a considerable<br>number of hair cells.  Maximum excitation occurs at the center <br>for the band, with excitation diminishing toward the ends."<br>[David Doty, Topic 1, Digest 429]<br>David Worrall claims: "Futhermore, when two tones are close<br>together these bands of cells overlaps, causing an inability<br>to distinguish the two frequencies: hence difference<br>between frequency and pitch. Related to the Critical Band..."<br>[David Worrall, Topic 3, Digest 429]<br>And William Alves claims: "This is true.  Apparently along the<br>neural pathways to the brain, the middle frequency is calculated,<br>and that is what we hear." [William Alves, Topic 4, Digest 429]<br>The problem is that each of these statements, while in general<br>incorrect, contains enough crumbs of fact to bamboozle the <br>unwary reader.  <br>Johnny Reinhard's idea that each hair cell on the basilar <br>membrane corresponds to a given frequency isn't correct, but<br>it has an important germ of truth in it.<br>Why couldn't each hair cell on the basilar membrane corresond<br>to a given musical pitch?  First, because there aren't enough <br>hairs to account for  human sensitivity to small pitch changes.<br>While there are 15,000 hair cells in the average human ear, only<br>3000 inner hair cells are responsible for pitch detection; the <br>other 12,000 outer hair cells serve a supporting role. The 10-octave<br>range of human hearing divided by 3000 inner hair cells gives a<br>a just noticeable frequency difference limen of 4 cents, but measured<br>human frequency sensitivity  for prolonged test tones is much<br>finer, down to + or -1 Hz for long-held harmonic test tones. <br>In fact the theory that individual stereocilia are "tuned" to <br>particular notes is not a new idea--it was first advanced by<br>Herophilus and Erasistratus around 490 B.C. and  then by Aristotle <br>in 344 B.C. The notion imported into Europe in modern times<br>by Joannes Muelle in his 1838 text Handbuch der Physiologie, in which<br>he called it the doctrine of "specific nerve energies."  While<br>this theory of hearing is now known to be incorrect, at the<br>time it was a significant advance over Empedocles' theory of<br>"implanted air." <br>Thus, while incorrect, "the doctrine of specific nerve energies<br>prepared the way for interpretations of new anatomical<br>discoveries that came with the development of better methods,<br>such as the improved compound microscope that appeared around<br>1830." ["Hearing: Physiological Acoustics, Neural Coding and<br>Psychoacoustics," W. Lawrence Gulick, George A. Gescheider and<br>Robert D. Frisina, Oxford University Press, 1989, pg. 59] <br>So while this notion comes from antique sources, there's an important<br>element of truth in Johnny's concept of the ear.  As Pierre Buser &<br>Michel Imbert point out in "Audition," (MIT Press, 1995), "some<br>neurons [in the auditory nerve] produce strong signals when<br>presented with tones in a particular range, but do not respond<br>to tones in other frequency ranges.  A small proportion of<br>neurons emit strong signals when two different frequencies<br>are sounded togehter but respond weakly when either of<br>these frequencies is sounded alone.  Some neurons are activated<br>best by sounds at particular amplitudes and less well at lower<br>or higher amplitudes.  For yet other nerve cells, the higher the <br>amplitude of the sound, the stronger the signal that is produced,<br>until some saturation point is reached."<br>Thus Johnny's specific picture is inaccurate, but it's founded on<br>a deep insight: certain nerve cells [NOT hair cells--we're talking<br>about neurons in the auditory nerve and other brain centers]<br>in the ear/brain system *do* react to specific frequencies.  <br>Thus, crucial elements of the ear/brain system *are* in fact <br>sensitive to specific frequencies (and amplitudes, and specific <br>frequency-differences, etc.), contrary to the implications of<br>Doty, Alves, Worrall, et al.<br>Johnny's post also raises an important question--one which<br>Doty, Worrall and Alves conveniently ignore.  To wit:<br>If the human ear/brain system performs a purely mechanical<br>Fourier analyzer of input sounds, what need is there for all these<br>different kinds of neurons in the auditory nerve, the medial<br>geniculate nucleus, the Sylvian fissure, etc.?  <br>It is well known that the description of the ear to which Doty,<br>Worrall and Alves (known as the place theory of hearing) refer is<br>incomplete and conflicts with much of the psychoacoustic<br>evidence.  "A second difficulty with the place theory lies in the<br>fact that, in complex sounds, components are often heard<br>that are present in the Fourier analysis.  or loudness judgments <br>of components may be made which do not agree with the amplitudes <br>obtained for Fourier components.  It is certainly true that there<br>are phenomena which cannot at the present time be explained by<br>the place theory of hearing." [von Bekesy, Georg, "Hearing Theories<br>and Complex Sounds," Journ. of the Acoust. Soc. Am, 35(4), April<br>1963, pg. 589]  Be it noted that von Bekesy is the researcher most<br>responsible for compiling experimental evidence for the place<br>theory. (In fact he won the Nobel prize for it.)<br>The place theory describes the ear as a mechanical Fourier<br>analyzer. This model of the ear does not explain many of the observed<br>characteristics of the ear/brain system. For example, given<br>the width of regions of maximal stimulation along the basilar<br>membrane, human frequency discrimination should<br>be quite coarse--yet tests should that we can easily detect very<br>fine changes in frequency. "For a sinusoidal tone, the locus of maximum<br>stimulation [of the basilar membrane] changes regularly with frequency<br>only from about 50 through 16,000 Hz, so that place cannot account for<br>low pitches from 20 through 50 Hz. Further, the just noticeable difference<br>(jnd) in frequency of sinusoidal tones apears to be too small to be accounted<br>for by spectral resolution along the basilar membrane. Figure 3.5 shows that for  500 Hz the critical band width is about 100 Hz, yet jnd's having values less than 1 Hz have been reported (Moore, 1974; Nordmark, 1968). While <br>there are mechanisms based on place which have been proposed for <br>discriminating tones separated by considerably less than a critical band <br>(Bekesy, 1960; Tonndorf, 1970; Zwicker, 1970), none seems capable of handling jnd's as small as those reported by Nordmark and Moore."<br>["Auditory Perception: A New Synthesis," Warren, R. A, Pergamon Press,<br>New York, 1985] <br>Moreover, according to the place theory the ear should be insensitive to<br>phase.  But both Newman Guttman's 1959 data and Robert M. Green's<br>1973 experiments show this is not the case.  Most damning of all, if the<br>ear merely performs a mechanical Fourier transform (as Worrall,<br>Doty and Alves claim), how do we account for the ear's ability<br>to extract a missing fundamental?  Schouten's siren experiment,<br>Seebeck's fifth and sixth click series, and Stumpf's experiments<br>all contradict this model of the ear as a simple mechanical Fourier<br>analyzer.  In short, "The discovery of second order effects in auditory <br>processing, such as the perception of phase changes, beats of mistuned <br>consonances and fundamental tracking, has had a great impact on the <br>theory of hearing.  Indeed, these effects cannot be explained appropriately<br>with the conventional `place' theory." [Roderer, Juan, "The Physics and<br>Psychophysics of Music," 1973, 2nd, ed., pg. 41]<br>Moreover, Doty, Worrall and Alves leave unanswered the question of <br>how the ear conjures up a sensation of pitch from a flat noise spectrum.<br>According to a Fourier model of the ear, a broad-band noise with a flat<br>spectrum *cannot* produce a sensation of pitch.  It is by definition UNpitched.<br>Yet, as we all know, white noise generates a weak sensation of<br>pitch.  Eberhard Zwicker summarizes this point concisely: <br>"While the pitch of the noises so far can be traced back to a<br>spectral feature, namely a distinct change in the spectrum, broad-band <br>noises with flat spectra also produce pitch sensations." [Zwicker, E. and <br>H. Fastl, "Psychoacoustics: Facts and Models," 1990, pg. 121]<br>This conclusion is so antithetical to the Fourier description of the ear<br>as to that it's clear that "Auditory physiologists divide into three <br>groups, namely those that think only temporal information [from <br>the firing of neurons] is used, those that think only place information<br>[location on the basilar membrane] is used, and an eclectice group<br>whoe supporse that temporal information is used at low frequencies<br>and place information at high. (..) There are several lines of evidence<br>for and against these theories, none of which is conclusive." [Pickles,<br>James. O, "An Introduction to the Physiology of Hearing," Academic<br>Press, 1988, pg. 271]<br>Doty, Worrall and Alves pointedly ignore this controversy between<br>psychoacoustic researchers--charitably, we'll assume there was no duplicitous intent.  Regardless, the net effect of their posts is <br>to create a false impression.<br>Moreover, the arguments put forward in their posts hide a multitude of<br>contradictions and inconsistencies by giving only a few scraps of<br>fact and suppressing the rest.<br>Alves claims that the center regions of the basilar membrane excitatory regions are  "calculated"--implying the  involvement of higher brain regions.<br>This is one of the three competing hypotheses of the ear, today<br>known as the "pattern recognition" model.  <br>What Alves does NOT mention is that "calculation" by neurons<br>cannot be whole story.  Recent experiments with cochlear impants<br>in the deaf have cast grave doubts on the pattern recognition model<br>of hearing, according to which the ear "calculates" pitches from<br>volleys of neural impulses produced by excitation of the basilar<br>membrane: <br>"If we believe the extreme position that at low requencies information<br>is carried purely by the temporal pattern of nerve impulses, then periodic<br>electrical stimulation should produce faithful auditory sensations and<br>good discrimination of frequencies. The results of electrical stimulation<br>have on the whole been disappointing for such a prediciton. In only a few<br>few cases do electrical stimuli seem to produce clear tonal sensations. A typical report is that tones sound like "comb and paper" (e.g., Fourcin et<br>al, 1979)." [Pickles, James O., "An Introduction to the Physiology of<br>Hearing," 1988, Academic Press, pg. 316]  <br>And in any case Alves' notion of "calcuation" of center frequencies from basilar membrane maxima  opens up a Pandora's box and undermines the very place theory he esposes.<br>If higher brain centers supervene to "calculate" pitch, the Fourier analysis<br>activity of the basilar membrane becomes suspect as adequate explanation<br>for human hearing.  And in fact an approximate Fourier analysis is only<br>performed on the lower six harmonics, and then only above 5 khz...<br>casting strong doubts about the importance of the entire mechanical<br>Fourier analysis activity of the basilar membrane.<br>But if basilar membrane activity *isn't* the whole<br>picture, how to account for the Zwicker tone?   How to explain <br>Wessel's "streaming" phenomenon?  How can we then explain Risset's<br>auditory illusions? <br>The invocation of higher brain centers leads to endless amounts<br>of trouble for the place theory--yet, as Alves' post shows, it<br>cannot be avoided if we want to explain many auditory<br>phenomena.  <br>A classic catch-22. <br>If indeed higher brain centers  *are* involved in hearing, we're now on the slippery slope.  <br>Because if the ear "calculates" frequencies rather than perceiving<br>them via von Bekesy's model of mechanical Fourier analysis, why not posit<br>a greater role for "calculation"...to the point where the ear's mechanical<br>Fourier analysis role becomes unimportant? Since it only operates on<br>the lower six harmonics and then only above 5 Khz, its importance is<br>surely questionable to begin with.<br>Recent models of hearing emphasize the operation of higher brain centers <br>and discount the significance of the basilar membrane in hearing.<br>ial optimum-processor model all tend to bely the  purported importance of the basilar membrane in favor of higher-level processing.<br>Experimental data also show that higher brain centers are crucial to the perception of pitch:<br>A. J. Dowling's article "The 1215-Cent Octave: Convergence of Western<br>and Non-Western Data on Pitch Scaling," Abstract QQ5, 84th Meeting of the <br>Acoustical Society of Maerica, Friday, December 1, 1971, pg. 101, adduces<br>a wealth of data proving that the preference for stretched octaves<br>is universal.  Sunderg and Linqvist, in "Musical Octaves and Pitch," Journ.<br>Acoust. Soc. Am., Vol. 54, No 4, 1973, pp. 973-929, and Lichte's, Ward's,<br>Corso's and Burn's research also show the same result: "As a rule, the<br>perceptual octave corresponds to a fundamental frequency ratio exceeding<br>2:1."  [Sundberg, J. and Lindqvist, J. "Musical Octaves and Pitch," JASA, <br>54(4), 1973, pg. 978]  All of these data broadly contradict the predictions<br>that follow from a model of the ear as Fourier analyzer, and instead<br>tend to support the hypothesis that the ear is a learned-response system.<br>Moreover, the known data showing that when Fourier analysis operates along<br>the basilar membrane (much of the time it doesn't; other ear/brain mechanisms operate, depending on the type of auditory input) only for the lower 6 harmonics raises the question:<br>How can the ear decipher the fundmental pitch of a harmonic sounds<br>whose lower 6 harmonics have been completely filtered out?  Schouten<br>and Seebeck have shown that this occurs--the Fourier-analysis view<br>of the ear cannot possiply explain it.  <br>Again, Doty, Worrall and Alves conveniently slither & slide over this point without so much as a word of explanation.<br>And there's more: the brain employs feedback networks between<br>auditory neurons in  many<br>of different brain regions.  Some feedback loops run from<br>the Sylvian fissure, still others from the medial geniculate body. And in<br>all cases neural filaments radiate from fourth-order auditory neurons<br>in the cerebral cortex back to the geniculate body, thence to the auditory<br>neurons of the inferior colliculus, back even farther to the primary<br>auditory neurons of the cochlear nucleus.  If the ear is a simple mechanical<br>Fourier analyzer, why such a complex software-controlled feedback loop,<br>full of neurons which react in so many different ways to so many different<br>kinds of amplitudes and frequencies and frequency differences?  <br>Clearly something more is going on in the ear than the simplistic<br>mechanical Fourier transform which Doty, Worrall and Alves claim.<br>My point here is not that Reinhard, Doty, Worrall and Alves were<br>right or wrong: the big problem is that these posts (like so many others on <br>this forum) purvey information dredged up from a single antique model of <br>the ear/brain system as though it were *the ONLY* model of the ear/brain <br>system.  As though one single 1940-vintage hypothesis<br> were the truth, the whole truth, and nothing but the truth.<br>In addition, the posts by Mssrs. Reinhard, Doty, Worrall and Alves<br>systematically avoid mentioning auditory phenomena which<br>contradict their particular pet theory of hearing. <br>The place theory of hearing is the *only* theory  congenial to just intonation; thus Mssrs. Doty and Alves have a hidden agenda when<br>they purvey this notion and neglect to mention the many<br>psychoacoustic results which minimize the significance of just<br>intonation, or militate against it.  For example, Mssrs. Doty and<br>Alves do not mention the results of Plomp & Levelt or Kameoka and<br>Kuriyagawa, which demonstrate that consonance is a matter not<br>of harmonic spectra but of partials separated by more than a<br>critical bandwidth; moreover, K&K, von Bekesy, Johan Sundberg<br>and John Pierce all point out that even in pure harmonic spectra<br>intervals theoretically consonant can sound dissonant depending<br>on sequence of overtones and temporal sequence of notes. "It<br>became clear that the fifth was not always a consonant interval. <br>A chord of two tones that consists of only odd harmonics, for example,<br>shows much worse consonance at the fith (2:3) than at the major sixth<br>(3:5) or some other frequency ratios. This was proved true by psychological<br>experiments carried out in another institute (Sensory Inspection<br>Committee in the Japan Union of Scientists and Engineers with a <br>different method of scaling. Thus, the fact warns against making a <br>mistake in applying the conventional theory of harmony to musical<br>tones that can take on a variety in the harmnic structure." [Kameoka,<br>A. and Kuriyagawa, M. "Consonance Theory Part II: Consonance of Complex<br>Tones and Its Calculation Method," Journ. Acoust. Socc. Am., 45 (6), 1969, pg. <br>1460]<br> etc., etc.<br>While Doty, Alves, Canright and other have puffed up the aging and<br>antiquated place theory as though it were the only one ever advanced to<br>explain the operation of the ear, there are in fact 3 models of human hearing: the place theory ; the periodicity theory, and the learned-response (or software)  model.<br>Thus the place theory, put forward as THE model of human hearing by Doty, <br>Worrall and Alves, is merely one of several.  It has a lot of problems.  <br>There's plenty of data contradicting this model of the ear/brain system--<br>none of which has ever been mentioned in this forum by anyone but Your<br>Humble E-Mail Correspondent.<br>Even more surprising is that fact that *none* of these theories of<br>human hearing is at all new.  <br>All 3 models of the ear/brain system were proposed within 5<br>years of each other--between 1841 and 1845.  Moreover, experimental<br>evidence was brought forward by proponents of each of these <br>psychoacoustic models to confute the other paradigms.<br>Thus, while some psychoacoustic experiments strongly support each<br>model of human hearing, other evidence strongly contradicts it.  For<br>example, strong evidence for the place theory (ear as mechanical<br>Fourier analyzer) is provided by "cocktail party effect," through which<br>the ear easily manages to extract a single conversation from many<br>overlapping sounds.  Strong evidence against the place theory, however,<br>comes from the Schouten/Seebeck missing fundamental effect (the ear's<br>uncanny ability to "fill in" a fundamental that's been filtered out<br>of a sound, which can only be explained if the ear is detecting the<br>fundamental periodicity of the sound rather than its <br>Fourier components).  Strong evidence *for* the periodicity theory<br>of hearing is provided by the observed neural coding of sounds as<br>pulse-coded action potentials along the auditory nerve,<br>measured via microelectrodes.  However, strong evidence *against* the<br>periodicity theory comes from the calculated width of the pulses<br>on the auditory nerve--a datum leading inevitably to the conclusion that<br>the ear cannot sense frequencies higher than 1600 hz due to the<br>latency of the auditory nerve and the known limit of propagation of<br>nerve impulses in the human nervous system (circa 240 mph).  Since<br>the ear is obviously sensitive to frequencies *higher* than 1600 Hz,<br>the periodicity theory cannot be whole story either.<br>Strong evidence for the Fetis/Ward/Burns theory of the ear/brain<br>system as governed by learned response comes from the many<br>musical cultures on this planet...many of which do not use harmonic<br>timbres or just intervals.  (Are the Javanese and the Balinese <br>deluded?  Or are their inner ears physically different from ours? <br>There is no evidence for this, yet--as Marc Perlman has pointed out,<br>no one has shown how Javanese or Balinese  music can be described<br>by small whole-number ratios.  Ditto the musics of the Thais, of<br>sub-Sharan Africa, of various Brazilian indian tribes, of the Mongolian<br>herders and of indigenous peoples of Nepal and Tibet...ad infinitum.)<br>Strong evidence *against* the Fetis/Ward/Burns model of the ear<br>as molded primarily by learned response comes from the data showing <br>that for some timbres Fourier analysis of the lower 6 harmonics does<br>occur on the basilar membrane for at least some kinds of tones.<br>And so the reality of psychoacoustics is a lot more complex than<br>the simplistic claims made on this forum.<br>One reason for this confusion has been the rate at which science<br>has progressed over the last 70 years. Up to the late 1940s,<br>researchers'  understanding of the entire ear/brain<br>system stopped at the physical level--the level of the basilar<br>membrane.  (These are the results, primarily from von Bekesy, cited<br>by most of the subscribers to this forum.  As we have seen, however, von <br>Bekesy himself was well aware of the problems with this view of<br>the ear.) Then, in the late 1940s, technology for the first time<br>allowed researchers to insert microelectrodes into the auditory<br>nerves of living creatures and study the pattern of nerve impulses<br>generated by sound.  <br>Thus, while the view of researchers during the 1920s-1940s was<br>that the ear was a purely physical system that performed a <br>mechanical Fourier analysis of input sound waves, the view changed<br>after the 1940s.  Researchers who analyzed the pattern of nerve<br>impulses in the ear/brain system began to emphasize the<br>role of neural coding in human perception of sound.   The application<br>of the computer from the 1960s onward led to a third theory<br>of the ear/brain system which emphasized the "software" aspects<br>of the brain and the role of software-controlled feedback paths<br>in the ear/brain system. Roger Shepard, Carol Krumhansl, Burns,<br>Ward,  and many others have advanced such models of the ear<br>within the last few years.<br>>From this standpoint it becomes clear why so many older textbooks<br>are filled with so much outdated or simply incorrect information.<br>It is less easy to explain why so many subscribers to this forum <br>continue to blow the dust off moldy texts and cite obsolete<br>hypotheses as though a majority of current researchers<br>still believed them. <br>With any luck, my upcoming series of posts will clear up some of<br>this confusion, and replace citations of obsolete hypotheses & texts <br>dating from the1940s with modern research and accurate data.<br> --mclaren<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Sun, 24 Sep 1995 18:55 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id JAA11775; Sun, 24 Sep 1995 09:55:13 -0700<br>Date: Sun, 24 Sep 1995 09:55:13 -0700<br>Message-Id:  <9509240954.aa14951@cyber.cyber.net><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><h3><a id=2040 href="#2040">ðŸ”—</a>Timothy Tikker and Julia Harlow &#x3C;tjt@efn.org&#x3E;</h3><span>9/24/1995 8:50:37 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>On Sun, 24 Sep 1995, Gary Morrison wrote:<br><br>>    Does anybody know how Amazing Grace became popular to play on Bagpipes?  Just<br>> curious of course.  <br>> <br><br>Speaking as a piper, I would guess it's been popular at least 20 years.  <br><br>Julia Harlow<br><br>Received: from eartha.mills.edu [144.91.3.20] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Mon, 25 Sep 1995 07:01 +0100<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <coul@ezh.nl> id WAA16862; Sun, 24 Sep 1995 22:00:51 -0700<br>Date: Sun, 24 Sep 1995 22:00:51 -0700<br>Message-Id: <v01510100ac8bf3c1f5ad@[205.161.158.181]><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div>