<a href="/old-tuning-list">back to list</a><h1>Diatonic Key Detection</h1><h3><a id=3806 href="#3806">ðŸ”—</a>Gary Morrison &#x3C;71670.2576@CompuServe.COM&#x3E;</h3><span>10/21/1996 10:17:15 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>I'm pondering a problem that, while not tuning itself, is certainly related<br>to the field of tuning:  "Here's a MIDI file of some music;  what key is it in?"<br>Or more specifically, which key signature it's in?<br><br>   Two very different ways of doing that came to mind, and perhaps a<br>heuristically reasonable weighting of the two would make the best sense.  Or<br>perhaps somebody out there has a better algorithm?  <br><br>   The first was to create an array of pitch classes in the order along the<br>circle of fifths (i.e., not C C# D..., but ... Eb Bb F C G D A...), tally up the<br>computer equivalent of tick-marks each time a pitch class is used, and then<br>choose the key from the most commonly used seven adjacent notes.  <br><br>   The tricky part of in this algorithm is where to tally up enharmonic<br>equivalents.  In concept you'd probably be best to have a 19-pitch-class array<br>(Cb Gb Db Ab Eb Bb F C G D A E B F# C# G# D# A# E#), and tally up a note as all<br>of its enharmonic equivalents.  That is, if an Eb key goes down, tally it up<br>both as an Eb and as a D#.  If the music being examined is in the key of A major<br>for example, the resulting histogram will show:<br>1.  A whole lot of notes in D-G# region,<br>2.  A substantial, but overall lower-commonness, "alias" in the Cb-Ab part of <br>    the array, and <br>3.  A few stray accidentals largely down in the proverbial noise, and mostly <br>    clustering around the main D-G# region.  <br><br>   The other method that came to mind was somewhat more like what a human would<br>concentrate on:  To look at structurally significant spots in the sequence -<br>cadential points in short - and attempt to choose a tonal center around that.<br>The obvious problem with that is that it's very difficult to automate to say the<br>least.  It's essentially an artificial intelligence problem rather than an<br>algorithmic problem.  <br><br>   But perhaps some basic heuristics of this artificial-intelligence-like<br>approach can be used to augment the first approach.  Most importantly to prevent<br>there being an "off-by-one" ambiguity sort of problem.  In particular, what pops<br>into mind are:<br>1.  Tally up fewer, or no points at all, for clearly nondiatonic constructs.  <br>    For example, if a note is a chromatic passing tone a half-step away from <br>    both of its neighbors, give it no points at all.  Or only give it half a<br>    point if it is a minor third above the preceding note and a minor third<br>    below the next (or the descending equivalent).  <br>2.  Tally up more points for structurally significant intervals, like 5ths.<br>3.  Tally up more points for the notes toward the beginning and end of the <br>    fragment.<br>4.  Give slightly more points to notes toward the middle of the circle (why<br>    play something in D# major instead of Eb major?!).  <br>5.  Tally up more points for notes with longer durations, or higher <br>    velocities.  This rule could be risky though, since there's strong value <br>    in accenting (agogically or by volume) chromatically altered notes for <br>    drama.  On the other hand, failure to do this could be even more risky, <br>    in that one innocent little #4 to 5 trill could easily make the tally for<br>    #4 four or five times that for any of the diatonic notes!  That would<br>    obviously throw the results totally out of whack.  <br><br>   Does that seem like a reasonable approach?  Anybody have a more elegant<br>solution.  Or perhaps other heuristic refinements to consider?  <br><br>   Actually, the problem I'm interested in is not exactly key-signature<br>detection, but a closely related problem:  Diatonic transposition.  By that I<br>mean pushing up by a diatonic third for example, predominantly diatonic music<br>fragment.  So, in this example, scale degree 2 goes up a minor third to 4, while<br>5 goes up a major third to 7.  Perhaps there's a more elegant algorithm for that<br>problem than my assumed solution of finding the key and moving the original<br>notes diatonically within that key?  <br><br><br>Received: from ns.ezh.nl [137.174.112.59] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Tue, 22 Oct 1996 10:35 +0200<br>Received: by ns.ezh.nl; (5.65v3.2/1.3/10May95) id AA06595; Tue, 22 Oct 1996 10:36:51 +0200<br>Received: from eartha.mills.edu by ns (smtpxd); id XA06518<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <manuel.op.de.coul@ezh.nl> id BAA10017; Tue, 22 Oct 1996 01:36:46 -0700<br>Date: Tue, 22 Oct 1996 01:36:46 -0700<br>Message-Id: <009AA38D0BC028E0.3FB8@vbv40.ezh.nl><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div><a href="/old-tuning-list">back to list</a><h1>Diatonic Key Detection</h1><h3><a id=3806 href="#3806">ðŸ”—</a>Gary Morrison &#x3C;71670.2576@CompuServe.COM&#x3E;</h3><span>10/21/1996 10:17:15 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'>I'm pondering a problem that, while not tuning itself, is certainly related<br>to the field of tuning:  "Here's a MIDI file of some music;  what key is it in?"<br>Or more specifically, which key signature it's in?<br><br>   Two very different ways of doing that came to mind, and perhaps a<br>heuristically reasonable weighting of the two would make the best sense.  Or<br>perhaps somebody out there has a better algorithm?  <br><br>   The first was to create an array of pitch classes in the order along the<br>circle of fifths (i.e., not C C# D..., but ... Eb Bb F C G D A...), tally up the<br>computer equivalent of tick-marks each time a pitch class is used, and then<br>choose the key from the most commonly used seven adjacent notes.  <br><br>   The tricky part of in this algorithm is where to tally up enharmonic<br>equivalents.  In concept you'd probably be best to have a 19-pitch-class array<br>(Cb Gb Db Ab Eb Bb F C G D A E B F# C# G# D# A# E#), and tally up a note as all<br>of its enharmonic equivalents.  That is, if an Eb key goes down, tally it up<br>both as an Eb and as a D#.  If the music being examined is in the key of A major<br>for example, the resulting histogram will show:<br>1.  A whole lot of notes in D-G# region,<br>2.  A substantial, but overall lower-commonness, "alias" in the Cb-Ab part of <br>    the array, and <br>3.  A few stray accidentals largely down in the proverbial noise, and mostly <br>    clustering around the main D-G# region.  <br><br>   The other method that came to mind was somewhat more like what a human would<br>concentrate on:  To look at structurally significant spots in the sequence -<br>cadential points in short - and attempt to choose a tonal center around that.<br>The obvious problem with that is that it's very difficult to automate to say the<br>least.  It's essentially an artificial intelligence problem rather than an<br>algorithmic problem.  <br><br>   But perhaps some basic heuristics of this artificial-intelligence-like<br>approach can be used to augment the first approach.  Most importantly to prevent<br>there being an "off-by-one" ambiguity sort of problem.  In particular, what pops<br>into mind are:<br>1.  Tally up fewer, or no points at all, for clearly nondiatonic constructs.  <br>    For example, if a note is a chromatic passing tone a half-step away from <br>    both of its neighbors, give it no points at all.  Or only give it half a<br>    point if it is a minor third above the preceding note and a minor third<br>    below the next (or the descending equivalent).  <br>2.  Tally up more points for structurally significant intervals, like 5ths.<br>3.  Tally up more points for the notes toward the beginning and end of the <br>    fragment.<br>4.  Give slightly more points to notes toward the middle of the circle (why<br>    play something in D# major instead of Eb major?!).  <br>5.  Tally up more points for notes with longer durations, or higher <br>    velocities.  This rule could be risky though, since there's strong value <br>    in accenting (agogically or by volume) chromatically altered notes for <br>    drama.  On the other hand, failure to do this could be even more risky, <br>    in that one innocent little #4 to 5 trill could easily make the tally for<br>    #4 four or five times that for any of the diatonic notes!  That would<br>    obviously throw the results totally out of whack.  <br><br>   Does that seem like a reasonable approach?  Anybody have a more elegant<br>solution.  Or perhaps other heuristic refinements to consider?  <br><br>   Actually, the problem I'm interested in is not exactly key-signature<br>detection, but a closely related problem:  Diatonic transposition.  By that I<br>mean pushing up by a diatonic third for example, predominantly diatonic music<br>fragment.  So, in this example, scale degree 2 goes up a minor third to 4, while<br>5 goes up a major third to 7.  Perhaps there's a more elegant algorithm for that<br>problem than my assumed solution of finding the key and moving the original<br>notes diatonically within that key?  <br><br><br>Received: from ns.ezh.nl [137.174.112.59] by vbv40.ezh.nl<br>           with SMTP-OpenVMS via TCP/IP; Tue, 22 Oct 1996 10:35 +0200<br>Received: by ns.ezh.nl; (5.65v3.2/1.3/10May95) id AA06595; Tue, 22 Oct 1996 10:36:51 +0200<br>Received: from eartha.mills.edu by ns (smtpxd); id XA06518<br>Received: from  by eartha.mills.edu via SMTP (940816.SGI.8.6.9/930416.SGI)<br>	for <manuel.op.de.coul@ezh.nl> id BAA10017; Tue, 22 Oct 1996 01:36:46 -0700<br>Date: Tue, 22 Oct 1996 01:36:46 -0700<br>Message-Id: <009AA38D0BC028E0.3FB8@vbv40.ezh.nl><br>Errors-To: madole@ella.mills.edu<br>Reply-To: tuning@eartha.mills.edu<br>Originator: tuning@eartha.mills.edu<br>Sender: tuning@eartha.mills.edu</div>