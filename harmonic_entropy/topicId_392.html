<a href="/harmonic_entropy">back to list</a><h1>RE: [harmonic_entropy] Re: Eureka part one (actually, complexity  measures)</h1><h3>Paul H. Erlich &#x3C;PERLICH@...&#x3E;</h3><span>5/9/2001 2:59:49 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Robert Valentine wrote,</p><p>&gt;take output into excel and ooo and ahhh when sensible<br/>&gt;          results appear (like 204c being the &apos;best&apos; B for<br/>&gt;          the Ionian, followed by 194c)</p><p>Can I ask you where this is coming from? I always get something like 194&cent; as<br/>best.</p><p>&gt;Okay, so one thing that is interesting for input from this<br/>&gt;list is &apos;step 2&apos;. Paul has produced his lovely graphs, and<br/>&gt;from the documentation I down;oaded, I couldn&apos;t figure out<br/>&gt;a hack that produced similar ones.</p><p>Why don&apos;t you reproduce the calculation itself, as Manuel has?<br/>Or if you really want a hack, you can probably just superimpose a bunch of<br/>bell curves.</p><p>Thats okay, I&apos;m an engineer, not a mathematician. If I can<br/>hack a solution that produces &apos;good enough&apos; results (like<br/>the 204c and 194c mentioned above) then I have something I<br/>can feel good about investigating.</p><p>&gt;So, firstly, I believe that to produce something more like<br/>&gt;Pauls HE graph I would sum at each point, rather than taking<br/>&gt;minimum,</p><p>Yup.</p><p>&gt;while still using the existing technique to identify<br/>&gt;the identity of the RI at that point on the graph?</p><p>Unnecessary.</p><p>&gt;Regarding the complexity calculation. I am currently just<br/>&gt;using the product, with a pinch of fudging to favor otonal<br/>&gt;relationships</p><p>Any dyad is just as much &quot;otonal&quot; as &quot;utonal&quot;. I think you mean &quot;rooted&quot;<br/>relationships, with duality _not_ assumed.</p><p>&gt;In point of fact, leaving<br/>&gt;out the otonal &apos;correction&apos; does not have much affect on the<br/>&gt;final results once all rotations are considered.</p><p>That&apos;s because 5:4 and 8:5 must represent the same dyad, correct?</p><p>&gt;It may have<br/>&gt;a more result on the modal minimums, which are also<br/>&gt;interesting,</p><p>I don&apos;t think the &quot;modal minima&quot; according to the algorithm you&apos;ve described<br/>will be useful except in a style of music where the modal tonic occurs as a<br/>drone, a melody is played against that, and no further simultaneities<br/>between notes occur.</p><p>&gt;Oh, an IMPORTANT point (probably THE most important) is the<br/>&gt;data culling.</p><p>Not really understanding but it all sounds overly complicated.</p><p>&gt;The point here is that harmonic entropy mixes complexity of<br/>&gt;the intervals being heard and the accuracy that they are being<br/>&gt;produced at. Until I feel that I am mixing them in a sensible<br/>&gt;manner, I&apos;ll get more trustworthy results by seperating them.</p><p>Oh, OK. I&apos;m here to help you with the mixing. I don&apos;t think the two can be<br/>separated, actually -- in harmonic entropy they&apos;re pretty much one and the<br/>same.</p><p>&gt;SOmething that came up on the other list, and is also something<br/>&gt;to consider here, is ways to make my algorithm produce results<br/>&gt;which are more &apos;lattice-like&apos;. This may be an interesting are<br/>&gt;for harmonic entropy anyhow, as I believe that the 9/8 pocket<br/>&gt;SHOULD be deeper than the 8/7 or 10/9, although if this opens<br/>&gt;a debate that can be settled by creating this structure with a<br/>&gt;different name, I&apos;m all for it.</p><p>I think you may be thinking as follows: 9/8 will occur more often than 8/7<br/>or 10/9, because 9/8 is just two 3/2s. You&apos;re right. But I think this result<br/>has to (and will) come out as a result of the kinds of scale investigations<br/>you&apos;re doing. I don&apos;t believe it should be built in as a premise or feature<br/>of the underlying harmonic entropy curve.</p><p>&gt;SO (engineer, not scientist) a complexity measure that I<br/>&gt;posed in the other list was to consider both the prime factors<br/>&gt;and the distance on the lattice (exponents).</p><p>I&apos;d agree with this in principle.</p><p>&gt;For instance,<br/>&gt;just the product of these would be</p><p>&gt;81/64 = 3^4/2^6 =&gt; 3*4*2*6 = 144</p><p>Why are you multiplying 3*4 with 2*6 rather than adding them? A lattice<br/>approach would seem to indicate addition.</p><p>I&apos;d argue that (as you can see on some of the plots I did) harmonic entropy<br/>seems to indicate that the complexity associated with each prime factor p is<br/>log(p). So I&apos;d perform the calculation as follows:</p><p>81/64 = 3^4/2^6 =&gt; log(3)*4 + log(2)*6.</p><p>&gt;The case I had which this seemed to solve was that 19/15 at<br/>&gt;409c swallowed (for better or worse) the 81/64 at 408. Although<br/>&gt;pythagorean major scales came out as a minimum in the program,<br/>&gt;the fact that they report the third as 19/15 suggests a useage<br/>&gt;model that may be misleading.</p><p>Aha -- now here&apos;s something we can agree on! You see, you shouldn&apos;t expect<br/>every interval in the scale to come out as a local minimum of harmonic<br/>entropy. For example, when you found B=194&cent; for the diatonic scale, what<br/>ratio is that? Answer: it&apos;s not a ratio! It&apos;s a mean-tone.</p><p>Similarly, if you&apos;re finding Pythagorean diatonic scales with your program,<br/>it&apos;s only because your fifths are so strong. You _are_ getting 9/8s and<br/>81/64s, but this is _unrelated_ to what may lie near these intervals in the<br/>harmonic entropy graph. These intervals are _resultants_, _by-products_ of<br/>the strong fifths. So 9/8 and 81/64 are important scale intervals because of<br/>harmonic entropy . . . it&apos;s sort of an &quot;emergent&quot; feature of harmonic<br/>entropy. That&apos;s a good thing. But it would be a mistake to attempt to go<br/>back to the original harmonic entropy model and try to favor these intervals<br/>from the start. They&apos;re already (implicitly, rather than explicitly) favored<br/>enough!</p><p>&gt;3*2* (4*6)^(1/2) uses a more accurate distance metric (2 comes<br/>&gt;from the number of dimensions one is travelling) and</p><p>&gt;3*2* (4+6) uses more of a manhatten distance.</p><p>I don&apos;t get either of these. If the length of one step along each prime axis<br/>is p, then the manhattan distance for 81/64 would be 3*4 + 2*6 -- right?</p><p>But again, I feel strongly that log(p) rather than p should be the length of<br/>one step . . . because of Tenney and because of harmonic entropy.</p><p>&gt;I haven&apos;t addresses octave equivalence here, and thats<br/>&gt;important.</p><p>You might want to look over the discussion of octave-equivalent harmonic<br/>entropy models and graphs.</p></div>