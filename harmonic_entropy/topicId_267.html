<a href="/harmonic_entropy">back to list</a><h1>New dyadic ordering for tetrads</h1><h3><a id=267 href="#267">ðŸ”—</a>Paul H. Erlich &#x3C;PERLICH@...&#x3E;</h3><span>11/16/2000 12:44:43 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Rather than just summing the exponential, N=10000, s=1% dyadic entropies for<br/>the six intervals in the tetrad, I wanted to use a function that would give<br/>more emphasis to the most dissonant intervals. So I raised the exponential<br/>entropies to the power of 6*pi before summing them (kind of an arbitrary<br/>choice -- 6*pi comes up in the formula for the probability of two numbers<br/>being mutually prime). Here&apos;s the new ordering:</p><p>bass is always 0</p><p>rank     tenor         alto      soprano<br/>(sum(exp(entropy)^(6*pi)))^(1/(6*pi))<br/>1.        498          886         1384       99.304<br/>2.        492          980         1472       99.834<br/>3-4.      184          498          886       101.63<br/>3-4.      388          702          886       101.63<br/>5.        316          702         1018       101.84<br/>6-7.      502         1002         1390       102.22<br/>6-7.      388          888         1390       102.22<br/>8-9.      388          702          970       102.76<br/>8-9.      268          582          970       102.76<br/>10.       386          702         1088       103.12<br/>11-12.    184          388          886       103.14<br/>11-12.    498          702          886       103.14<br/>13-14.    186          576          888       103.37<br/>13-14.    312          702          888       103.37<br/>15-16.    302          502         1004       103.72<br/>15-16.    502          702         1004       103.72<br/>17-18.    386          884         1088       104.14<br/>17-18.    204          702         1088       104.14<br/>19.       268          702          970       104.47<br/>20-21.    318          816         1020       104.63<br/>20-21.    204          702         1020       104.63<br/>22-23.    384          588         1086       105.17<br/>22-23.    498          702         1086       105.17<br/>24.       500          816         1316       105.41<br/>25-26.    202          702          974       105.64<br/>25-26.    272          772          974       105.64<br/>27-28.    502         1002         1320       105.75<br/>27-28.    318          818         1320       105.75<br/>29-30.    434          820         1320       105.87<br/>29-30.    500          886         1320       105.87<br/>31-32.    388          776         1090       105.95<br/>31-32.    314          702         1090       105.95<br/>33.       388          886         1274       107.41<br/>34-35.    498          888         1282       107.64<br/>34-35.    394          784         1282       107.64<br/>36.       442          884         1326       108.08</p><p>For an ordering which cannot distinguish otonal and utonal, is this better<br/>than the one we had before? I certainly like seeing those bottom four where<br/>they are, the complete 7-limit tetrads move up to #8 and #9, and of course I<br/>have a personal interest in seeing the 22-tET stacked-fourth tetrad move up<br/>to #2 . . . seriously, what do you guys think?</p></div><h3><a id=268 href="#268">ðŸ”—</a>Paul H. Erlich &#x3C;PERLICH@...&#x3E;</h3><span>11/16/2000 10:05:12 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>In case anyone didn&apos;t know, (exp(entropy))^(6*pi) = exp(entropy*6*pi).</p></div><h3><a id=269 href="#269">ðŸ”—</a>Paul H. Erlich &#x3C;PERLICH@...&#x3E;</h3><span>11/16/2000 12:26:59 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>I wrote,</p><p>&gt;6*pi comes up in the formula for the probability of two numbers being<br/>mutually prime</p><p>Actually that probability is 6/(pi^2). So the Farey series of order N<br/>contains about 6*(N/pi)^2 fractions, since, of the N^2 possible fractions of<br/>numbers up to N, a fraction ~6/(pi^2) of them are in lowest terms.</p><p>What if I calculate the harmonic entropy, using the &quot;probablity is<br/>proportional to 1/sqrt(n*d)&quot; rule as before, but _not_ restricting the<br/>possible fractions to be in lowest terms? This thought comes to me a lot<br/>since a 3:2 can also be a 6:4 or a 9:6, etc., with lower fundamentals . . .</p><p>I think I&apos;ll try this out!</p></div><h3><a id=270 href="#270">ðŸ”—</a>Paul H. Erlich &#x3C;PERLICH@...&#x3E;</h3><span>11/16/2000 1:10:09 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Apparently the probability that n randomly chosen integers will be mutually<br/>prime is zeta(n), where zeta is the Riemann zeta function (see the current<br/>thread on the tuning list). So the zetafunction is pretty closely related to<br/>harmonic entropy.</p></div><h3><a id=271 href="#271">ðŸ”—</a>Paul H. Erlich &#x3C;PERLICH@...&#x3E;</h3><span>11/16/2000 2:31:00 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>I wrote,</p><p>&gt;What if I calculate the harmonic entropy, using the &quot;probablity is<br/>proportional to 1/sqrt(n*d)&quot; rule as &gt;before, but _not_ restricting the<br/>possible fractions to be in lowest terms? This thought comes to me a &gt;lot<br/>since a 3:2 can also be a 6:4 or a 9:6, etc., with lower fundamentals . . .</p><p>&gt;I think I&apos;ll try this out!</p><p>I did this and I was shocked by the result:</p><p><a href="http://www.egroups.com/files/harmonic_entropy/dyadic/t3_01_13p2877.jpg">http://www.egroups.com/files/harmonic_entropy/dyadic/t3_01_13p2877.jpg</a></p><p>It&apos;s virtually the same shape as the _exponential_ as the harmonic entropy<br/>curve obtained when the fractions _were_ restricted to be in lowest terms!<br/>For those curves, see</p><p><a href="http://www.egroups.com/files/tuning/perlich/tenney/">http://www.egroups.com/files/tuning/perlich/tenney/</a></p><p>This is kind of a relief -- I was wondering why discordance seemed better<br/>modeled by exponentials (or powers of exponentials) of entropy, rather than<br/>entropy itself . . . but maybe all I had to do was include all the unreduced<br/>ratios . . .</p><p>But of course the 1/sqrt(n*d) weighting becomes harder to justify in this<br/>scheme, since the interpretation in terms the widths of mutually exclusive,<br/>mutually exhaustive segments of interval space no longer applies . . .</p></div><h3><a id=272 href="#272">ðŸ”—</a>Paul H. Erlich &#x3C;PERLICH@...&#x3E;</h3><span>11/16/2000 2:32:00 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>I wrote,</p><p>&gt;It&apos;s virtually the same shape as the _exponential_ as the harmonic entropy<br/>&gt;curve obtained . . .</p><p>that should read:</p><p>&quot;It&apos;s virtually the same shape as the _exponential_ of the harmonic entropy<br/>curve obtained . . .&quot;</p></div>