<a href="/harmonic_entropy">back to list</a><h1>Re: [harmonic_entropy] Digest Number 51</h1><h3><a id=347 href="#347">ðŸ”—</a>Robert Walker &#x3C;robert_walker@...&#x3E;</h3><span>1/31/2001 7:24:17 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Hi Paul,</p><p>&gt; That&apos;s where my knowledge falls short. I program in Matlab, and I don&apos;t have<br/>&gt; the Matlab compiler (costs a thousand or two).<br/>&gt;<br/>&gt; Great idea, though! Actually, if you want to volunteer, I can step you<br/>&gt; through the details of the calculation, verify that you get the same results<br/>&gt; as me for some simple case, and then we&apos;re off!</p><p>Depends how complex the calc. is - if it is one I can program quickly, then fine.<br/>The shell to run it is a matter of moments to do.</p><p>Or else, I could give it a go some time later if I have time.</p><p>Why not give a short overview of it, and I&apos;ll see what i think<br/>about how easy it will be to do. May also see some computational<br/>shortcuts too, you never know - I quite enjoy optimising computations.</p><p>Then again, if I don&apos;t have time to do it, and anyone else wants to have<br/>a go at writing it in c, I can easily provide the shell.</p><p>It would run in a separate thread, and it just needs to check for a<br/>global variable , bAction (say) frequently, like a fraction of a second between<br/>checks.</p><p>If it ever changes to 1, save data to disk and return (shell is about to exit).</p><p>Also save every few minutes. (Or if you prefer, if it changes to 2, save and reset to 0,<br/>and shell can set it to 2 every minute.)</p><p>Use a global szProgLocPath for location of file to save the data<br/>to / read from at start up.</p><p>That&apos;s about it.</p><p>Robert</p></div><h3><a id=350 href="#350">ðŸ”—</a>Paul H. Erlich &#x3C;PERLICH@...&#x3E;</h3><span>1/31/2001 1:18:39 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Robert Walker wrote,</p><p>&gt;Why not give a short overview of it, and I&apos;ll see what i think<br/>&gt;about how easy it will be to do. May also see some computational<br/>&gt;shortcuts too, you never know - I quite enjoy optimising computations.</p><p>OK. For the dyadic case, first you calculate all the ratios such that the<br/>product does not exceed a certain limit. Then either:</p><p>(a) calculate the mediants between the adjacent ratios, and assign each of<br/>the original ratios a &quot;width&quot; according to the distance between the mediants</p><p>(b) assign a &quot;width&quot; to each ratio based on an approximate formula (this<br/>approach will have to be used for the triadic case since no one has figured<br/>out how to generalize mediants to 2-d).</p><p>Now, for the interval in question (often, every cents value from 0 to 2400),<br/>construct a bell curve centered around that interval and with the particular<br/>standard deviation you&apos;ve assumed. Assign a probability to each of the<br/>original set of ratios: the probability is proportional to the product of<br/>the ratio&apos;s &quot;width&quot; times the height of the bell curve at that ratio.<br/>Finally, calculate the following sum over all the probabilities p:</p><p>entropy = -sum(p*log(p))</p><p>Does this make sense? If so, I&apos;ll proceed to explain the triadic case (which<br/>is virtually identical in concept).</p></div><h3><a id=507 href="#507">ðŸ”—</a>genewardsmith@...</h3><span>9/6/2001 4:02:47 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In harmonic_entropy@y..., &quot;Paul H. Erlich&quot; &lt;PERLICH@A...&gt; wrote:</p><p>&gt; (b) assign a &quot;width&quot; to each ratio based on an approximate formula<br/>(this<br/>&gt; approach will have to be used for the triadic case since no one has<br/>figured<br/>&gt; out how to generalize mediants to 2-d).</p><p>The usual generalization of the mediant gives the mediant of p1/q1,<br/>p2/q2, and p3/q3 as (p1+p2+p3)/(q1+q2+q3). So for 1/1, 5/4, 3/2 we<br/>would get 9/7, for 1/1, 6/5, 3/2 we have 5/4 and 1/1, 4/3, 5/3 gives<br/>us 10/7, and so forth. Does this help?</p><p>&gt; Now, for the interval in question (often, every cents value from 0<br/>to 2400),<br/>&gt; construct a bell curve centered around that interval and with the<br/>particular<br/>&gt; standard deviation you&apos;ve assumed.</p><p>Why a bell curve? It seems to me something compactly supported (ie<br/>with nonzero values only inside a certain range) would make more<br/>sense.</p></div><h3><a id=508 href="#508">ðŸ”—</a>Paul H. Erlich &#x3C;PERLICH@...&#x3E;</h3><span>9/7/2001 11:18:59 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>&gt;The usual generalization of the mediant gives the mediant of p1/q1,<br/>&gt;p2/q2, and p3/q3 as (p1+p2+p3)/(q1+q2+q3). So for 1/1, 5/4, 3/2 we<br/>&gt;would get 9/7, for 1/1, 6/5, 3/2 we have 5/4 and 1/1, 4/3, 5/3 gives<br/>&gt;us 10/7, and so forth. Does this help?</p><p>No. We need to divide the 2-D plane into mutually exclusive, exhaustive set<br/>of sub-regions. See the link in the &quot;Eureka&quot; post for more. But I think this<br/>will be unnecessary anyway, since approach (b) should work.</p><p>&gt;&gt; Now, for the interval in question (often, every cents value from 0<br/>to 2400),<br/>&gt;&gt; construct a bell curve centered around that interval and with the<br/>particular<br/>&gt;&gt; standard deviation you&apos;ve assumed.</p><p>&gt;Why a bell curve? It seems to me something compactly supported (ie<br/>&gt;with nonzero values only inside a certain range) would make more<br/>&gt;sense.</p><p>Why? I don&apos;t mind assuming a 1% probability that a 3-standard deviation<br/>error will be made. I see the bell curve as the distribution that makes the<br/>fewest assumptions (just the standard deviation needs to be specified). Of<br/>course we&apos;re free to calculate variants using other curves.</p></div>