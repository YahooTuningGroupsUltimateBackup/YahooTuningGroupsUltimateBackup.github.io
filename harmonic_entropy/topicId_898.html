<a href="/harmonic_entropy">back to list</a><h1>re: Dan, Dave, experience, entropy</h1><h3><a id=898 href="#898">ðŸ”—</a>Carl Lumma &#x3C;ekin@...&#x3E;</h3><span>10/20/2005 11:00:57 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Just saw a post from 2001 (when I wasn&apos;t on the lists) about<br/>11:9 having lower entropy than 8:5 with very large s.</p><p>The thread apparently started here...<br/><a href="http://launch.groups.yahoo.com/group/tuning/message/18643">http://launch.groups.yahoo.com/group/tuning/message/18643</a><br/>...with s=1.5.</p><p>Does anyone else think this is a highly anomalous result?</p><p>More recent data from Paul, with s=1.0, gives...</p><p>347 4.6234905<br/>814 4.5761788</p><p>...which seems much better.</p><p>Comments?</p><p>-Carl</p></div><h3><a id=900 href="#900">ðŸ”—</a>wallyesterpaulrus &#x3C;wallyesterpaulrus@...&#x3E;</h3><span>10/20/2005 5:46:53 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:harmonic_entropy@yahoogroups.com">harmonic_entropy@yahoogroups.com</a>, Carl Lumma &lt;ekin@l...&gt; wrote:<br/>&gt;<br/>&gt; Just saw a post from 2001 (when I wasn&apos;t on the lists) about<br/>&gt; 11:9 having lower entropy than 8:5 with very large s.<br/>&gt;<br/>&gt; The thread apparently started here...<br/>&gt; <a href="http://launch.groups.yahoo.com/group/tuning/message/18643">http://launch.groups.yahoo.com/group/tuning/message/18643</a><br/>&gt; ...with s=1.5.<br/>&gt;<br/>&gt; Does anyone else think this is a highly anomalous result?</p><p>Not I.</p><p>&gt; More recent data from Paul, with s=1.0, gives...<br/>&gt;<br/>&gt; 347 4.6234905<br/>&gt; 814 4.5761788<br/>&gt;<br/>&gt; ...which seems much better.<br/>&gt;<br/>&gt; Comments?<br/>&gt;<br/>&gt; -Carl</p><p>Have you looked at all four graphs, not just stearns.jpg referred to<br/>in the message above, but also stearns2.jpg, stearns3.jpg, and<br/>stearns4.jpg?</p></div><h3><a id=902 href="#902">ðŸ”—</a>Carl Lumma &#x3C;ekin@...&#x3E;</h3><span>10/20/2005 9:09:44 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>&gt;&gt; Just saw a post from 2001 (when I wasn&apos;t on the lists) about<br/>&gt;&gt; 11:9 having lower entropy than 8:5 with very large s.<br/>&gt;&gt;<br/>&gt;&gt; The thread apparently started here...<br/>&gt;&gt; <a href="http://launch.groups.yahoo.com/group/tuning/message/18643">http://launch.groups.yahoo.com/group/tuning/message/18643</a><br/>&gt;&gt; ...with s=1.5.<br/>&gt;&gt;<br/>&gt;&gt; Does anyone else think this is a highly anomalous result?<br/>&gt;<br/>&gt;Not I.<br/>&gt;<br/>&gt;&gt; More recent data from Paul, with s=1.0, gives...<br/>&gt;&gt;<br/>&gt;&gt; 347 4.6234905<br/>&gt;&gt; 814 4.5761788<br/>&gt;&gt;<br/>&gt;&gt; ...which seems much better.<br/>&gt;&gt;<br/>&gt;&gt; Comments?<br/>&gt;&gt;<br/>&gt;&gt; -Carl<br/>&gt;<br/>&gt;Have you looked at all four graphs, not just stearns.jpg referred to<br/>&gt;in the message above, but also stearns2.jpg, stearns3.jpg, and<br/>&gt;stearns4.jpg?</p><p>Where do I get them?</p><p>-Carl</p></div><h3><a id=903 href="#903">ðŸ”—</a>yahya_melb &#x3C;yahya@...&#x3E;</h3><span>10/21/2005 7:13:27 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:harmonic_entropy@yahoogroups.com">harmonic_entropy@yahoogroups.com</a>, Carl Lumma &lt;ekin@l...&gt;<br/>wrote:<br/>&gt;<br/>&gt; &gt;&gt; Just saw a post from 2001 (when I wasn&apos;t on the lists) about<br/>&gt; &gt;&gt; 11:9 having lower entropy than 8:5 with very large s.<br/>&gt; &gt;&gt;<br/>&gt; &gt;&gt; The thread apparently started here...<br/>&gt; &gt;&gt; <a href="http://launch.groups.yahoo.com/group/tuning/message/18643">http://launch.groups.yahoo.com/group/tuning/message/18643</a><br/>&gt; &gt;&gt; ...with s=1.5.<br/>&gt; &gt;&gt;<br/>&gt; &gt;&gt; Does anyone else think this is a highly anomalous result?<br/>&gt; &gt;<br/>&gt; &gt;Not I.<br/>&gt; &gt;<br/>&gt; &gt;&gt; More recent data from Paul, with s=1.0, gives...<br/>&gt; &gt;&gt;<br/>&gt; &gt;&gt; 347 4.6234905<br/>&gt; &gt;&gt; 814 4.5761788<br/>&gt; &gt;&gt;<br/>&gt; &gt;&gt; ...which seems much better.<br/>&gt; &gt;&gt;<br/>&gt; &gt;&gt; Comments?<br/>&gt; &gt;&gt;<br/>&gt; &gt;&gt; -Carl<br/>&gt; &gt;<br/>&gt; &gt;Have you looked at all four graphs, not just stearns.jpg referred<br/>to<br/>&gt; &gt;in the message above, but also stearns2.jpg, stearns3.jpg, and<br/>&gt; &gt;stearns4.jpg?<br/>&gt;<br/>&gt; Where do I get them?<br/>&gt;<br/>&gt; -Carl</p><p>The reference for stearns.jpg is to a file on the files list;<br/>however, that list says it can&apos;t find it.  So please do tell us<br/>where they are.</p><p>I&apos;d also be interested to know just how sensitive this kind<br/>of &quot;anomalous&quot; result is to the factor s (=1.2% in the graph in the<br/>group description.)  What is the experimentally observed range of s?</p><p>Regards,<br/>Yahya</p></div><h3><a id=906 href="#906">ðŸ”—</a>wallyesterpaulrus &#x3C;wallyesterpaulrus@...&#x3E;</h3><span>10/26/2005 2:28:45 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:harmonic_entropy@yahoogroups.com">harmonic_entropy@yahoogroups.com</a>, &quot;yahya_melb&quot; &lt;yahya@m...&gt;<br/>wrote:<br/>&gt;<br/>&gt; --- In <a href="mailto:harmonic_entropy@yahoogroups.com">harmonic_entropy@yahoogroups.com</a>, Carl Lumma &lt;ekin@l...&gt;<br/>&gt; wrote:<br/>&gt; &gt;<br/>&gt; &gt; &gt;&gt; Just saw a post from 2001 (when I wasn&apos;t on the lists) about<br/>&gt; &gt; &gt;&gt; 11:9 having lower entropy than 8:5 with very large s.<br/>&gt; &gt; &gt;&gt;<br/>&gt; &gt; &gt;&gt; The thread apparently started here...<br/>&gt; &gt; &gt;&gt; <a href="http://launch.groups.yahoo.com/group/tuning/message/18643">http://launch.groups.yahoo.com/group/tuning/message/18643</a><br/>&gt; &gt; &gt;&gt; ...with s=1.5.<br/>&gt; &gt; &gt;&gt;<br/>&gt; &gt; &gt;&gt; Does anyone else think this is a highly anomalous result?<br/>&gt; &gt; &gt;<br/>&gt; &gt; &gt;Not I.<br/>&gt; &gt; &gt;<br/>&gt; &gt; &gt;&gt; More recent data from Paul, with s=1.0, gives...<br/>&gt; &gt; &gt;&gt;<br/>&gt; &gt; &gt;&gt; 347 4.6234905<br/>&gt; &gt; &gt;&gt; 814 4.5761788<br/>&gt; &gt; &gt;&gt;<br/>&gt; &gt; &gt;&gt; ...which seems much better.<br/>&gt; &gt; &gt;&gt;<br/>&gt; &gt; &gt;&gt; Comments?<br/>&gt; &gt; &gt;&gt;<br/>&gt; &gt; &gt;&gt; -Carl<br/>&gt; &gt; &gt;<br/>&gt; &gt; &gt;Have you looked at all four graphs, not just stearns.jpg<br/>referred<br/>&gt; to<br/>&gt; &gt; &gt;in the message above, but also stearns2.jpg, stearns3.jpg, and<br/>&gt; &gt; &gt;stearns4.jpg?<br/>&gt; &gt;<br/>&gt; &gt; Where do I get them?<br/>&gt; &gt;<br/>&gt; &gt; -Carl<br/>&gt;<br/>&gt; The reference for stearns.jpg is to a file on the files list;<br/>&gt; however, that list says it can&apos;t find it.  So please do tell us<br/>&gt; where they are.<br/>&gt;<br/>&gt; I&apos;d also be interested to know just how sensitive this kind<br/>&gt; of &quot;anomalous&quot; result is to the factor s (=1.2% in the graph in the<br/>&gt; group description.)</p><p>Well that&apos;s part of what the graphs tell you:</p><p><a href="http://launch.groups.yahoo.com/group/tuning/files/perlich/stearns.jpg">http://launch.groups.yahoo.com/group/tuning/files/perlich/stearns.jpg</a><br/><a href="http://launch.groups.yahoo.com/group/tuning/files/perlich/stearns2.jpg">http://launch.groups.yahoo.com/group/tuning/files/perlich/stearns2.jpg</a><br/><a href="http://launch.groups.yahoo.com/group/tuning/files/perlich/stearns3.jpg">http://launch.groups.yahoo.com/group/tuning/files/perlich/stearns3.jpg</a><br/><a href="http://launch.groups.yahoo.com/group/tuning/files/perlich/stearns4.jpg">http://launch.groups.yahoo.com/group/tuning/files/perlich/stearns4.jpg</a></p><p>Two different values of s are used; for s significantly less than the<br/>smaller value or significantly more than the larger value, this<br/>particular &quot;anomaly&quot; concerning 11:9 disappears.</p><p>&gt;What is the experimentally observed range of s?</p><p>In one Goldsmith experiment, using small numbers of sine waves, s was<br/>found to be as low as 0.6% for the best listener in the best<br/>frequency range (~3 KHz), and as high as 3% or more for most<br/>listeners once one is well outside that range.</p></div><h3><a id=908 href="#908">ðŸ”—</a>Magnus Jonsson &#x3C;magnus@...&#x3E;</h3><span>10/26/2005 3:16:56 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On Wed, 26 Oct 2005, wallyesterpaulrus wrote:</p><p>&gt; Well that&apos;s part of what the graphs tell you:<br/>&gt;<br/>&gt; <a href="http://launch.groups.yahoo.com/group/tuning/files/perlich/stearns.jpg">http://launch.groups.yahoo.com/group/tuning/files/perlich/stearns.jpg</a><br/>&gt; <a href="http://launch.groups.yahoo.com/group/tuning/files/perlich/stearns2.jpg">http://launch.groups.yahoo.com/group/tuning/files/perlich/stearns2.jpg</a><br/>&gt; <a href="http://launch.groups.yahoo.com/group/tuning/files/perlich/stearns3.jpg">http://launch.groups.yahoo.com/group/tuning/files/perlich/stearns3.jpg</a><br/>&gt; <a href="http://launch.groups.yahoo.com/group/tuning/files/perlich/stearns4.jpg">http://launch.groups.yahoo.com/group/tuning/files/perlich/stearns4.jpg</a></p><p>I will go a bit offtopic here, thinking about n*d. It will probably be a newbie question:</p><p>As far as I can see, n*d measures how sensitive an interval is to mistuning. It is also a measurement of the period of the temporal or spectral repetition is.</p><p>Another possible measurement which I propose would be &quot;fraction of harmonics that overlap&quot;. For properly factored dyadic intervals that would be 1/(n+d-1). It can be inverted to get a measurement of discordance or spectral messyness: n+d-1.</p><p>I am wondering if there is a reason to prefer using n*d to n+d-1. Could they be combined to get an overall better approximation?</p><p>- Magnus</p></div><h3><a id=909 href="#909">ðŸ”—</a>wallyesterpaulrus &#x3C;wallyesterpaulrus@...&#x3E;</h3><span>10/26/2005 6:21:13 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:harmonic_entropy@yahoogroups.com">harmonic_entropy@yahoogroups.com</a>, Magnus Jonsson &lt;magnus@s...&gt;<br/>wrote:<br/>&gt;<br/>&gt; On Wed, 26 Oct 2005, wallyesterpaulrus wrote:<br/>&gt;<br/>&gt; &gt; Well that&apos;s part of what the graphs tell you:<br/>&gt; &gt;<br/>&gt; &gt;<br/><a href="http://launch.groups.yahoo.com/group/tuning/files/perlich/stearns.jpg">http://launch.groups.yahoo.com/group/tuning/files/perlich/stearns.jpg</a><br/>&gt; &gt;<br/><a href="http://launch.groups.yahoo.com/group/tuning/files/perlich/stearns2.jpg">http://launch.groups.yahoo.com/group/tuning/files/perlich/stearns2.jpg</a><br/>&gt; &gt;<br/><a href="http://launch.groups.yahoo.com/group/tuning/files/perlich/stearns3.jpg">http://launch.groups.yahoo.com/group/tuning/files/perlich/stearns3.jpg</a><br/>&gt; &gt;<br/><a href="http://launch.groups.yahoo.com/group/tuning/files/perlich/stearns4.jpg">http://launch.groups.yahoo.com/group/tuning/files/perlich/stearns4.jpg</a><br/>&gt;<br/>&gt; I will go a bit offtopic here, thinking about n*d. It will probably<br/>&gt; be a newbie question:<br/>&gt;<br/>&gt; As far as I can see, n*d measures how sensitive an interval is to<br/>&gt; mistuning.</p><p>Unless n*d is too large, or undefined (as it is for irrational<br/>intervals).</p><p>&gt; It is also a measurement of the period of the temporal or<br/>&gt; spectral repetition is.<br/>&gt;<br/>&gt; Another possible measurement which I propose would be &quot;fraction<br/>&gt; of harmonics that overlap&quot;. For properly factored dyadic intervals<br/>&gt; that would be 1/(n+d-1). It can be inverted to get a measurement of<br/>&gt; discordance or spectral messyness: n+d-1.</p><p>If every nth harmonic of note a overlaps with every dth harmonic of<br/>note b, it seems that, overall, ((1/d)+(1/n)/2) or (n+d)/(n*d)/2 of<br/>the harmonics overlap. Why don&apos;t we agree?</p><p>&gt; I am wondering if there is a reason to prefer using n*d to n+d-1.</p><p>When used for the seeding, the former gives a harmonic entropy curve<br/>which has an overall flat character, while the latter gives a<br/>harmonic entropy curve with a decreasing trend as one moves to larger<br/>and larger intervals.</p><p>&gt;Could<br/>&gt; they be combined to get an overall better approximation?</p><p>For these graphs, n*d was used, in a sense, for both quantities --<br/>it&apos;s used to seed the harmonic entropy calculation, and to compute a<br/>naive discordance value for various simple just intervals. When you<br/>use n+d or n+d-1 to seed the harmonic entropy calculation, you&apos;d get<br/>a worse agreement whether you use n*d or n+d-1 to compute the naive<br/>discordance value for various simple just intervals. But maybe you<br/>meant &quot;an overall better approximation&quot; in some other sense?</p></div><h3><a id=910 href="#910">ðŸ”—</a>Magnus Jonsson &#x3C;magnus@...&#x3E;</h3><span>10/27/2005 3:29:25 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On Thu, 27 Oct 2005, wallyesterpaulrus wrote:</p><p>&gt; --- In <a href="mailto:harmonic_entropy@yahoogroups.com">harmonic_entropy@yahoogroups.com</a>, Magnus Jonsson &lt;magnus@s...&gt;<br/>&gt; wrote:<br/>&gt;&gt;<br/>&gt;&gt; As far as I can see, n*d measures how sensitive an interval is to<br/>&gt;&gt; mistuning.<br/>&gt;<br/>&gt; Unless n*d is too large, or undefined (as it is for irrational<br/>&gt; intervals).</p><p>Ah, that is possible.</p><p>&gt;&gt; It is also a measurement of the period of the temporal or<br/>&gt;&gt; spectral repetition is.<br/>&gt;&gt;<br/>&gt;&gt; Another possible measurement which I propose would be &quot;fraction<br/>&gt;&gt; of harmonics that overlap&quot;. For properly factored dyadic intervals<br/>&gt;&gt; that would be 1/(n+d-1). It can be inverted to get a measurement of<br/>&gt;&gt; discordance or spectral messyness: n+d-1.<br/>&gt;<br/>&gt; If every nth harmonic of note a overlaps with every dth harmonic of<br/>&gt; note b, it seems that, overall, ((1/d)+(1/n)/2) or (n+d)/(n*d)/2 of<br/>&gt; the harmonics overlap. Why don&apos;t we agree?</p><p>Let&apos;s take the 5/4 case as an example (I will assume a very bright/sharp timbre in which all harmonics are strong):</p><p>5.......: |....|....|....|....|....|....|....|....|..<br/>4.......: |...|...|...|...|...|...|...|...|...|...|..<br/>combined: |...||..|.|.|..||...|...||..|.|.|..||...|..<br/>period..: {..................}{..................}{..</p><p>(whew, that&apos;s a lot of dots)</p><p>Within each period, there is one shared harmonic, and<br/>8 harmonics total (combined). That gives 1/8.<br/>One of the combined harmonics is the shared one, three<br/>come from the 5, and four come from the 4.</p><p>Your formula gives here 9/40 ~= 1/4.</p><p>In the n/d case: The period will be n*d. n will have d harmonics in each period and d will have n harmonics in each period. One harmonic will overlap in each period, so there will be a total of n+d-1 harmonics in each period. Hence 1/(n+d-1).</p><p>&gt;&gt; I am wondering if there is a reason to prefer using n*d to n+d-1.<br/>&gt;<br/>&gt; When used for the seeding, the former gives a harmonic entropy curve<br/>&gt; which has an overall flat character, while the latter gives a<br/>&gt; harmonic entropy curve with a decreasing trend as one moves to larger<br/>&gt; and larger intervals.</p><p>I see.</p><p>&gt;&gt; Could<br/>&gt;&gt; they be combined to get an overall better approximation?<br/>&gt;<br/>&gt; For these graphs, n*d was used, in a sense, for both quantities --<br/>&gt; it&apos;s used to seed the harmonic entropy calculation, and to compute a<br/>&gt; naive discordance value for various simple just intervals. When you<br/>&gt; use n+d or n+d-1 to seed the harmonic entropy calculation, you&apos;d get<br/>&gt; a worse agreement whether you use n*d or n+d-1 to compute the naive<br/>&gt; discordance value for various simple just intervals. But maybe you<br/>&gt; meant &quot;an overall better approximation&quot; in some other sense?</p><p>I meant using n*d or n+d to estimate which intervals sound more discordant than others. I assume that the entropy calculation is very accurate and does this almost perfectly. So whichever formula agrees most closely with the entropy curve (in terms of ordering, not straightness of lines) would be better.</p><p>One way to combine them would be to use for example n*d+n+d or (n+1)*(d+1)<br/>instead of n*d.</p><p>- Magnus Jonsson</p></div><h3><a id=911 href="#911">ðŸ”—</a>wallyesterpaulrus &#x3C;wallyesterpaulrus@...&#x3E;</h3><span>10/27/2005 2:22:06 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:harmonic_entropy@yahoogroups.com">harmonic_entropy@yahoogroups.com</a>, Magnus Jonsson &lt;magnus@s...&gt;<br/>wrote:<br/>&gt;<br/>&gt; On Thu, 27 Oct 2005, wallyesterpaulrus wrote:<br/>&gt;<br/>&gt; &gt; --- In <a href="mailto:harmonic_entropy@yahoogroups.com">harmonic_entropy@yahoogroups.com</a>, Magnus Jonsson<br/>&lt;magnus@s...&gt;<br/>&gt; &gt; wrote:<br/>&gt; &gt;&gt;<br/>&gt; &gt;&gt; As far as I can see, n*d measures how sensitive an interval is to<br/>&gt; &gt;&gt; mistuning.<br/>&gt; &gt;<br/>&gt; &gt; Unless n*d is too large, or undefined (as it is for irrational<br/>&gt; &gt; intervals).<br/>&gt;<br/>&gt; Ah, that is possible.<br/>&gt;<br/>&gt; &gt;&gt; It is also a measurement of the period of the temporal or<br/>&gt; &gt;&gt; spectral repetition is.<br/>&gt; &gt;&gt;<br/>&gt; &gt;&gt; Another possible measurement which I propose would be &quot;fraction<br/>&gt; &gt;&gt; of harmonics that overlap&quot;. For properly factored dyadic<br/>intervals<br/>&gt; &gt;&gt; that would be 1/(n+d-1). It can be inverted to get a measurement<br/>of<br/>&gt; &gt;&gt; discordance or spectral messyness: n+d-1.<br/>&gt; &gt;<br/>&gt; &gt; If every nth harmonic of note a overlaps with every dth harmonic<br/>of<br/>&gt; &gt; note b, it seems that, overall, ((1/d)+(1/n)/2) or (n+d)/(n*d)/2<br/>of<br/>&gt; &gt; the harmonics overlap. Why don&apos;t we agree?<br/>&gt;<br/>&gt; Let&apos;s take the 5/4 case as an example (I will assume a very<br/>bright/sharp<br/>&gt; timbre in which all harmonics are strong):<br/>&gt;<br/>&gt; 5.......: |....|....|....|....|....|....|....|....|..<br/>&gt; 4.......: |...|...|...|...|...|...|...|...|...|...|..<br/>&gt; combined: |...||..|.|.|..||...|...||..|.|.|..||...|..<br/>&gt; period..: {..................}{..................}{..<br/>&gt;<br/>&gt; (whew, that&apos;s a lot of dots)<br/>&gt;<br/>&gt; Within each period, there is one shared harmonic, and<br/>&gt; 8 harmonics total (combined). That gives 1/8.<br/>&gt; One of the combined harmonics is the shared one, three<br/>&gt; come from the 5, and four come from the 4.</p><p>I count 9 harmonics in each &quot;period&quot;, 2 of which overlap.</p><p>&gt; Your formula gives here 9/40 ~= 1/4.</p><p>2/9 = 0.2222<br/>9/40 = 0.2250<br/>1/4 = 0.25</p><p>&gt; &gt;&gt; I am wondering if there is a reason to prefer using n*d to n+d-1.<br/>&gt; &gt;<br/>&gt; &gt; When used for the seeding, the former gives a harmonic entropy<br/>curve<br/>&gt; &gt; which has an overall flat character, while the latter gives a<br/>&gt; &gt; harmonic entropy curve with a decreasing trend as one moves to<br/>larger<br/>&gt; &gt; and larger intervals.<br/>&gt;<br/>&gt; I see.<br/>&gt;<br/>&gt; &gt;&gt; Could<br/>&gt; &gt;&gt; they be combined to get an overall better approximation?<br/>&gt; &gt;<br/>&gt; &gt; For these graphs, n*d was used, in a sense, for both quantities --<br/>&gt; &gt; it&apos;s used to seed the harmonic entropy calculation, and to<br/>compute a<br/>&gt; &gt; naive discordance value for various simple just intervals. When<br/>you<br/>&gt; &gt; use n+d or n+d-1 to seed the harmonic entropy calculation, you&apos;d<br/>get<br/>&gt; &gt; a worse agreement whether you use n*d or n+d-1 to compute the<br/>naive<br/>&gt; &gt; discordance value for various simple just intervals. But maybe you<br/>&gt; &gt; meant &quot;an overall better approximation&quot; in some other sense?<br/>&gt;<br/>&gt; I meant using n*d or n+d to estimate which intervals sound more<br/>discordant<br/>&gt; than others. I assume that the entropy calculation is very accurate<br/>and<br/>&gt; does this almost perfectly.</p><p>But you have to seed it somehow. You assume that a finite probability<br/>gets associated with each ratio in some huge set of ratios. The huge<br/>set of ratios has to be selected somehow. I often use n*d &lt; 10000 or<br/>n*d &lt; 65536 . . .</p><p>&gt; So whichever formula agrees most closely with<br/>&gt; the entropy curve (in terms of ordering, not straightness of lines)<br/>would<br/>&gt; be better.</p><p>n*d agrees with the entropy curve much better when the entropy curve<br/>is seeded with n*d. I don&apos;t know how to seed it to make n+d agree<br/>with the curve, but it doesn&apos;t look straighforward . . .</p><p>In these early postings, I used n to seed and I also used n+d to<br/>seed . . . I hadn&apos;t tried n*d yet . . .</p><p><a href="http://sonic-arts.org/td/erlich/entropy-erlich.htm">http://sonic-arts.org/td/erlich/entropy-erlich.htm</a></p><p>Since you&apos;re a newbie, it might be good to read this . . .</p><p>As you can see, using n leads to much less variation in the shape of<br/>the curve as you increment your seed limit on n, than using n+d does<br/>as you increment your seed limit on n+d. Using n seems more &quot;stable&quot;<br/>than using n+d . . . Using n*d keeps the resulting curve &quot;flat&quot; in<br/>its overall trend,</p><p>What&apos;s striking is that it seems that no matter how you seed the<br/>calculation, the *depth* of the (inverted) humps, from crest to<br/>trough, at the simple-integer ratios goes according to an n*d<br/>ranking, and the set of ratios which show humps at all is the set<br/>under some limit of n*d. So n*d &quot;pops out&quot; even if you didn&apos;t put it<br/>in in the first place.</p></div>