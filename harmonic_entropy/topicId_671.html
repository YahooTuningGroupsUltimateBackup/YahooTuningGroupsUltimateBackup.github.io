<a href="/harmonic_entropy">back to list</a><h1>Thermodynamic approach to entropy</h1><h3><a id=671 href="#671">ðŸ”—</a>Dominique Larr&#xE9; &#x3C;dominique.larre@...&#x3E;</h3><span>11/29/2002 2:58:06 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Hello members, this timid lurker of the &quot;main&quot; tuning list has just<br/>discovered the wealth of this group&apos;s archives. Somehow the discussions here<br/>are often clearer to me than the big group&apos;s.</p><p>As a chemical engineer by education my most immediate internal image of<br/>entropy is related to thermodynamics.</p><p>In my mind&apos;s simplistic image, an amount of energy is represented by the<br/>product of an intensive factor by an extensive factor. For example, work is<br/>the product of force by distance, force being intensive, displacement being<br/>the extensity. Similar &quot;Intensity times Extensity&quot; formulas exist for<br/>electric energy, chemical energy, etc. Entropy is the extensity of thermal<br/>energy, with temperature being its intensity, so that dQ = T multiplied by<br/>dS.</p><p>Having read Paul&apos;s answer to David Finnamore request (Message 24 of this<br/>group&apos;s archives), and being well aware that it is the same &quot;entropy&quot; that<br/>appears in the probability distribution approach, I wonder if a simple<br/>representation can be given for our &quot;harmonic entropy&quot; which would link it<br/>to the thermodynamic model.</p><p>Greetings to all</p><p>Dominique Larr&iuml;&iquest;&half;</p><p>- - - - - - - - - - - - - -<br/>P.S. Is anyone aware of Scala users in France, particularly (but not<br/>exclusively) in the Paris area?</p></div><h3><a id=672 href="#672">ðŸ”—</a>wallyesterpaulrus &#x3C;wallyesterpaulrus@...&#x3E;</h3><span>11/29/2002 6:28:59 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In harmonic_entropy@y..., Dominique Larr&eacute; &lt;dominique.larre@w...&gt;<br/>wrote:</p><p>&gt; Having read Paul&apos;s answer to David Finnamore request (Message 24 of<br/>this<br/>&gt; group&apos;s archives), and being well aware that it is the<br/>same &quot;entropy&quot; that<br/>&gt; appears in the probability distribution approach, I wonder if a<br/>simple<br/>&gt; representation can be given for our &quot;harmonic entropy&quot; which would<br/>link it<br/>&gt; to the thermodynamic model.</p><p>fascinating, but i can&apos;t think of any such analogy . . .</p></div><h3><a id=673 href="#673">ðŸ”—</a>Carl Lumma &#x3C;clumma@...&#x3E;</h3><span>11/29/2002 5:42:02 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>&gt;&gt;Entropy is the extensity of thermal energy, with temperature<br/>&gt;&gt;being its intensity, so that dQ = T multiplied by dS.</p><p>Sorry, I don&apos;t follow.  Do you mean dQ = T(dS)?  If so, what<br/>are d and Q?</p><p>&gt;&gt;I wonder if a simple representation can be given for our<br/>&gt;&gt;&quot;harmonic entropy&quot; which would link it to the thermodynamic<br/>&gt;&gt;model.<br/>&gt;<br/>&gt;fascinating, but i can&apos;t think of any such analogy . . .</p><p>They are ultimately the same entropy, in the sense that they<br/>correspond to a lack of knowledge about a system.  You can<br/>see that I don&apos;t follow the chemical side of the analogy, but<br/>probably the answer is that the type of entropy we use on<br/>this list is wrapped up in the concept of &quot;temperature&quot;.</p><p>Feynman gives a thought experiment... a box with a removable<br/>piston and a single gas molecule inside.  With the piston<br/>removed, the pressure of the gas inside the box is based on<br/>the total volume of the box.  If you know where in the box<br/>the melecule is at a given instant, you can position the<br/>piston in such a way to extract work from the gas.  IIRC he<br/>is able to derrive Shannon&apos;s entropy from 19th-century<br/>thermodynamics with this analogy.</p><p>-Carl</p></div><h3><a id=674 href="#674">ðŸ”—</a>wallyesterpaulrus &#x3C;wallyesterpaulrus@...&#x3E;</h3><span>11/30/2002 10:18:37 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In harmonic_entropy@y..., &quot;Carl Lumma&quot; &lt;clumma@y...&gt;<br/>wrote:<br/>&gt; &gt;&gt;Entropy is the extensity of thermal energy, with temperature<br/>&gt; &gt;&gt;being its intensity, so that dQ = T multiplied by dS.<br/>&gt;<br/>&gt; Sorry, I don&apos;t follow.  Do you mean dQ = T(dS)?  If so, what<br/>&gt; are d and Q?</p><p>d means differential, and Q is energy. so</p><p>T = dQ/dS,</p><p>that is, temperature is the derivative of energy with respect to<br/>entropy . . .</p><p>&gt; &gt;&gt;I wonder if a simple representation can be given for our<br/>&gt; &gt;&gt;&quot;harmonic entropy&quot; which would link it to the thermodynamic<br/>&gt; &gt;&gt;model.<br/>&gt; &gt;<br/>&gt; &gt;fascinating, but i can&apos;t think of any such analogy . . .<br/>&gt;<br/>&gt; IIRC he<br/>&gt; is able to derrive Shannon&apos;s entropy from 19th-century<br/>&gt; thermodynamics with this analogy.</p><p>this i&apos;d love to see!</p></div><h3><a id=675 href="#675">ðŸ”—</a>Carl Lumma &#x3C;clumma@...&#x3E;</h3><span>12/1/2002 11:20:58 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>&gt; d means differential,</p><p>thought so.</p><p>&gt; and Q is energy.</p><p>ah.</p><p>&gt; so T = dQ/dS,<br/>&gt;<br/>&gt; that is, temperature is the derivative of energy with respect<br/>&gt; to entropy . . .</p><p>Ah, yes.</p><p>&gt;&gt; IIRC he is able to derrive Shannon&apos;s entropy from 19th-century<br/>&gt;&gt; thermodynamics with this analogy.<br/>&gt;<br/>&gt; this i&apos;d love to see!</p><p>pp. 140-148 in the &quot;Lectures on Computation&quot;.</p><p>-Carl</p></div>