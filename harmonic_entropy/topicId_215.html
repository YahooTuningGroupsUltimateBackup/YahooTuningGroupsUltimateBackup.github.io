<a href="/harmonic_entropy">back to list</a><h1>verifying weighting rule</h1><h3><a id=215 href="#215">ðŸ”—</a>Paul H. Erlich &#x3C;PERLICH@...&#x3E;</h3><span>10/16/2000 2:27:45 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>As I think Carl was warning at one point, if we are using a weighting rule<br/>to mimic the &quot;width&quot; or &quot;area&quot; in a harmonic entropy calculation, we should<br/>be sure that the probabilities thus calculated (before scaling to sum to 1)<br/>should sum to something that is independent of where you are on the curve. I<br/>looked at this sum for the 1/sqrt(n*d) rule I&apos;ve been using for dyadic<br/>harmonic entropy, with n*d&lt;10000 and s=1%. At the unison, the sum is 104% of<br/>its mean value; at 30 cents, it&apos;s 98% of its mean value; and thereafter it<br/>fluctates between 99% and 101%. By contrast, if we use a -log(n*d) rule, the<br/>fluctuations range from 61% to 114%; a 1/(n*d) rule leads to a range from<br/>43% to 1150%(!) (and a believable discordance curve already -- _without_<br/>calculating entropy -- perhaps we should think about this), and a<br/>1/cuberoot(n*d) rule fluctuates between 65% and 107%.</p><p>As far as I am concerned, this verifies the 1/sqrt(n*d) weighting rule for<br/>dyads. Now to verify, or find an alterative to, the 1/cuberoot(l*m*n) rule<br/>for triads, armed with the set of triads with l*m*n&lt;1million that Graham<br/>sent me (thanks Graham!) This could take a lot of CPU cycles!</p></div>