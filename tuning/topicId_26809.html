<!DOCTYPE html>
            <html>
            <head>
            <meta charset="utf-8">
                <meta name="viewport"
            content="width=device-width, height=device-height, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no">
                <meta http-equiv="x-ua-compatible" content="ie=edge">
                <title>Yahoo Tuning Groups Ultimate Backup tuning There is an easy solution to this problem....</title>
                <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
            </head>
            <body>
            </body>
            </html>
        <a href="/tuning">back to list</a><h1>There is an easy solution to this problem....</h1><h3><a id=26809 href="#26809">ðŸ”—</a>PageWizard, Magician of the Caverns &#x3C;PageWizard17@aol.com&#x3E;</h3><span>8/8/2001 11:10:01 PM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>First of all, it is ridiculous to expect the computer to guess what<br/>you are thinking about before you play it on a keyboard.  This would<br/>be extremely difficult, if not impossible to implement.  The software<br/>does not need to do this in order for the user to be able to<br/>modulate.  The software would calculate the ratios once the key(s)<br/>are physically struck.  The delay time between the physical action<br/>and the actual sound produced would be exactly proportional to the<br/>software&apos;s speed of correct ratio configuration.  Here is an example:</p><p>  Normally, lets say, the tuning tables in the software are aligned<br/>with a fixed frequency at a C note of 100 Hz for instance.  With any<br/>tuning table there must be some standard set before all other<br/>subsequent notes are played in relation to the reference.  Even in 12<br/>ET, the identity of a played note depends on its relation to a<br/>reference note, even if the reference is never played.<br/>  The software will store an accumulation bank between all previously<br/>played notes, so that it will be able to use the bank to access<br/>relations between the notes.  When given a certain scale formula in<br/>ratios, the software will only output signals corresponding to<br/>specific combinations of those ratios.  If false signals are inputed,<br/>the software will be able to detect that a modulation is occurring<br/>and it will be able to adjust all other notes accordingly.<br/>  First, I will start with a transition involving simultaneous<br/>chords.  After this, I will talk about transitions involving<br/>individual note progressions.  I am sure you will agree that chordal<br/>progressions are a much simpler matter than single note<br/>progressions.  You are correct in this, but you must remember that<br/>scalar (single note) progressions have an order which depends on the<br/>notes previously played.  With the knowledge of the previously played<br/>notes and the scale ratio table, the software will have a very good<br/>idea of what frequency to produce when a subsequent physical note is<br/>sounded.<br/>  Remember, our fixed note on the keyboard is an arbitrary &quot;C&quot; at 100<br/>Hz.  At this time, I physically play the pattern on the keyboard<br/>which represents a C Major.  I will later show a different transition<br/>which does not rely on chords which include the reference frequency.<br/>The C Major is represented as 1/1-5/4-3/2 or as in Hz 100-125-150.<br/>There is, of course, much more information here that the software<br/>must recognize before it produces the final tonal combination.  The<br/>software must recognize the ratios within the ratios or the ratios<br/>between points in this chord.  Here is a list.</p><p>1/1 base (100)<br/>-d (distance) to 5/4= +5/4 (plus 25)<br/>-d to 3/2= +3/2 (plus 50)</p><p>5/4 base (125 as compared to 1/1)<br/>-d to 1/1= -5/4 (minus 25)<br/>-d to 3/2= +6/5 (plus 25)</p><p>3/2 base (150 as compared to 1/1)<br/>-d to 1/1= -3/2 (minus 50)<br/>-d to 5/4= -6/5 (minus 25)</p><p>  This is a standard example of chord data involving all of the<br/>possible relations between the individual tones of a chord to each<br/>other.  Even when this chord is written, all of the ratios are wired<br/>to the reference.  The reference here is the one in which we base our<br/>whole tuning archive from.  If this chord were a specific distance<br/>from the reference, the software would calculate each tone&apos;s distance<br/>from the global reference and construct a chordal relationship with<br/>the tonal relations of that chord.  I will get into this later.<br/>  First, lets make the transition from C Major to C# Major since it<br/>will offer a very good contrast between an erroneous result and a<br/>valid result.  First I will show what a false C# Major would look<br/>like using the ratios based off of 100 Hz (arbitrary C).</p><p>INCORRECT PHYSICAL INPUT (TRUNCATED FOR CONVENIENCE)<br/>False C#<br/>16/15     4/3     8/5<br/>106 2/3  133 1/3  160</p><p>After the software analyzes that the frequencies of 106 2/3 and 133<br/>1/3 are correct.  The false fifth is 40 Hz narrow. The software moves<br/>the new fifth up to 200 Hz.  The final signal is then sent for<br/>transmission.</p><p>  I will submit further information in the future involving single<br/>note progressions.  You may, though, be wondering how the software<br/>would decide whether the C# is itself or one of its inversions since<br/>any could be just as likely.  The software will be able to solve this<br/>problem since it makes all of its calculations based on an arbitrary<br/>reference such as C (physical key on the keyboard) represents 100<br/>Hz.  All corresponding ratios of inputs will be based off of this.<br/>The software will be able to see that (in this case) I am playing<br/>ratios of 16/15, 4/3, and 8/5 in relation to 100 Hz.  It will have<br/>tables of all of the possible combinations of three notes in a given<br/>scale system.  This will allow it to narrow down possibilities.  Each<br/>chord has a distinct identity.  Since there are only a limited number<br/>of possible chord identities within a specific scale, the software<br/>will be able to narrow down the possibilities using its bank of<br/>relations between notes in a chord.  Since 106 2/3-133 1/3-160 is not<br/>a correct chord in the software&apos;s lists, it begins to narrow down<br/>posssibilities.  Firstly, it will see that 106 2/3 to 133 1/3 is<br/>a &quot;major third&quot; distance.  There is only a distinct amount of<br/>possibilities left for the last false note within this specific scale<br/>system.  I will have to do additional work on this, but I believe<br/>that by using its table of scalar relations and by already attaining<br/>half of the chord&apos;s information, it will be able to realize that 200<br/>is the relation implied instead of 160.  In order to do this, 200<br/>must be the likeliest choice out of all of the other possibilities.<br/>For instance, the software will not (globally) know whether you imply<br/>an infinitude of choices for the third note played (since no physical<br/>note is ever fixed except the C 100 Hz -arbitrary-).  These two<br/>things, theoretically, will allow the software to make a good choice:</p><p>1)  The number of pure ratios in the scale system and the number of<br/>notes physically played, gives the software a good idea of where to<br/>look.  It knows there are only 12 notes in a set of this system<br/>(within an octave), and it knows that only 3 entities are being<br/>played at once.</p><p>2)  The played entities&apos; relation to the global reference of 100 Hz<br/>will allow the software to construct a draft table of this new<br/>chord&apos;s identity.</p><p>3)  This draft table is searched for relations which are true within<br/>the ratios allowed in this system.  Any true ratios are saved.</p><p>4)  The software uses the diad (in this case) of a third distance to<br/>narrow down its possibilities to a possible identity for the last<br/>note.</p><p>5)  Since the table only has a limited number of possible<br/>alternatives when given the previous information, it will likely<br/>transform the false 160 into the correct alternative of 200 Hz.</p><p>  I will have to work out further details especially in the last step<br/>of &quot;estimation.&quot; The effectiveness of this step will primarily depend<br/>on the software&apos;s ability to narrow down possibilities in order to<br/>make the correct guess everytime.  If there is any more information<br/>that would prove helpful in this case, please let me know of it.<br/>Single note progressions will be described in a later message.  I<br/>would appreciate your help in working together to design software<br/>which can do this revolutionary technology effectively.  Thank you.</p><p>Sincerely,<br/>PageWizard</p></div><h3><a id=26810 href="#26810">ðŸ”—</a>carl@lumma.org</h3><span>8/9/2001 12:29:56 AM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>&gt;   First of all, it is ridiculous to expect the computer to guess<br/>&gt; what you are thinking about before you play it on a keyboard.</p><p>Agreed.</p><p>&gt; The software does not need to do this in order for the user to be<br/>&gt; able to modulate.</p><p>I am aware of the general concept of key-guessing.  I have not<br/>heard of any attempts to anticipate harmony before it is played.<br/>When I said that I don&apos;t want the computer guessing what I<br/>played, I meant this for the following reason: I want to choose<br/>the modulations myself (believe it or not, there is more than<br/>one type of modulation).  I want to choose exactly everything<br/>that happens, specify it in a score or with my hands... If the<br/>computer does this according to some fixed algorithm, I haven&apos;t<br/>gained any new musical resources, I&apos;ve simply made my existing<br/>music sound better... A great idea, but not the particular path<br/>I&apos;m on.</p><p>&gt; The software would calculate the ratios once the key(s) are<br/>&gt; physically struck.  The delay time between the physical action<br/>&gt; and the actual sound produced would be exactly proportional to<br/>&gt; the software&apos;s speed of correct ratio configuration.</p><p>It&apos;s actually not easy to sit between a synth and a midi<br/>controller without introducing a noticeable delay in an<br/>instrument&apos;s response.  You need to get it below 5 ms, really.<br/>Doable, but not off-the-shelf easy.  You can get away with<br/>more delay, as they say, but I wouldn&apos;t enjoy it to play.</p><p>&gt; Even in 12 ET, the identity of a played note depends on its<br/>&gt; relation to a reference note, even if the reference is never<br/>&gt; played.</p><p>Sorry, I lost you here.</p><p>&gt;   The software will store an accumulation bank between all<br/>&gt; previously played notes, so that it will be able to use the<br/>&gt; bank to access relations between the notes.  When given a<br/>&gt; certain scale formula in ratios, the software will only output<br/>&gt; signals corresponding to specific combinations of those ratios.<br/>&gt; If false signals are inputed, the software will be able to<br/>&gt; detect that a modulation is occurring and it will be able to<br/>&gt; adjust all other notes accordingly.<br/>&gt;<br/>&gt;   First, I will start with a transition involving simultaneous<br/>&gt; chords.  After this, I will talk about transitions involving<br/>&gt; individual note progressions.  I am sure you will agree that<br/>&gt; chordal progressions are a much simpler matter than single note<br/>&gt; progressions.</p><p>By single note progressions, you mean melodies?  I do agree.</p><p>&gt; You are correct in this, but you must remember that scalar (single<br/>&gt; note) progressions have an order which depends on the notes<br/>&gt; previously played.</p><p>This is the part I don&apos;t get.</p><p>&gt;   First, lets make the transition from C Major to C# Major since it<br/>&gt; will offer a very good contrast between an erroneous result and a<br/>&gt; valid result.  First I will show what a false C# Major would look<br/>&gt; like using the ratios based off of 100 Hz (arbitrary C).<br/>&gt;<br/>&gt; INCORRECT PHYSICAL INPUT (TRUNCATED FOR CONVENIENCE)<br/>&gt; False C#<br/>&gt; 16/15     4/3     8/5<br/>&gt; 106 2/3  133 1/3  160<br/>&gt;<br/>&gt; After the software analyzes that the frequencies of 106 2/3 and 133<br/>&gt; 1/3 are correct.  The false fifth is 40 Hz narrow. The software<br/>&gt; moves the new fifth up to 200 Hz.  The final signal is then sent<br/>&gt; for transmission.</p><p>Actually, the ratios shown do form a major triad with consonant<br/>proportions 4:5:6, just like the one on C major did.  You&apos;ve made<br/>an error -- the interval from 160 to 106 hz is a just 3:2 &quot;fifth&quot;.</p><p>&gt;   I will submit further information in the future involving single<br/>&gt; note progressions.  You may, though, be wondering how the software<br/>&gt; would decide whether the C# is itself or one of its inversions<br/>&gt; since any could be just as likely.</p><p>Sounds like you&apos;re thinking about the famous &quot;comma&quot; problem?</p><p>&gt; The software will be able to solve this problem since it makes<br/>&gt; all of its calculations based on an arbitrary reference such as<br/>&gt; C (physical key on the keyboard) represents 100 Hz.  All<br/>&gt; corresponding ratios of inputs will be based off of this.<br/>&gt; The software will be able to see that (in this case) I am playing<br/>&gt; ratios of 16/15, 4/3, and 8/5 in relation to 100 Hz.  It will have<br/>&gt; tables of all of the possible combinations of three notes in a<br/>&gt; given scale system.  This will allow it to narrow down<br/>&gt; possibilities.  Each chord has a distinct identity.  Since there<br/>&gt; are only a limited number of possible chord identities within a<br/>&gt; specific scale, the software will be able to narrow down the<br/>&gt; possibilities using its bank of relations between notes in a<br/>&gt; chord.<br/>/.../<br/>&gt; I  would appreciate your help in working together to design<br/>&gt; software which can do this revolutionary technology effectively.<br/>&gt; Thank you.</p><p>I&apos;d love to help out, but I&apos;ve already got my hands full with<br/>my own projects.  I encourage you to develop you&apos;re ideas and<br/>make them a reality!</p><p>-Carl</p></div><h3><a id=26816 href="#26816">ðŸ”—</a>jpehrson@rcn.com</h3><span>8/9/2001 8:08:46 AM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning@y..., &quot;PageWizard, Magician of the Caverns&quot;</p><p><a href="/tuning/topicId_26809.html#26809">/tuning/topicId_26809.html#26809</a></p><p>&gt;<br/>&gt;   I will have to work out further details especially in the last<br/>step<br/>&gt; of &quot;estimation.&quot; The effectiveness of this step will primarily<br/>depend<br/>&gt; on the software&apos;s ability to narrow down possibilities in order to<br/>&gt; make the correct guess everytime.  If there is any more information<br/>&gt; that would prove helpful in this case, please let me know of it.<br/>&gt; Single note progressions will be described in a later message.  I<br/>&gt; would appreciate your help in working together to design software<br/>&gt; which can do this revolutionary technology effectively.  Thank you.<br/>&gt;<br/>&gt; Sincerely,<br/>&gt; PageWizard</p><p>I believe John deLaubenfels is really the person to discuss this<br/>further...  I think he&apos;s shown that &quot;adaptive just intonation&quot; is<br/>really quite a bit more complex than some of the examples you have<br/>been giving... it&apos;s really a rather involved problem, and he goes<br/>quite a way in solving it...</p><p>However, John doesn&apos;t attempt to do this all in &quot;real time...&quot;</p><p>Is that really possible.... I would have my doubts...</p><p>______________ ____________ _________<br/>Joseph Pehrson</p></div><h3><a id=26823 href="#26823">ðŸ”—</a>Robert Walker &#x3C;robertwalker@ntlworld.com&#x3E;</h3><span>11/9/2001 7:48:50 AM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Hi PageWizard,</p><p>I&apos;m sure John can give more detailed examples, but here is a simple<br/>one (of my own) to show where software can easily get confused without<br/>look ahead.</p><p>You&apos;ve been playing consonant triads for a while appropriate for<br/>j.i. scale of<br/> 1  16/15  9/8  6/5  5/4  4/3  45/32  3/2  8/5  5/3  9/5  15/8  2</p><p>with 1/1 = c<br/>Here the 8/5 is the Gb, a major third below the C=2/1</p><p>Now without preparation you play a note in the vicinity of Gb or F#</p><p>How can the software tell if you intend a Gb = 8/5, or a F# = 25/16<br/>which is 5/4 above the E.</p><p>If you play it simulataneously with an E then it will know that you mean<br/>the 25/16. But suppose you play the E a little after it (intending it<br/>to be sim. perhaps, but on microsecond level it isn&apos;t).</p><p>Or, suppose you just play a sustained F# and then introduce the E later.</p><p>How can the software tell, without anticipating what you are going to<br/>do next, whether you want an F# or a Gb?</p><p>Let&apos;s suppose it decides on an F#. What does it do if you were to play<br/>a C next instead? It would have to slide the F# to a Gb at that point.<br/>Or, play the C at a 5/4 above the F# at 125/64, and at some later point<br/>slide that up to the 2/1.</p><p>So clearly it is going to make &quot;mistakes&quot; that a leisure time retuning<br/>program wouldn&apos;t make.</p><p>To minimise those mistakes, you have to find a way to get the program<br/>to try to anticipate what is most likely to be played next, which<br/>is hard. It probably can be done, but chances are you&apos;ll always find a composer<br/>who delights in breaking whatever rules it is using to do that.</p><p>Thinking this over a bit more thoroughly I see that even a half second<br/>delay isn&apos;t really going to help. You&apos;ll want a two or three bars<br/>delay prob. in many cases, between playing the notes and hearing them!</p><p>Do say if you see any way round this kind of an example.</p><p>Robert</p></div><h3><a id=26824 href="#26824">ðŸ”—</a>Robert Walker &#x3C;robertwalker@ntlworld.com&#x3E;</h3><span>11/9/2001 7:56:28 AM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Hi PageWizard,</p><p>Of course, in that post, Gb should read Ab and F# should read G#,<br/>sorry.</p><p>Robert</p></div><h3><a id=26827 href="#26827">ðŸ”—</a>carl@lumma.org</h3><span>8/9/2001 11:52:53 AM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>&gt; I believe John deLaubenfels is really the person to discuss this<br/>&gt; further...  I think he&apos;s shown that &quot;adaptive just intonation&quot; is<br/>&gt; really quite a bit more complex than some of the examples you have<br/>&gt; been giving... it&apos;s really a rather involved problem, and he goes<br/>&gt; quite a way in solving it...</p><p>True.</p><p>&gt; However, John doesn&apos;t attempt to do this all in &quot;real time...&quot;</p><p>An early version of his software, called JI Relay, did.</p><p>&gt; Is that really possible.... I would have my doubts...</p><p>It isn&apos;t possible to do drift control in the same way as<br/>John&apos;s latest stuff does, since it uses knowledge of where<br/>the music is going.  But it is possible to sit between a<br/>midi stream and a synth and do things, as PageWizard suggests.</p><p>-Carl</p></div><h3><a id=26834 href="#26834">ðŸ”—</a>carl@lumma.org</h3><span>8/9/2001 1:29:03 PM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>&gt; You&apos;ve been playing consonant triads for a while appropriate for<br/>&gt; j.i. scale of<br/>&gt;  1  16/15  9/8  6/5  5/4  4/3  45/32  3/2  8/5  5/3  9/5  15/8  2<br/>&gt;<br/>&gt; with 1/1 = c<br/>&gt; Here the 8/5 is the Gb, a major third below the C=2/1<br/>&gt;<br/>&gt; Now without preparation you play a note in the vicinity of Gb or F#<br/>&gt;<br/>&gt; How can the software tell if you intend a Gb = 8/5, or a F# = 25/16<br/>&gt; which is 5/4 above the E.</p><p>I can see two possibilities...</p><p>&#x9;1. use the last tuning used for that note<br/>&#x9;2. use the tuning in the last key you were<br/>&#x9;known to be in (ie 8/5 in C)</p><p>...if there is no previous information -- the note is out of the<br/>blue -- it can choose randomly, or perhaps the performer is to<br/>specify a default key before he begins playing.</p><p>&gt; If you play it simulataneously with an E then it will know that you<br/>&gt; mean the 25/16. But suppose you play the E a little after it<br/>&gt; (intending it to be sim. perhaps, but on microsecond level it<br/>&gt; isn&apos;t).</p><p>The note can be bent into tune once the simultaneity is recognized,<br/>or left as it is until the it is replayed.  Both options are cool --<br/>bending sounds cool, and so do the &quot;krunchy&quot; (Keenan Pepper&apos;s term)<br/>suspended sonorities you get if the old note is frozen until its<br/>next note-on.</p><p>&gt; How can the software tell, without anticipating what you are going<br/>&gt; to do next, whether you want an F# or a Gb?</p><p>It has a notion of what key you&apos;re in.  Besides just making sure<br/>chords<br/>are as in-tune as it can make them, it assumes you&apos;re composing<br/>in the diatonic scale, more or less, and maintains a persistant notion<br/>of key.  It takes a certain amount of something to change this notion,<br/>the exact amount and type of this something up to the programmer.  I<br/>can get code from Stephen if anybody&apos;s interested.</p><p>I should also say I suspect software _without_ this feature would also<br/>be worth having.  It just bends chords, and has no persistent vision<br/>at all.</p><p>&gt; So clearly it is going to make &quot;mistakes&quot; that a leisure time<br/>&gt; retuning program wouldn&apos;t make.</p><p>Yes.</p><p>&gt; To minimise those mistakes, you have to find a way to get the<br/>&gt; program to try to anticipate what is most likely to be played<br/>&gt; next, which is hard. It probably can be done, but chances are<br/>&gt; you&apos;ll always find a composer who delights in breaking whatever<br/>&gt; rules it is using to do that.</p><p>Sure.</p><p>&gt; Thinking this over a bit more thoroughly I see that even a half<br/>&gt; second delay isn&apos;t really going to help. You&apos;ll want a two or<br/>&gt; three bars delay prob. in many cases, between playing the notes<br/>&gt; and hearing them!</p><p>That&apos;s leisure time.  I wouldn&apos;t call something real-time until<br/>it&apos;s quicker than .1 seconds, I wouldn&apos;t call something good<br/>real-time until it&apos;s faster than .01 seconds, and I wouldn&apos;t call<br/>something excellent real-time until it&apos;s faster than .005 seconds.<br/>Kyma should be able to do this.</p><p>&gt; Do say if you see any way round this kind of an example.</p><p>I&apos;m sure there are ways around it that I haven&apos;t thought of, but<br/>the thing I&apos;d like to drive home is that they all result in<br/>compositional resources not substantially greater than 12-tET.<br/>You&apos;re music will sound great, and there will be all sorts of<br/>microtonal action to follow, but this action is not precisely<br/>under the control of the composer.  For that, we need a guitar<br/>with more frets, a keyboard with more keys, or a different<br/>system of notation.</p><p>-Carl</p></div><h3><a id=26858 href="#26858">ðŸ”—</a>Robert Walker &#x3C;robertwalker@ntlworld.com&#x3E;</h3><span>11/10/2001 2:09:24 AM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Hi PageWizard, and Carl,</p><p>PageWizard wrote:</p><p>....<br/>&gt; We need to realize that for two different things, there must be two<br/>&gt; different keys on the keyboard or apparatus altogether.  We must<br/>&gt; design a new instrument of the future which allows for these<br/>&gt; different identities.  I need to, first of all, figure out how many<br/>&gt; different identities are there.  Equal temperament only disregarded<br/>&gt; the problem by cramping these dual identities into one for<br/>&gt; convenience and impurity.  In this case the 8/5 and the 5/4 are the<br/>&gt; same note really.  Two separate identities really are not the same,<br/>&gt; and until we realize that we will not have purity without each<br/>&gt; separate identity, then we will never have purity.  ET is not purity,<br/>&gt; it is a compromise which minimizes note numbers.</p><p>I found Margo Schulter&apos;s article on development of 12 tone helpful,<br/>with perspective that Bb come as result of splitting the note B into<br/>two notes, one reached by a fifth from above, and one by a fifth from<br/>below.</p><p>You can find her article in the faq linked to from<br/><a href="/tuning2">/tuning2</a></p><p>As of writing it is still available at nbci, but<br/>will need to be moved soon, prob. to v3space.<br/>At present, the url for the article is:<br/><a href="http://members.nbci.com/_XMCM/tune_smithy/tree/on_site_tree/margoschulter/Why_12_notes_as_one_attrac">http://members.nbci.com/_XMCM/tune_smithy/tree/on_site_tree/margoschulter/Why_12_notes_as_one_attrac</a><br/>tive_arrangement.html</p><p>So now one is doing the same with thirds, and getting two notes for Ab / G#,<br/>one reached by two thirds from below, and one by a single third from above.</p><p>I know that there are keyboards with split keys to help play, e.g.<br/>19-tet, or 31 - tet. Not sure, but think I remember reading that it<br/>is also done for quarter comma meantone, skipping round the wolf fifth by<br/>splitting a key.</p><p>Also know of a split key pythagorean 17 tone system that Margo describes<br/>by 15th century theorists:<br/>1/1 256/243 2187/2048 9/8 32/27 19683/16384 81/64 4/3 1024/729 729/512<br/>3/2 128/81 6561/4096 27/16 16/9 59049/32768 243/128 2/1</p><p>See<br/><a href="http://www.medieval.org/emfaq/harmony/pyth4.html">http://www.medieval.org/emfaq/harmony/pyth4.html</a><br/>section 4.5.</p><p>However, and this is question for the list as a whole too:</p><p>Has anyone devised, say, a 17 or 19 tone scale for a split<br/>key arrangement with just intonation ratios, targetting the<br/>simpler ratios for triads, like 5/4, 6/5, etc?</p><p>If so, would be nice to add to FTS midi in relaying presets<br/>- I&apos;ve added the C 15 pyth. one there. (It&apos;s set up so that one<br/>can select either note of a &quot;split key&quot; by pressing the<br/>sustain pedal, or alternatively, caps lock key on keyboard<br/>etc, just before playing the note).</p><p>Seems to me this is somewhat the direction you are considering<br/>at the moment.</p><p>I know also of scale by Erv Wilson that is made by stacking<br/>1/1 5/4 3/2 on top of itself until you get 17 notes and<br/>reducing it into the octave, which we discussed on this<br/>list a little while back. It&apos;s not quite the same thing<br/>though, as one is stacking triads, rather than 5/4s.</p><p>wilson_17.scl | Wilson&apos;s 17-tone 5-limit scale</p><p>1/1 135/128 10/9 9/8 1215/1024 5/4 81/64 4/3 45/32 729/512 3/2<br/>405/256 5/3 27/16 16/9 15/8 243/128 2/1</p><p>Carl wrote:</p><p>&gt; &gt; You&apos;ve been playing consonant triads for a while appropriate for<br/>&gt; &gt; j.i. scale of<br/>&gt; &gt;  1  16/15  9/8  6/5  5/4  4/3  45/32  3/2  8/5  5/3  9/5  15/8  2<br/>&gt; &gt;<br/>&gt; &gt; with 1/1 = c<br/>&gt; &gt; Here the 8/5 is the Gb, a major third below the C=2/1<br/>&gt; &gt;<br/>&gt; &gt; Now without preparation you play a note in the vicinity of Gb or F#<br/>&gt; &gt;<br/>&gt; &gt; How can the software tell if you intend a Gb = 8/5, or a F# = 25/16<br/>&gt; &gt; which is 5/4 above the E.<br/>&gt;<br/>&gt; I can see two possibilities...<br/>&gt;<br/>&gt; 1. use the last tuning used for that note<br/>&gt; 2. use the tuning in the last key you were<br/>&gt; known to be in (ie 8/5 in C)<br/>&gt;<br/>&gt; ...if there is no previous information -- the note is out of the<br/>&gt; blue -- it can choose randomly, or perhaps the performer is to<br/>&gt; specify a default key before he begins playing.<br/>&gt;<br/>&gt; &gt; If you play it simulataneously with an E then it will know that you<br/>&gt; &gt; mean the 25/16. But suppose you play the E a little after it<br/>&gt; &gt; (intending it to be sim. perhaps, but on microsecond level it<br/>&gt; &gt; isn&apos;t).<br/>&gt;<br/>&gt; The note can be bent into tune once the simultaneity is recognized,<br/>&gt; or left as it is until the it is replayed.  Both options are cool --<br/>&gt; bending sounds cool, and so do the &quot;krunchy&quot; (Keenan Pepper&apos;s term)<br/>&gt; suspended sonorities you get if the old note is frozen until its<br/>&gt; next note-on.<br/>&gt;</p><p>Yes, can sound nice. However can also sound just as if it is a mistake<br/>being corrected. One would have to see which it turned out as.</p><p>&gt; &gt; Thinking this over a bit more thoroughly I see that even a half<br/>&gt; &gt; second delay isn&apos;t really going to help. You&apos;ll want a two or<br/>&gt; &gt; three bars delay prob. in many cases, between playing the notes<br/>&gt; &gt; and hearing them!<br/>&gt;<br/>&gt; That&apos;s leisure time.  I wouldn&apos;t call something real-time until<br/>&gt; it&apos;s quicker than .1 seconds, I wouldn&apos;t call something good<br/>&gt; real-time until it&apos;s faster than .01 seconds, and I wouldn&apos;t call<br/>&gt; something excellent real-time until it&apos;s faster than .005 seconds.<br/>&gt; Kyma should be able to do this.<br/>&gt;</p><p>Yes, I agree. I think, say, 0.2 seconds or even 0.5 secs delay<br/>could be got used to if it is the only way to achieve j.i. chords.<br/>If software needs to look ahead for notes of chord perceived as simultaneous<br/>(or very slightly arpeggiated) then there&apos;s no choice, as the time<br/>is set by the amount of inevitable raggedness, or acceptable<br/>arpeggiation that one gets in human performances, and isn&apos;t<br/>a limitation of the software as such.</p><p>However, I think it most likely would be pretty hard to get used to playing<br/>music and hearing it two bars later!</p><p>Maybe could be done,... I wonder.</p><p>Robert</p></div><h3><a id=26860 href="#26860">ðŸ”—</a>jpehrson@rcn.com</h3><span>8/10/2001 6:29:05 AM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning@y..., &quot;Robert Walker&quot; &lt;robertwalker@n...&gt; wrote:</p><p><a href="/tuning/topicId_26809.html#26823">/tuning/topicId_26809.html#26823</a></p><p>&gt; Hi PageWizard,<br/>&gt;<br/>&gt; I&apos;m sure John can give more detailed examples, but here is a simple<br/>&gt; one (of my own) to show where software can easily get confused<br/>without<br/>&gt; look ahead.<br/>&gt;<br/>&gt; You&apos;ve been playing consonant triads for a while appropriate for<br/>&gt; j.i. scale of<br/>&gt;  1  16/15  9/8  6/5  5/4  4/3  45/32  3/2  8/5  5/3  9/5  15/8  2<br/>&gt;<br/>&gt; with 1/1 = c<br/>&gt; Here the 8/5 is the Gb, a major third below the C=2/1<br/>&gt;<br/>&gt; Now without preparation you play a note in the vicinity of Gb or F#<br/>&gt;<br/>&gt; How can the software tell if you intend a Gb = 8/5, or a F# = 25/16<br/>&gt; which is 5/4 above the E.<br/>&gt;<br/>&gt; If you play it simulataneously with an E then it will know that you<br/>mean<br/>&gt; the 25/16. But suppose you play the E a little after it (intending<br/>it<br/>&gt; to be sim. perhaps, but on microsecond level it isn&apos;t).<br/>&gt;<br/>&gt; Or, suppose you just play a sustained F# and then introduce the E<br/>later.<br/>&gt;<br/>&gt; How can the software tell, without anticipating what you are going<br/>to<br/>&gt; do next, whether you want an F# or a Gb?<br/>&gt;<br/>&gt; Let&apos;s suppose it decides on an F#. What does it do if you were to<br/>play<br/>&gt; a C next instead? It would have to slide the F# to a Gb at that<br/>point.<br/>&gt; Or, play the C at a 5/4 above the F# at 125/64, and at some later<br/>point<br/>&gt; slide that up to the 2/1.<br/>&gt;<br/>&gt; So clearly it is going to make &quot;mistakes&quot; that a leisure time<br/>retuning<br/>&gt; program wouldn&apos;t make.<br/>&gt;<br/>&gt; To minimise those mistakes, you have to find a way to get the<br/>program<br/>&gt; to try to anticipate what is most likely to be played next, which<br/>&gt; is hard. It probably can be done, but chances are you&apos;ll always<br/>find a composer<br/>&gt; who delights in breaking whatever rules it is using to do that.<br/>&gt;<br/>&gt; Thinking this over a bit more thoroughly I see that even a half<br/>second<br/>&gt; delay isn&apos;t really going to help. You&apos;ll want a two or three bars<br/>&gt; delay prob. in many cases, between playing the notes and hearing<br/>them!<br/>&gt;<br/>&gt; Do say if you see any way round this kind of an example.<br/>&gt;<br/>&gt; Robert</p><p>Thanks, Robert for your clear example of this.  I actually understood<br/>the entire post  (!)  :)</p><p>Is this the reason that John deLaubenfels abandoned &quot;real time&quot; just<br/>intonation tuning??</p><p>*Did* he totally abandon that??  John??</p><p>___________ ________ ________<br/>Joseph Pehrson</p></div><h3><a id=26863 href="#26863">ðŸ”—</a>jpehrson@rcn.com</h3><span>8/10/2001 6:34:31 AM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In tuning@y..., carl@l... wrote:</p><p><a href="/tuning/topicId_26809.html#26827">/tuning/topicId_26809.html#26827</a></p><p>&gt; &gt; I believe John deLaubenfels is really the person to discuss this<br/>&gt; &gt; further...  I think he&apos;s shown that &quot;adaptive just intonation&quot; is<br/>&gt; &gt; really quite a bit more complex than some of the examples you<br/>have<br/>&gt; &gt; been giving... it&apos;s really a rather involved problem, and he goes<br/>&gt; &gt; quite a way in solving it...<br/>&gt;<br/>&gt; True.<br/>&gt;<br/>&gt; &gt; However, John doesn&apos;t attempt to do this all in &quot;real time...&quot;<br/>&gt;<br/>&gt; An early version of his software, called JI Relay, did.<br/>&gt;<br/>&gt; &gt; Is that really possible.... I would have my doubts...<br/>&gt;<br/>&gt; It isn&apos;t possible to do drift control in the same way as<br/>&gt; John&apos;s latest stuff does, since it uses knowledge of where<br/>&gt; the music is going.  But it is possible to sit between a<br/>&gt; midi stream and a synth and do things, as PageWizard suggests.<br/>&gt;<br/>&gt; -Carl</p><p>Hi Carl...</p><p>But Robert Walker just said that THREE MEASURES were necessary...</p><p>One couldn&apos;t play an instrument in &quot;real time&quot; like that, could they??</p><p>____________ _______ _______<br/>Joseph Pehrson</p></div><h3><a id=26883 href="#26883">ðŸ”—</a>carl@lumma.org</h3><span>8/10/2001 11:24:37 AM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>&gt;&gt; That&apos;s leisure time.  I wouldn&apos;t call something real-time until<br/>&gt;&gt; it&apos;s quicker than .1 seconds, I wouldn&apos;t call something good<br/>&gt;&gt; real-time until it&apos;s faster than .01 seconds, and I wouldn&apos;t call<br/>&gt;&gt; something excellent real-time until it&apos;s faster than .005 seconds.<br/>&gt;&gt; Kyma should be able to do this.<br/>&gt;<br/>&gt; Yes, I agree. I think, say, 0.2 seconds or even 0.5 secs delay<br/>&gt; could be got used to if it is the only way to achieve j.i. chords.<br/>&gt; If software needs to look ahead for notes of chord perceived as<br/>&gt; simultaneous (or very slightly arpeggiated) then there&apos;s no<br/>&gt; choice, as the time is set by the amount of inevitable raggedness,<br/>&gt; or acceptable arpeggiation that one gets in human performances,<br/>&gt; and isn&apos;t a limitation of the software as such.<br/>&gt;<br/>&gt; However, I think it most likely would be pretty hard to get used<br/>&gt; to playing music and hearing it two bars later!<br/>&gt;<br/>&gt; Maybe could be done,... I wonder.</p><p>It could probably be done, but it wouldn&apos;t be easy, and the work<br/>would just be to get as good as you would be normally.  I&apos;d<br/>rather work to get somewhere better!</p><p>Fortunately, I think .005 should be quite possible.  The thing I<br/>think you&apos;re missing is that the program doesn&apos;t have to wait for<br/>near simultaneous notes any more than it has to wait for distantly<br/>simultaneous notes... it just keeps a record of the last used<br/>pitch for each note, starts there, and then bends it as soon as<br/>other notes come in, if necessary.  It can also try key-guessing,<br/>and take the initial value for a note from the key it thinks<br/>you&apos;re in rather than just using the previous value of the pitch.</p><p>Re your question on if anyone has come up with a JI scale with<br/>17 or 19 notes... it takes 18 notes to play in every key of<br/>the classical 5-limit diatonic scale, and I have a keyboard<br/>mapping for this in the files section under &quot;Carl&quot;.  Notice that<br/>each instance of the scale has uniform fingering.</p><p>-Carl</p></div>
                <script>
                    let monospace = false
                    $('button').on('click', function () {
                      if (monospace) {
                        $('p').css("font-family", "")
                      } else {
                        $('p').css("font-family", "monospace")
                      }
                      monospace = !monospace
                    })
                </script>
            