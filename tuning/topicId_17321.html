<a href="/tuning">back to list</a><h1>Re: detail</h1><h3><a id=17321 href="#17321">ðŸ”—</a>Robert C Valentine &#x3C;BVAL@IIL.INTEL.COM&#x3E;</h3><span>1/8/2001 11:46:58 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Graham said :</p><p>&gt; &gt; I know deep down this could work, but in the end I don&apos;t have the<br/>&gt; &gt; patience to build a universe atom by atom.</p><p>This has been my exact problem with doing computer and electronic<br/>music, despite being an enthusiast for that late fifties, early<br/>sixties &apos;beep and boop&apos; style.</p><p>The problem is that composition should be at a much &apos;higher&apos;<br/>heirarchical level than one seems to get with any of the current<br/>interfaces. FOr instance, if you have a sequence of notes and want<br/>them in a scratchy but lyrical timbre, with the volume and tempo<br/>incresing during their production, drawing a horizontal &apos;v&apos; under<br/>them with the word accelerando and specifying &apos;violin molto<br/>expressivo&apos; says in five seconds of writing what may take a whole<br/>day to realize &apos;tolerably&apos; in MIDI or other methods. (Of course,<br/>you DO have a &apos;tolerable&apos; sound with the electronic realisation,<br/>with only the promise of a better sound with the more composerly<br/>version).</p><p>One could sum some of the problem as electronic music makes the<br/>composer into the performer. The performance is what people hear.<br/>Therefor, you should put AN AWFUL LOT OF EFFORT into the<br/>performance. Do you have time to both come up with something of<br/>worth to perform and the to perform it at the &apos;antlike&apos; level of<br/>electronic music interfaces?</p><p>Bob Valentine</p></div><h3><a id=17327 href="#17327">ðŸ”—</a>graham@microtonal.co.uk</h3><span>1/9/2001 7:10:00 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>In-Reply-To: &lt;<a href="mailto:200101090746.JAA69486@ius267.iil.intel.com">200101090746.JAA69486@ius267.iil.intel.com</a>&gt;<br/>This is now decidedly off-topic.</p><p>Bob Valentine wrote:</p><p>&gt; Graham said :<br/>&gt;<br/>&gt; &gt; &gt; I know deep down this could work, but in the end I don&apos;t have the<br/>&gt; &gt; &gt; patience to build a universe atom by atom.<br/>&gt;<br/>&gt; This has been my exact problem with doing computer and electronic<br/>&gt; music, despite being an enthusiast for that late fifties, early<br/>&gt; sixties &apos;beep and boop&apos; style.</p><p>That actually cuts out my reply, but I&apos;ll answer anyway.  Late 50s, early<br/>60s?  I suppose that must be Stockhausen and the Dr Who theme.  The more<br/>mainstream &apos;boom and bleep&apos; will be later.</p><p>&gt; The problem is that composition should be at a much &apos;higher&apos;<br/>&gt; heirarchical level than one seems to get with any of the current<br/>&gt; interfaces. FOr instance, if you have a sequence of notes and want<br/>&gt; them in a scratchy but lyrical timbre, with the volume and tempo<br/>&gt; incresing during their production, drawing a horizontal &apos;v&apos; under<br/>&gt; them with the word accelerando and specifying &apos;violin molto<br/>&gt; expressivo&apos; says in five seconds of writing what may take a whole<br/>&gt; day to realize &apos;tolerably&apos; in MIDI or other methods. (Of course,<br/>&gt; you DO have a &apos;tolerable&apos; sound with the electronic realisation,<br/>&gt; with only the promise of a better sound with the more composerly<br/>&gt; version).</p><p>In that case your interface appears to be a violinist.  A violinist will<br/>still be more intelligent than a sequencer until we crack the strong-AI<br/>problem.  Fortunately, sequencers are much cheaper, and won&apos;t leave pizza<br/>crumbs on the carpet.</p><p>So how would your day be spent in a MIDI studio?</p><p>The volume increase could be achieved by key velocity, volume(!) or<br/>expression controllers.  Key velocity would be the most obvious, and part<br/>of the keyboard performance.  If that isn&apos;t good enough, as may be the<br/>case, you can get the expression messages in there by using an expression<br/>pedal while playing whatever you&apos;re playing, drawing the envelope into the<br/>sequencer, or recording the expression as a separate performance.</p><p>I don&apos;t have a MIDI tempo knob.  I suppose it could be done, but the Phat<br/>Boy only supports continous controllers.  So that&apos;d have to be drawn in.<br/>I expect tempo could be controlled via Kyma, and I plan to look at this<br/>one day.  It might be able to handle &quot;swing rhythms&quot; as explained in the<br/>New Scientist last year.  Now where was I?</p><p>Oh yes, now you have to set your MIDI &quot;scratchy but lyrical&quot; knob to the<br/>right position.  In reality, you&apos;d have to spend a few minutes playing<br/>with the overdrive and EQ settings, and it still wouldn&apos;t be right.  But<br/>that&apos;s the implementation at fault, not the interface.</p><p>Which leaves plenty of the day left to go outside and listen to the birds<br/>in the park.</p><p>The {controller, sequencer} interface is still lower-level than the<br/>{manuscript paper, skilled musician} one.  There are conventions built<br/>into traditional notation to cover what people have wanted to do in the<br/>past.  MIDI hasn&apos;t been around long enough for these conventions to be<br/>enshrined in the interface.  But that means you have plenty of flexibility<br/>where you need it.  Quite useful, what with sequencers not being as smart<br/>as skilled musicians (see above).</p><p>&gt; One could sum some of the problem as electronic music makes the<br/>&gt; composer into the performer. The performance is what people hear.<br/>&gt; Therefor, you should put AN AWFUL LOT OF EFFORT into the<br/>&gt; performance. Do you have time to both come up with something of<br/>&gt; worth to perform and the to perform it at the &apos;antlike&apos; level of<br/>&gt; electronic music interfaces?</p><p>Making the composer the performer is neither an inevitable offshoot of<br/>electronic music, nor a problem when it occurs.  There are plenty of ways<br/>the work could be divided among a team.  The most obvious is {instrument<br/>designer, composer, performer}.  Very like the traditional break down,<br/>except that the intrument designer would be more visible.  Violinists<br/>rarely have to collaborate with violin makers, because off the shelf<br/>violins don&apos;t suck nearly as badly as MIDI presets.</p><p>Coming up with something worth performing is certainly a problem for me.<br/>But it&apos;s also a problem for guitar pieces, where nobody quibbles with the<br/>interface.  Unfortunately, there are dumb laws that stop me buying<br/>refugees at affordable prices to compose and perform using the virtual<br/>instruments I design.  So I&apos;ve got more chance of realizing an electronic<br/>piece than a string quartet, but it&apos;s slow progress.</p><p>So in what way do an X5D or a Phat Boy resemble an ant?  These are the<br/>interfaces I use most often for pure electronic music.  Although they&apos;re<br/>not perfect, they&apos;re more comparable to other musical instruments than<br/>social insects.  You do have to put a lot of effort into a perfomance.<br/>But then the only time I ever played a violin, it made a &quot;scratchy but not<br/>at all lyrical&quot; sound.  Apparently it takes a great deal of effort to get<br/>the &quot;lyrical&quot; bit working.</p><p>Now, an ant-like implementation, I can see the possibilities in that!<br/>Hundreds of subtle parameters, all taking their lead from each other.  You<br/>could get a satisfyingly complex sound out.  But it would take some time<br/>to get right, and a fair bit of hardware to implement in real time.  And<br/>not at all how I understand existing synthesizers to work.  Still, nice<br/>idea.</p><p>                    Graham</p></div><h3><a id=17340 href="#17340">ðŸ”—</a>Robert C Valentine &#x3C;BVAL@IIL.INTEL.COM&#x3E;</h3><span>1/10/2001 5:50:03 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>&gt;<br/>&gt;    From: <a href="mailto:graham@microtonal.co.uk">graham@microtonal.co.uk</a><br/>&gt; This is now decidedly off-topic.<br/>&gt;</p><p>Perhaps, although microtonalists are wont to turn to machine<br/>realisations sooner than people who don&apos;t need to find accordians<br/>(and players) cognizant of 17.3tet.</p><p>&gt; Bob Valentine wrote:<br/>&gt;<br/>&gt; That actually cuts out my reply, but I&apos;ll answer anyway.  Late 50s, early<br/>&gt; 60s?  I suppose that must be Stockhausen and the Dr Who theme.  The more<br/>&gt; mainstream &apos;boom and bleep&apos; will be later.</p><p>And Otto Luening and Babbitt and the whole Columbia thing... I guess<br/>Morton Subotnik was came closest to finding the commercial potential.</p><p>&lt; snip my description of the simplicity of writing in impassioned passage<br/>  for violin which, WHEN REALISED by a competent player, will have a degree<br/>  of complexitie in timing, dynamics and timbre that would take a REALLY<br/>  LONG TIME to realize in midi/csound and would likely not result in as<br/>  &apos;musical&apos; a renderring as that of the competent violinist. &gt;</p><p>&gt; Graham :<br/>&gt;<br/>&gt; In that case your interface appears to be a violinist.  A violinist will<br/>&gt; still be more intelligent than a sequencer until we crack the strong-AI<br/>&gt; problem.  Fortunately, sequencers are much cheaper, and won&apos;t leave pizza<br/>&gt; crumbs on the carpet.</p><p>Yes, there is a cost and reward that have to be balanced here. I can hear<br/>my music, renderred as well as my software/soundcard allow given that I<br/>am willing to spend a large amount of time supervising that renderring<br/>(massaging each note, which I thought you were referring to as build ing<br/>a universe atom by atom and which I look at as an ant-like labor). Or<br/>I can pay a violinist to read through the thing and tape it.</p><p>If I was just doing a trad sort of thing, I know which way I&apos;d go. But<br/>if having the violinist &quot;read through&quot; means explaininga tuning system<br/>as well, then the computer realisation is probably more reliable.</p><p>&gt;<br/>&gt; So how would your day be spent in a MIDI studio?<br/>&gt;<br/>&gt; The volume increase could be achieved by key velocity, volume(!) or<br/>&gt; expression controllers.  Key velocity would be the most obvious, and part<br/>&gt; of the keyboard performance.  If that isn&apos;t good enough, as may be the<br/>&gt; case, you can get the expression messages in there by using an expression<br/>&gt; pedal while playing whatever you&apos;re playing, drawing the envelope into the<br/>&gt; sequencer, or recording the expression as a separate performance.<br/>&gt;</p><p>All true, and if I am not a competent pianist then I will spend 20~2000x<br/>the time drawing these envelopes (or massaging each note) compared to<br/>drawing the &apos;two lines and three words&apos; on the handwritten score.</p><p>&gt; I don&apos;t have a MIDI tempo knob.  I suppose it could be done, but the Phat<br/>&gt; Boy only supports continous controllers.  So that&apos;d have to be drawn in.<br/>&gt; I expect tempo could be controlled via Kyma, and I plan to look at this<br/>&gt; one day.  It might be able to handle &quot;swing rhythms&quot; as explained in the<br/>&gt; New Scientist last year.  Now where was I?<br/>&gt;</p><p>&quot;tempo maps&quot; are a pretty old concept and should be able to be done in<br/>a sequencer.</p><p>&gt; Oh yes, now you have to set your MIDI &quot;scratchy but lyrical&quot; knob to the<br/>&gt; right position.  In reality, you&apos;d have to spend a few minutes playing<br/>&gt; with the overdrive and EQ settings, and it still wouldn&apos;t be right.  But<br/>&gt; that&apos;s the implementation at fault, not the interface.<br/>&gt;</p><p>Actually, the interface in common music notation is a mess here. If you want<br/>&apos;lyrical&apos; you write &apos;lyrical&apos; and hope the player does what you want. If<br/>you want a &quot;wheezy lyrical&quot;, you write &quot;arco col legno&quot;. Guess what. That<br/>doesn&apos;t work on trombone! This is a place where a synthesizer / compute music<br/>language should push things UP the heirarchy, so that specifying &quot;more<br/>wheeze&quot; would have an intelligent interpretation no matter what the<br/>&apos;instrument&apos; was it was asked from.</p><p>You might say &quot;turn the wheeze knob&quot;. Unfortunately, this really means<br/>&apos;find a synthesis system with a wheeze knob, figure out a sysex to assign<br/>it to a controllable parameter, insert that into the file, enter the<br/>wheeze amounts with the mouse and see how they fit&apos;.</p><p>All the way to the other end of the heirarchy.</p><p>&gt; Which leaves plenty of the day left to go outside and listen to the birds<br/>&gt; in the park.</p><p>But thats where I want to do my composing in the first place.</p><p>Oh well... I don&apos;t mean to sound like I&apos;m arguing about anything. I<br/>certainly don&apos;t know how to improve it all, other than write my<br/>own programs to do things my way. I&apos;ve done this in the past, but<br/>this too forces a period of atom assmbling &quot;I want to write music<br/>close to CMN, I also want very free microtonality, how should the<br/>program intelligently interpret C#4 if the tuning is 88cet?&quot;. So,<br/>now I&apos;m in play-with-people mode. Oh well, next years HW/SW will<br/>change everything, I&apos;m sure.</p><p>[Oh, I&apos;ll probably be starting a new program using some of your<br/>code so, thanks for putting it out there.]</p><p>Bob Valentine</p></div>