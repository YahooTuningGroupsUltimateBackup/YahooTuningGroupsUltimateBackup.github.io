<!DOCTYPE html>
            <html>
            <head>
            <meta charset="utf-8">
                <meta name="viewport"
            content="width=device-width, height=device-height, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no">
                <meta http-equiv="x-ua-compatible" content="ie=edge">
                <title>Yahoo Tuning Groups Ultimate Backup tuning Bayesian tuning</title>
                <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
            </head>
            <body>
            </body>
            </html>
        <a href="/tuning">back to list</a><h1>Bayesian tuning</h1><h3><a id=98574 href="#98574">ðŸ”—</a>Daniel Nielsen &#x3C;nielsed@...&#x3E;</h3><span>4/24/2011 10:02:48 PM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>This is a set of tunings based on the Bayes formula.</p><p>How it is generated:<br/>It assumes a binary Bayes process (i.e. two exhaustive, mutually exclusive<br/>possible outcomes) with an initial prior probability for &quot;success&quot; of 1/2.<br/>From there, a likelihood ratio is found that causes the value after N<br/>iterative evaluations to fall on the 2/1 octave. (N, therefore, is the<br/>number of pitches in the octave, since the value at each iteration<br/>represents a pitch.)</p><p>Here are results for N=9, as an example:<br/>     0.0000<br/>  -108.8867<br/>  -224.1946<br/>  -345.8528<br/>  -473.7450<br/>  -607.7137<br/>  -747.5635<br/>  -893.0673<br/> -1043.9709<br/> -1200.0000</p><p>Why are these negative? Well, I wasn&apos;t certain whether to add another octave<br/>or to invert the values to make a tuning. What&apos;s interesting is that, if we<br/>invert the likelihood ratio that defines this set, we get a 3/2 range in the<br/>opposite direction instead. Values are the following (again using the<br/>example of N=9):<br/>     0.0000<br/>   102.4416<br/>   198.4620<br/>   288.1322<br/>   371.5683<br/>   448.9280<br/>   520.4065<br/>   586.2311<br/>   646.6557<br/>   701.9550</p><p>Below you&apos;ll find a hacked-together BASIC program to generate values for<br/>different N. This program can also generate another set of related values<br/>which I&apos;ll describe briefly now:</p><p>The 2-variable generating function for the poly-Bernoulli numbers of<br/>negative index (first presented in 1999 by Kaneko and called &quot;the symmetric<br/>formula&quot; in related papers) is simply a form of the Bayes formula times a<br/>likelihood ratio (the inverse likelihood ratio of what is commonly used by<br/>statisticians). I&apos;m not certain whether or not this has been noted<br/>explicitly, but I haven&apos;t seen any mention of the fact in Kaneko&apos;s papers or<br/>other related writings that I&apos;ve read. The fact might be picked up on by<br/>those who investigate neural networks, since such a form is very important<br/>in that field. Anyway, replacing that likelihood ratio with the inverse of<br/>that gives the generating function for the alternating poly-Bernoulli<br/>numbers of negative index. Such properties also directly extend to the<br/>multi-poly-Bernoulli numbers, but this gets off-track.</p><p>I made proofs for the above facts about 3/2 yrs ago; if interested, more<br/>detail may be provided.</p><p>Here&apos;s the program; I&apos;ll also put a compiled version in my folder. It<br/>outputs to OUT.TXT in the directory it is run in.<br/>___________________________</p><p>&apos;BAYESTUN.BAS<br/>&apos;Dan Nielsen</p><p>DECLARE FUNCTION eq# (a AS DOUBLE, b AS DOUBLE)</p><p>CONST N = 9 &apos;Number of pitches in list minus 1</p><p>&apos;Choose one of the following<br/>CONST a = 0 &apos;Bayes formula<br/>&apos;CONST a = -1 &apos;Kaneko symmetric formula</p><p>DEFDBL A-Z<br/>CLS<br/>OPEN &quot;out.txt&quot; FOR OUTPUT AS #1</p><p>&apos;Find k<br/>k = 0 &apos;Initial guess for k<br/>delta = .1 &apos;Initial correction change increment<br/>dir = 0 &apos;Last correction direction (1 for add; -1 for subtract)<br/>kloop:<br/>x = .5 &apos;Initial prior probability<br/>y = EXP(k) &apos;Likelihood ratio (inverse of common convention)<br/>FOR i = 1 TO N<br/>  IF a THEN b = y ELSE b = 1<br/>  x = (b * x) / (x + y - x * y)<br/>  z = (1200 * LOG(x) / LOG(2)) + 1200<br/>NEXT<br/>IF NOT eq(ABS(z), 1200) THEN<br/>  IF ABS(z) &lt; 1200 THEN<br/>    k = k + delta<br/>    IF dir &lt;&gt; 1 THEN delta = .5 * delta<br/>    dir = 1<br/>  END IF<br/>  IF ABS(z) &gt; 1200 THEN<br/>    k = k - delta<br/>    IF dir &lt;&gt; -1 THEN delta = .5 * delta<br/>    dir = -1<br/>  END IF<br/>  GOTO kloop<br/>END IF</p><p>PRINT #1, &quot; k =&quot;; k<br/>PRINT &quot; k =&quot;; k</p><p>FOR j = 1 TO -1 STEP -2 &apos;Inverts likelihood ratio on second iteration</p><p>  x = .5 &apos;Initial prior probability<br/>  y = EXP(j * k) &apos;Likelihood ratio (inverse of common convention)<br/>  z = (1200 * LOG(x) / LOG(2)) + 1200</p><p>  PRINT #1, &quot; &quot;; : PRINT #1, USING &quot;#####.####&quot;; z<br/>  PRINT &quot; &quot;; : PRINT USING &quot;#####.####&quot;; z</p><p>  FOR i = 1 TO N</p><p>    IF a THEN b = y ELSE b = 1<br/>    x = (b * x) / (x + y - x * y)<br/>    z = (1200 * LOG(x) / LOG(2)) + 1200</p><p>    PRINT #1, &quot; &quot;; : PRINT #1, USING &quot;#####.####&quot;; z<br/>    PRINT &quot; &quot;; : PRINT USING &quot;#####.####&quot;; z</p><p>  NEXT</p><p>PRINT #1, &quot;--------------&quot;<br/>PRINT &quot;--------------&quot;<br/>SLEEP</p><p>NEXT</p><p>CLOSE</p><p>FUNCTION eq (a AS DOUBLE, b AS DOUBLE)<br/>  IF (ABS(a - b) &lt; .000001) THEN eq = -1 ELSE eq = 0<br/>END FUNCTION</p></div><h3><a id=98576 href="#98576">ðŸ”—</a>Mike Battaglia &#x3C;battaglia01@...&#x3E;</h3><span>4/24/2011 10:50:35 PM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On Mon, Apr 25, 2011 at 1:02 AM, Daniel Nielsen &lt;nielsed@...&gt; wrote:<br/>&gt;<br/>&gt; This is a set of tunings based on the Bayes formula.<br/>&gt; How it is generated:<br/>&gt; It assumes a binary Bayes process&nbsp;(i.e. two exhaustive, mutually exclusive possible outcomes)&nbsp;with an initial prior probability for &quot;success&quot; of 1/2. From there, a likelihood ratio is found that causes the value after N iterative evaluations to fall on the 2/1 octave. (N, therefore, is the number of pitches in the octave, since the value at each iteration represents a pitch.)</p><p>Hi Dan,</p><p>For the record, you might find a better response if you start posting<br/>stuff like this to tuning-math:</p><p><a href="/tuning-math/">/tuning-math/</a></p><p>But I&apos;m not sure I understand exactly what you&apos;re doing here - would<br/>you mind spelling it out for me a bit? It looks fascinating, but I<br/>admit that I&apos;m completely lost.</p><p>-Mike</p></div><h3><a id=98582 href="#98582">ðŸ”—</a>Daniel Nielsen &#x3C;nielsed@...&#x3E;</h3><span>4/24/2011 11:50:59 PM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>&gt;<br/>&gt; Hi Dan,<br/>&gt;<br/>&gt; For the record, you might find a better response if you start posting<br/>&gt; stuff like this to tuning-math:<br/>&gt;<br/>&gt; <a href="/tuning-math/">/tuning-math/</a><br/>&gt;<br/>&gt; But I&apos;m not sure I understand exactly what you&apos;re doing here - would<br/>&gt; you mind spelling it out for me a bit? It looks fascinating, but I<br/>&gt; admit that I&apos;m completely lost.<br/>&gt;<br/>&gt; -Mike<br/>&gt;</p><p>Thanks for the response, Mike. Honestly I&apos;m terrified of tuning-math since I<br/>have a hard enough time understanding what&apos;s going on here, but since these<br/>sorts of things do fall into the more general realm than the mainstays of<br/>contemporary tuning theory, I probably should register over there, if that&apos;d<br/>be okay.</p><p>I&apos;ll start by describing my motivation for something like this as best I can<br/>piece it together. The Bayes formula at its most simple root is just<br/>probabilistic multiplication:<br/>P(S and R) = P(S|R) P(R) = P(R|S) P(S)<br/>where P(R|S) means &quot;probability of condition R is true given condition S is<br/>true&quot;; therefore<br/>P(R|S) = P(S|R) P(R) / P(S)<br/>Now, from that point, folks go in LOTS of different directions with Bayes<br/>theorem, but one common approach is to set up a binary Bayes formula -<br/>meaning only two possible outcomes can exist, R or (not R):<br/>P(R|S) = P(S|R) P(R) / (P(S|R) P(R) + P(S|not R) (1-P(R))</p><p>With this simple formula, we can now incorporate new data into our<br/>experience. Say we had two mutually exclusive hypotheses - you can call them<br/>&quot;flatter&quot; or &quot;sharper&quot;, &quot;hotter&quot; or &quot;colder&quot;, &quot;good&quot; or &quot;bad&quot;, whatever - as<br/>new evidence is brought in, we can update the weighting of the two<br/>hypotheses. This is done by a simple additive process when we take the log<br/>of the binary Bayes formula (actually best expressed by taking a ratio of<br/>Bayesian probabilities called the odds). For more hypotheses than two, the<br/>simple additive process does not work out so well, however, so this was one<br/>justification I had for choosing the binary Bayes formula.</p><p>A common question, and one that has caused lots of arguments, is how then to<br/>think about the first prior probability, whether it can exist or if it must<br/>come from observation, what data it should be based on, etc. One<br/>mathematically justified approach is, in the complete absence of any<br/>information about the system (and this is more rare than it sounds like,<br/>since even describing a problem or a solution method implies information),<br/>to use the &quot;Jeffreys prior probability&quot;, but even this is under a bit of<br/>contention. I chose to initialize the probability at 1/2. I believe that is<br/>most common. I think one possible alternative is to initialize at 0.5^0.5,<br/>but I&apos;m not really sure.</p><p>The reason the Bayes theorem might make a good tuning is for the same reason<br/>that the golden ratio might. It describes a well-ingrained process that<br/>directs the course of development and perception. Therefore, one might<br/>expect that we are very adept at picking up on the results of these<br/>calculations. The Bayes formula is prominent in artificial neural networks.<br/>The association I made with the poly-Bernoulli numbers may have significant<br/>implications for our perceptive processes, which I won&apos;t try to describe at<br/>the moment (its very late).</p><p>Anyway, the binary Bayes formula uses 2 variables essentially - the prior<br/>probability and the likelihood ratio. The prior probability is simply<br/>updated each round, so we have no control over that excepting its initial<br/>value. The likelihood ratio (which I express in the program as exp(k)) can<br/>be adjusted, however, so that after N steps we arrive at the 2/1 octave. The<br/>really surprising thing was that simply by inverting the likelihood ratio<br/>(and, BTW, this inversion has a very straightforward implication in its<br/>association to the poly-Bernoulli numbers) we get a 3/2 range (in the<br/>opposite direction) instead of the 2/1. That seems to hint that it might<br/>have some harmonic interpretation (and it is somewhat tempting to try to use<br/>the tritave that could be made from the two ranges together).</p><p>(ADDENDUM: Correction to the OP - Kaneko published that paper in &apos;97, not<br/>&apos;99)</p></div><h3><a id=99383 href="#99383">ðŸ”—</a>Daniel Nielsen &#x3C;nielsed@...&#x3E;</h3><span>5/21/2011 1:41:58 AM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On Mon, Apr 25, 2011 at 12:02 AM, Daniel Nielsen &lt;nielsed@...&gt; wrote:</p><p>&gt; This is a set of tunings based on the Bayes formula.<br/>&gt;<br/>&gt; How it is generated:<br/>&gt; It assumes a binary Bayes process (i.e. two exhaustive, mutually exclusive<br/>&gt; possible outcomes) with an initial prior probability for &quot;success&quot; of 1/2.<br/>&gt; From there, a likelihood ratio is found that causes the value after N<br/>&gt; iterative evaluations to fall on the 2/1 octave. (N, therefore, is the<br/>&gt; number of pitches in the octave, since the value at each iteration<br/>&gt; represents a pitch.)<br/>&gt;<br/>&gt; Here are results for N=9, as an example:<br/>&gt;      0.0000<br/>&gt;   -108.8867<br/>&gt;   -224.1946<br/>&gt;   -345.8528<br/>&gt;   -473.7450<br/>&gt;   -607.7137<br/>&gt;   -747.5635<br/>&gt;   -893.0673<br/>&gt;  -1043.9709<br/>&gt;  -1200.0000<br/>&gt;<br/>&gt; Why are these negative? Well, I wasn&apos;t certain whether to add another<br/>&gt; octave or to invert the values to make a tuning. What&apos;s interesting is that,<br/>&gt; if we invert the likelihood ratio that defines this set, we get a 3/2 range<br/>&gt; in the opposite direction instead. Values are the following (again using the<br/>&gt; example of N=9):<br/>&gt;      0.0000<br/>&gt;    102.4416<br/>&gt;    198.4620<br/>&gt;    288.1322<br/>&gt;    371.5683<br/>&gt;    448.9280<br/>&gt;    520.4065<br/>&gt;    586.2311<br/>&gt;    646.6557<br/>&gt;    701.9550<br/>&gt; (blah blah blah...)<br/>&gt;</p><p>Don&apos;t know if anyone remembers these two sets of values based on a binary<br/>Bayesian process with reciprocal likelihoods. It occurred to me to try to<br/>make a scale in the 3tave by subtracting one set from the other. What does<br/>this give? It simply gives N-ED3. In this way Bayesian understandings might<br/>be considered a further decomposition of EDn form, producing the EDn state<br/>when a Bayesian balancing act occurs. In this case 3/1 is formed by a<br/>&quot;balancing act&quot; of 2/1 and 3/2-period scales.</p><p>Then it occurred to me why ED3 was produced: This is essentially just<br/>log-of-odds updating (<a href="http://www-biba.inrialpes.fr/Jaynes/cc04q.pdf">http://www-biba.inrialpes.fr/Jaynes/cc04q.pdf</a>). This<br/>explains why, within each set of values, the differences are not constant,<br/>but when taken together subtractively they are.</p></div><h3><a id=99388 href="#99388">ðŸ”—</a>lobawad &#x3C;lobawad@...&#x3E;</h3><span>5/21/2011 8:51:26 AM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Was this done in the logarithmic realm or the frequency realm? Whichever it was, what would be the other version?</p><p>At any rate, both scales seem to have an audible acoustic continuity to them- proportional beating or something, I don&apos;t know. Maybe it&apos;s just a matter of them being comprised of intervals which are very close to intervals I&apos;m accustomed to.</p><p>--- In <a href="mailto:tuning@yahoogroups.com">tuning@yahoogroups.com</a>, Daniel Nielsen &lt;nielsed@...&gt; wrote:<br/>&gt;<br/>&gt; On Mon, Apr 25, 2011 at 12:02 AM, Daniel Nielsen &lt;nielsed@...&gt; wrote:<br/>&gt;<br/>&gt; &gt; This is a set of tunings based on the Bayes formula.<br/>&gt; &gt;<br/>&gt; &gt; How it is generated:<br/>&gt; &gt; It assumes a binary Bayes process (i.e. two exhaustive, mutually exclusive<br/>&gt; &gt; possible outcomes) with an initial prior probability for &quot;success&quot; of 1/2.<br/>&gt; &gt; From there, a likelihood ratio is found that causes the value after N<br/>&gt; &gt; iterative evaluations to fall on the 2/1 octave. (N, therefore, is the<br/>&gt; &gt; number of pitches in the octave, since the value at each iteration<br/>&gt; &gt; represents a pitch.)<br/>&gt; &gt;<br/>&gt; &gt; Here are results for N=9, as an example:<br/>&gt; &gt;      0.0000<br/>&gt; &gt;   -108.8867<br/>&gt; &gt;   -224.1946<br/>&gt; &gt;   -345.8528<br/>&gt; &gt;   -473.7450<br/>&gt; &gt;   -607.7137<br/>&gt; &gt;   -747.5635<br/>&gt; &gt;   -893.0673<br/>&gt; &gt;  -1043.9709<br/>&gt; &gt;  -1200.0000<br/>&gt; &gt;<br/>&gt; &gt; Why are these negative? Well, I wasn&apos;t certain whether to add another<br/>&gt; &gt; octave or to invert the values to make a tuning. What&apos;s interesting is that,<br/>&gt; &gt; if we invert the likelihood ratio that defines this set, we get a 3/2 range<br/>&gt; &gt; in the opposite direction instead. Values are the following (again using the<br/>&gt; &gt; example of N=9):<br/>&gt; &gt;      0.0000<br/>&gt; &gt;    102.4416<br/>&gt; &gt;    198.4620<br/>&gt; &gt;    288.1322<br/>&gt; &gt;    371.5683<br/>&gt; &gt;    448.9280<br/>&gt; &gt;    520.4065<br/>&gt; &gt;    586.2311<br/>&gt; &gt;    646.6557<br/>&gt; &gt;    701.9550<br/>&gt; &gt; (blah blah blah...)<br/>&gt; &gt;<br/>&gt;<br/>&gt;<br/>&gt; Don&apos;t know if anyone remembers these two sets of values based on a binary<br/>&gt; Bayesian process with reciprocal likelihoods. It occurred to me to try to<br/>&gt; make a scale in the 3tave by subtracting one set from the other. What does<br/>&gt; this give? It simply gives N-ED3. In this way Bayesian understandings might<br/>&gt; be considered a further decomposition of EDn form, producing the EDn state<br/>&gt; when a Bayesian balancing act occurs. In this case 3/1 is formed by a<br/>&gt; &quot;balancing act&quot; of 2/1 and 3/2-period scales.<br/>&gt;<br/>&gt; Then it occurred to me why ED3 was produced: This is essentially just<br/>&gt; log-of-odds updating (<a href="http://www-biba.inrialpes.fr/Jaynes/cc04q.pdf">http://www-biba.inrialpes.fr/Jaynes/cc04q.pdf</a>). This<br/>&gt; explains why, within each set of values, the differences are not constant,<br/>&gt; but when taken together subtractively they are.<br/>&gt;</p></div><h3><a id=99394 href="#99394">ðŸ”—</a>Daniel Nielsen &#x3C;nielsed@...&#x3E;</h3><span>5/21/2011 9:54:44 AM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On Sat, May 21, 2011 at 10:51 AM, lobawad &lt;lobawad@...&gt; wrote:</p><p>&gt;<br/>&gt;<br/>&gt; Was this done in the logarithmic realm or the frequency realm? Whichever it<br/>&gt; was, what would be the other version?<br/>&gt;<br/>&gt; At any rate, both scales seem to have an audible acoustic continuity to<br/>&gt; them- proportional beating or something, I don&apos;t know. Maybe it&apos;s just a<br/>&gt; matter of them being comprised of intervals which are very close to<br/>&gt; intervals I&apos;m accustomed to.<br/>&gt;</p><p>If you are talking about the cents listed, then it was done in<br/>log-probability (since cents are logarithmic values). Apparently I didn&apos;t<br/>explicitly state that $12.00 was added to the results to make each start at<br/>0 cents (although you can see that in the BASIC program in the OP), so<br/>hopefully that clears things up if you were wondering how a probability of<br/>2/1 might exist - it doesn&apos;t, it&apos;s really 1/1. I think at the time of the<br/>OP, I was trying to keep my explanation as simple and stripped-down as<br/>possible.</p><p>Also, while it seems true that<br/>&quot;...why ED3 was produced: This is essentially just log-of-odds updating (<br/><a href="http://www-biba.inrialpes.fr/Jaynes/cc04q.pdf">http://www-biba.inrialpes.fr/Jaynes/cc04q.pdf</a>). This explains why, within<br/>each set of values, the differences are not constant, but when taken<br/>together subtractively they are.&quot;<br/>I haven&apos;t managed yet to prove it this morning.</p></div><h3><a id=99395 href="#99395">ðŸ”—</a>Daniel Nielsen &#x3C;nielsed@...&#x3E;</h3><span>5/21/2011 9:59:26 AM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Cameron:<br/>&quot;At any rate, both scales seem to have an audible acoustic continuity to<br/>them- proportional beating or something, I don&apos;t know. Maybe it&apos;s just a<br/>matter of them being comprised of intervals which are very close to<br/>intervals I&apos;m accustomed to.&quot;</p><p>Yeah, I&apos;m not completely sure either. I tend to think that they sound<br/>exceptionally good due to distinctive qualities, but that could be bias<br/>talking.</p></div><h3><a id=99397 href="#99397">ðŸ”—</a>genewardsmith &#x3C;genewardsmith@...&#x3E;</h3><span>5/21/2011 10:24:15 AM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning@yahoogroups.com">tuning@yahoogroups.com</a>, Daniel Nielsen &lt;nielsed@...&gt; wrote:<br/>&gt; I think at the time of the<br/>&gt; OP, I was trying to keep my explanation as simple and stripped-down as<br/>&gt; possible.</p><p>I think instead you should give very explicit formulas and post to tuning-math.</p></div><h3><a id=99450 href="#99450">ðŸ”—</a>lobawad &#x3C;lobawad@...&#x3E;</h3><span>5/21/2011 11:49:12 PM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Whatever the reason, the scales and resulting vertical sonorities, including more clustered intervals, sound good to me, too.</p><p>--- In <a href="mailto:tuning@yahoogroups.com">tuning@yahoogroups.com</a>, Daniel Nielsen &lt;nielsed@...&gt; wrote:<br/>&gt;<br/>&gt; Cameron:<br/>&gt; &quot;At any rate, both scales seem to have an audible acoustic continuity to<br/>&gt; them- proportional beating or something, I don&apos;t know. Maybe it&apos;s just a<br/>&gt; matter of them being comprised of intervals which are very close to<br/>&gt; intervals I&apos;m accustomed to.&quot;<br/>&gt;<br/>&gt; Yeah, I&apos;m not completely sure either. I tend to think that they sound<br/>&gt; exceptionally good due to distinctive qualities, but that could be bias<br/>&gt; talking.<br/>&gt;</p></div><h3><a id=99478 href="#99478">ðŸ”—</a>Daniel Nielsen &#x3C;nielsed@...&#x3E;</h3><span>5/22/2011 1:11:50 PM</span><button style="float: right; margin-right: 20px">toggle monospace</button><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Hi, are you subscribed to tuning-math? That&apos;s where I&apos;m doing the follow-up<br/>on this. Feel free to post here, though, and I&apos;ll definitely reply. Another<br/>interesting thing to try might be to perform a dynamic Bayesian process that<br/>doesn&apos;t necessarily always fall on pitches of a predefined scale. I don&apos;t<br/>know what hypotheses and collection of data would drive this process,<br/>though.</p><p>Dan N</p></div>
                <script>
                    let monospace = false
                    $('button').on('click', function () {
                      if (monospace) {
                        $('p').css("font-family", "")
                      } else {
                        $('p').css("font-family", "monospace")
                      }
                      monospace = !monospace
                    })
                </script>
            