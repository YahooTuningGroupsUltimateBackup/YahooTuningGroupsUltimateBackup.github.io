<a href="/tuning">back to list</a><h1>Harmonic Entropy</h1><h3><a id=2000 href="#2000">ðŸ”—</a>Graham Breed &#x3C;g.breed@xxx.xx.xxx&#x3E;</h3><span>3/23/1999 5:39:40 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>I discussed this privately with Paul Erlich a while back.  I was happy with<br/>the derivation, except for it&apos;s singling out of the denominator rule.  It<br/>seemed to me that the following rules all followed:</p><p>Hold the upper note constant, and entropy is proportional to the<br/>denominator.</p><p>Hold the lower note constant, and entropy is proportional to the numerator.</p><p>Hold the arithmetic mean of the frequencies of the two notes constant, and<br/>entropy is proportional to the arithmetic mean of the numerator and<br/>denominator.  This is a sum rule.</p><p>Hold the geometric mean of the frequencies of the two notes constant, and<br/>entropy is proportional to the geometric mean of the numerator and<br/>denominator.  This is a product or LCM rule.</p><p>So, Paul, are you happy with this or do we have to start that row again?</p><p>Dave Keenan&apos;s conclusion:</p><p>&gt;What we are suggesting here is that the dissonance is related to the period<br/>&gt;(inverse of frequency) of the virtual fundamental (VF). When the ratio for<br/>&gt;an interval is in lowest terms, the VF corresponds to a 1.</p><p>is in the right area but wrong.  Harmonic entropy, which may or may not be<br/>related to dissonance, is in fact related to the frequency an LCM above the<br/>VF.  I believe this is known as the &quot;guide tone&quot; in the literature.  So, the<br/>lower the guide tone, the lower the entropy.</p><p>Dave Keenan&apos;s assertion:</p><p>&gt;If we want to talk about the realtive dissonance of intervals (or chords<br/>&gt;for that metter) without considering frequency, then the only sensible<br/>&gt;thing to do is to compare them all with the same average frequency, hence<br/>&gt;n+d or (n+d)/2 is the right approximation for dyads, not d.</p><p>seems to apply also to the geometric mean.  But maybe we&apos;re splitting hairs.<br/>I&apos;ll consider all these rules to be equally good for the time being.  They<br/>are all qualitatively the same for most intervals within an octave.<br/>However, for large intervals they are divergent.  15/1 is the same as 5/3<br/>with a product rule.  With a denominator rule, 15/1 is better.  With a sum<br/>rule, 5/3 is better.  With a numerator rule, 5/3 is much better.  So, the<br/>four rules can be ranked in order of how much they prefer large intervals:</p><p>big is better -&gt;<br/>numerator  sum  product  denominator</p><p>As large intervals do appear to be less consonant, the denominator rule<br/>looks like the most &quot;musical&quot; of the four.  I am not convinced that the<br/>harmonic entropy derivation proves it to be so.</p><p>I don&apos;t know how to generalise the harmonic entropy beyond dyads.  However,<br/>my intuition strongly suggests that it will still lead to the guide tone.</p></div><h3><a id=2039 href="#2039">ðŸ”—</a>Paul H. Erlich &#x3C;PErlich@xxxxxxxxxxxxx.xxxx&#x3E;</h3><span>3/24/1999 12:50:30 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Graham Breed wrote,</p><p>&gt;Hold the upper note constant, and entropy is proportional to the<br/>&gt;denominator.</p><p>&gt;Hold the lower note constant, and entropy is proportional to the<br/>numerator.</p><p>&gt;Hold the arithmetic mean of the frequencies of the two notes constant,<br/>and<br/>&gt;entropy is proportional to the arithmetic mean of the numerator and<br/>&gt;denominator.  This is a sum rule.</p><p>&gt;Hold the geometric mean of the frequencies of the two notes constant,<br/>and<br/>&gt;entropy is proportional to the geometric mean of the numerator and<br/>&gt;denominator.  This is a product or LCM rule.</p><p>&gt;So, Paul, are you happy with this or do we have to start that row<br/>again?</p><p>First of all, entropy is not the right word to use in the above<br/>statements. &quot;Width&quot; or even &quot;field of attraction&quot; would be better, but<br/>then the proportionalities hold inversely. It is an input into the<br/>entropy formula, not the output.</p><p>Secondly, I&apos;ve only proved and numerically verified that the first of<br/>the four statements above (suitable reworded) is a good approximation. I<br/>just tried the third one numerically and the results look very poor --<br/>the width for some of the most complex ratios can be up to half the<br/>width for 1/1! That may explain some of the weird minima I found using<br/>the Mann (num+den&lt;N) series. You tried modifying my derivation to prove<br/>the last one but I thought your manipulations were not valid, since they<br/>assumed a contradiction. What I just found for the last case is that in<br/>fact the width is, to an even better approximation that the one for the<br/>first (Farey) case, inversely proportional to the _square root_ of the<br/>product of the numerator and denominator. This is interesting!</p><p>&gt;&gt;What we are suggesting here is that the dissonance is related to the<br/>period<br/>&gt;&gt;(inverse of frequency) of the virtual fundamental (VF). When the ratio<br/>for<br/>&gt;&gt;an interval is in lowest terms, the VF corresponds to a 1.</p><p>&gt;is in the right area but wrong.  Harmonic entropy, which may or may not<br/>be<br/>&gt;related to dissonance, is in fact related to the frequency an LCM above<br/>the<br/>&gt;VF.  I believe this is known as the &quot;guide tone&quot; in the literature.<br/>So, the<br/>&gt;lower the guide tone, the lower the entropy.</p><p>I tend to side with Keenan here and don&apos;t really know where you&apos;re<br/>coming from.</p><p>&gt;I don&apos;t know how to generalise the harmonic entropy beyond dyads.<br/>However,<br/>&gt;my intuition strongly suggests that it will still lead to the guide<br/>tone.</p><p>The guide tone is lower and simpler for utonal chords than otonal<br/>chords. However, harmonic entropy will definitely be lower for otonal<br/>chords.</p></div><h3><a id=2048 href="#2048">ðŸ”—</a>Paul H. Erlich &#x3C;PErlich@xxxxxxxxxxxxx.xxxx&#x3E;</h3><span>3/24/1999 2:18:17 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Of course, the square root of the product _is_ the geometric mean. So<br/>Graham&apos;s fourth rule is correct, except entropy needs to be replaced<br/>with width and the proportionality is inverse. Now the geometric mean is<br/>of course the center of the interval, as normally measured (e.g., in<br/>cents). So this is probably the most sensible way of comparing<br/>intervals. I don&apos;t see how LCM figures into it. If we can somehow<br/>believe that for triads, the &quot;area&quot; is inversely proportional to the<br/>geometric mean of the three integers most simply expressing the chord<br/>(e.g., 4:5:6 or 10:12:15), then we have a way to compute harmonic<br/>entropy for triads. But if you look at a 2-d plot (such as a Dalitz<br/>plot) of all the triads, you&apos;ll see that this &quot;area&quot; may have a very<br/>strange shape and might not be possible to define with some<br/>generalization of mediants. Then again, it might . . .</p><p>The conceptual advantage of the Farey series (which leads to a<br/>denominator rule) is that is seems reasonable to believe that the brain<br/>has a &quot;template&quot; of sorts of the harmonic series up to a certain limit.<br/>Then all intervals within that template are possible interpretations,<br/>and others aren&apos;t. If this is the way it works, it doesn&apos;t matter if you<br/>are holding the lower note, upper note, arithmetic mean, or geometric<br/>mean constant. With the other series, there isn&apos;t a corresponding<br/>&quot;template&quot; that the brain could be referencing. I admit that this isn&apos;t<br/>a major conceptual advantage, though.</p></div><h3><a id=2051 href="#2051">ðŸ”—</a>Daniel Wolf &#x3C;DJWOLF_MATERIAL@xxxxxxxxxx.xxxx&#x3E;</h3><span>3/24/1999 2:22:33 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Message text written by Paul Erlich<br/>&gt; mediants&lt;</p><p>Isn&apos;t the word &quot;median&quot;? Mediant is a musical term for a tonal function.</p><p>Daniel Wolf</p></div><h3><a id=2053 href="#2053">ðŸ”—</a>Paul H. Erlich &#x3C;PErlich@xxxxxxxxxxxxx.xxxx&#x3E;</h3><span>3/24/1999 3:19:11 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>I wrote,</p><p>&gt;I just tried the third one numerically and the results look very poor<br/>-- the width for some of the most &gt;complex ratios can be up to half the<br/>width for 1/1! That may explain some of the weird minima I found &gt;using<br/>the Mann (num+den&lt;N) series.</p><p>Well, I don&apos;t know about that last statement, but here&apos;s an example of<br/>the first one:</p><p>For N=80, the nearest fractions to 1/1 are 39/40 and 40/39. The mediants<br/>are therefore 40/41 and 41/40, for a width of 1681/1600 = 85.5 cents.<br/>Now the nearest fractions to 39/1 are 40/1 and 77/2. The mediants are<br/>79/2 and 116/3, for a width of 36.9 cents. This doesn&apos;t compare well<br/>with the 20-fold decrease in width Graham&apos;s third rule would predict!</p><p>Using just the denominator (i.e., smaller integer) works much better for<br/>widths in the Mann series than using the sum. But the approximation of<br/>using just the denominator is rougher in the Mann series than in the<br/>Farey series.</p></div><h3><a id=2083 href="#2083">ðŸ”—</a>Paul H. Erlich &#x3C;PErlich@Acadian-Asset.com&#x3E;</h3><span>3/25/1999 2:05:44 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>I wrote,</p><p>&gt;&gt; mediants&lt;</p><p>Daniel Wolf wrote,</p><p>&gt;Isn&apos;t the word &quot;median&quot;? Mediant is a musical term for a tonal<br/>function.</p><p>The word is mediant; it is a mathematical term as well as a musical<br/>term. The median is a type of average which takes the central entry in a<br/>rank-ordered list.</p></div>