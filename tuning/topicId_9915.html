<a href="/tuning">back to list</a><h1>Re: http://www.intelliscore.net/</h1><h3>Carl Lumma &#x3C;CLUMMA@NNI.COM&#x3E;</h3><span>5/7/2000 7:24:01 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>&gt;Interesting; have you tried out their demo?</p><p>Yes, I have (since my last message).  I wasn&apos;t surprised, and I&apos;m sure<br/>you&apos;re not, to learn that it doesn&apos;t really work yet.  I think I could get<br/>better results by spending more time with it, but I also think (admittedly,<br/>without spending that time) that I have an idea of the limits of such<br/>improvement.  For certain types of music, with a certain amount of touch-up<br/>afterwards, you could get workable results.  But for music like mine it&apos;s<br/>just a no-go at this point.  Ditto for any music of fast tempo, and/or<br/>intricate rhythms.  And even in ideal circumstances, I _don&apos;t_ buy the 35%<br/>saved-time figure.  Touch-up can be very time-consuming.  Just like with<br/>OCR (how&apos;s your OCR project coming, BTW?).</p><p>OTOH, I was just thinking the other day (yesterday, I think!) how far off<br/>something even this good was.  I am shocked and a-ghast.  Now, I&apos;d stop<br/>before I ruling out the possibility that transcribing by ear could be<br/>obsolete in 3-4 years.</p><p>-Carl</p></div><h3>Carl Lumma &#x3C;CLUMMA@NNI.COM&#x3E;</h3><span>5/8/2000 7:19:59 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>&gt;1. When the software guesses wrong, a single mistake often has wide-ranging<br/>&gt;consequences. This suggests that you want to help it along, so that when<br/>&gt;it gets to a place where it isn&apos;t sure, you can prevent it from making the<br/>&gt;mistake.</p><p>With intelliscore, you have to tap the tempo, and declare the time<br/>signature before the recognition starts.</p><p>&gt;2. There are lots of places where the sound is simply ambiguous. You<br/>&gt;likewise want to be able to make decisions about this as part of the first<br/>&gt;pass.</p><p>Well, the recognition works in very nearly realtime on my single P2-400, so<br/>you wouldn&apos;t have time on the first pass as it stands.</p><p>&gt;One would be to synthesize a score with the extracted pitches, and create a<br/>&gt;second spectrogram, which you could compare by eye with the first.</p><p>The software, as it stands, creates a midi file, so it would simply amount<br/>to feeding back the output from that into a second spectrogram.  Trouble is,<br/>synthesized timbres probably look a lot different from real timbres on a<br/>spectrogram at this point.  In fact, at this point, the software cannot tell<br/>the difference between instruments -- its MIDI output is all on a single<br/>track.</p><p>&gt;3. There&apos;s a lot of variation in the performance of rhythm (and in what<br/>&gt;actually comes out of an instrument) that you want the software to ignore;<br/>&gt;listening, you can often know what&apos;s *meant* better than the software<br/>&gt;(though it may be absolutely right about what actually happened).</p><p>As it stands, the software is completely ignorant about rhythm.  It seems<br/>there are two general ways to proceed...</p><p>&gt;6. In order to correct the transcription, you need to compare the<br/>&gt;transcription to the sound; the software ought to provide tools for doing<br/>&gt;this.<br/>&gt;<br/>&gt;What I&apos;m imagining is something where the sound presented as a spectrogram,<br/>&gt;processed to highlight possible note onsets, etc. Overlaid would be a grid<br/>&gt;showing where pitches (in whatever tuning) would be. The software would<br/>&gt;guess at barlines, and you&apos;d correct them. Likewise for beats within<br/>&gt;bars. Likewise for notes. Once the notes were in place, there&apos;d be<br/>&gt;various tools for comparing the transcription to the original audio.</p><p>This would be a great tool.  As far as I&apos;m concerned, it wouldn&apos;t even have<br/>to guess the rhythms.  I can do that about as quickly as I can correct them.<br/>The main thing would be the spectrogram display with note overlay, and an<br/>good score entry window below that.  In this setup, the computer simply<br/>handles the absolute and relative pitch skills, which are generally<br/>difficult for humans.</p><p>The second way to proceed would be to try and have the computer do<br/>everything, with no touch-up afterwards.  It was this possibility that I<br/>said may be 3 years off.  I can imagine an algorithm, whereby several meter<br/>choices are generated concurently, and then fit to the sound source with a<br/>tempo map (ala MOTU&apos;s FreeStyle).  The tempo maps are then compared, and the<br/>meter choice corresponding to the simplest tempo map wins.</p><p>~~</p><p>I would also be happy to see these kinds of tools, and I&apos;m sure we won&apos;t<br/>have too long to wait.  OTOH, I am bound to ask which is more of an advance:<br/>Proliferation of software that can transcribe music as well as humans, or<br/>proliferation of what history and science have shown to be a very _human_<br/>skill throughout our society?  (I said above that absolute and relative<br/>pitch were &quot;difficult&quot; for humans -- what did I mean by that?)</p><p>Sorry -- you aren&apos;t working on OCR to my knowledge.  Rather, it was speech<br/>recognition (which is probably even more analogous to the current topic than<br/>OCR).</p><p>-Carl</p></div><h3>Allan Myhara &#x3C;amyhara@mb.sympatico.ca&#x3E;</h3><span>5/8/2000 12:55:23 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>&gt; &gt;Interesting; have you tried out their demo?<br/>&gt;<br/>&gt; Yes, I have (since my last message).  I wasn&apos;t surprised, and I&apos;m sure<br/>&gt; you&apos;re not, to learn that it doesn&apos;t really work yet.  I think I could get<br/>&gt; better results by spending more time with it, but I also think (admittedly,<br/>&gt; without spending that time) that I have an idea of the limits of such<br/>&gt; improvement.  For certain types of music, with a certain amount of touch-up<br/>&gt; afterwards, you could get workable results.  But for music like mine it&apos;s<br/>&gt; just a no-go at this point.  Ditto for any music of fast tempo, and/or<br/>&gt; intricate rhythms.  And even in ideal circumstances, I _don&apos;t_ buy the 35%<br/>&gt; saved-time figure.  Touch-up can be very time-consuming.  Just like with<br/>&gt; OCR (how&apos;s your OCR project coming, BTW?).<br/>&gt;<br/>&gt; OTOH, I was just thinking the other day (yesterday, I think!) how far off<br/>&gt; something even this good was.  I am shocked and a-ghast.  Now, I&apos;d stop<br/>&gt; before I ruling out the possibility that transcribing by ear could be<br/>&gt; obsolete in 3-4 years.<br/>&gt;<br/>&gt; -Carl</p><p>Try <a href="http://www.chat.ru/~andreenk/">http://www.chat.ru/~andreenk/</a><br/>I have an earlier version of their program (its called Widi, short for<br/>Wave-to-Midi) that worked fairly well for transcribing bird calls and<br/>the like, with a minimum of parameter twiddling. For complex music<br/>though, you can only hear echoes of the original.<br/>--<br/>Bye for now</p><p>Allan Myhara<br/>Winnipeg, Manitoba, Canada</p></div>