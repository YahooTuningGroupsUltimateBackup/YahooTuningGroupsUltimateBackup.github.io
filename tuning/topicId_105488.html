<a href="/tuning">back to list</a><h1>The difference between difference-tones and beats</h1><h3>dkeenanuqnetau &#x3C;d.keenan@...&#x3E;</h3><span>12/3/2012 7:37:45 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>The Wikipedia article on Combination Tones<br/><a href="http://en.wikipedia.org/wiki/Combination_tone">http://en.wikipedia.org/wiki/Combination_tone</a><br/>contains an unsubstantiated claim for the existence of &quot;binaural difference tones&quot; (4th pragraph). I suspect they are confusing them with &quot;binaural beats&quot;. They also seem to be confusing the Bohlen-Pierce scale with Heinz Bohlen&apos;s phi scale.</p><p>Here&apos;s what you have to understand. We have two closely related but different phenomena. Difference tones and Beats. You might be thinking &quot;I know the difference. A beat is a difference tone that&apos;s slow enough to be heard as a pulsation&quot;. Wrong! Completely and utterly wrong.</p><p>Difference tones are real tones. They can be measured with a spectrum analyser. They are subtle, but really there.<br/>Beats are a product of human perception. Perceived as a variation in the volume of a single frequency when really there are two nearby frequencies at constant volume. Beats are obvious, but they are ghosts.</p><p>Yes beats must be slower than about 20 Hz to be audible,<br/>and difference tones must be faster than about 20 Hz to be audible,<br/>but a fast beat is not a difference tone, and a slow difference tone is not a beat.</p><p>As you speed up a beat, at first it becomes &quot;roughness&quot;, and then it becomes inaudible. These are called &quot;critical-band effects&quot;.<br/>As you slow down a difference tone it becomes inaudible below about 20 Hz. However it is difficult to produce an infrasonic difference tone without also producing a beat. But if you filter out the two parent tones, leaving just the difference tone, then there will be no beat. Nothing at all will be heard, but a spectrum analyser will still measure the infrasonic difference tone.</p><p>You will find that these two different phenomena are often confused in the non-scientific literature and online.</p><p>You automatically hear beats if you have two frequencies close enough together.</p><p>But you don&apos;t automatically get difference tones. Difference tones are only generated by a particular kind of distortion called &quot;non-linearity&quot; or &quot;intermodulation distortion&quot;. These are two complementary names for the same thing, one viewing it as a function of time, the other as a function of frequency. Non-linearity is required if you want to turn a beat into a real tone -- a difference tone. Non-linearity gives the ghost solid flesh.</p><p>Certain combination-tone chords with four frequencies A:B:C:D as described here <a href="http://launch.groups.yahoo.com/group/tuning/message/105487">http://launch.groups.yahoo.com/group/tuning/message/105487</a> depend on a difference between two differences, e.g. (D-C) - (B-A). Without non-linearity this would be just the difference between two inaudibly-fast beats. But there&apos;s no such thing as a beat between beats -- a ghost of a ghost.</p><p>With non-linearity, D-C and B-A become real frequencies, real sounds, and therefore able to be perceived as beating -- as a pulsation in volume of a single frequency midway between the two real frequencies.</p><p>Engineers usually go to great pains to make our sound systems as linear as possible, so that they will _not_ create new frequencies that did not exist in the original. Electric guitar amplifiers are an exception.</p><p>But if you read the first page here <a href="http://books.google.com.au/books?id=eGcfn9ddRhcC&pg=PA277#v=onepage&q&f=false">http://books.google.com.au/books?id=eGcfn9ddRhcC&pg=PA277#v=onepage&q&f=false</a> you will learn that I have been over-simplifying for educational purposes, as we teachers often do.</p><p>Difference tones, it turns out, can _also_ be a product of human perception. So it&apos;s easy to understand why there is confusion of these things in the non-scientific literature. However they remain distinct from beats. Such difference tones are produced by non-linearity in the mechanical components of the middle and inner ear, while beats are produced by higher-level neural processing in the brain.</p><p>However, if you rely entirely on your listeners&apos; ears for the required non-linearity, the difference tones will be quite subtle and may require directed attention, and hence any _beating_ of the difference tones may be more subtle again.</p></div><h3>Mike Battaglia &#x3C;battaglia01@...&#x3E;</h3><span>12/3/2012 8:20:34 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>On Mon, Dec 3, 2012 at 10:37 AM, dkeenanuqnetau &lt;d.keenan@...&gt;<br/>wrote:<br/>&gt;<br/>&gt; Here&apos;s what you have to understand. We have two closely related but<br/>&gt; different phenomena. Difference tones and Beats. You might be thinking &quot;I<br/>&gt; know the difference. A beat is a difference tone that&apos;s slow enough to be<br/>&gt; heard as a pulsation&quot;. Wrong! Completely and utterly wrong.</p><p>Thumbs up to that. This is one of the most common misconceptions out there.</p><p>&gt; Difference tones are real tones. They can be measured with a spectrum<br/>&gt; analyser. They are subtle, but really there.</p><p>This is also true, unless they&apos;re happening in your ears. Then they&apos;d<br/>require us to put a microphone in your ear and record them, but yes,<br/>theoretically possible.</p><p>&gt; Beats are a product of human perception. Perceived as a variation in the<br/>&gt; volume of a single frequency when really there are two nearby frequencies at<br/>&gt; constant volume. Beats are obvious, but they are ghosts.</p><p>I have a nit to pick about this, however. Beats are very real, and are<br/>just as &quot;real&quot; as the concept of &quot;sounds that change in time.&quot;</p><p>For instance, if I were to place a tape recorder in your ears and<br/>record everything that you&apos;ve ever heard across your entire life, I<br/>could take the Fourier transform of the entire tape as one huge<br/>signal, putting it into the frequency domain. When it&apos;s in the<br/>frequency domain, the frequency response of the signal will have no<br/>time resolution at all. It&apos;ll give you no information about &quot;when&quot;<br/>some frequency appears at some point in your life. It&apos;ll just split<br/>the signal up into an infinite summation* of sine waves stretching<br/>from time=the day you&apos;re born to time=the day you die that<br/>automagically add back together to reconstruct the original signal,<br/>with the sines interfering with one another in precisely the right way<br/>to recreate what you&apos;d perceive as time information in the signal.</p><p>It&apos;s a very &quot;dumb&quot; transform in this respect, not much different than<br/>splitting a number up into a prime factorization that automagically<br/>multiplies together to yield the original number. This is, as you<br/>might imagine, not much more useful than just looking at the original<br/>signal in the time domain. This is because we don&apos;t just hear<br/>&quot;frequencies,&quot; we hear frequencies that change in time. So the<br/>frequency response of a signal isn&apos;t any more &quot;real&quot; than the time<br/>domain waveform itself is.</p><p>So as you know, what we really want is a time-frequency signal<br/>representation like a spectrogram. And the key is that there&apos;s no one<br/>way to do this. You can have a representation which gives you more<br/>time information at the cost of having less frequency information, or<br/>vice versa, and none of these representations are ultimately any more<br/>&quot;real&quot; than any others.</p><p>So when your ears hear two sine waves close to one another as just<br/>being one sine wave that&apos;s changing in amplitude, this reflects a<br/>certain time-frequency tradeoff being made; in this case, the ear has<br/>sacrificed some frequency resolution for the sake of getting some time<br/>resolution. If you were to drastically increase the frequency<br/>resolution of the ear so that we could perceive 440 and 441 Hz as two<br/>separate pitches ringing out in simultaneity, this would have to come<br/>at the cost of some time resolution in that area. If our ears were set<br/>up like that, we&apos;d probably have 3x as many vowels as we have now, but<br/>we&apos;d all talk a lot more slowly. Maybe 17/16 would be a very<br/>pleasantly harmonic dyad, but triplets would sound chaotic and<br/>disorienting or something.</p><p>So any time you have a single frequency &quot;changing in time,&quot; whether<br/>it&apos;s a sinusoid modulating in amplitude or covered by some envelope,<br/>you can rightly say that the change in time is a &quot;ghost&quot; relative to<br/>what the signal would look like in the frequency domain. However, the<br/>frequency domain itself isn&apos;t any more &quot;real&quot; than the time domain;<br/>mixed time-frequency domains correspond more directly to what we<br/>perceive and there&apos;s an infinite number of ways to make the tradeoff.<br/>But there&apos;s no difference at all between you playing 439 Hz, 440 Hz,<br/>and 441 Hz out of your speaker, vs playing 440 Hz out of your speaker<br/>and paying some guy to sinusoidally modulate your volume knob at 1<br/>cycle per second; the only difference is how you want to think about<br/>it.</p><p>TL;DR, whether or not the beats you see are real will depend on the<br/>resolution of the spectrogram.</p><p>Other than that point, though, I agree with the rest of the post.</p><p>-Mike</p><p>PS, some caveats for technical accuracy<br/>- The above is very oversimplified and doesn&apos;t handle how the signal<br/>undergoes a wave of severe nonlinear processing after leaving the<br/>cochlea (and particularly during transduction into the auditory nerve,<br/>where it turns into a series of impulses)<br/>- Unlike the spectrogram, the time-frequency resolution of the ear is<br/>not the same across the entire spectrum. As a general rule, the higher<br/>end of the spectrum has better time resolution and the lower end has<br/>better (linear, not logarithmic) frequency resolution (though that<br/>rule may not hold in the lowest registers, not sure)<br/>- There are much more intelligent time-frequency representations of<br/>the signal than your ordinary spectrogram; wavelet analysis is big<br/>business these days and then there&apos;s things like the SPEAR algorithm<br/>which Carl&apos;s posted on here before. We can safely assume that the<br/>brain is using some such &quot;intelligent&quot; (and adaptive way) to make the<br/>tradeoff.<br/>- Despite the above, the time-frequency tradeoff still has to exist in<br/>some form at the end of the day, and as a very general rule of thumb,<br/>it&apos;s true that the phenomenon of beating is really just indicative of<br/>the presence of time resolution in the signal, in general, sacrificing<br/>some frequency resolution.</p></div><h3>dkeenanuqnetau &#x3C;d.keenan@...&#x3E;</h3><span>12/3/2012 4:41:21 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Thanks Mike,</p><p>I agree with everything you say, but I&apos;m sure you agree that to go into that sort of detail tends to lose the mnemonic value of:</p><p>&quot;Beats are obvious ghosts.<br/> Difference tones are subtle flesh.<br/> Distortion enfleshes the ghost.&quot;</p><p>I guess the point is that the spectrum analyser will always measure the difference tone we hear (with your proviso of a microphone in the ear when the ear is the only cause of non-linearity), but it will only measure the beat we hear if its time-frequency-tradeoff filter is set to be something like the one we have evolved to have, which in terms of pure physics is completely arbitrary. One can imagine that Carl Sagan&apos;s enormous slow-moving gas-bag animals in the atmosphere of Jupiter might not hear a beat until the two frequencies get within 0.001 Hz of each other.</p></div><h3>gedankenwelt94 &#x3C;gedankenwelt94@...&#x3E;</h3><span>12/4/2012 6:35:17 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Hi,</p><p>--- In <a href="mailto:tuning@yahoogroups.com">tuning@yahoogroups.com</a>, &quot;dkeenanuqnetau&quot; &lt;d.keenan@...&gt; wrote:<br/>&gt; I guess the point is that the spectrum analyser will always measure the difference tone we hear (with your proviso of a microphone in the ear when the ear is the only cause of non-linearity), but it will only measure the beat we hear if its time-frequency-tradeoff filter is set to be something like the one we have evolved to have, which in terms of pure physics is completely arbitrary. One can imagine that Carl Sagan&apos;s enormous slow-moving gas-bag animals in the atmosphere of Jupiter might not hear a beat until the two frequencies get within 0.001 Hz of each other.</p><p>It is true that beats *can* be ghosts; if both ears hear a tone with a slightly different pitch, we hear binaural beats, even if they don&apos;t exist on an acoustical level.</p><p>It is also true that - from an acoustic perspective - it is arbitrary to say that beats occur if the two frequencies are close enough together that a human would perceive them as beats.</p><p>However, it is a mathematical fact that the superposition of two sine waves with identical amplitude and different frequencies f and g can be expressed as a single sine wave with pitch frequency (f+g)/2 (= the arithmetic mean of both frequencies), and beat frequency (f-g)/2, so beats are an acoustical fact as long as we don&apos;t premise arbitrary ranges for the difference between f and g.</p><p>A fourier transform is designed to represent sounds as superpositions of sine waves, so if you don&apos;t recognize beats (or just with arbitrary parameters) when using a spectrum analyzer, this doesn&apos;t mean they&apos;re not real, it just means you&apos;re using a method that is not very efficient to detect them.</p><p>If you want to convince yourself that beats are real, just look at the wave form of two superposed sine waves. This works especially well if there&apos;s no simple ratio between f and g.</p><p>-Gedankenwelt</p><p>P.S.: A similar case where the choice of representation matters is FM synthesis, where a tone with a frequency spectrum is identical to a sine wave with a vibrato. Here again, it depends on the parameters how a human would perceive that sound, but independent from the parameters both representations are acoustical facts.</p></div><h3>dkeenanuqnetau &#x3C;d.keenan@...&#x3E;</h3><span>12/4/2012 4:34:26 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Hi Gedankenwelt,</p><p>What you say is true. But it seems we need different terms for the acoustic phenomenon (which can be visualised as a waveform or spectrum display) and the human perception. We do have such terms: &quot;amplitude modulation&quot; vs &quot;beats&quot;. But I am aware that the term &quot;beats&quot; is already hopelessly used for amplitude modulation in general, even at radio frequencies that no human can sense.</p><p>So yes, I&apos;m well aware that the sum of two sine waves is completely equivalent to the sine wave modulation of the amplitude of a single sine wave mid way in frequency between the two.</p><p>My purpose is to help people understand the difference between this phenomenon and the phenomenon of difference tones, which require some nonlinear function to be applied to the sum of sines.</p><p>So what does this look like on a waveform display? It is visually indistinguishable unless the nonlinearity is extreme. But on a spectrum display a difference tone will appear as a separate spike while a beat will either not appear at all (only the original two spikes for the two frequencies), or it will appear as a single spike whose height wobbles up and down. This depends on the bandwidth of its filter, as it does with humans.</p><p>-- Dave</p></div><h3>gedankenwelt94 &#x3C;gedankenwelt94@...&#x3E;</h3><span>12/4/2012 5:50:46 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning@yahoogroups.com">tuning@yahoogroups.com</a>, &quot;dkeenanuqnetau&quot; &lt;d.keenan@...&gt; wrote:<br/>&gt; But it seems we need different terms for the acoustic phenomenon (which can be visualised as a waveform or spectrum display) and the human perception. We do have such terms: &quot;amplitude modulation&quot; vs &quot;beats&quot;. But I am aware that the term &quot;beats&quot; is already hopelessly used for amplitude modulation in general, even at radio frequencies that no human can sense.</p><p>Yeah, I think it makes sense to use different terms here, thanks for pointing that out! It seems I talked about something different when I said &quot;beats&quot;, but now I understand your point of view much better. ;)</p></div>