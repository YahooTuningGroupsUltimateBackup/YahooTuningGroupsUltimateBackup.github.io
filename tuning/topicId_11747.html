<a href="/tuning">back to list</a><h1>RE: [tuning] Re: Concordance Ex Nihilo [tuning experiment]</h1><h3>Paul H. Erlich &#x3C;PERLICH@ACADIAN-ASSET.COM&#x3E;</h3><span>8/23/2000 2:25:12 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Jacky wrote,</p><p>&gt;I too must admit that I&apos;ve been thinking the whole time we were<br/>&gt;speaking of the variety of &quot;Entropy&quot; used in Communication Theory:</p><p>&gt;&quot;A measure of the efficiency of a system (as a code or a language) in<br/>&gt;transmitting information, being equal to the logarithm of the number<br/>&gt;of different messages that can be sent by selection from the same set<br/>&gt;of symbols and thus indicating the degree of inital uncertainty that<br/>&gt;can be resolved by any one message.&quot;</p><p>&gt;Are we in fact talking about the physics variety of entropy?</p><p>No, Jacky, I&apos;m in fact referring to the Information Theory definition of<br/>entropy, which minus the sum over a bunch of possibilities of p*log(p),<br/>where p is the probability of the corresponding possibility. In the case of<br/>Harmonic Entropy, the possibilities are the ratios in the Farey series or<br/>whatever series is being used as the total set of ratios.</p><p>&gt;Paul would you be so kind as to guide me<br/>&gt;to a past post or paper that will clarify this for me and I will<br/>&gt;endeavor to follow more closely. Forgive my naivete.</p><p>None taken. See <a href="http://www.ixpres.com/interval/td/entropy.htm">http://www.ixpres.com/interval/td/entropy.htm</a> for a<br/>collection of my early posts to the Tuning List on the subject.</p></div>