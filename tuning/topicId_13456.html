<a href="/tuning">back to list</a><h1>Quantitative harmonic entropy</h1><h3><a id=13456 href="#13456">ðŸ”—</a>Graham Breed &#x3C;graham@microtonal.co.uk&#x3E;</h3><span>9/25/2000 7:48:19 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Hello there Paul and friends!</p><p>I haven&apos;t been following the ongoing discussion on harmonic entropy,<br/>so to write this message I&apos;ve refreshed myself from this page:</p><p><a href="http://www.ixpres.com/interval/td/erlich/entropy.htm">http://www.ixpres.com/interval/td/erlich/entropy.htm</a></p><p>There doesn&apos;t seem to be enough information there to reproduce the<br/>graphs.  The important quotes seem to be</p><p>Paul Erlich:</p><p>&quot;When I worked out a model for harmonic entropy, which should also<br/>describe critical band roughness if the partials decrease in<br/>amplitude<br/>in some specific fashion, I derived that to a good approximation, the<br/>complexity of a just ratio is directly related to its DENOMINATOR.&quot;</p><p>Joe Monzo:</p><p>&quot;DENOMINATOR should read &quot;the smaller term in the ratio&quot;, because in<br/>some cases the numerater can be the smaller term.&quot;</p><p>(To comment on Monz&apos;s commentary, the intervals are actually defined<br/>as &gt;=1, so the denominator must be the smaller term.)</p><p>and</p><p>Paul Erlich:</p><p>&quot;...the assumption that our brain can ideally recognize ratios with<br/>numerator up to N but our hearing of frequencies is blurred in the<br/>form of a normal distribution with standard deviation 1% (based on<br/>Goldstein&apos;s work).&quot;</p><p>The first part, about the denominator as an indicator of complexity,<br/>I<br/>remember from way back, and will discuss below.</p><p>The second part seems to cover the process of moving from a measure<br/>of<br/>complexity of integer ratios to a continuous function that depends on<br/>pitch.  I&apos;d like more details on this, including the algorithm used<br/>to<br/>generate the graphs.</p><p>Right, to the denominator limit then.</p><p>Paul did explain this a long time ago on the Mills list, but I don&apos;t<br/>have that post to hand.  So here&apos;s how I remember it.</p><p>You start by assuming that no intervals with a virtual root (is that<br/>the right word?) below a certain pitch can be resolved.  This is<br/>justified with a reference to psychoacoustics (Terhardt?).  If the<br/>higher note is held at a constant pitch, this means that the<br/>resolvable approximations must belong to a Farey series.  It is then<br/>shown that, in the limit where the size of the Farey series tends to<br/>infinity, a measure of complexity equal to the frequency of the guide<br/>tone comes out.  As the higher not is held constant, this means<br/>complexity is proportional to the denominator.</p><p>Now, my objection to this is that the denominator result is<br/>arbitrary.<br/> The very approximation used to prove this -- of the resolvable<br/>ratios<br/>becoming arbitrarily large -- also means the size of the intervals<br/>only changes by an infinitessimal amount for different rational<br/>approximations.  So the size of the denominator must be directly<br/>proportional to the size of the numerator!  Hence either can be used<br/>as an index of complexity.</p><p>So, we&apos;re left with the same conclusion as Partch: small integer<br/>ratios are more concordant.</p><p>However, Paul&apos;s result still has some connection with entropy I<br/>think.<br/> The question is: how to apply it where intervals differ by a finite<br/>amount?  It seemed to me that the most important result is that the<br/>complexity is proportional to the guide tone.  The problem is that<br/>transposing an interval will change its complexity.  This isn&apos;t what<br/>we want:  a fourth should have the same complexity wherever it occurs.</p><p>So, we have to decide on what to hold constant when comparing<br/>intervals.</p><p>When the higher note is held constant, the guide tone is proportional<br/>to the denominator.</p><p>When the lower note is held constant, the guide tone is proportional<br/>to the numerator.</p><p>When the arithmetic mean of the frequencies is held constant, the<br/>guide tone is proportional to the arithmetic mean of the numerator<br/>and<br/>denominator.</p><p>When the geometric mean of the frequencies is held constant, the<br/>guide<br/>tone is proportional to the geometric mean of the numerator and<br/>denominator.</p><p>I consider these functions to all be equally valid indicators of<br/>complexity, in the light of Paul&apos;s derivition.  He thought otherwise,<br/>and we had an argument about it that didn&apos;t go anywhere.</p><p>I notice that some charts are drawn using the &quot;Mann series&quot;.  A bit<br/>higher up, Monz says &quot;... a series such as used by Mann where the sum<br/>of numerator and denominator does not exceed a certain limit.&quot;  I<br/>take<br/>it, then, that the Mann series results are those you&apos;d get from<br/>holding the arithmetic mean constant.  Sure enough, the graphs are<br/>qualitatively the same.</p><p>My opinion is that the geometric mean is the one to go for, because<br/>that connects with pitch being perceived on a logarithmic scale.</p><p>Now, the interesting question is: how do we generalize this to<br/>chords?<br/> It&apos;s to be hoped that we come up with a non-arbitrary measure of<br/>accordance that rates otonal chords as more concordant than utonal<br/>ones.  To find this, I&apos;d prefer to look at psychoacoustics, rather<br/>than number theory.</p><p>The simplest measure is to stay with the guide tone.  It&apos;s easy to<br/>find this for a chord: multiply the virtual root by the lcm.<br/>Unfortunately, this gives the wrong results: utonal chords would be<br/>more concordant than otonal ones.  It&apos;s also not intuitively obvious<br/>why Paul&apos;s result should be generalized in this way.</p><p>So, let&apos;s take a step back.  Like in Pauls derivation of complexity<br/>of<br/>dyads, set an arbitrary limit on the virtual pitch.  This would lead<br/>to chords being more concordant the higher the virtual pitch.</p><p>I&apos;m not sure if this result is the equivalent of the guide-tone rule<br/>for chords, or if a better rule needs to be derived from it.  If the<br/>latter, it may be doable numerically.</p><p>Anyway, a virtual root limit gives the following measures of<br/>complexity of chords.  I&apos;m considering the chord as a ratio like<br/>4:5:6<br/>or 10:12:15.  Complexity is the reciprocal of the virtual root (this<br/>is easier to describe than the vr itself).</p><p>When the highest note is held constant, complexity is proportional to<br/>the highest number in the ratio.</p><p>When the lowest note is held constant, complexity is proportional to<br/>the lowest number in the ratio.</p><p>When the arithmetic mean of frequencies is held constant, complexity<br/>is proportional to the arithmetic mean of the numbers in the ratio.</p><p>When the geometric mean of frequencies (arithmetic mean of pitches)<br/>is<br/>held constant, complexity is proportional to the geometric mean of<br/>the<br/>numbers in the ratio.</p><p>For choosing rational approximations infinitessimally close to a<br/>given<br/>interval, these measures should all give the same result.  As a<br/>higher-level measure of complexity, the last is my preference,<br/>because<br/>the average pitch is a good indicator of the pitch of a chord.</p><p>I&apos;d be interested in seeing some kind of harmonic entropy plots using<br/>these measures plugged into the relevant part.</p><p>I take it that, for the calculation to be performed, an algorithm for<br/>generating all resolvable approximations is required.  The easiest<br/>chordal measure for doing this is that where the highest note is held<br/>constant, so a limit is placed on the highest number in the ratio.</p><p>The following Python function should do the job:</p><p>def getRatios(nNotes, cap):<br/>  &quot;&quot;&quot;return a list of lists of numbers.</p><p>  Each entry in the big list containing<br/>  nNotes numbers, all smaller than cap,<br/>  in order lowest first.</p><p>  All such ratios are returned.<br/>  &quot;&quot;&quot;<br/>  chords = []<br/>  for note in xrange(nNotes, cap):<br/>    if nNotes==1:<br/>      chords.append([note])<br/>    else:<br/>      for each in getRatios(nNotes-1,note):<br/>        chords.append(each+[note])<br/>  return chords</p><p># and this for testing:</p><p>import string</p><p>def printRatios(nNotes, cap):<br/>  for ratio in getRatios(nNotes, cap):<br/>    print string.join(map(str, ratio),&apos;:&apos;),</p><p>The &quot;cap&quot; parameter is one greater than the largest number you want<br/>to<br/>see in the ratios.  Plugging in 3 and 5 gives the Pythagorean triads:</p><p>1:2:3 1:2:4 1:3:4 2:3:4</p><p>This isn&apos;t a very efficient function, because adding a magic &quot;xrange&quot;<br/>doesn&apos;t do much to reduce the memory requirements of holding all<br/>possible ratios in memory at once.  Returning all 156,849 triads with<br/>two digit numbers in their ratios takes about 45 seconds on my PC.<br/>Three digit numbers will take ... a great deal longer.  Two digit<br/>numbers with four note chords gives a MemoryError after 4&apos;45&apos;&apos;.</p><p>So, we have a measure of complexity of chords that is calculable, and<br/>has some relationship with Paul&apos;s original &quot;denominator-limit&quot;.  What<br/>do harmonic entropy fans make of it?</p><p>         Graham</p></div><h3><a id=13484 href="#13484">ðŸ”—</a>Paul H. Erlich &#x3C;PERLICH@ACADIAN-ASSET.COM&#x3E;</h3><span>9/25/2000 2:30:15 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Graham wrote,</p><p>&gt;I haven&apos;t been following the ongoing discussion on harmonic entropy,<br/>&gt;so to write this message I&apos;ve refreshed myself from this page:</p><p>&gt;<a href="http://www.ixpres.com/interval/td/erlich/entropy.htm">http://www.ixpres.com/interval/td/erlich/entropy.htm</a></p><p>I&apos;m afraid you&apos;re very much behind, then, in regard to the specific<br/>questions you ask below.</p><p>&gt;There doesn&apos;t seem to be enough information there to reproduce the<br/>&gt;graphs.</p><p>Manuel Op de Coul can reproduce them, and I&apos;d be happy to give you whatever<br/>you need to get up to speed.</p><p>&gt;The important quotes seem to be</p><p>&gt;Paul Erlich:</p><p>&gt;&quot;When I worked out a model for harmonic entropy, which should also<br/>&gt;describe critical band roughness if the partials decrease in<br/>&gt;amplitude<br/>&gt;in some specific fashion, I derived that to a good approximation, the<br/>&gt;complexity of a just ratio is directly related to its DENOMINATOR.&quot;</p><p>That&apos;s actually a result in the pre-entropy, Van Eck model and is no longer<br/>relevant anyway.</p><p>&gt;Now, my objection to this is that the denominator result is<br/>&gt;arbitrary.<br/>&gt; The very approximation used to prove this -- of the resolvable<br/>&gt;ratios<br/>&gt;becoming arbitrarily large -- also means the size of the intervals<br/>&gt;only changes by an infinitessimal amount for different rational<br/>&gt;approximations.  So the size of the denominator must be directly<br/>&gt;proportional to the size of the numerator!  Hence either can be used<br/>&gt;as an index of complexity.</p><p>Absolutely right!</p><p>&gt;So, we&apos;re left with the same conclusion as Partch: small integer<br/>&gt;ratios are more concordant.</p><p>Well, no: 3000:2001 is more concorant than 13:9.</p><p>&gt;However, Paul&apos;s result still has some connection with entropy I<br/>&gt;think.<br/>&gt; The question is: how to apply it where intervals differ by a finite<br/>&gt;amount?  It seemed to me that the most important result is that the<br/>&gt;complexity is proportional to the guide tone.  The problem is that<br/>&gt;transposing an interval will change its complexity.  This isn&apos;t what<br/>&gt;we want:  a fourth should have the same complexity wherever it occurs.</p><p>&gt;So, we have to decide on what to hold constant when comparing<br/>&gt;intervals.</p><p>&gt;When the higher note is held constant, the guide tone is proportional<br/>&gt;to the denominator.</p><p>&gt;When the lower note is held constant, the guide tone is proportional<br/>&gt;to the numerator.</p><p>&gt;When the arithmetic mean of the frequencies is held constant, the<br/>&gt;guide tone is proportional to the arithmetic mean of the numerator<br/>&gt;and<br/>&gt;denominator.</p><p>&gt;When the geometric mean of the frequencies is held constant, the<br/>&gt;guide<br/>&gt;tone is proportional to the geometric mean of the numerator and<br/>&gt;denominator.</p><p>&gt;I consider these functions to all be equally valid indicators of<br/>&gt;complexity, in the light of Paul&apos;s derivition.  He thought otherwise,<br/>&gt;and we had an argument about it that didn&apos;t go anywhere.</p><p>&gt;I notice that some charts are drawn using the &quot;Mann series&quot;.  A bit<br/>&gt;higher up, Monz says &quot;... a series such as used by Mann where the sum<br/>&gt;of numerator and denominator does not exceed a certain limit.&quot;  I<br/>&gt;take<br/>&gt;it, then, that the Mann series results are those you&apos;d get from<br/>&gt;holding the arithmetic mean constant.  Sure enough, the graphs are<br/>&gt;qualitatively the same.</p><p>&gt;My opinion is that the geometric mean is the one to go for, because<br/>&gt;that connects with pitch being perceived on a logarithmic scale.</p><p>You&apos;ll be happy to know that in the posts you haven&apos;t been following, I&apos;ve<br/>independently come to the same conclusion (well, I use the product or the<br/>log-product, but that gives the same rank-order as the geometric mean, and<br/>the rank-order is all that matters because we&apos;re only choosing a single<br/>value as the cutoff for which ratios go into the harmonic entropy<br/>calculation.</p><p>&gt;Now, the interesting question is: how do we generalize this to<br/>&gt;chords?<br/>&gt; It&apos;s to be hoped that we come up with a non-arbitrary measure of<br/>&gt;accordance that rates otonal chords as more concordant than utonal<br/>&gt;ones.  To find this, I&apos;d prefer to look at psychoacoustics, rather<br/>&gt;than number theory.</p><p>I don&apos;t see why this should be any different in principle from the two-tone<br/>case.</p><p>&gt;The simplest measure is to stay with the guide tone.  It&apos;s easy to<br/>&gt;find this for a chord: multiply the virtual root by the lcm.<br/>&gt;Unfortunately, this gives the wrong results: utonal chords would be<br/>&gt;more concordant than otonal ones.</p><p>Wouldn&apos;t they be identically concordant?</p><p>&gt;When the highest note is held constant, complexity is proportional to<br/>&gt;the highest number in the ratio.</p><p>&gt;When the lowest note is held constant, complexity is proportional to<br/>&gt;the lowest number in the ratio.</p><p>&gt;When the arithmetic mean of frequencies is held constant, complexity<br/>&gt;is proportional to the arithmetic mean of the numbers in the ratio.</p><p>&gt;When the geometric mean of frequencies (arithmetic mean of pitches)<br/>&gt;is<br/>&gt;held constant, complexity is proportional to the geometric mean of<br/>&gt;the<br/>&gt;numbers in the ratio.</p><p>&gt;For choosing rational approximations infinitessimally close to a<br/>&gt;given<br/>&gt;interval, these measures should all give the same result.  As a<br/>&gt;higher-level measure of complexity, the last is my preference,<br/>&gt;because<br/>&gt;the average pitch is a good indicator of the pitch of a chord.</p><p>&gt;I&apos;d be interested in seeing some kind of harmonic entropy plots using<br/>&gt;these measures plugged into the relevant part.</p><p>Good idea! I&apos;ll do it for dyads first, and then try it for triads. (I was<br/>actually thinking the same thing earlier, before I read your post, because<br/>the list seems ever more eager for some true chordal harmonic entropy<br/>results). As you may or may not know, I&apos;ve been using the actual distance<br/>between mediants or midpoints in my calculations so far, but I could<br/>certainly use some pre-defined measure of complexity instead.</p><p>&gt;I take it that, for the calculation to be performed, an algorithm for<br/>&gt;generating all resolvable approximations is required.  The easiest<br/>&gt;chordal measure for doing this is that where the highest note is held<br/>&gt;constant, so a limit is placed on the highest number in the ratio.</p><p>Wait a minute! That kind of defeats everything we just went through! It<br/>seems to me that the only reasonable way to proceed, if one expects to<br/>compare chords with very different-sized intervals, is to set a limit on the<br/>geometric mean (or product or log-product) of the numbers in the &quot;ratio&quot;.<br/>But, in case you didn&apos;t know, I already tried your suggestion using 64 as<br/>the highest number, and though I didn&apos;t go ahead and calculate the entropy<br/>function, you can see the triads in this Voronoi graph:<br/><a href="http://www.egroups.com/files/tuning/triads.jpg">http://www.egroups.com/files/tuning/triads.jpg</a> (where the red dots are the<br/>three inversions of the 4:5:6 major triad, the blue dots are the three<br/>inversions of the 10:12:15 minor triad, and the green dots are the three<br/>inversions of the 16:19:24 minor triad) which, if you blur your eyes just<br/>the right amount, gives you a sense of how the resulting entropy function<br/>would turn out (except that the axes should be at a 60-degree angle and some<br/>of the cells may change as a result).</p></div><h3><a id=13529 href="#13529">ðŸ”—</a>Carl Lumma &#x3C;CLUMMA@NNI.COM&#x3E;</h3><span>9/25/2000 9:25:59 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>&gt;I&apos;d be interested in seeing some kind of harmonic entropy plots using<br/>&gt;these measures plugged into the relevant part.</p><p>Graham, that&apos;s a great idea!!  Only... don&apos;t we have to show that the<br/>measure being used sums to a meaningful total as some function of the<br/>limit used?  For example, if we use the set of all triads whose Tenney<br/>limit (a.k.a. geometric mean) is less than 30, the Tenney limits of<br/>all of them ought to sum to some special value?  The widths of the<br/>ratios in a given order of the Farey series sum to that order, anyway...<br/>I suppose the series-limiting condition could be different from the<br/>measure used to evaluate each member of the series, but I can&apos;t imagine<br/>it would be a good thing if the total evaluation fluctuated wildly as<br/>the limiting condition was incremented.  That sound right, anybody?</p><p>=carl</p></div><h3><a id=13530 href="#13530">ðŸ”—</a>Paul H. Erlich &#x3C;PERLICH@ACADIAN-ASSET.COM&#x3E;</h3><span>9/25/2000 9:29:26 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Graham wrote,</p><p>&gt;When the higher note is held constant, the guide tone is proportional<br/>&gt;to the denominator.</p><p>and the width is proportional to the denominator.</p><p>&gt;When the lower note is held constant, the guide tone is proportional<br/>&gt;to the numerator.</p><p>and the width is proportional to the numerator.</p><p>&gt;When the arithmetic mean of the frequencies is held constant, the<br/>&gt;guide tone is proportional to the arithmetic mean of the numerator<br/>&gt;and<br/>&gt;denominator.</p><p>And the width is _not_ proportional to the arithmetic mean!</p><p>&gt;When the geometric mean of the frequencies is held constant, the<br/>&gt;guide<br/>&gt;tone is proportional to the geometric mean of the numerator and<br/>&gt;denominator.</p><p>And the width _is_ proportional to the geometric mean!!!</p></div><h3><a id=13538 href="#13538">ðŸ”—</a>Paul H. Erlich &#x3C;PERLICH@ACADIAN-ASSET.COM&#x3E;</h3><span>9/25/2000 11:13:30 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Carl wrote,</p><p>&gt;Graham, that&apos;s a great idea!!  Only... don&apos;t we have to show that the<br/>&gt;measure being used sums to a meaningful total as some function of the<br/>&gt;limit used?  For example, if we use the set of all triads whose Tenney<br/>&gt;limit (a.k.a. geometric mean) is less than 30, the Tenney limits of<br/>&gt;all of them ought to sum to some special value?</p><p>Nah, you can always normalize them to sum to one . . . which probabilities<br/>always do. And use sqrt(n*d) for the width in the diadic case. I found this<br/>to be a great approximation for the simpler ratios in the limit.</p><p>&gt;The widths of the<br/>&gt;ratios in a given order of the Farey series sum to that order, anyway...</p><p>Hmm?</p><p>&gt;I suppose the series-limiting condition could be different from the<br/>&gt;measure used to evaluate each member of the series, but I can&apos;t imagine<br/>&gt;it would be a good thing if the total evaluation fluctuated wildly as<br/>&gt;the limiting condition was incremented.  That sound right, anybody?</p><p>Confused at 2:20.</p></div><h3><a id=13557 href="#13557">ðŸ”—</a>Paul H. Erlich &#x3C;PERLICH@ACADIAN-ASSET.COM&#x3E;</h3><span>9/26/2000 11:43:53 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>I wrote,</p><p>&gt;And use sqrt(n*d) for the width in the diadic case.</p><p>Whoops, I meant 1/sqrt(n*d). I&apos;m about to try this . . . should eliminate<br/>the necessity of calculating a normal cdf integral, etc.</p></div><h3><a id=13568 href="#13568">ðŸ”—</a>Paul H. Erlich &#x3C;PERLICH@ACADIAN-ASSET.COM&#x3E;</h3><span>9/26/2000 2:01:20 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>I wrote,</p><p>&gt;Whoops, I meant 1/sqrt(n*d). I&apos;m about to try this . . . should eliminate<br/>the necessity of &gt;calculating a normal cdf integral, etc.</p><p>Here&apos;s a comparison of the result this way with the result of using the<br/>integrals over the mediant-to-mediant intervals:</p><p><a href="http://www.egroups.com/files/tuning/perlich/tenney/tcmp3.jpg">http://www.egroups.com/files/tuning/perlich/tenney/tcmp3.jpg</a>.</p><p>I&apos;m pretty happy with the approximation.</p><p>This is based on my finding (two years ago?) that the mediant-to-mediant<br/>widths of the simpler ratios n/d in the &quot;Tenney series&quot; are proportional to<br/>1/sqrt(n*d). (Can anyone prove that?) So to calculate the blue curve, I used<br/>1/sqrt(n*d) times the height of the bell curve as the probability for each<br/>ratio, and then normalized so that all the probabilities sum to one. The<br/>calculation ran very quickly, needless to say.</p><p>It is straightforward to generalize this to triads, using a Chalmers-like<br/>60-degree angle plot and a bivariate normal distribution. But there&apos;s a leap<br/>of faith involved. Is there an analogue to mediants such that the triadic<br/>surface is divided into cells, one for each triad within a certain (high)<br/>product-limit, where, for the simpler triads, the area of the cell is<br/>inversely proportional to the geometric mean of the numbers in the otonal<br/>representation of the triad? It would be nice if we could actually construct<br/>this decomposition, but I&apos;m clueless at the moment. Anyway, I&apos;ll get to<br/>working on this soon . . .</p></div><h3><a id=13569 href="#13569">ðŸ”—</a>graham@microtonal.co.uk</h3><span>9/26/2000 2:21:00 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Paul wrote:</p><p>&gt; and the width is proportional to the denominator.<br/>           &lt;snip&gt;<br/>&gt; and the width is proportional to the numerator.<br/>           &lt;snip&gt;<br/>&gt; And the width is _not_ proportional to the arithmetic mean!<br/>           &lt;snip&gt;<br/>&gt; And the width _is_ proportional to the geometric mean!!!</p><p>Okay, Paul, what&apos;s so special about the arithmetic mean?  And what is the<br/>width here, the interval between the highest and lowest note in the chord?</p></div><h3><a id=13570 href="#13570">ðŸ”—</a>graham@microtonal.co.uk</h3><span>9/26/2000 2:21:00 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Paul H. Erlich wrote:</p><p>&gt;&gt; It&apos;s to be hoped that we come up with a non-arbitrary measure of<br/>&gt;&gt;accordance that rates otonal chords as more concordant than utonal<br/>&gt;&gt;ones.  To find this, I&apos;d prefer to look at psychoacoustics, rather<br/>&gt;&gt;than number theory.</p><p>&gt; I don&apos;t see why this should be any different in principle from the<br/>&gt; two-tone case.</p><p>Voronoi cells got mentioned previously.  They look suspiciously like<br/>number theory to me, although I&apos;m starting to get the hang of what you&apos;re<br/>doing with them.</p><p>Like Monzo said recently, chords are rated according to how often they<br/>occur in the limit specified.  So it&apos;s a highest-number rule by the back<br/>door.</p><p>&gt; &gt;The simplest measure is to stay with the guide tone.  It&apos;s easy to<br/>&gt; &gt;find this for a chord: multiply the virtual root by the lcm.<br/>&gt; &gt;Unfortunately, this gives the wrong results: utonal chords would be<br/>&gt; &gt;more concordant than otonal ones.<br/>&gt;<br/>&gt; Wouldn&apos;t they be identically concordant?</p><p>No, not unless you give both the chords the same virtual root, which would<br/>be silly. Or I got my terminology wrong.  Otonal and utonal chords have<br/>the same lcm.  So for such chords, the virtual root would be proportional<br/>to the guide tone.  As the virtual root should be high, and the guide tone<br/>low, for simple chords the two measures are in conflict when the lcms are<br/>the same.</p><p>&gt; &gt;I&apos;d be interested in seeing some kind of harmonic entropy plots using<br/>&gt; &gt;these measures plugged into the relevant part.<br/>&gt;<br/>&gt; Good idea! I&apos;ll do it for dyads first, and then try it for triads. (I<br/>&gt; was<br/>&gt; actually thinking the same thing earlier, before I read your post,<br/>&gt; because<br/>&gt; the list seems ever more eager for some true chordal harmonic entropy<br/>&gt; results). As you may or may not know, I&apos;ve been using the actual<br/>&gt; distance<br/>&gt; between mediants or midpoints in my calculations so far, but I could<br/>&gt; certainly use some pre-defined measure of complexity instead.</p><p>This isn&apos;t clear to me.  Are these the midpoints you&apos;re using for<br/>describing the Voronoi cells?</p><p>&gt; &gt;I take it that, for the calculation to be performed, an algorithm for<br/>&gt; &gt;generating all resolvable approximations is required.  The easiest<br/>&gt; &gt;chordal measure for doing this is that where the highest note is held<br/>&gt; &gt;constant, so a limit is placed on the highest number in the ratio.<br/>&gt;<br/>&gt; Wait a minute! That kind of defeats everything we just went through! It<br/>&gt; seems to me that the only reasonable way to proceed, if one expects to<br/>&gt; compare chords with very different-sized intervals, is to set a limit<br/>&gt; on the<br/>&gt; geometric mean (or product or log-product) of the numbers in the<br/>&gt; &quot;ratio&quot;.</p><p>Don&apos;t know about the only reasonable way to proceed.  Highest number&apos;s the<br/>simplest.  Geometric mean&apos;s the best, if you can get it to work.</p><p>&gt; But, in case you didn&apos;t know, I already tried your suggestion using 64<br/>&gt; as<br/>&gt; the highest number, and though I didn&apos;t go ahead and calculate the<br/>&gt; entropy<br/>&gt; function, you can see the triads in this Voronoi graph:<br/>&gt; <a href="http://www.egroups.com/files/tuning/triads.jpg">http://www.egroups.com/files/tuning/triads.jpg</a></p><p>Right, yes, I alluded to that above.</p><p>(where the red dots are<br/>&gt;  which, if you blur your eyes<br/>&gt; just<br/>&gt; the right amount, gives you a sense of how the resulting entropy<br/>&gt; function<br/>&gt; would turn out (except that the axes should be at a 60-degree angle and<br/>&gt; some<br/>&gt; of the cells may change as a result).</p><p>What&apos;s the significance of this angle?</p><p>I notice that the consonant intervals have large cells surrounding them.<br/>Presumably another way of calculating the mediants would put them nearer<br/>to the more complex ratios?</p><p>         Graham</p></div><h3><a id=13582 href="#13582">ðŸ”—</a>Paul H. Erlich &#x3C;PERLICH@ACADIAN-ASSET.COM&#x3E;</h3><span>9/26/2000 4:48:15 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Graham wrote,</p><p>&gt;&gt;&gt; It&apos;s to be hoped that we come up with a non-arbitrary measure of<br/>&gt;&gt;&gt;accordance that rates otonal chords as more concordant than utonal<br/>&gt;&gt;&gt;ones.  To find this, I&apos;d prefer to look at psychoacoustics, rather<br/>&gt;&gt;&gt;than number theory.</p><p>&gt;&gt; I don&apos;t see why this should be any different in principle from the<br/>&gt;&gt; two-tone case.</p><p>&gt;Voronoi cells got mentioned previously.  They look suspiciously like<br/>&gt;number theory to me, although I&apos;m starting to get the hang of what you&apos;re<br/>&gt;doing with them.</p><p>In the diadic case, you can either use midpoints, or mediants. The latter<br/>are kind of number-theoretic (?). Voronoi cells are the analogue of<br/>midpoints, so if anything, they&apos;re less number-theoretic . . .</p><p>&gt;Like Monzo said recently, chords are rated according to how often they<br/>&gt;occur in the limit specified.</p><p>Not directly . . .</p><p>&gt;So it&apos;s a highest-number rule by the back<br/>&gt;door.</p><p>Hmm . . . in the diadic analogue, the Farey series gives you (approximately)<br/>a lowest-number rule. Why would this flip to highest in the triadic case?</p><p>&gt;&gt; Good idea! I&apos;ll do it for dyads first, and then try it for triads. (I<br/>&gt;&gt; was<br/>&gt;&gt; actually thinking the same thing earlier, before I read your post,<br/>&gt;&gt; because<br/>&gt;&gt; the list seems ever more eager for some true chordal harmonic entropy<br/>&gt;&gt; results). As you may or may not know, I&apos;ve been using the actual<br/>&gt;&gt; distance<br/>&gt;&gt; between mediants or midpoints in my calculations so far, but I could<br/>&gt;&gt; certainly use some pre-defined measure of complexity instead.</p><p>&gt;This isn&apos;t clear to me.  Are these the midpoints you&apos;re using for<br/>&gt;describing the Voronoi cells?</p><p>The Voronoi cells are the 2-d analogue of midpoints. Every point in a<br/>Voronoi cell is closer to the &quot;nucleus&quot; of that cell (the chord defining it)<br/>than to any other nucleus.</p><p>&gt;Don&apos;t know about the only reasonable way to proceed.  Highest number&apos;s the<br/>&gt;simplest.  Geometric mean&apos;s the best, if you can get it to work.</p><p>I intend to use that going forward, since the Farey (highest number) method<br/>is biased against large intervals.</p><p>&gt;What&apos;s the significance of this angle?</p><p>The two axes are the lower interval and the upper interval. What if you<br/>chose one of the axes to be the outer interval? You&apos;d want the resulting<br/>diagram to be simply a rotation of the original one, without any distortion.<br/>The only way to do that is to use an equilateral triangular diagram, in<br/>which the angle between the axes is either 120 degrees or 60 degrees -- ask<br/>John Chalmers.</p><p>&gt;I notice that the consonant intervals have large cells surrounding them.<br/>&gt;Presumably another way of calculating the mediants would put them nearer<br/>&gt;to the more complex ratios?</p><p>. . . making the consonant chords occupy even larger cells. Yes, a<br/>substitute for Voronoi cells which was analogous to mediants rather than<br/>midpoints would have this effect. But it doesn&apos;t matter much for harmonic<br/>entropy, once the cells are much smaller than s.</p></div><h3><a id=13583 href="#13583">ðŸ”—</a>Paul H. Erlich &#x3C;PERLICH@ACADIAN-ASSET.COM&#x3E;</h3><span>9/26/2000 4:58:09 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>I wrote,</p><p>&gt;&gt; and the width is proportional to the denominator.<br/>           &lt;snip&gt;<br/>&gt;&gt; and the width is proportional to the numerator.<br/>           &lt;snip&gt;<br/>&gt;&gt; And the width is _not_ proportional to the arithmetic mean!<br/>           &lt;snip&gt;<br/>&gt;&gt; And the width _is_ proportional to the geometric mean!!!</p><p>Graham wrote,</p><p>&gt;Okay, Paul, what&apos;s so special about the arithmetic mean?</p><p>I don&apos;t know! I left out &quot;inversely&quot; in all of the above. But I don&apos;t think<br/>the arithmetic mean is special; I think the other ones are special.</p><p>&gt;And what is the<br/>&gt;width here, the interval between the highest and lowest note in the chord?</p><p>Nope. Remember that derivation of mine that caused you so much trouble? It<br/>was concerned with finding a simple formula for the width of each of the<br/>simple ratios, where width means the distance between the lower mediant and<br/>the upper mediant. In that derivation, I used the Farey series, where the<br/>numerator has a limit, and I showed that the width was approximately<br/>inversely proportional to the denominator. If you use a denominator limit,<br/>the width is approximately inversely proportional to the numerator. If you<br/>use a product limit, the width is approximately inversely proportional to<br/>the geometric mean. And if you use a sum limit, the width is _not_<br/>approximately inversely proportional to the arithmetic mean . . .</p><p>Anyway, this &quot;width&quot; is the relevant quantity in the harmonic entropy<br/>calculation. The analogue in the triadic case would be the area of the<br/>Voronoi-like cell. Since, in the diadic case, if you use a product limit,<br/>the width for the simple ratios is approximately inversely proportional to<br/>the geometric mean, and, as I just posted, the resulting harmonic entropy<br/>curve is essentially the same as the one that doesn&apos;t use this<br/>approximation, I&apos;m willing to take a leap of faith and suppose that<br/>something similar holds in the triadic case, so that I can try to calculate<br/>a triadic harmonic entropy surface.</p></div><h3><a id=13624 href="#13624">ðŸ”—</a>Carl Lumma &#x3C;CLUMMA@NNI.COM&#x3E;</h3><span>9/26/2000 9:52:02 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>&gt;&gt;Graham, that&apos;s a great idea!!  Only... don&apos;t we have to show that the<br/>&gt;&gt;measure being used sums to a meaningful total as some function of the<br/>&gt;&gt;limit used?  For example, if we use the set of all triads whose Tenney<br/>&gt;&gt;limit (a.k.a. geometric mean) is less than 30, the Tenney limits of<br/>&gt;&gt;all of them ought to sum to some special value?<br/>&gt;<br/>&gt;Nah, you can always normalize them to sum to one . . . which probabilities<br/>&gt;always do.</p><p>I know.  But if our total didn&apos;t increase in some way as we upped the<br/>limit on the series, it wouldn&apos;t bode well for our orriginal assumption<br/>that discordance is related to the limiting function we chose.  That is,<br/>doesn&apos;t our usage of a complexity measure instead of real widths (we<br/>imply the complexities can be used _as_ widths) depend on if the particular<br/>measure means something acoustically?</p><p>Also, wouldn&apos;t we like to see some stability to the ordering of the few<br/>widest ratios as the limit is upped... in fact, a _slow_, uniform<br/>narrowing of their widths that dosen&apos;t change their ordering too much.<br/>So we can approximate an infinite limit with a finite one, as we did with<br/>the Farey series?</p><p>&gt;&gt;The widths of the ratios in a given order of the Farey series sum to<br/>&gt;&gt;that order, anyway...<br/>&gt;<br/>&gt;Hmm?</p><p>I realized while going to sleep that this was an error.  But I haven&apos;t<br/>found any errors with my point yet, which is simply that for mediant-<br/>based widths on the Farey series, the total of all the widths is trivially<br/>bound by the width of the entire series, and this is a good thing.  Check<br/>it out...</p><p>For a Farey series of order z, the boundaries of the series on the<br/>number line are 1/1 and z/1.  By mistake, I forgot that you can&apos;t get<br/>widths for the boundary points, so the total will be less than z.  It<br/>will in fact be:</p><p>( 2z - 1 )   ( (z+1) )<br/>| -----  | - |   -   |  =  z - 3/2 - 1/z<br/>(    2   )   (   z   )</p><p>&gt;Confused at 2:20.</p><p>And how!</p><p>&gt;&gt;I suppose the series-limiting condition could be different from the<br/>&gt;&gt;measure used to evaluate each member of the series,</p><p>We could, say, use Farey limit to choose our ratios, and then Tenney<br/>limit to approximate their widths, just so the sum of the latter is<br/>well-behaved as we change the former.  Or do you think that simply<br/>expressing the complexities in terms of the total is enough?</p><p>-Carl</p></div><h3><a id=13640 href="#13640">ðŸ”—</a>Graham Breed &#x3C;graham@microtonal.co.uk&#x3E;</h3><span>9/27/2000 3:21:26 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Paul Erlich wrote:</p><p>&gt; &gt;Voronoi cells got mentioned previously.  They look suspiciously<br/>like<br/>&gt; &gt;number theory to me, although I&apos;m starting to get the hang of what<br/>you&apos;re<br/>&gt; &gt;doing with them.<br/>&gt;<br/>&gt; In the diadic case, you can either use midpoints, or mediants. The<br/>latter<br/>&gt; are kind of number-theoretic (?). Voronoi cells are the analogue of<br/>&gt; midpoints, so if anything, they&apos;re less number-theoretic . . .</p><p>Yes, more crystallography than number theory.  The &quot;musical&quot;<br/>equivalent of a mid-point would have to use a &quot;musical&quot; metric, as<br/>mentioned below.</p><p>&gt; &gt;Like Monzo said recently, chords are rated according to how often<br/>they<br/>&gt; &gt;occur in the limit specified.<br/>&gt;<br/>&gt; Not directly . . .</p><p>Well, it looks like that&apos;s what&apos;s going on.</p><p>&gt; &gt;So it&apos;s a highest-number rule by the back<br/>&gt; &gt;door.<br/>&gt;<br/>&gt; Hmm . . . in the diadic analogue, the Farey series gives you<br/>(approximately)<br/>&gt; a lowest-number rule. Why would this flip to highest in the triadic<br/>case?</p><p>Because a different method&apos;s being used?  If the highest number in a<br/>ratio is 64, then 4:5:6 can also occur as 8:10:12, 12:15:18,<br/>16:20:24,<br/>and so on up to 40:50:60.  The next one, 44:55:66 is too big because<br/>the highest number&apos;s too high.  The number of times a ratio can occur<br/>is the integer part of the limit divided by the highest number in the<br/>ratio.  In this case, 64/6=10.7, so it&apos;s there 10 times.</p><p>&gt; &gt;&gt; As you may or may not know, I&apos;ve been using the actual<br/>&gt; &gt;&gt; distance<br/>&gt; &gt;&gt; between mediants or midpoints in my calculations so far, but I<br/>could<br/>&gt; &gt;&gt; certainly use some pre-defined measure of complexity instead.<br/>&gt;<br/>&gt; &gt;This isn&apos;t clear to me.  Are these the midpoints you&apos;re using for<br/>&gt; &gt;describing the Voronoi cells?<br/>&gt;<br/>&gt; The Voronoi cells are the 2-d analogue of midpoints. Every point in<br/>a<br/>&gt; Voronoi cell is closer to the &quot;nucleus&quot; of that cell (the chord<br/>defining it)<br/>&gt; than to any other nucleus.</p><p>And at the moment &quot;closer&quot; is by the Euclidian distance as you see it<br/>on the page?  So that metric could be replaced by something like the<br/>Tenney harmonic distance.</p><p>It&apos;s been mentioned (like here<br/>&lt;<a href="http://www.egroups.com/message/tuning/13529">http://www.egroups.com/message/tuning/13529</a>&gt;) that the Tenney<br/>distance between chords is measured by the product or geometric mean<br/>of the ratios.  Did Tenney propose this, or is it a generalization of<br/>his diadic measure?</p><p>&gt; &gt;I notice that the consonant intervals have large cells surrounding<br/>them.<br/>&gt; &gt;Presumably another way of calculating the mediants would put them<br/>nearer<br/>&gt; &gt;to the more complex ratios?<br/>&gt;<br/>&gt; . . . making the consonant chords occupy even larger cells. Yes, a<br/>&gt; substitute for Voronoi cells which was analogous to mediants rather<br/>than<br/>&gt; midpoints would have this effect. But it doesn&apos;t matter much for<br/>harmonic<br/>&gt; entropy, once the cells are much smaller than s.</p><p>What&apos;s s?  We&apos;ll see.  Could you do a Voronoi-like plot where the<br/>divisions are chosen so that each point is as near as possible to the<br/>middle of the cell?  That would give the right result, but be more<br/>computationally intensive.  Fudging it with a complexity measure<br/>would<br/>likely come out the same.  If a ratio occurs 5 times as often as the<br/>one next door, draw the division 5/6 of the way between them.</p><p>Since I put &quot;quantitative&quot; in the title, I could work this out.</p><p>The 4:5:6 is at point (415,467) on triads.jpg.  The next ratio on the<br/>spine is at (429, 446), 25.2 pixels from 4:5:6.  And the one after<br/>that (431,444), another 2.8 pixels away.  Assuming these other ratios<br/>have the lowest consonance index of 1, that means the difference<br/>between a 10 and 1 ratio is 8.9 times that between two 1 ratios.<br/>Taking some other points, we have (375,427) and (370,423), giving a<br/>proportion of 8.8.</p><p>So it&apos;s a bit smaller than 9.  Unfortunately, this isn&apos;t what I&apos;d<br/>have<br/>predicted.  If each ratio has the same area, then 4:5:6 would have 10<br/>times the area of the most complex ratios through being there 10<br/>times.  Then, the distance would be scaled by the square root of 10,<br/>or 3.2.  Taking the 5/6 logic I used above, the distances should be<br/>scaled by 11/2=5.5.  So it isn&apos;t that either.</p><p>With a pair of points near 3:4:5, I get (587,195), (553,139) and<br/>(549,133) giving a proportion of 9.1.  3:4:5 should be represented 12<br/>times.</p><p>So, 10 gives 8.9 and 12 gives 9.1.  I dunno ...</p><p>Ah, but the diagram&apos;s drawn to a pitch, not frequency, scale!</p><p>Did anybody find free software for drawing these diagrams?</p><p>       Graham</p></div><h3><a id=13657 href="#13657">ðŸ”—</a>Paul H. Erlich &#x3C;PERLICH@ACADIAN-ASSET.COM&#x3E;</h3><span>9/27/2000 8:40:31 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Carl wrote,</p><p>&gt;&gt;&gt;Graham, that&apos;s a great idea!!  Only... don&apos;t we have to show that the<br/>&gt;&gt;&gt;measure being used sums to a meaningful total as some function of the<br/>&gt;&gt;&gt;limit used?  For example, if we use the set of all triads whose Tenney<br/>&gt;&gt;&gt;limit (a.k.a. geometric mean) is less than 30, the Tenney limits of<br/>&gt;&gt;&gt;all of them ought to sum to some special value?</p><p>I wrote,</p><p>&gt;&gt;Nah, you can always normalize them to sum to one . . . which probabilities<br/>&gt;&gt;always do.</p><p>Carl wrote,</p><p>&gt;I know.  But if our total didn&apos;t increase in some way as we upped the<br/>&gt;limit on the series, it wouldn&apos;t bode well for our orriginal assumption<br/>&gt;that discordance is related to the limiting function we chose.  That is,<br/>&gt;doesn&apos;t our usage of a complexity measure instead of real widths (we<br/>&gt;imply the complexities can be used _as_ widths) depend on if the particular<br/>&gt;measure means something acoustically?</p><p>It should be an approximation to the widths. I showed that using 1/sqrt(n*d)<br/>gives you virtually the same results as integrating over the actual<br/>mediant-to-mediant widths, for the &quot;Tenney series&quot;.</p><p>&gt;For a Farey series of order z, the boundaries of the series on the<br/>&gt;number line are 1/1 and z/1.</p><p>1/z and z/1.</p><p>&gt;By mistake, I forgot that you can&apos;t get<br/>&gt;widths for the boundary points</p><p>Sure you can -- the mediant between 0/1 and 1/z is 1/(z+1), and the mediant<br/>between z/1 and 1/0 is (z+1)/1.</p><p>&gt;We could, say, use Farey limit to choose our ratios, and then Tenney<br/>&gt;limit to approximate their widths, just so the sum of the latter is<br/>&gt;well-behaved as we change the former.</p><p>Oh, behave!</p><p>&gt;Or do you think that simply<br/>&gt;expressing the complexities in terms of the total is enough?</p><p>Some function of the complexities which is an approximation to width, yes. I<br/>think my graphs yesterday showed that.</p></div><h3><a id=13663 href="#13663">ðŸ”—</a>Paul H. Erlich &#x3C;PERLICH@ACADIAN-ASSET.COM&#x3E;</h3><span>9/27/2000 9:17:19 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Graham wrote,</p><p>&gt;&gt;&gt;So it&apos;s a highest-number rule by the back<br/>&gt;&gt;&gt;door.</p><p>I wrote,</p><p>&gt;&gt; Hmm . . . in the diadic analogue, the Farey series gives you<br/>(approximately)<br/>&gt;&gt; a lowest-number rule. Why would this flip to highest in the triadic<br/>case?</p><p>Graham wrote,</p><p>&gt;Because a different method&apos;s being used?  If the highest number in a<br/>&gt;ratio is 64, then 4:5:6 can also occur as 8:10:12, 12:15:18,<br/>&gt;16:20:24,<br/>&gt;and so on up to 40:50:60.  The next one, 44:55:66 is too big because<br/>&gt;the highest number&apos;s too high.  The number of times a ratio can occur<br/>&gt;is the integer part of the limit divided by the highest number in the<br/>&gt;ratio.  In this case, 64/6=10.7, so it&apos;s there 10 times.</p><p>And why doesn&apos;t this argument carry over to dyads?</p><p>&gt;And at the moment &quot;closer&quot; is by the Euclidian distance as you see it<br/>&gt;on the page?</p><p>Right.</p><p>&gt;So that metric could be replaced by something like the<br/>&gt;Tenney harmonic distance.</p><p>I think you&apos;re getting confused. Midpoint, mediant, these are in<br/>pitch-space, not Tenney harmonic lattice space.</p><p>&gt;It&apos;s been mentioned (like here<br/>&gt;&lt;<a href="http://www.egroups.com/message/tuning/13529">http://www.egroups.com/message/tuning/13529</a>&gt;) that the Tenney<br/>&gt;distance between chords is measured by the product or geometric mean<br/>&gt;of the ratios.  Did Tenney propose this, or is it a generalization of<br/>&gt;his diadic measure?</p><p>I think Carl was just thinking about generalizing the diadic measure.</p><p>&gt;What&apos;s s?</p><p>s -- the standard deviation of hearing errors assumed in the harmonic<br/>entropy calculation.</p><p>&gt;We&apos;ll see.  Could you do a Voronoi-like plot where the<br/>&gt;divisions are chosen so that each point is as near as possible to the<br/>&gt;middle of the cell?  That would give the right result, but be more<br/>&gt;computationally intensive.  Fudging it with a complexity measure<br/>&gt;would<br/>&gt;likely come out the same.  If a ratio occurs 5 times as often as the<br/>&gt;one next door, draw the division 5/6 of the way between them.</p><p>It&apos;s easy to say these things, but to actually construct a set of polygons<br/>that satisfies these properties is very difficult. If you can find a way do<br/>create polygons that satisfy your last condition above, you&apos;ll win my<br/>personal . . . uh . . . _noble_ prize.</p><p>&gt;Since I put &quot;quantitative&quot; in the title, I could work this out.</p><p>God bless you!</p></div><h3><a id=13684 href="#13684">ðŸ”—</a>Carl Lumma &#x3C;CLUMMA@NNI.COM&#x3E;</h3><span>9/27/2000 12:33:22 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>&gt;&gt;I know.  But if our total didn&apos;t increase in some way as we upped the<br/>&gt;&gt;limit on the series, it wouldn&apos;t bode well for our orriginal assumption<br/>&gt;&gt;that discordance is related to the limiting function we chose.  That is,<br/>&gt;&gt;doesn&apos;t our usage of a complexity measure instead of real widths (we<br/>&gt;&gt;imply the complexities can be used _as_ widths) depend on if the particular<br/>&gt;&gt;measure means something acoustically?<br/>&gt;<br/>&gt;It should be an approximation to the widths.</p><p>Which was my only point.</p><p>&gt;I showed that using 1/sqrt(n*d) gives you virtually the same results as<br/>&gt;integrating over the actual mediant-to-mediant widths, for the &quot;Tenney<br/>&gt;series&quot;.</p><p>Right.  And a good thing it was.  I was just pointing out that we&apos;ll<br/>want some like result for whatever complexity measure we use... Graham<br/>was throwing around suggestions there...</p><p>&gt;&gt;For a Farey series of order z, the boundaries of the series on the<br/>&gt;&gt;number line are 1/1 and z/1.<br/>&gt;<br/>&gt;1/z and z/1.</p><p>I don&apos;t normally allow fractions less than 1.  Which shouldn&apos;t matter,<br/>since there&apos;s mirror symmetry there; the Stern-Brocot tree is symmetrical<br/>between 0/1 - 1/1 and 1/1 - 1/0.</p><p>&gt;&gt;By mistake, I forgot that you can&apos;t get<br/>&gt;&gt;widths for the boundary points<br/>&gt;<br/>&gt;Sure you can -- the mediant between 0/1 and 1/z is 1/(z+1), and the mediant<br/>&gt;between z/1 and 1/0 is (z+1)/1.</p><p>Those fractions with zero can bite me.</p><p>&gt;&gt;We could, say, use Farey limit to choose our ratios, and then Tenney<br/>&gt;&gt;limit to approximate their widths, just so the sum of the latter is<br/>&gt;&gt;well-behaved as we change the former.<br/>&gt;<br/>&gt;Oh, behave!</p><p>:)</p><p>&gt;&gt;Or do you think that simply expressing the complexities in terms of the<br/>&gt;&gt;total is enough?<br/>&gt;<br/>&gt;Some function of the complexities which is an approximation to width, yes.</p><p>But otherwise, simply expressing the complexities in terms of their total<br/>is _not_ enough, right?</p><p>&gt;I think my graphs yesterday showed that.</p><p>Who?  Missed &apos;em.</p><p>-Carl</p></div><h3><a id=13685 href="#13685">ðŸ”—</a>Joseph Pehrson &#x3C;pehrson@pubmedia.com&#x3E;</h3><span>9/27/2000 12:40:16 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning@egroups.com">tuning@egroups.com</a>, Carl Lumma &lt;CLUMMA@N...&gt; wrote:</p><p><a href="http://www.egroups.com/message/tuning/13684">http://www.egroups.com/message/tuning/13684</a></p><p>Carl...</p><p>Zies post shoot be over at zie neue &quot;Harmonic Entropy&quot; egroups:</p><p><a href="http://www.egroups.com/messages/harmonic_entropy">http://www.egroups.com/messages/harmonic_entropy</a></p><p>______________ ___ _ _<br/>Joseph Pehrson</p></div><h3><a id=13700 href="#13700">ðŸ”—</a>Carl Lumma &#x3C;CLUMMA@NNI.COM&#x3E;</h3><span>9/27/2000 6:31:37 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>[Joseph Pehrson wrote...]<br/>&gt;<a href="http://www.egroups.com/message/tuning/13684">http://www.egroups.com/message/tuning/13684</a><br/>&gt;<br/>&gt;Carl...<br/>&gt;<br/>&gt;Zies post shoot be over at zie neue &quot;Harmonic Entropy&quot; egroups:</p><p>If it belonged there, I would have posted it there.</p><p>[David Beardsley wrote...]<br/>&gt;&gt;Good luck, boys!  We&apos;ll be counting on regular summaries of<br/>&gt;&gt;what you&apos;ve discovered!<br/>&gt;<br/>&gt;That would kind of defeat the point of having<br/>&gt;SEPARATE lists.</p><p>Not true.  There&apos;s a difference between a conclusion and the many<br/>exchanges it took to reach it.  To ask to completely remove a topic<br/>like harmonic entropy from this list defeats _its_ purpose.</p><p>-Carl</p></div><h3><a id=13704 href="#13704">ðŸ”—</a>Joseph Pehrson &#x3C;josephpehrson@compuserve.com&#x3E;</h3><span>9/27/2000 7:42:23 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>--- In <a href="mailto:tuning@egroups.com">tuning@egroups.com</a>, Carl Lumma &lt;CLUMMA@N...&gt; wrote:</p><p><a href="http://www.egroups.com/message/tuning/13700">http://www.egroups.com/message/tuning/13700</a></p><p>&gt; [Joseph Pehrson wrote...]<br/>&gt; &gt;<a href="http://www.egroups.com/message/tuning/13684">http://www.egroups.com/message/tuning/13684</a><br/>&gt; &gt;<br/>&gt; &gt;Carl...<br/>&gt; &gt;<br/>&gt; &gt;Zies post shoot be over at zie neue &quot;Harmonic Entropy&quot; egroups:<br/>&gt;<br/>&gt; If it belonged there, I would have posted it there.<br/>&gt;</p><p>Whatever, Carl.  I was never one to advocate for separate lists in<br/>the first place (!!)<br/>________ ___ __ __ _ _<br/>Joseph Pehrson</p></div><h3><a id=13713 href="#13713">ðŸ”—</a>Paul H. Erlich &#x3C;PERLICH@ACADIAN-ASSET.COM&#x3E;</h3><span>9/27/2000 9:47:00 PM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>Carl Lumma wrote,</p><p>&gt;But otherwise, simply expressing the complexities in terms of their total<br/>&gt;is _not_ enough, right?</p><p>Complexities . . . how about simplicities (1/sqrt(n*d)). It produces the<br/>blue curve in the graph below. It&apos;s enough.</p><p>&gt;&gt;I think my graphs yesterday showed that.</p><p>&gt;Who?  Missed &apos;em.</p><p><a href="http://www.egroups.com/files/tuning/perlich/tenney/tcmp3.jpg">http://www.egroups.com/files/tuning/perlich/tenney/tcmp3.jpg</a>.</p></div><h3><a id=13724 href="#13724">ðŸ”—</a>Carl Lumma &#x3C;CLUMMA@NNI.COM&#x3E;</h3><span>9/28/2000 6:49:39 AM</span><div style='margin: 0px 20px 20px; padding: 20px; background-color: #eee'><p>&gt;&gt;But otherwise, simply expressing the complexities in terms of their total<br/>&gt;&gt;is _not_ enough, right?<br/>&gt;<br/>&gt;Complexities . . . how about simplicities (1/sqrt(n*d)). It produces the<br/>&gt;blue curve in the graph below. It&apos;s enough.</p><p>I said _otherwise_!  We already know that 1/sqrt(n*d) is cool.  But what<br/>about for triads, as Graham was asking?  What if the measure was the<br/>totient of the smallest number in the ratio?  It wouldn&apos;t _necessarily_<br/>work.</p><p>&gt;&gt;&gt;I think my graphs yesterday showed that.<br/>&gt;<br/>&gt;&gt;Who?  Missed &apos;em.<br/>&gt;<br/>&gt;<a href="http://www.egroups.com/files/tuning/perlich/tenney/tcmp3.jpg">http://www.egroups.com/files/tuning/perlich/tenney/tcmp3.jpg</a>.</p><p>Groovy!  I&apos;ll take a close look tonight.</p><p>-Carl</p></div>